{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sebastiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam, Adadelta, SGD\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPool2D, Dropout, Flatten, Conv1D, GlobalAveragePooling1D, Convolution1D\n",
    "from keras.layers.convolutional import MaxPooling2D, MaxPooling1D\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.utils import class_weight\n",
    "from scipy import signal\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants:\n",
    "SUBSAMPLE = 10  # scales the data by this factor\n",
    "COLUMNS = ['HandStart', 'FirstDigitTouch',\n",
    "        'BothStartLoadPhase', 'LiftOff',\n",
    "        'Replace', 'BothReleased']\n",
    "TRAIN_SUBJECTS = range(9, 13)\n",
    "TEST_SUBJECTS = range(9, 13)\n",
    "N_LABELS = 6\n",
    "\n",
    "# Below are the paths to the data. Please pay attention to the % and * signs, these are needed in the loop.\n",
    "TRAIN_DATA_PATH = 'C:/Users/Sebastiaan/Desktop/Programming/MachineLearning/Datasets/EEG/train/subj%d_series*_data.csv'\n",
    "# TRAIN_DATA_PATH = 'C:/Users/bas/Documents/MachineLearning/train/subj%d_series*_data.csv'\n",
    "\n",
    "EPOCHS = 100\n",
    "WINDOW_SIZE = 2000\n",
    "SPLIT_SIZE = 50\n",
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_data(data_path):\n",
    "    data = pd.read_csv(data_path)\n",
    "    event_path = data_path.replace('_data', '_events')\n",
    "    labels = pd.read_csv(event_path)\n",
    "    clean_data = data.drop(['id'], axis = 1)\n",
    "    labels = labels.drop(['id'], axis = 1)\n",
    "    return clean_data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(x_raw, WINDOW_SIZE, subsample):\n",
    "    x_raw, scaler = scaler_transform(x_raw[::subsample], None)\n",
    "    x_raw = image_mappping(x_raw, WINDOW_SIZE)\n",
    "    return x_raw, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaler_transform(data, scaler):\n",
    "    if scaler == None:\n",
    "        scaler = Normalizer()\n",
    "        return scaler.fit_transform(data), scaler\n",
    "    else:\n",
    "        return scaler.transform(data)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_training_data(train_data_paths):\n",
    "    labels_raw = []\n",
    "    features_raw = []\n",
    "    for data_path in train_data_paths:\n",
    "        data, labels = prepare_training_data(data_path)\n",
    "        features_raw.append(data)\n",
    "        labels_raw.append(labels)\n",
    "    features_raw = pd.concat(features_raw)\n",
    "    labels_raw = pd.concat(labels_raw)\n",
    "    x_train = np.asarray(features_raw.astype(float))\n",
    "    y_train = np.asarray(labels_raw.astype(float))\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_auc_score(predictions, y_test, with_plot):\n",
    "    scores = []\n",
    "    legend_text = []\n",
    "    for i in range(N_LABELS):\n",
    "        fpr, tpr, _  = roc_curve(y_test[:,i], predictions[:,i], 1)\n",
    "        scores.append(roc_auc_score(y_test[:,i], predictions[:,i]))\n",
    "        legend_text.append(COLUMNS[i]+' (area = %.3f)' % (scores[i]))\n",
    "        if with_plot == True:\n",
    "            plt.plot(fpr, tpr)\n",
    "    if with_plot == True:\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curves')\n",
    "        plt.legend(legend_text)\n",
    "        plt.show()\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_metric_auc_score(prediction_total, test_data_total, with_plot):\n",
    "    legend_text = []\n",
    "    counter = 0\n",
    "    for i in range(len(prediction_total)):\n",
    "        fpr, tpr, _  = roc_curve(test_data_total[i], prediction_total[i], pos_label=1)\n",
    "        score = roc_auc_score(test_data_total[i],prediction_total[i])\n",
    "        legend_text.append(COLUMNS[i]+' (area = %.3f)' % (score))\n",
    "        print(COLUMNS[i]+' AUC score = %.3f' % (score))\n",
    "        plt.plot(fpr, tpr)\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curves')\n",
    "        plt.legend(legend_text)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_metric_auc_score(predictions, y_test, with_plot, i):\n",
    "    fpr, tpr, _  = roc_curve(y_test, predictions, 1)\n",
    "    score = roc_auc_score(y_test, predictions)\n",
    "    print(COLUMNS[i]+' AUC score = %.3f' % (score))\n",
    "    if with_plot == True:\n",
    "        plt.plot(fpr, tpr)\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curves')\n",
    "        plt.show()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_auc_scores(prediction_total, test_data_total, subjects, with_plot):\n",
    "    scores = []\n",
    "    for subject in subjects:\n",
    "        score = metric_auc_score(prediction_total[subject-1],\n",
    "                                 test_data_total[subject-1], with_plot)\n",
    "        scores.append(score)\n",
    "        print('Mean AUC Score of Subject %d: %.3f' % \\\n",
    "              (subject, np.mean(score)))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_mappping(x_train, WINDOW_SIZE):\n",
    "    result = []\n",
    "    empty_matrix = np.zeros(np.shape(x_train[0:WINDOW_SIZE]))\n",
    "    for i in range(len(x_train)):\n",
    "        if i-WINDOW_SIZE < 0:\n",
    "            result.append(empty_matrix)\n",
    "        else:\n",
    "            result.append(x_train[i-WINDOW_SIZE:i])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_and_shuffle(labels):\n",
    "    when_task = np.where(labels == 1)\n",
    "    when_no_task = np.where(labels == 0)\n",
    "    when_no_task = when_no_task[0][0:len(when_task[0])]\n",
    "    indices = np.concatenate([when_task[0], when_no_task])\n",
    "    np.random.shuffle(indices)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_set(indices, x_train, y_train):\n",
    "    balance_x = []\n",
    "    balance_y = []\n",
    "    for index in indices:\n",
    "        balance_x.append(x_train[index])\n",
    "        balance_y.append(y_train[index])\n",
    "    return np.array(balance_x), np.array(balance_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_imbalance(x_train, y_train):\n",
    "    indices = resample_and_shuffle(y_train)\n",
    "    balanced_x_train, balanced_y_train = balance_set(indices, x_train, y_train)\n",
    "    return balanced_x_train, balanced_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_sub(x_test, model, split_size, batch_size):\n",
    "    split_size = int(len(x_test) / split_size)\n",
    "    sub_x_test = x_test[1000::batch_size]\n",
    "    batch = []\n",
    "    predictions = np.array([])\n",
    "    for i in range(len(sub_x_test)):\n",
    "        batch.append(sub_x_test[i])\n",
    "        if i+1 == len(sub_x_test):\n",
    "            return np.concatenate([predictions, model.predict(np.array(batch))[:,1]])\n",
    "        elif (i+1) % split_size == 0:\n",
    "            predictions = np.concatenate([predictions, model.predict(np.array(batch))[:,1]])\n",
    "            batch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_cnn(window):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(nb_filter=16, filter_length=3, activation='relu', input_shape=(window, 32)))\n",
    "    model.add(MaxPooling1D(3,2))\n",
    "    model.add(Conv1D(nb_filter=32, filter_length=3, activation='relu'))\n",
    "    model.add(Conv1D(nb_filter=64, filter_length=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(3,2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "#     model.summary()\n",
    "    \n",
    "    optimizer = SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)\n",
    "#     optimizer = Adam(lr=1e-6)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\sebastiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "Train subject 9, class HandStart\n",
      "Train on 3504 samples, validate on 876 samples\n",
      "Epoch 1/100\n",
      "3504/3504 [==============================] - 9s 3ms/step - loss: 0.5175 - acc: 0.8858 - val_loss: 0.4614 - val_acc: 0.9326\n",
      "Epoch 2/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.4465 - acc: 0.9198 - val_loss: 0.4232 - val_acc: 0.9326\n",
      "Epoch 3/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.4126 - acc: 0.9198 - val_loss: 0.3852 - val_acc: 0.9326\n",
      "Epoch 4/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.3699 - acc: 0.9198 - val_loss: 0.3337 - val_acc: 0.9326\n",
      "Epoch 5/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.3059 - acc: 0.9198 - val_loss: 0.2542 - val_acc: 0.9326\n",
      "Epoch 6/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.2218 - acc: 0.9232 - val_loss: 0.1740 - val_acc: 0.9806\n",
      "Epoch 7/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.1582 - acc: 0.9729 - val_loss: 0.1331 - val_acc: 0.9749\n",
      "Epoch 8/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.1285 - acc: 0.9786 - val_loss: 0.1163 - val_acc: 0.9749\n",
      "Epoch 9/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.1148 - acc: 0.9775 - val_loss: 0.1073 - val_acc: 0.9749\n",
      "Epoch 10/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.1077 - acc: 0.9775 - val_loss: 0.1030 - val_acc: 0.9749\n",
      "Epoch 11/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.1041 - acc: 0.9766 - val_loss: 0.1008 - val_acc: 0.9749\n",
      "Epoch 12/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.1011 - acc: 0.9763 - val_loss: 0.0980 - val_acc: 0.9749\n",
      "Epoch 13/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0988 - acc: 0.9763 - val_loss: 0.0968 - val_acc: 0.9749\n",
      "Epoch 14/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0973 - acc: 0.9763 - val_loss: 0.0961 - val_acc: 0.9749\n",
      "Epoch 15/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0965 - acc: 0.9763 - val_loss: 0.0945 - val_acc: 0.9749\n",
      "Epoch 16/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0957 - acc: 0.9763 - val_loss: 0.0937 - val_acc: 0.9749\n",
      "Epoch 17/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0942 - acc: 0.9772 - val_loss: 0.0934 - val_acc: 0.9749\n",
      "Epoch 18/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0934 - acc: 0.9766 - val_loss: 0.0926 - val_acc: 0.9749\n",
      "Epoch 19/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0932 - acc: 0.9766 - val_loss: 0.0916 - val_acc: 0.9749\n",
      "Epoch 20/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0924 - acc: 0.9772 - val_loss: 0.0913 - val_acc: 0.9749\n",
      "Epoch 21/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0918 - acc: 0.9783 - val_loss: 0.0909 - val_acc: 0.9749\n",
      "Epoch 22/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0916 - acc: 0.9775 - val_loss: 0.0901 - val_acc: 0.9749\n",
      "Epoch 23/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0908 - acc: 0.9783 - val_loss: 0.0896 - val_acc: 0.9749\n",
      "Epoch 24/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0903 - acc: 0.9789 - val_loss: 0.0893 - val_acc: 0.9749\n",
      "Epoch 25/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0900 - acc: 0.9792 - val_loss: 0.0888 - val_acc: 0.9749\n",
      "Epoch 26/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0900 - acc: 0.9789 - val_loss: 0.0881 - val_acc: 0.9749\n",
      "Epoch 27/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0893 - acc: 0.9789 - val_loss: 0.0878 - val_acc: 0.9749\n",
      "Epoch 28/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0894 - acc: 0.9789 - val_loss: 0.0874 - val_acc: 0.9749\n",
      "Epoch 29/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0888 - acc: 0.9789 - val_loss: 0.0870 - val_acc: 0.9749\n",
      "Epoch 30/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0883 - acc: 0.9792 - val_loss: 0.0867 - val_acc: 0.9772\n",
      "Epoch 31/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0882 - acc: 0.9792 - val_loss: 0.0865 - val_acc: 0.9806\n",
      "Epoch 32/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0880 - acc: 0.9792 - val_loss: 0.0862 - val_acc: 0.9806\n",
      "Epoch 33/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0877 - acc: 0.9792 - val_loss: 0.0854 - val_acc: 0.9806\n",
      "Epoch 34/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0877 - acc: 0.9792 - val_loss: 0.0856 - val_acc: 0.9806\n",
      "Epoch 35/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0872 - acc: 0.9792 - val_loss: 0.0852 - val_acc: 0.9806\n",
      "Epoch 36/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0872 - acc: 0.9792 - val_loss: 0.0847 - val_acc: 0.9806\n",
      "Epoch 37/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0868 - acc: 0.9792 - val_loss: 0.0845 - val_acc: 0.9806\n",
      "Epoch 38/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0864 - acc: 0.9792 - val_loss: 0.0844 - val_acc: 0.9806\n",
      "Epoch 39/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0860 - acc: 0.9792 - val_loss: 0.0843 - val_acc: 0.9806\n",
      "Epoch 40/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0861 - acc: 0.9792 - val_loss: 0.0841 - val_acc: 0.9806\n",
      "Epoch 41/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0861 - acc: 0.9792 - val_loss: 0.0838 - val_acc: 0.9806\n",
      "Epoch 42/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0863 - acc: 0.9792 - val_loss: 0.0839 - val_acc: 0.9806\n",
      "Epoch 43/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0858 - acc: 0.9792 - val_loss: 0.0834 - val_acc: 0.9806\n",
      "Epoch 44/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0855 - acc: 0.9792 - val_loss: 0.0837 - val_acc: 0.9806\n",
      "Epoch 45/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0846 - acc: 0.9792 - val_loss: 0.0834 - val_acc: 0.9806\n",
      "Epoch 46/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0851 - acc: 0.9792 - val_loss: 0.0831 - val_acc: 0.9806\n",
      "Epoch 47/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0844 - acc: 0.9792 - val_loss: 0.0831 - val_acc: 0.9806\n",
      "Epoch 48/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0851 - acc: 0.9792 - val_loss: 0.0829 - val_acc: 0.9806\n",
      "Epoch 49/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0845 - acc: 0.9792 - val_loss: 0.0828 - val_acc: 0.9806\n",
      "Epoch 50/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0846 - acc: 0.9792 - val_loss: 0.0824 - val_acc: 0.9806\n",
      "Epoch 51/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0841 - acc: 0.9792 - val_loss: 0.0823 - val_acc: 0.9806\n",
      "Epoch 52/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0844 - acc: 0.9792 - val_loss: 0.0822 - val_acc: 0.9806\n",
      "Epoch 53/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0843 - acc: 0.9792 - val_loss: 0.0820 - val_acc: 0.9806\n",
      "Epoch 54/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0839 - acc: 0.9792 - val_loss: 0.0818 - val_acc: 0.9806\n",
      "Epoch 55/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0844 - acc: 0.9792 - val_loss: 0.0817 - val_acc: 0.9806\n",
      "Epoch 56/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0838 - acc: 0.9792 - val_loss: 0.0816 - val_acc: 0.9806\n",
      "Epoch 57/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0837 - acc: 0.9792 - val_loss: 0.0815 - val_acc: 0.9806\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0835 - acc: 0.9792 - val_loss: 0.0815 - val_acc: 0.9806\n",
      "Epoch 59/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0834 - acc: 0.9792 - val_loss: 0.0814 - val_acc: 0.9806\n",
      "Epoch 60/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0836 - acc: 0.9792 - val_loss: 0.0812 - val_acc: 0.9806\n",
      "Epoch 61/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0831 - acc: 0.9792 - val_loss: 0.0812 - val_acc: 0.9806\n",
      "Epoch 62/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0829 - acc: 0.9792 - val_loss: 0.0811 - val_acc: 0.9806\n",
      "Epoch 63/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0830 - acc: 0.9792 - val_loss: 0.0811 - val_acc: 0.9806\n",
      "Epoch 64/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0830 - acc: 0.9792 - val_loss: 0.0809 - val_acc: 0.9806\n",
      "Epoch 65/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0829 - acc: 0.9792 - val_loss: 0.0808 - val_acc: 0.9806\n",
      "Epoch 66/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0831 - acc: 0.9792 - val_loss: 0.0808 - val_acc: 0.9806\n",
      "Epoch 67/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0830 - acc: 0.9792 - val_loss: 0.0807 - val_acc: 0.9806\n",
      "Epoch 68/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0827 - acc: 0.9792 - val_loss: 0.0806 - val_acc: 0.9806\n",
      "Epoch 69/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0823 - acc: 0.9792 - val_loss: 0.0807 - val_acc: 0.9806\n",
      "Epoch 70/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0828 - acc: 0.9792 - val_loss: 0.0805 - val_acc: 0.9806\n",
      "Epoch 71/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0821 - acc: 0.9792 - val_loss: 0.0804 - val_acc: 0.9806\n",
      "Epoch 72/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0823 - acc: 0.9792 - val_loss: 0.0804 - val_acc: 0.9806\n",
      "Epoch 73/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0820 - acc: 0.9792 - val_loss: 0.0802 - val_acc: 0.9806\n",
      "Epoch 74/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0820 - acc: 0.9792 - val_loss: 0.0801 - val_acc: 0.9806\n",
      "Epoch 75/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0819 - acc: 0.9792 - val_loss: 0.0802 - val_acc: 0.9806ss: 0.0774 - acc:\n",
      "Epoch 76/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0821 - acc: 0.9792 - val_loss: 0.0800 - val_acc: 0.9806\n",
      "Epoch 77/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0821 - acc: 0.9792 - val_loss: 0.0801 - val_acc: 0.9806\n",
      "Epoch 78/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0818 - acc: 0.9792 - val_loss: 0.0799 - val_acc: 0.9806\n",
      "Epoch 79/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0819 - acc: 0.9792 - val_loss: 0.0799 - val_acc: 0.9806\n",
      "Epoch 80/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0818 - acc: 0.9792 - val_loss: 0.0797 - val_acc: 0.9806\n",
      "Epoch 81/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0820 - acc: 0.9792 - val_loss: 0.0797 - val_acc: 0.9806\n",
      "Epoch 82/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0815 - acc: 0.9792 - val_loss: 0.0796 - val_acc: 0.9806\n",
      "Epoch 83/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0815 - acc: 0.9792 - val_loss: 0.0797 - val_acc: 0.9806\n",
      "Epoch 84/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0812 - acc: 0.9792 - val_loss: 0.0797 - val_acc: 0.9806\n",
      "Epoch 85/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0814 - acc: 0.9792 - val_loss: 0.0795 - val_acc: 0.9806\n",
      "Epoch 86/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0816 - acc: 0.9792 - val_loss: 0.0795 - val_acc: 0.9806\n",
      "Epoch 87/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0816 - acc: 0.9792 - val_loss: 0.0795 - val_acc: 0.9806\n",
      "Epoch 88/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0812 - acc: 0.9792 - val_loss: 0.0794 - val_acc: 0.9806\n",
      "Epoch 89/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0814 - acc: 0.9792 - val_loss: 0.0794 - val_acc: 0.9806\n",
      "Epoch 90/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0811 - acc: 0.9792 - val_loss: 0.0793 - val_acc: 0.9806\n",
      "Epoch 91/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0811 - acc: 0.9792 - val_loss: 0.0793 - val_acc: 0.9806\n",
      "Epoch 92/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0808 - acc: 0.9792 - val_loss: 0.0792 - val_acc: 0.9806\n",
      "Epoch 93/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0810 - acc: 0.9792 - val_loss: 0.0791 - val_acc: 0.9806\n",
      "Epoch 94/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0812 - acc: 0.9792 - val_loss: 0.0791 - val_acc: 0.9806\n",
      "Epoch 95/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0809 - acc: 0.9795 - val_loss: 0.0790 - val_acc: 0.9806\n",
      "Epoch 96/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0808 - acc: 0.9792 - val_loss: 0.0790 - val_acc: 0.9806\n",
      "Epoch 97/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0806 - acc: 0.9792 - val_loss: 0.0789 - val_acc: 0.9806\n",
      "Epoch 98/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0808 - acc: 0.9792 - val_loss: 0.0789 - val_acc: 0.9806\n",
      "Epoch 99/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0803 - acc: 0.9792 - val_loss: 0.0788 - val_acc: 0.9806\n",
      "Epoch 100/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0809 - acc: 0.9792 - val_loss: 0.0788 - val_acc: 0.9806\n",
      "Train subject 9, class FirstDigitTouch\n",
      "Train on 3504 samples, validate on 876 samples\n",
      "Epoch 1/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.5550 - acc: 0.9074 - val_loss: 0.4888 - val_acc: 0.9178\n",
      "Epoch 2/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.4538 - acc: 0.9235 - val_loss: 0.4384 - val_acc: 0.9178\n",
      "Epoch 3/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.4147 - acc: 0.9235 - val_loss: 0.4010 - val_acc: 0.9178\n",
      "Epoch 4/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.3774 - acc: 0.9235 - val_loss: 0.3610 - val_acc: 0.9178\n",
      "Epoch 5/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.3336 - acc: 0.9235 - val_loss: 0.3104 - val_acc: 0.9178\n",
      "Epoch 6/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.2740 - acc: 0.9364 - val_loss: 0.2408 - val_acc: 0.9737\n",
      "Epoch 7/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.2007 - acc: 0.9772 - val_loss: 0.1742 - val_acc: 0.9703\n",
      "Epoch 8/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.1445 - acc: 0.9777 - val_loss: 0.1370 - val_acc: 0.9703\n",
      "Epoch 9/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.1160 - acc: 0.9775 - val_loss: 0.1212 - val_acc: 0.9703\n",
      "Epoch 10/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.1031 - acc: 0.9775 - val_loss: 0.1147 - val_acc: 0.9703\n",
      "Epoch 11/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0965 - acc: 0.9775 - val_loss: 0.1115 - val_acc: 0.9703\n",
      "Epoch 12/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0922 - acc: 0.9775 - val_loss: 0.1098 - val_acc: 0.9703\n",
      "Epoch 13/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0904 - acc: 0.9775 - val_loss: 0.1091 - val_acc: 0.9703\n",
      "Epoch 14/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0887 - acc: 0.9775 - val_loss: 0.1083 - val_acc: 0.9703\n",
      "Epoch 15/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0872 - acc: 0.9775 - val_loss: 0.1079 - val_acc: 0.9703\n",
      "Epoch 16/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0864 - acc: 0.9783 - val_loss: 0.1070 - val_acc: 0.9703\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0852 - acc: 0.9783 - val_loss: 0.1062 - val_acc: 0.9703\n",
      "Epoch 18/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0844 - acc: 0.9789 - val_loss: 0.1055 - val_acc: 0.9703\n",
      "Epoch 19/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0839 - acc: 0.9809 - val_loss: 0.1049 - val_acc: 0.9703\n",
      "Epoch 20/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0834 - acc: 0.9809 - val_loss: 0.1045 - val_acc: 0.9715\n",
      "Epoch 21/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0827 - acc: 0.9809 - val_loss: 0.1036 - val_acc: 0.9737\n",
      "Epoch 22/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0818 - acc: 0.9809 - val_loss: 0.1035 - val_acc: 0.9737\n",
      "Epoch 23/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0818 - acc: 0.9809 - val_loss: 0.1028 - val_acc: 0.9737\n",
      "Epoch 24/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0808 - acc: 0.9809 - val_loss: 0.1023 - val_acc: 0.9737\n",
      "Epoch 25/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0807 - acc: 0.9809 - val_loss: 0.1015 - val_acc: 0.9737\n",
      "Epoch 26/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0803 - acc: 0.9809 - val_loss: 0.1012 - val_acc: 0.9737\n",
      "Epoch 27/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0801 - acc: 0.9809 - val_loss: 0.1008 - val_acc: 0.9737\n",
      "Epoch 28/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0793 - acc: 0.9809 - val_loss: 0.1010 - val_acc: 0.9737\n",
      "Epoch 29/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0789 - acc: 0.9809 - val_loss: 0.1007 - val_acc: 0.97370.0\n",
      "Epoch 30/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0783 - acc: 0.9809 - val_loss: 0.1000 - val_acc: 0.9737\n",
      "Epoch 31/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0783 - acc: 0.9809 - val_loss: 0.0992 - val_acc: 0.9737\n",
      "Epoch 32/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0780 - acc: 0.9809 - val_loss: 0.0997 - val_acc: 0.9737\n",
      "Epoch 33/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0775 - acc: 0.9809 - val_loss: 0.0988 - val_acc: 0.9737\n",
      "Epoch 34/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0775 - acc: 0.9809 - val_loss: 0.0985 - val_acc: 0.9737\n",
      "Epoch 35/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0769 - acc: 0.9809 - val_loss: 0.0996 - val_acc: 0.9737\n",
      "Epoch 36/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0773 - acc: 0.9809 - val_loss: 0.0988 - val_acc: 0.97370.\n",
      "Epoch 37/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0766 - acc: 0.9809 - val_loss: 0.0982 - val_acc: 0.9737\n",
      "Epoch 38/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0762 - acc: 0.9809 - val_loss: 0.0986 - val_acc: 0.9737\n",
      "Epoch 39/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0763 - acc: 0.9809 - val_loss: 0.0976 - val_acc: 0.9737\n",
      "Epoch 40/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0761 - acc: 0.9809 - val_loss: 0.0979 - val_acc: 0.9737\n",
      "Epoch 41/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0756 - acc: 0.9809 - val_loss: 0.0971 - val_acc: 0.9737\n",
      "Epoch 42/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0754 - acc: 0.9809 - val_loss: 0.0978 - val_acc: 0.9737\n",
      "Epoch 43/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0758 - acc: 0.9809 - val_loss: 0.0971 - val_acc: 0.9737\n",
      "Epoch 44/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0756 - acc: 0.9809 - val_loss: 0.0970 - val_acc: 0.9737\n",
      "Epoch 45/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0755 - acc: 0.9809 - val_loss: 0.0969 - val_acc: 0.9737\n",
      "Epoch 46/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0751 - acc: 0.9812 - val_loss: 0.0966 - val_acc: 0.9737\n",
      "Epoch 47/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0748 - acc: 0.9812 - val_loss: 0.0961 - val_acc: 0.9737\n",
      "Epoch 48/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0747 - acc: 0.9817 - val_loss: 0.0964 - val_acc: 0.9737\n",
      "Epoch 49/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0745 - acc: 0.9820 - val_loss: 0.0965 - val_acc: 0.9737\n",
      "Epoch 50/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0745 - acc: 0.9812 - val_loss: 0.0966 - val_acc: 0.9737\n",
      "Epoch 51/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0745 - acc: 0.9809 - val_loss: 0.0958 - val_acc: 0.9737\n",
      "Epoch 52/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0738 - acc: 0.9823 - val_loss: 0.0953 - val_acc: 0.9737\n",
      "Epoch 53/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0741 - acc: 0.9834 - val_loss: 0.0957 - val_acc: 0.9737\n",
      "Epoch 54/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0738 - acc: 0.9829 - val_loss: 0.0961 - val_acc: 0.9737\n",
      "Epoch 55/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0738 - acc: 0.9823 - val_loss: 0.0952 - val_acc: 0.9737\n",
      "Epoch 56/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0732 - acc: 0.9832 - val_loss: 0.0956 - val_acc: 0.9737\n",
      "Epoch 57/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0737 - acc: 0.9829 - val_loss: 0.0955 - val_acc: 0.9737\n",
      "Epoch 58/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0739 - acc: 0.9826 - val_loss: 0.0947 - val_acc: 0.9760\n",
      "Epoch 59/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0730 - acc: 0.9832 - val_loss: 0.0951 - val_acc: 0.9749\n",
      "Epoch 60/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0733 - acc: 0.9832 - val_loss: 0.0942 - val_acc: 0.9772\n",
      "Epoch 61/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0727 - acc: 0.9837 - val_loss: 0.0948 - val_acc: 0.9760\n",
      "Epoch 62/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0731 - acc: 0.9829 - val_loss: 0.0938 - val_acc: 0.9772\n",
      "Epoch 63/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0728 - acc: 0.9837 - val_loss: 0.0952 - val_acc: 0.9760\n",
      "Epoch 64/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0728 - acc: 0.9834 - val_loss: 0.0952 - val_acc: 0.9760\n",
      "Epoch 65/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0729 - acc: 0.9837 - val_loss: 0.0955 - val_acc: 0.9760\n",
      "Epoch 66/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0726 - acc: 0.9832 - val_loss: 0.0941 - val_acc: 0.9772\n",
      "Epoch 67/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0726 - acc: 0.9837 - val_loss: 0.0934 - val_acc: 0.9772\n",
      "Epoch 68/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0726 - acc: 0.9840 - val_loss: 0.0938 - val_acc: 0.9772\n",
      "Epoch 69/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0726 - acc: 0.9840 - val_loss: 0.0935 - val_acc: 0.9783\n",
      "Epoch 70/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0726 - acc: 0.9837 - val_loss: 0.0943 - val_acc: 0.9772\n",
      "Epoch 71/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0720 - acc: 0.9840 - val_loss: 0.0927 - val_acc: 0.9783\n",
      "Epoch 72/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0726 - acc: 0.9840 - val_loss: 0.0932 - val_acc: 0.9783\n",
      "Epoch 73/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0720 - acc: 0.9840 - val_loss: 0.0935 - val_acc: 0.9783\n",
      "Epoch 74/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0722 - acc: 0.9840 - val_loss: 0.0940 - val_acc: 0.9783\n",
      "Epoch 75/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0723 - acc: 0.9840 - val_loss: 0.0923 - val_acc: 0.9783\n",
      "Epoch 76/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0722 - acc: 0.9837 - val_loss: 0.0922 - val_acc: 0.9783\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0719 - acc: 0.9840 - val_loss: 0.0921 - val_acc: 0.9783\n",
      "Epoch 78/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0723 - acc: 0.9840 - val_loss: 0.0932 - val_acc: 0.9783\n",
      "Epoch 79/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0718 - acc: 0.9840 - val_loss: 0.0927 - val_acc: 0.9783\n",
      "Epoch 80/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0720 - acc: 0.9840 - val_loss: 0.0928 - val_acc: 0.9783\n",
      "Epoch 81/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0717 - acc: 0.9840 - val_loss: 0.0924 - val_acc: 0.9783\n",
      "Epoch 82/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0719 - acc: 0.9840 - val_loss: 0.0926 - val_acc: 0.9783\n",
      "Epoch 83/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0716 - acc: 0.9840 - val_loss: 0.0932 - val_acc: 0.9783\n",
      "Epoch 84/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0716 - acc: 0.9837 - val_loss: 0.0931 - val_acc: 0.9783\n",
      "Epoch 85/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0711 - acc: 0.9840 - val_loss: 0.0916 - val_acc: 0.9783\n",
      "Epoch 86/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0719 - acc: 0.9840 - val_loss: 0.0929 - val_acc: 0.9783\n",
      "Epoch 87/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0714 - acc: 0.9840 - val_loss: 0.0928 - val_acc: 0.9783\n",
      "Epoch 88/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0715 - acc: 0.9840 - val_loss: 0.0929 - val_acc: 0.9783\n",
      "Epoch 89/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0715 - acc: 0.9840 - val_loss: 0.0936 - val_acc: 0.9783\n",
      "Epoch 90/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0710 - acc: 0.9840 - val_loss: 0.0914 - val_acc: 0.9783\n",
      "Epoch 91/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0715 - acc: 0.9840 - val_loss: 0.0922 - val_acc: 0.9783\n",
      "Epoch 92/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0715 - acc: 0.9840 - val_loss: 0.0919 - val_acc: 0.9783\n",
      "Epoch 93/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0714 - acc: 0.9840 - val_loss: 0.0910 - val_acc: 0.9783\n",
      "Epoch 94/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0713 - acc: 0.9840 - val_loss: 0.0919 - val_acc: 0.9783\n",
      "Epoch 95/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0711 - acc: 0.9840 - val_loss: 0.0916 - val_acc: 0.9783\n",
      "Epoch 96/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0715 - acc: 0.9840 - val_loss: 0.0914 - val_acc: 0.9783\n",
      "Epoch 97/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0706 - acc: 0.9840 - val_loss: 0.0932 - val_acc: 0.9783\n",
      "Epoch 98/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0709 - acc: 0.9840 - val_loss: 0.0924 - val_acc: 0.9783\n",
      "Epoch 99/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0707 - acc: 0.9840 - val_loss: 0.0914 - val_acc: 0.9783\n",
      "Epoch 100/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0712 - acc: 0.9840 - val_loss: 0.0920 - val_acc: 0.9783\n",
      "Train subject 9, class BothStartLoadPhase\n",
      "Train on 3504 samples, validate on 876 samples\n",
      "Epoch 1/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.6117 - acc: 0.9088 - val_loss: 0.5501 - val_acc: 0.9304\n",
      "Epoch 2/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.4990 - acc: 0.9204 - val_loss: 0.4587 - val_acc: 0.9304\n",
      "Epoch 3/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.4348 - acc: 0.9204 - val_loss: 0.4041 - val_acc: 0.9304\n",
      "Epoch 4/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.3938 - acc: 0.9204 - val_loss: 0.3617 - val_acc: 0.9304\n",
      "Epoch 5/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.3477 - acc: 0.9204 - val_loss: 0.3055 - val_acc: 0.9304\n",
      "Epoch 6/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.2779 - acc: 0.9218 - val_loss: 0.2253 - val_acc: 0.9783\n",
      "Epoch 7/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.1957 - acc: 0.9760 - val_loss: 0.1579 - val_acc: 0.9760\n",
      "Epoch 8/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.1414 - acc: 0.9780 - val_loss: 0.1236 - val_acc: 0.9760\n",
      "Epoch 9/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.1163 - acc: 0.9766 - val_loss: 0.1099 - val_acc: 0.9760\n",
      "Epoch 10/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.1051 - acc: 0.9760 - val_loss: 0.1028 - val_acc: 0.9760\n",
      "Epoch 11/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0998 - acc: 0.9763 - val_loss: 0.0991 - val_acc: 0.9760\n",
      "Epoch 12/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0969 - acc: 0.9760 - val_loss: 0.0975 - val_acc: 0.9760\n",
      "Epoch 13/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0949 - acc: 0.9766 - val_loss: 0.0962 - val_acc: 0.9760TA: 0s - loss: 0.0951 -\n",
      "Epoch 14/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0936 - acc: 0.9763 - val_loss: 0.0952 - val_acc: 0.9760\n",
      "Epoch 15/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0929 - acc: 0.9760 - val_loss: 0.0945 - val_acc: 0.9760\n",
      "Epoch 16/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0918 - acc: 0.9772 - val_loss: 0.0934 - val_acc: 0.9760\n",
      "Epoch 17/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0910 - acc: 0.9789 - val_loss: 0.0931 - val_acc: 0.9760\n",
      "Epoch 18/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0908 - acc: 0.9780 - val_loss: 0.0925 - val_acc: 0.9760\n",
      "Epoch 19/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0901 - acc: 0.9786 - val_loss: 0.0917 - val_acc: 0.9760\n",
      "Epoch 20/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0896 - acc: 0.9792 - val_loss: 0.0921 - val_acc: 0.9760\n",
      "Epoch 21/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0892 - acc: 0.9792 - val_loss: 0.0915 - val_acc: 0.9760\n",
      "Epoch 22/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0888 - acc: 0.9789 - val_loss: 0.0912 - val_acc: 0.9760\n",
      "Epoch 23/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0881 - acc: 0.9795 - val_loss: 0.0902 - val_acc: 0.9783\n",
      "Epoch 24/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0880 - acc: 0.9797 - val_loss: 0.0903 - val_acc: 0.9760\n",
      "Epoch 25/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0873 - acc: 0.9797 - val_loss: 0.0902 - val_acc: 0.9760\n",
      "Epoch 26/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0872 - acc: 0.9795 - val_loss: 0.0900 - val_acc: 0.9772\n",
      "Epoch 27/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0871 - acc: 0.9797 - val_loss: 0.0892 - val_acc: 0.9783\n",
      "Epoch 28/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0865 - acc: 0.9797 - val_loss: 0.0896 - val_acc: 0.9783\n",
      "Epoch 29/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0865 - acc: 0.9795 - val_loss: 0.0890 - val_acc: 0.9783\n",
      "Epoch 30/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0854 - acc: 0.9797 - val_loss: 0.0887 - val_acc: 0.9783\n",
      "Epoch 31/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0856 - acc: 0.9797 - val_loss: 0.0881 - val_acc: 0.9783\n",
      "Epoch 32/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0855 - acc: 0.9797 - val_loss: 0.0881 - val_acc: 0.9783\n",
      "Epoch 33/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0854 - acc: 0.9797 - val_loss: 0.0878 - val_acc: 0.9783\n",
      "Epoch 34/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0847 - acc: 0.9797 - val_loss: 0.0880 - val_acc: 0.9783\n",
      "Epoch 35/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0845 - acc: 0.9797 - val_loss: 0.0878 - val_acc: 0.9783\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0843 - acc: 0.9797 - val_loss: 0.0877 - val_acc: 0.9783\n",
      "Epoch 37/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0846 - acc: 0.9797 - val_loss: 0.0868 - val_acc: 0.9783\n",
      "Epoch 38/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0841 - acc: 0.9797 - val_loss: 0.0869 - val_acc: 0.9783\n",
      "Epoch 39/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0838 - acc: 0.9797 - val_loss: 0.0864 - val_acc: 0.9783\n",
      "Epoch 40/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0840 - acc: 0.9797 - val_loss: 0.0861 - val_acc: 0.9783\n",
      "Epoch 41/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0828 - acc: 0.9797 - val_loss: 0.0857 - val_acc: 0.9783\n",
      "Epoch 42/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0832 - acc: 0.9797 - val_loss: 0.0865 - val_acc: 0.9783\n",
      "Epoch 43/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0828 - acc: 0.9797 - val_loss: 0.0863 - val_acc: 0.9783\n",
      "Epoch 44/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0822 - acc: 0.9797 - val_loss: 0.0865 - val_acc: 0.9783\n",
      "Epoch 45/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0822 - acc: 0.9797 - val_loss: 0.0853 - val_acc: 0.9783\n",
      "Epoch 46/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0821 - acc: 0.9797 - val_loss: 0.0861 - val_acc: 0.9783\n",
      "Epoch 47/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0821 - acc: 0.9797 - val_loss: 0.0863 - val_acc: 0.9783\n",
      "Epoch 48/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0820 - acc: 0.9797 - val_loss: 0.0855 - val_acc: 0.9783\n",
      "Epoch 49/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0818 - acc: 0.9797 - val_loss: 0.0861 - val_acc: 0.9783\n",
      "Epoch 50/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0816 - acc: 0.9797 - val_loss: 0.0854 - val_acc: 0.9783\n",
      "Epoch 51/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0819 - acc: 0.9797 - val_loss: 0.0850 - val_acc: 0.9783\n",
      "Epoch 52/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0814 - acc: 0.9797 - val_loss: 0.0848 - val_acc: 0.9783\n",
      "Epoch 53/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0812 - acc: 0.9797 - val_loss: 0.0844 - val_acc: 0.9783\n",
      "Epoch 54/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0812 - acc: 0.9797 - val_loss: 0.0849 - val_acc: 0.9783\n",
      "Epoch 55/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0808 - acc: 0.9797 - val_loss: 0.0836 - val_acc: 0.9783\n",
      "Epoch 56/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0809 - acc: 0.9797 - val_loss: 0.0849 - val_acc: 0.9783\n",
      "Epoch 57/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0811 - acc: 0.9797 - val_loss: 0.0850 - val_acc: 0.9783\n",
      "Epoch 58/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0804 - acc: 0.9797 - val_loss: 0.0847 - val_acc: 0.9783\n",
      "Epoch 59/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0800 - acc: 0.9797 - val_loss: 0.0844 - val_acc: 0.9783\n",
      "Epoch 60/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0804 - acc: 0.9797 - val_loss: 0.0840 - val_acc: 0.9783\n",
      "Epoch 61/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0800 - acc: 0.9797 - val_loss: 0.0842 - val_acc: 0.9783\n",
      "Epoch 62/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0803 - acc: 0.9797 - val_loss: 0.0843 - val_acc: 0.9783\n",
      "Epoch 63/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0799 - acc: 0.9797 - val_loss: 0.0844 - val_acc: 0.9783\n",
      "Epoch 64/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0800 - acc: 0.9797 - val_loss: 0.0833 - val_acc: 0.9783\n",
      "Epoch 65/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0799 - acc: 0.9797 - val_loss: 0.0838 - val_acc: 0.9783\n",
      "Epoch 66/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0791 - acc: 0.9797 - val_loss: 0.0827 - val_acc: 0.9783\n",
      "Epoch 67/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0790 - acc: 0.9800 - val_loss: 0.0828 - val_acc: 0.9783\n",
      "Epoch 68/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0793 - acc: 0.9797 - val_loss: 0.0833 - val_acc: 0.9783\n",
      "Epoch 69/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0791 - acc: 0.9800 - val_loss: 0.0837 - val_acc: 0.9783\n",
      "Epoch 70/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0786 - acc: 0.9797 - val_loss: 0.0849 - val_acc: 0.9783\n",
      "Epoch 71/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0788 - acc: 0.9797 - val_loss: 0.0844 - val_acc: 0.9783\n",
      "Epoch 72/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0790 - acc: 0.9800 - val_loss: 0.0825 - val_acc: 0.9783\n",
      "Epoch 73/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0788 - acc: 0.9797 - val_loss: 0.0836 - val_acc: 0.9783\n",
      "Epoch 74/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0784 - acc: 0.9803 - val_loss: 0.0823 - val_acc: 0.9783\n",
      "Epoch 75/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0784 - acc: 0.9809 - val_loss: 0.0826 - val_acc: 0.9783\n",
      "Epoch 76/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0791 - acc: 0.9806 - val_loss: 0.0834 - val_acc: 0.9783\n",
      "Epoch 77/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0787 - acc: 0.9803 - val_loss: 0.0830 - val_acc: 0.9783\n",
      "Epoch 78/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0780 - acc: 0.9817 - val_loss: 0.0831 - val_acc: 0.9783\n",
      "Epoch 79/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0783 - acc: 0.9800 - val_loss: 0.0831 - val_acc: 0.9783\n",
      "Epoch 80/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0783 - acc: 0.9803 - val_loss: 0.0827 - val_acc: 0.9783\n",
      "Epoch 81/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0785 - acc: 0.9800 - val_loss: 0.0824 - val_acc: 0.9783\n",
      "Epoch 82/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0780 - acc: 0.9809 - val_loss: 0.0823 - val_acc: 0.9783\n",
      "Epoch 83/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0779 - acc: 0.9814 - val_loss: 0.0828 - val_acc: 0.9783\n",
      "Epoch 84/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0777 - acc: 0.9809 - val_loss: 0.0818 - val_acc: 0.9783\n",
      "Epoch 85/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0781 - acc: 0.9817 - val_loss: 0.0818 - val_acc: 0.9783\n",
      "Epoch 86/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0779 - acc: 0.9817 - val_loss: 0.0829 - val_acc: 0.9783\n",
      "Epoch 87/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0779 - acc: 0.9809 - val_loss: 0.0817 - val_acc: 0.9783\n",
      "Epoch 88/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0773 - acc: 0.9809 - val_loss: 0.0820 - val_acc: 0.9783\n",
      "Epoch 89/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0776 - acc: 0.9814 - val_loss: 0.0819 - val_acc: 0.9783\n",
      "Epoch 90/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0771 - acc: 0.9826 - val_loss: 0.0814 - val_acc: 0.9783\n",
      "Epoch 91/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0772 - acc: 0.9820 - val_loss: 0.0808 - val_acc: 0.9795\n",
      "Epoch 92/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0766 - acc: 0.9823 - val_loss: 0.0827 - val_acc: 0.9783\n",
      "Epoch 93/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0769 - acc: 0.9823 - val_loss: 0.0821 - val_acc: 0.9783\n",
      "Epoch 94/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0771 - acc: 0.9826 - val_loss: 0.0825 - val_acc: 0.9783\n",
      "Epoch 95/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0772 - acc: 0.9817 - val_loss: 0.0816 - val_acc: 0.9783\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0770 - acc: 0.9826 - val_loss: 0.0816 - val_acc: 0.9783\n",
      "Epoch 97/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0772 - acc: 0.9832 - val_loss: 0.0815 - val_acc: 0.9783\n",
      "Epoch 98/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0771 - acc: 0.9829 - val_loss: 0.0818 - val_acc: 0.9783\n",
      "Epoch 99/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0770 - acc: 0.9826 - val_loss: 0.0821 - val_acc: 0.9783\n",
      "Epoch 100/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0766 - acc: 0.9826 - val_loss: 0.0822 - val_acc: 0.9783\n",
      "Train subject 9, class LiftOff\n",
      "Train on 3504 samples, validate on 876 samples\n",
      "Epoch 1/100\n",
      "3504/3504 [==============================] - 7s 2ms/step - loss: 0.5707 - acc: 0.9025 - val_loss: 0.4839 - val_acc: 0.9338\n",
      "Epoch 2/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.4578 - acc: 0.9195 - val_loss: 0.4162 - val_acc: 0.9338\n",
      "Epoch 3/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.4113 - acc: 0.9195 - val_loss: 0.3710 - val_acc: 0.9338\n",
      "Epoch 4/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.3647 - acc: 0.9195 - val_loss: 0.3177 - val_acc: 0.9338\n",
      "Epoch 5/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.3036 - acc: 0.9198 - val_loss: 0.2459 - val_acc: 0.9840s - loss: 0.3044 - acc: 0.91\n",
      "Epoch 6/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.2283 - acc: 0.9612 - val_loss: 0.1708 - val_acc: 0.9840\n",
      "Epoch 7/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.1660 - acc: 0.9783 - val_loss: 0.1224 - val_acc: 0.9840\n",
      "Epoch 8/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.1315 - acc: 0.9780 - val_loss: 0.0979 - val_acc: 0.9829\n",
      "Epoch 9/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.1145 - acc: 0.9772 - val_loss: 0.0860 - val_acc: 0.9829\n",
      "Epoch 10/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.1063 - acc: 0.9775 - val_loss: 0.0798 - val_acc: 0.9829\n",
      "Epoch 11/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.1019 - acc: 0.9769 - val_loss: 0.0762 - val_acc: 0.9829\n",
      "Epoch 12/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0988 - acc: 0.9772 - val_loss: 0.0740 - val_acc: 0.9840\n",
      "Epoch 13/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0970 - acc: 0.9775 - val_loss: 0.0725 - val_acc: 0.9840\n",
      "Epoch 14/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0954 - acc: 0.9780 - val_loss: 0.0715 - val_acc: 0.9840\n",
      "Epoch 15/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0948 - acc: 0.9783 - val_loss: 0.0706 - val_acc: 0.9840\n",
      "Epoch 16/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0941 - acc: 0.9783 - val_loss: 0.0700 - val_acc: 0.9840\n",
      "Epoch 17/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0935 - acc: 0.9783 - val_loss: 0.0695 - val_acc: 0.9840\n",
      "Epoch 18/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0919 - acc: 0.9780 - val_loss: 0.0690 - val_acc: 0.9840\n",
      "Epoch 19/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0921 - acc: 0.9783 - val_loss: 0.0686 - val_acc: 0.9840\n",
      "Epoch 20/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0905 - acc: 0.9783 - val_loss: 0.0683 - val_acc: 0.9840\n",
      "Epoch 21/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0906 - acc: 0.9783 - val_loss: 0.0679 - val_acc: 0.9840\n",
      "Epoch 22/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0901 - acc: 0.9783 - val_loss: 0.0676 - val_acc: 0.9840\n",
      "Epoch 23/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0900 - acc: 0.9783 - val_loss: 0.0674 - val_acc: 0.9840\n",
      "Epoch 24/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0893 - acc: 0.9783 - val_loss: 0.0671 - val_acc: 0.9840\n",
      "Epoch 25/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0895 - acc: 0.9783 - val_loss: 0.0669 - val_acc: 0.9840\n",
      "Epoch 26/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0889 - acc: 0.9783 - val_loss: 0.0667 - val_acc: 0.9840\n",
      "Epoch 27/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0888 - acc: 0.9783 - val_loss: 0.0665 - val_acc: 0.9840\n",
      "Epoch 28/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0880 - acc: 0.9783 - val_loss: 0.0663 - val_acc: 0.9840\n",
      "Epoch 29/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0881 - acc: 0.9783 - val_loss: 0.0660 - val_acc: 0.9840\n",
      "Epoch 30/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0876 - acc: 0.9783 - val_loss: 0.0659 - val_acc: 0.9840\n",
      "Epoch 31/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0875 - acc: 0.9783 - val_loss: 0.0656 - val_acc: 0.9840\n",
      "Epoch 32/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0871 - acc: 0.9783 - val_loss: 0.0654 - val_acc: 0.9840\n",
      "Epoch 33/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0863 - acc: 0.9783 - val_loss: 0.0653 - val_acc: 0.9840\n",
      "Epoch 34/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0860 - acc: 0.9783 - val_loss: 0.0652 - val_acc: 0.9840\n",
      "Epoch 35/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0868 - acc: 0.9783 - val_loss: 0.0649 - val_acc: 0.9840\n",
      "Epoch 36/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0856 - acc: 0.9786 - val_loss: 0.0649 - val_acc: 0.9840\n",
      "Epoch 37/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0860 - acc: 0.9783 - val_loss: 0.0647 - val_acc: 0.9840\n",
      "Epoch 38/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0857 - acc: 0.9783 - val_loss: 0.0645 - val_acc: 0.9840\n",
      "Epoch 39/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0857 - acc: 0.9783 - val_loss: 0.0644 - val_acc: 0.9840\n",
      "Epoch 40/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0849 - acc: 0.9789 - val_loss: 0.0644 - val_acc: 0.9840\n",
      "Epoch 41/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0850 - acc: 0.9783 - val_loss: 0.0642 - val_acc: 0.9840\n",
      "Epoch 42/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0849 - acc: 0.9783 - val_loss: 0.0640 - val_acc: 0.9840\n",
      "Epoch 43/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0849 - acc: 0.9783 - val_loss: 0.0639 - val_acc: 0.9840\n",
      "Epoch 44/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0849 - acc: 0.9783 - val_loss: 0.0637 - val_acc: 0.9840\n",
      "Epoch 45/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0844 - acc: 0.9786 - val_loss: 0.0636 - val_acc: 0.9840\n",
      "Epoch 46/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0845 - acc: 0.9786 - val_loss: 0.0635 - val_acc: 0.9840\n",
      "Epoch 47/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0838 - acc: 0.9783 - val_loss: 0.0634 - val_acc: 0.9840\n",
      "Epoch 48/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0841 - acc: 0.9783 - val_loss: 0.0634 - val_acc: 0.9840\n",
      "Epoch 49/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0839 - acc: 0.9795 - val_loss: 0.0633 - val_acc: 0.9840\n",
      "Epoch 50/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0840 - acc: 0.9783 - val_loss: 0.0631 - val_acc: 0.9840\n",
      "Epoch 51/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0836 - acc: 0.9786 - val_loss: 0.0630 - val_acc: 0.9840\n",
      "Epoch 52/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0837 - acc: 0.9789 - val_loss: 0.0629 - val_acc: 0.9840\n",
      "Epoch 53/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0833 - acc: 0.9789 - val_loss: 0.0628 - val_acc: 0.9840\n",
      "Epoch 54/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0833 - acc: 0.9789 - val_loss: 0.0626 - val_acc: 0.9840\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0830 - acc: 0.9800 - val_loss: 0.0626 - val_acc: 0.9840\n",
      "Epoch 56/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0828 - acc: 0.9789 - val_loss: 0.0625 - val_acc: 0.9840\n",
      "Epoch 57/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0828 - acc: 0.9792 - val_loss: 0.0624 - val_acc: 0.9840\n",
      "Epoch 58/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0826 - acc: 0.9792 - val_loss: 0.0622 - val_acc: 0.9840\n",
      "Epoch 59/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0826 - acc: 0.9795 - val_loss: 0.0621 - val_acc: 0.9840\n",
      "Epoch 60/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0822 - acc: 0.9797 - val_loss: 0.0621 - val_acc: 0.9840\n",
      "Epoch 61/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0823 - acc: 0.9795 - val_loss: 0.0620 - val_acc: 0.9840\n",
      "Epoch 62/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0824 - acc: 0.9797 - val_loss: 0.0619 - val_acc: 0.9840\n",
      "Epoch 63/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0823 - acc: 0.9800 - val_loss: 0.0618 - val_acc: 0.9840\n",
      "Epoch 64/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0825 - acc: 0.9797 - val_loss: 0.0617 - val_acc: 0.9840\n",
      "Epoch 65/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0818 - acc: 0.9809 - val_loss: 0.0617 - val_acc: 0.9840\n",
      "Epoch 66/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0819 - acc: 0.9812 - val_loss: 0.0617 - val_acc: 0.9840\n",
      "Epoch 67/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0820 - acc: 0.9800 - val_loss: 0.0615 - val_acc: 0.9840\n",
      "Epoch 68/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0816 - acc: 0.9800 - val_loss: 0.0615 - val_acc: 0.9840\n",
      "Epoch 69/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0817 - acc: 0.9797 - val_loss: 0.0615 - val_acc: 0.9874\n",
      "Epoch 70/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0813 - acc: 0.9806 - val_loss: 0.0614 - val_acc: 0.9874\n",
      "Epoch 71/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0819 - acc: 0.9809 - val_loss: 0.0612 - val_acc: 0.9874\n",
      "Epoch 72/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0814 - acc: 0.9809 - val_loss: 0.0612 - val_acc: 0.9874\n",
      "Epoch 73/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0814 - acc: 0.9809 - val_loss: 0.0611 - val_acc: 0.9840\n",
      "Epoch 74/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0817 - acc: 0.9803 - val_loss: 0.0611 - val_acc: 0.9874\n",
      "Epoch 75/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0813 - acc: 0.9809 - val_loss: 0.0610 - val_acc: 0.9874\n",
      "Epoch 76/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0811 - acc: 0.9812 - val_loss: 0.0610 - val_acc: 0.9874\n",
      "Epoch 77/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0812 - acc: 0.9806 - val_loss: 0.0609 - val_acc: 0.9874 acc: 0.\n",
      "Epoch 78/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0809 - acc: 0.9817 - val_loss: 0.0608 - val_acc: 0.9874\n",
      "Epoch 79/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0811 - acc: 0.9809 - val_loss: 0.0608 - val_acc: 0.9874\n",
      "Epoch 80/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0805 - acc: 0.9812 - val_loss: 0.0607 - val_acc: 0.9874\n",
      "Epoch 81/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0803 - acc: 0.9814 - val_loss: 0.0607 - val_acc: 0.9852\n",
      "Epoch 82/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0806 - acc: 0.9817 - val_loss: 0.0606 - val_acc: 0.9874\n",
      "Epoch 83/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0809 - acc: 0.9814 - val_loss: 0.0605 - val_acc: 0.9874\n",
      "Epoch 84/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0805 - acc: 0.9806 - val_loss: 0.0606 - val_acc: 0.9874\n",
      "Epoch 85/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0809 - acc: 0.9817 - val_loss: 0.0604 - val_acc: 0.9874\n",
      "Epoch 86/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0803 - acc: 0.9817 - val_loss: 0.0605 - val_acc: 0.9874\n",
      "Epoch 87/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0812 - acc: 0.9812 - val_loss: 0.0603 - val_acc: 0.9874\n",
      "Epoch 88/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0804 - acc: 0.9814 - val_loss: 0.0603 - val_acc: 0.9874\n",
      "Epoch 89/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0803 - acc: 0.9817 - val_loss: 0.0603 - val_acc: 0.9874\n",
      "Epoch 90/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0803 - acc: 0.9812 - val_loss: 0.0602 - val_acc: 0.9874\n",
      "Epoch 91/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0803 - acc: 0.9817 - val_loss: 0.0602 - val_acc: 0.9874\n",
      "Epoch 92/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0804 - acc: 0.9812 - val_loss: 0.0602 - val_acc: 0.9874\n",
      "Epoch 93/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0801 - acc: 0.9814 - val_loss: 0.0601 - val_acc: 0.9874\n",
      "Epoch 94/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0804 - acc: 0.9817 - val_loss: 0.0601 - val_acc: 0.9874\n",
      "Epoch 95/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0801 - acc: 0.9817 - val_loss: 0.0601 - val_acc: 0.9874\n",
      "Epoch 96/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0800 - acc: 0.9812 - val_loss: 0.0600 - val_acc: 0.9874\n",
      "Epoch 97/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0799 - acc: 0.9817 - val_loss: 0.0600 - val_acc: 0.9874\n",
      "Epoch 98/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0801 - acc: 0.9817 - val_loss: 0.0600 - val_acc: 0.9874\n",
      "Epoch 99/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0799 - acc: 0.9814 - val_loss: 0.0600 - val_acc: 0.9874\n",
      "Epoch 100/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0800 - acc: 0.9817 - val_loss: 0.0600 - val_acc: 0.9874\n",
      "Train subject 9, class Replace\n",
      "Train on 3504 samples, validate on 876 samples\n",
      "Epoch 1/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.6006 - acc: 0.8483 - val_loss: 0.5497 - val_acc: 0.9304\n",
      "Epoch 2/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.4923 - acc: 0.9289 - val_loss: 0.4931 - val_acc: 0.9304\n",
      "Epoch 3/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.4524 - acc: 0.9289 - val_loss: 0.4606 - val_acc: 0.9304\n",
      "Epoch 4/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.4246 - acc: 0.9289 - val_loss: 0.4336 - val_acc: 0.9304\n",
      "Epoch 5/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.4003 - acc: 0.9289 - val_loss: 0.4061 - val_acc: 0.9304\n",
      "Epoch 6/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.3743 - acc: 0.9289 - val_loss: 0.3770 - val_acc: 0.9304\n",
      "Epoch 7/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.3466 - acc: 0.9289 - val_loss: 0.3450 - val_acc: 0.9304\n",
      "Epoch 8/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.3149 - acc: 0.9289 - val_loss: 0.3051 - val_acc: 0.9304\n",
      "Epoch 9/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.2728 - acc: 0.9289 - val_loss: 0.2509 - val_acc: 0.9772\n",
      "Epoch 10/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.2188 - acc: 0.9469 - val_loss: 0.1864 - val_acc: 0.9874\n",
      "Epoch 11/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.1667 - acc: 0.9780 - val_loss: 0.1345 - val_acc: 0.9874\n",
      "Epoch 12/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.1319 - acc: 0.9775 - val_loss: 0.1037 - val_acc: 0.9874\n",
      "Epoch 13/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.1133 - acc: 0.9775 - val_loss: 0.0871 - val_acc: 0.9874\n",
      "Epoch 14/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.1040 - acc: 0.9775 - val_loss: 0.0776 - val_acc: 0.9874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0992 - acc: 0.9775 - val_loss: 0.0720 - val_acc: 0.9874\n",
      "Epoch 16/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0961 - acc: 0.9775 - val_loss: 0.0685 - val_acc: 0.9874\n",
      "Epoch 17/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0938 - acc: 0.9775 - val_loss: 0.0663 - val_acc: 0.9874\n",
      "Epoch 18/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0930 - acc: 0.9775 - val_loss: 0.0646 - val_acc: 0.9874\n",
      "Epoch 19/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0925 - acc: 0.9775 - val_loss: 0.0634 - val_acc: 0.9874\n",
      "Epoch 20/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0916 - acc: 0.9775 - val_loss: 0.0623 - val_acc: 0.9874\n",
      "Epoch 21/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0910 - acc: 0.9775 - val_loss: 0.0616 - val_acc: 0.9874\n",
      "Epoch 22/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0908 - acc: 0.9775 - val_loss: 0.0610 - val_acc: 0.9874\n",
      "Epoch 23/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0904 - acc: 0.9775 - val_loss: 0.0604 - val_acc: 0.9874\n",
      "Epoch 24/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0895 - acc: 0.9775 - val_loss: 0.0599 - val_acc: 0.9874\n",
      "Epoch 25/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0894 - acc: 0.9775 - val_loss: 0.0594 - val_acc: 0.9874\n",
      "Epoch 26/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0897 - acc: 0.9775 - val_loss: 0.0590 - val_acc: 0.9874\n",
      "Epoch 27/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0892 - acc: 0.9775 - val_loss: 0.0588 - val_acc: 0.9874\n",
      "Epoch 28/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0883 - acc: 0.9775 - val_loss: 0.0584 - val_acc: 0.9874\n",
      "Epoch 29/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0887 - acc: 0.9775 - val_loss: 0.0581 - val_acc: 0.9874\n",
      "Epoch 30/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0882 - acc: 0.9775 - val_loss: 0.0580 - val_acc: 0.9874\n",
      "Epoch 31/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0883 - acc: 0.9775 - val_loss: 0.0577 - val_acc: 0.9874\n",
      "Epoch 32/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0876 - acc: 0.9777 - val_loss: 0.0574 - val_acc: 0.9874\n",
      "Epoch 33/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0876 - acc: 0.9775 - val_loss: 0.0573 - val_acc: 0.9874\n",
      "Epoch 34/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0871 - acc: 0.9775 - val_loss: 0.0571 - val_acc: 0.9874\n",
      "Epoch 35/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0872 - acc: 0.9775 - val_loss: 0.0567 - val_acc: 0.9874\n",
      "Epoch 36/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0870 - acc: 0.9775 - val_loss: 0.0566 - val_acc: 0.9874\n",
      "Epoch 37/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0865 - acc: 0.9775 - val_loss: 0.0564 - val_acc: 0.9874\n",
      "Epoch 38/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0869 - acc: 0.9775 - val_loss: 0.0563 - val_acc: 0.9874\n",
      "Epoch 39/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0866 - acc: 0.9777 - val_loss: 0.0562 - val_acc: 0.9874\n",
      "Epoch 40/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0871 - acc: 0.9775 - val_loss: 0.0562 - val_acc: 0.9874\n",
      "Epoch 41/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0864 - acc: 0.9783 - val_loss: 0.0559 - val_acc: 0.9874\n",
      "Epoch 42/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0863 - acc: 0.9780 - val_loss: 0.0556 - val_acc: 0.9874\n",
      "Epoch 43/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0862 - acc: 0.9786 - val_loss: 0.0555 - val_acc: 0.9874\n",
      "Epoch 44/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0858 - acc: 0.9777 - val_loss: 0.0555 - val_acc: 0.9874\n",
      "Epoch 45/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0862 - acc: 0.9780 - val_loss: 0.0552 - val_acc: 0.9874\n",
      "Epoch 46/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0857 - acc: 0.9777 - val_loss: 0.0555 - val_acc: 0.9874\n",
      "Epoch 47/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0856 - acc: 0.9809 - val_loss: 0.0549 - val_acc: 0.9874\n",
      "Epoch 48/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0855 - acc: 0.9777 - val_loss: 0.0548 - val_acc: 0.9874\n",
      "Epoch 49/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0855 - acc: 0.9792 - val_loss: 0.0547 - val_acc: 0.9874\n",
      "Epoch 50/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0852 - acc: 0.9795 - val_loss: 0.0546 - val_acc: 0.9874\n",
      "Epoch 51/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0853 - acc: 0.9797 - val_loss: 0.0545 - val_acc: 0.9874\n",
      "Epoch 52/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0853 - acc: 0.9789 - val_loss: 0.0546 - val_acc: 0.9874\n",
      "Epoch 53/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0848 - acc: 0.9797 - val_loss: 0.0546 - val_acc: 0.9874\n",
      "Epoch 54/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0852 - acc: 0.9792 - val_loss: 0.0542 - val_acc: 0.9874\n",
      "Epoch 55/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0849 - acc: 0.9795 - val_loss: 0.0543 - val_acc: 0.9874\n",
      "Epoch 56/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0849 - acc: 0.9800 - val_loss: 0.0540 - val_acc: 0.9874\n",
      "Epoch 57/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0841 - acc: 0.9800 - val_loss: 0.0541 - val_acc: 0.9874\n",
      "Epoch 58/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0845 - acc: 0.9803 - val_loss: 0.0539 - val_acc: 0.9874\n",
      "Epoch 59/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0848 - acc: 0.9800 - val_loss: 0.0539 - val_acc: 0.9897\n",
      "Epoch 60/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0842 - acc: 0.9809 - val_loss: 0.0537 - val_acc: 0.9874\n",
      "Epoch 61/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0845 - acc: 0.9803 - val_loss: 0.0536 - val_acc: 0.9886\n",
      "Epoch 62/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0841 - acc: 0.9809 - val_loss: 0.0534 - val_acc: 0.9874\n",
      "Epoch 63/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0840 - acc: 0.9806 - val_loss: 0.0535 - val_acc: 0.9874\n",
      "Epoch 64/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0837 - acc: 0.9806 - val_loss: 0.0531 - val_acc: 0.9874\n",
      "Epoch 65/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0842 - acc: 0.9797 - val_loss: 0.0532 - val_acc: 0.9897\n",
      "Epoch 66/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0844 - acc: 0.9800 - val_loss: 0.0533 - val_acc: 0.9909\n",
      "Epoch 67/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0840 - acc: 0.9806 - val_loss: 0.0532 - val_acc: 0.9909\n",
      "Epoch 68/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0842 - acc: 0.9809 - val_loss: 0.0530 - val_acc: 0.9909\n",
      "Epoch 69/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0837 - acc: 0.9809 - val_loss: 0.0529 - val_acc: 0.9909\n",
      "Epoch 70/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0840 - acc: 0.9809 - val_loss: 0.0529 - val_acc: 0.9909\n",
      "Epoch 71/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0839 - acc: 0.9809 - val_loss: 0.0529 - val_acc: 0.9909\n",
      "Epoch 72/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0836 - acc: 0.9806 - val_loss: 0.0530 - val_acc: 0.9909\n",
      "Epoch 73/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0840 - acc: 0.9809 - val_loss: 0.0526 - val_acc: 0.9909\n",
      "Epoch 74/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0836 - acc: 0.9806 - val_loss: 0.0526 - val_acc: 0.9909\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0834 - acc: 0.9809 - val_loss: 0.0525 - val_acc: 0.9909\n",
      "Epoch 76/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0834 - acc: 0.9809 - val_loss: 0.0525 - val_acc: 0.9909\n",
      "Epoch 77/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0832 - acc: 0.9809 - val_loss: 0.0523 - val_acc: 0.9909\n",
      "Epoch 78/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0833 - acc: 0.9806 - val_loss: 0.0525 - val_acc: 0.9909\n",
      "Epoch 79/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0836 - acc: 0.9809 - val_loss: 0.0525 - val_acc: 0.9909\n",
      "Epoch 80/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0834 - acc: 0.9809 - val_loss: 0.0522 - val_acc: 0.9909\n",
      "Epoch 81/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0832 - acc: 0.9809 - val_loss: 0.0520 - val_acc: 0.9909\n",
      "Epoch 82/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0831 - acc: 0.9809 - val_loss: 0.0520 - val_acc: 0.9909\n",
      "Epoch 83/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0827 - acc: 0.9809 - val_loss: 0.0519 - val_acc: 0.9909\n",
      "Epoch 84/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0831 - acc: 0.9809 - val_loss: 0.0519 - val_acc: 0.9909\n",
      "Epoch 85/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0826 - acc: 0.9809 - val_loss: 0.0521 - val_acc: 0.9909\n",
      "Epoch 86/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0830 - acc: 0.9809 - val_loss: 0.0521 - val_acc: 0.9909\n",
      "Epoch 87/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0826 - acc: 0.9809 - val_loss: 0.0520 - val_acc: 0.9909\n",
      "Epoch 88/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0825 - acc: 0.9809 - val_loss: 0.0515 - val_acc: 0.9909\n",
      "Epoch 89/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0825 - acc: 0.9809 - val_loss: 0.0518 - val_acc: 0.9909\n",
      "Epoch 90/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0829 - acc: 0.9809 - val_loss: 0.0518 - val_acc: 0.9909\n",
      "Epoch 91/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0823 - acc: 0.9809 - val_loss: 0.0518 - val_acc: 0.9909\n",
      "Epoch 92/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0828 - acc: 0.9809 - val_loss: 0.0515 - val_acc: 0.9909\n",
      "Epoch 93/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0827 - acc: 0.9809 - val_loss: 0.0514 - val_acc: 0.9909\n",
      "Epoch 94/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0826 - acc: 0.9809 - val_loss: 0.0514 - val_acc: 0.9909\n",
      "Epoch 95/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0823 - acc: 0.9809 - val_loss: 0.0516 - val_acc: 0.9909\n",
      "Epoch 96/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0824 - acc: 0.9809 - val_loss: 0.0516 - val_acc: 0.9909\n",
      "Epoch 97/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0822 - acc: 0.9809 - val_loss: 0.0513 - val_acc: 0.9909\n",
      "Epoch 98/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0824 - acc: 0.9809 - val_loss: 0.0512 - val_acc: 0.9909\n",
      "Epoch 99/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0818 - acc: 0.9809 - val_loss: 0.0514 - val_acc: 0.9909\n",
      "Epoch 100/100\n",
      "3504/3504 [==============================] - 5s 1ms/step - loss: 0.0822 - acc: 0.9809 - val_loss: 0.0511 - val_acc: 0.9909\n",
      "Train subject 9, class BothReleased\n",
      "Train on 3504 samples, validate on 876 samples\n",
      "Epoch 1/100\n",
      "3504/3504 [==============================] - 7s 2ms/step - loss: 0.5900 - acc: 0.8780 - val_loss: 0.5313 - val_acc: 0.9224\n",
      "Epoch 2/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.4726 - acc: 0.9309 - val_loss: 0.4658 - val_acc: 0.9224\n",
      "Epoch 3/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.4272 - acc: 0.9309 - val_loss: 0.4276 - val_acc: 0.9224\n",
      "Epoch 4/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.3956 - acc: 0.9309 - val_loss: 0.3944 - val_acc: 0.9224\n",
      "Epoch 5/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.3625 - acc: 0.9309 - val_loss: 0.3552 - val_acc: 0.9224loss: 0.3649 - acc\n",
      "Epoch 6/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.3186 - acc: 0.9309 - val_loss: 0.2975 - val_acc: 0.9224\n",
      "Epoch 7/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.2511 - acc: 0.9315 - val_loss: 0.2171 - val_acc: 0.9772\n",
      "Epoch 8/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.1771 - acc: 0.9726 - val_loss: 0.1570 - val_acc: 0.9749\n",
      "Epoch 9/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.1319 - acc: 0.9800 - val_loss: 0.1275 - val_acc: 0.9749\n",
      "Epoch 10/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.1106 - acc: 0.9797 - val_loss: 0.1145 - val_acc: 0.9749\n",
      "Epoch 11/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.1005 - acc: 0.9797 - val_loss: 0.1067 - val_acc: 0.9749\n",
      "Epoch 12/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0948 - acc: 0.9800 - val_loss: 0.1017 - val_acc: 0.9749\n",
      "Epoch 13/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0919 - acc: 0.9795 - val_loss: 0.1000 - val_acc: 0.9749\n",
      "Epoch 14/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0897 - acc: 0.9800 - val_loss: 0.0988 - val_acc: 0.9749\n",
      "Epoch 15/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0881 - acc: 0.9797 - val_loss: 0.0960 - val_acc: 0.9749\n",
      "Epoch 16/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0870 - acc: 0.9800 - val_loss: 0.0959 - val_acc: 0.9749\n",
      "Epoch 17/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0860 - acc: 0.9800 - val_loss: 0.0961 - val_acc: 0.9749\n",
      "Epoch 18/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0852 - acc: 0.9800 - val_loss: 0.0939 - val_acc: 0.9772\n",
      "Epoch 19/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0843 - acc: 0.9800 - val_loss: 0.0937 - val_acc: 0.9772\n",
      "Epoch 20/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0841 - acc: 0.9800 - val_loss: 0.0925 - val_acc: 0.9772\n",
      "Epoch 21/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0835 - acc: 0.9800 - val_loss: 0.0923 - val_acc: 0.9772\n",
      "Epoch 22/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0833 - acc: 0.9800 - val_loss: 0.0915 - val_acc: 0.9772\n",
      "Epoch 23/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0820 - acc: 0.9800 - val_loss: 0.0919 - val_acc: 0.9772\n",
      "Epoch 24/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0820 - acc: 0.9800 - val_loss: 0.0909 - val_acc: 0.9772\n",
      "Epoch 25/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0820 - acc: 0.9803 - val_loss: 0.0915 - val_acc: 0.9772\n",
      "Epoch 26/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0816 - acc: 0.9800 - val_loss: 0.0906 - val_acc: 0.9772\n",
      "Epoch 27/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0815 - acc: 0.9800 - val_loss: 0.0903 - val_acc: 0.9772\n",
      "Epoch 28/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0808 - acc: 0.9800 - val_loss: 0.0902 - val_acc: 0.9772\n",
      "Epoch 29/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0805 - acc: 0.9803 - val_loss: 0.0895 - val_acc: 0.97720s - loss: 0.0760 - ac\n",
      "Epoch 30/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0804 - acc: 0.9803 - val_loss: 0.0895 - val_acc: 0.9772\n",
      "Epoch 31/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0801 - acc: 0.9800 - val_loss: 0.0894 - val_acc: 0.9772\n",
      "Epoch 32/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0796 - acc: 0.9800 - val_loss: 0.0888 - val_acc: 0.9772\n",
      "Epoch 33/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0796 - acc: 0.9806 - val_loss: 0.0896 - val_acc: 0.9772\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0797 - acc: 0.9803 - val_loss: 0.0889 - val_acc: 0.9772\n",
      "Epoch 35/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0792 - acc: 0.9806 - val_loss: 0.0886 - val_acc: 0.9772\n",
      "Epoch 36/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0788 - acc: 0.9814 - val_loss: 0.0887 - val_acc: 0.9772\n",
      "Epoch 37/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0791 - acc: 0.9806 - val_loss: 0.0886 - val_acc: 0.9772\n",
      "Epoch 38/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0787 - acc: 0.9809 - val_loss: 0.0885 - val_acc: 0.9772\n",
      "Epoch 39/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0789 - acc: 0.9800 - val_loss: 0.0886 - val_acc: 0.9772\n",
      "Epoch 40/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0779 - acc: 0.9806 - val_loss: 0.0881 - val_acc: 0.9772\n",
      "Epoch 41/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0779 - acc: 0.9817 - val_loss: 0.0873 - val_acc: 0.9772\n",
      "Epoch 42/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0784 - acc: 0.9809 - val_loss: 0.0874 - val_acc: 0.9772\n",
      "Epoch 43/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0777 - acc: 0.9826 - val_loss: 0.0875 - val_acc: 0.9772\n",
      "Epoch 44/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0778 - acc: 0.9832 - val_loss: 0.0878 - val_acc: 0.9772\n",
      "Epoch 45/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0777 - acc: 0.9814 - val_loss: 0.0868 - val_acc: 0.9772\n",
      "Epoch 46/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0774 - acc: 0.9823 - val_loss: 0.0866 - val_acc: 0.9772\n",
      "Epoch 47/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0769 - acc: 0.9829 - val_loss: 0.0877 - val_acc: 0.9772\n",
      "Epoch 48/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0771 - acc: 0.9823 - val_loss: 0.0873 - val_acc: 0.9772\n",
      "Epoch 49/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0774 - acc: 0.9820 - val_loss: 0.0862 - val_acc: 0.9772\n",
      "Epoch 50/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0769 - acc: 0.9823 - val_loss: 0.0873 - val_acc: 0.9772\n",
      "Epoch 51/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0764 - acc: 0.9829 - val_loss: 0.0866 - val_acc: 0.9772\n",
      "Epoch 52/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0766 - acc: 0.9832 - val_loss: 0.0865 - val_acc: 0.9772\n",
      "Epoch 53/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0761 - acc: 0.9834 - val_loss: 0.0875 - val_acc: 0.9772\n",
      "Epoch 54/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0765 - acc: 0.9826 - val_loss: 0.0872 - val_acc: 0.9772\n",
      "Epoch 55/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0760 - acc: 0.9834 - val_loss: 0.0871 - val_acc: 0.9772\n",
      "Epoch 56/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0762 - acc: 0.9834 - val_loss: 0.0873 - val_acc: 0.9772\n",
      "Epoch 57/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0762 - acc: 0.9834 - val_loss: 0.0862 - val_acc: 0.9772\n",
      "Epoch 58/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0761 - acc: 0.9834 - val_loss: 0.0862 - val_acc: 0.9772\n",
      "Epoch 59/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0762 - acc: 0.9834 - val_loss: 0.0864 - val_acc: 0.9772\n",
      "Epoch 60/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0756 - acc: 0.9834 - val_loss: 0.0860 - val_acc: 0.9772\n",
      "Epoch 61/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0757 - acc: 0.9832 - val_loss: 0.0858 - val_acc: 0.9772\n",
      "Epoch 62/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0751 - acc: 0.9834 - val_loss: 0.0856 - val_acc: 0.9783\n",
      "Epoch 63/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0759 - acc: 0.9832 - val_loss: 0.0857 - val_acc: 0.9783\n",
      "Epoch 64/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0755 - acc: 0.9834 - val_loss: 0.0853 - val_acc: 0.9806\n",
      "Epoch 65/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0751 - acc: 0.9834 - val_loss: 0.0860 - val_acc: 0.9783\n",
      "Epoch 66/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0748 - acc: 0.9834 - val_loss: 0.0851 - val_acc: 0.9806\n",
      "Epoch 67/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0751 - acc: 0.9834 - val_loss: 0.0858 - val_acc: 0.9795\n",
      "Epoch 68/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0753 - acc: 0.9834 - val_loss: 0.0854 - val_acc: 0.9806\n",
      "Epoch 69/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0756 - acc: 0.9834 - val_loss: 0.0854 - val_acc: 0.9806\n",
      "Epoch 70/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0755 - acc: 0.9834 - val_loss: 0.0848 - val_acc: 0.9806\n",
      "Epoch 71/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0754 - acc: 0.9834 - val_loss: 0.0854 - val_acc: 0.9806\n",
      "Epoch 72/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0752 - acc: 0.9834 - val_loss: 0.0855 - val_acc: 0.9806\n",
      "Epoch 73/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0748 - acc: 0.9834 - val_loss: 0.0856 - val_acc: 0.9806\n",
      "Epoch 74/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0744 - acc: 0.9834 - val_loss: 0.0852 - val_acc: 0.9806\n",
      "Epoch 75/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0743 - acc: 0.9834 - val_loss: 0.0865 - val_acc: 0.9783\n",
      "Epoch 76/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0737 - acc: 0.9834 - val_loss: 0.0856 - val_acc: 0.9806\n",
      "Epoch 77/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0747 - acc: 0.9834 - val_loss: 0.0845 - val_acc: 0.9806\n",
      "Epoch 78/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0752 - acc: 0.9834 - val_loss: 0.0850 - val_acc: 0.9806\n",
      "Epoch 79/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0744 - acc: 0.9834 - val_loss: 0.0849 - val_acc: 0.9806\n",
      "Epoch 80/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0743 - acc: 0.9834 - val_loss: 0.0842 - val_acc: 0.9806\n",
      "Epoch 81/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0746 - acc: 0.9834 - val_loss: 0.0850 - val_acc: 0.9806\n",
      "Epoch 82/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0744 - acc: 0.9834 - val_loss: 0.0846 - val_acc: 0.9806\n",
      "Epoch 83/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0739 - acc: 0.9834 - val_loss: 0.0840 - val_acc: 0.9806\n",
      "Epoch 84/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0743 - acc: 0.9834 - val_loss: 0.0845 - val_acc: 0.9806\n",
      "Epoch 85/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0740 - acc: 0.9834 - val_loss: 0.0846 - val_acc: 0.9806\n",
      "Epoch 86/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0744 - acc: 0.9834 - val_loss: 0.0849 - val_acc: 0.9806\n",
      "Epoch 87/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0738 - acc: 0.9834 - val_loss: 0.0847 - val_acc: 0.9806\n",
      "Epoch 88/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0742 - acc: 0.9834 - val_loss: 0.0846 - val_acc: 0.9806\n",
      "Epoch 89/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0743 - acc: 0.9834 - val_loss: 0.0849 - val_acc: 0.9806\n",
      "Epoch 90/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0740 - acc: 0.9834 - val_loss: 0.0848 - val_acc: 0.9806\n",
      "Epoch 91/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0739 - acc: 0.9834 - val_loss: 0.0849 - val_acc: 0.9806\n",
      "Epoch 92/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0739 - acc: 0.9834 - val_loss: 0.0848 - val_acc: 0.98060766 -\n",
      "Epoch 93/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0740 - acc: 0.9834 - val_loss: 0.0836 - val_acc: 0.9806\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0740 - acc: 0.9834 - val_loss: 0.0838 - val_acc: 0.9806\n",
      "Epoch 95/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0737 - acc: 0.9834 - val_loss: 0.0831 - val_acc: 0.9806\n",
      "Epoch 96/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0737 - acc: 0.9834 - val_loss: 0.0833 - val_acc: 0.9806\n",
      "Epoch 97/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0736 - acc: 0.9834 - val_loss: 0.0841 - val_acc: 0.9806\n",
      "Epoch 98/100\n",
      "3504/3504 [==============================] - 5s 2ms/step - loss: 0.0735 - acc: 0.9834 - val_loss: 0.0841 - val_acc: 0.9806\n",
      "Epoch 99/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0733 - acc: 0.9834 - val_loss: 0.0839 - val_acc: 0.9806\n",
      "Epoch 100/100\n",
      "3504/3504 [==============================] - 6s 2ms/step - loss: 0.0732 - acc: 0.9834 - val_loss: 0.0842 - val_acc: 0.9806\n",
      "HandStart AUC score = 0.495\n",
      "FirstDigitTouch AUC score = 0.466\n",
      "BothStartLoadPhase AUC score = 0.476\n",
      "LiftOff AUC score = 0.476\n",
      "Replace AUC score = 0.474\n",
      "BothReleased AUC score = 0.488\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train subject 10, class HandStart\n",
      "Train on 3888 samples, validate on 972 samples\n",
      "Epoch 1/100\n",
      "3888/3888 [==============================] - 7s 2ms/step - loss: 0.5913 - acc: 0.7831 - val_loss: 0.5388 - val_acc: 0.8920\n",
      "Epoch 2/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.5190 - acc: 0.8933 - val_loss: 0.5026 - val_acc: 0.8920\n",
      "Epoch 3/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.4824 - acc: 0.8933 - val_loss: 0.4626 - val_acc: 0.8920\n",
      "Epoch 4/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.4333 - acc: 0.8933 - val_loss: 0.4032 - val_acc: 0.8920\n",
      "Epoch 5/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.3619 - acc: 0.8933 - val_loss: 0.3140 - val_acc: 0.8920\n",
      "Epoch 6/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.2670 - acc: 0.8953 - val_loss: 0.2189 - val_acc: 0.9393\n",
      "Epoch 7/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.1883 - acc: 0.9491 - val_loss: 0.1586 - val_acc: 0.9856\n",
      "Epoch 8/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.1411 - acc: 0.9861 - val_loss: 0.1267 - val_acc: 0.9846\n",
      "Epoch 9/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.1158 - acc: 0.9856 - val_loss: 0.1100 - val_acc: 0.9846\n",
      "Epoch 10/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.1003 - acc: 0.9856 - val_loss: 0.1018 - val_acc: 0.9835\n",
      "Epoch 11/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0906 - acc: 0.9853 - val_loss: 0.0922 - val_acc: 0.9846\n",
      "Epoch 12/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0833 - acc: 0.9856 - val_loss: 0.0881 - val_acc: 0.9846\n",
      "Epoch 13/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0791 - acc: 0.9851 - val_loss: 0.0814 - val_acc: 0.9846\n",
      "Epoch 14/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0747 - acc: 0.9861 - val_loss: 0.0783 - val_acc: 0.9846\n",
      "Epoch 15/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0718 - acc: 0.9856 - val_loss: 0.0755 - val_acc: 0.9846\n",
      "Epoch 16/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0697 - acc: 0.9856 - val_loss: 0.0732 - val_acc: 0.9846\n",
      "Epoch 17/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0669 - acc: 0.9859 - val_loss: 0.0712 - val_acc: 0.9846\n",
      "Epoch 18/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0655 - acc: 0.9866 - val_loss: 0.0713 - val_acc: 0.9846\n",
      "Epoch 19/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0647 - acc: 0.9866 - val_loss: 0.0690 - val_acc: 0.9846\n",
      "Epoch 20/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0634 - acc: 0.9866 - val_loss: 0.0679 - val_acc: 0.9846\n",
      "Epoch 21/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0621 - acc: 0.9864 - val_loss: 0.0664 - val_acc: 0.9846\n",
      "Epoch 22/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0609 - acc: 0.9874 - val_loss: 0.0673 - val_acc: 0.9846\n",
      "Epoch 23/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0601 - acc: 0.9874 - val_loss: 0.0671 - val_acc: 0.9846\n",
      "Epoch 24/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0594 - acc: 0.9874 - val_loss: 0.0636 - val_acc: 0.9856\n",
      "Epoch 25/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0590 - acc: 0.9879 - val_loss: 0.0638 - val_acc: 0.9846\n",
      "Epoch 26/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0581 - acc: 0.9874 - val_loss: 0.0642 - val_acc: 0.9846\n",
      "Epoch 27/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0572 - acc: 0.9879 - val_loss: 0.0639 - val_acc: 0.9846\n",
      "Epoch 28/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0568 - acc: 0.9879 - val_loss: 0.0623 - val_acc: 0.9856\n",
      "Epoch 29/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0563 - acc: 0.9879 - val_loss: 0.0636 - val_acc: 0.9846\n",
      "Epoch 30/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0563 - acc: 0.9879 - val_loss: 0.0609 - val_acc: 0.9866\n",
      "Epoch 31/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0556 - acc: 0.9879 - val_loss: 0.0615 - val_acc: 0.9866\n",
      "Epoch 32/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0554 - acc: 0.9879 - val_loss: 0.0605 - val_acc: 0.9866\n",
      "Epoch 33/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0555 - acc: 0.9879 - val_loss: 0.0602 - val_acc: 0.9866\n",
      "Epoch 34/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0548 - acc: 0.9879 - val_loss: 0.0603 - val_acc: 0.9866\n",
      "Epoch 35/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0545 - acc: 0.9879 - val_loss: 0.0602 - val_acc: 0.9866\n",
      "Epoch 36/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0543 - acc: 0.9879 - val_loss: 0.0603 - val_acc: 0.9866\n",
      "Epoch 37/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0539 - acc: 0.9879 - val_loss: 0.0583 - val_acc: 0.9866\n",
      "Epoch 38/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0534 - acc: 0.9879 - val_loss: 0.0577 - val_acc: 0.9866\n",
      "Epoch 39/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0533 - acc: 0.9879 - val_loss: 0.0598 - val_acc: 0.9866\n",
      "Epoch 40/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0529 - acc: 0.9879 - val_loss: 0.0585 - val_acc: 0.9866\n",
      "Epoch 41/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0528 - acc: 0.9879 - val_loss: 0.0576 - val_acc: 0.9866\n",
      "Epoch 42/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0528 - acc: 0.9879 - val_loss: 0.0572 - val_acc: 0.9866\n",
      "Epoch 43/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0523 - acc: 0.9879 - val_loss: 0.0561 - val_acc: 0.9866\n",
      "Epoch 44/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0524 - acc: 0.9879 - val_loss: 0.0571 - val_acc: 0.9866\n",
      "Epoch 45/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0519 - acc: 0.9879 - val_loss: 0.0563 - val_acc: 0.9866\n",
      "Epoch 46/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0519 - acc: 0.9887 - val_loss: 0.0570 - val_acc: 0.9866\n",
      "Epoch 47/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0516 - acc: 0.9879 - val_loss: 0.0579 - val_acc: 0.9866\n",
      "Epoch 48/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0516 - acc: 0.9879 - val_loss: 0.0551 - val_acc: 0.9866\n",
      "Epoch 49/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0518 - acc: 0.9879 - val_loss: 0.0567 - val_acc: 0.9866\n",
      "Epoch 50/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0511 - acc: 0.9882 - val_loss: 0.0565 - val_acc: 0.9866\n",
      "Epoch 51/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0506 - acc: 0.9879 - val_loss: 0.0579 - val_acc: 0.9866\n",
      "Epoch 52/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0508 - acc: 0.9879 - val_loss: 0.0565 - val_acc: 0.9866\n",
      "Epoch 53/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0507 - acc: 0.9879 - val_loss: 0.0563 - val_acc: 0.9866\n",
      "Epoch 54/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0502 - acc: 0.9887 - val_loss: 0.0577 - val_acc: 0.9866\n",
      "Epoch 55/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0510 - acc: 0.9884 - val_loss: 0.0561 - val_acc: 0.9866\n",
      "Epoch 56/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0510 - acc: 0.9879 - val_loss: 0.0554 - val_acc: 0.9866\n",
      "Epoch 57/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0493 - acc: 0.9884 - val_loss: 0.0549 - val_acc: 0.9866\n",
      "Epoch 58/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0503 - acc: 0.9882 - val_loss: 0.0552 - val_acc: 0.9866\n",
      "Epoch 59/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0502 - acc: 0.9884 - val_loss: 0.0556 - val_acc: 0.9866\n",
      "Epoch 60/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0498 - acc: 0.9882 - val_loss: 0.0550 - val_acc: 0.9866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0499 - acc: 0.9879 - val_loss: 0.0552 - val_acc: 0.9866\n",
      "Epoch 62/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0496 - acc: 0.9882 - val_loss: 0.0547 - val_acc: 0.9866\n",
      "Epoch 63/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0494 - acc: 0.9884 - val_loss: 0.0539 - val_acc: 0.9866\n",
      "Epoch 64/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0494 - acc: 0.9892 - val_loss: 0.0547 - val_acc: 0.9866\n",
      "Epoch 65/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0492 - acc: 0.9887 - val_loss: 0.0557 - val_acc: 0.9866\n",
      "Epoch 66/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0489 - acc: 0.9879 - val_loss: 0.0533 - val_acc: 0.9866\n",
      "Epoch 67/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0493 - acc: 0.9887 - val_loss: 0.0535 - val_acc: 0.9866\n",
      "Epoch 68/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0493 - acc: 0.9889 - val_loss: 0.0538 - val_acc: 0.9866\n",
      "Epoch 69/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0493 - acc: 0.9892 - val_loss: 0.0556 - val_acc: 0.9866\n",
      "Epoch 70/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0489 - acc: 0.9892 - val_loss: 0.0546 - val_acc: 0.9866\n",
      "Epoch 71/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0486 - acc: 0.9900 - val_loss: 0.0550 - val_acc: 0.9866\n",
      "Epoch 72/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0490 - acc: 0.9900 - val_loss: 0.0542 - val_acc: 0.9866\n",
      "Epoch 73/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0481 - acc: 0.9897 - val_loss: 0.0535 - val_acc: 0.9866\n",
      "Epoch 74/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0485 - acc: 0.9892 - val_loss: 0.0539 - val_acc: 0.9866\n",
      "Epoch 75/100\n",
      "3888/3888 [==============================] - 7s 2ms/step - loss: 0.0482 - acc: 0.9897 - val_loss: 0.0527 - val_acc: 0.9866\n",
      "Epoch 76/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0484 - acc: 0.9902 - val_loss: 0.0540 - val_acc: 0.9866\n",
      "Epoch 77/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0482 - acc: 0.9897 - val_loss: 0.0525 - val_acc: 0.9866\n",
      "Epoch 78/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0476 - acc: 0.9900 - val_loss: 0.0524 - val_acc: 0.9866\n",
      "Epoch 79/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0474 - acc: 0.9897 - val_loss: 0.0545 - val_acc: 0.9866\n",
      "Epoch 80/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0481 - acc: 0.9900 - val_loss: 0.0531 - val_acc: 0.9866\n",
      "Epoch 81/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0474 - acc: 0.9905 - val_loss: 0.0531 - val_acc: 0.9866\n",
      "Epoch 82/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0479 - acc: 0.9900 - val_loss: 0.0537 - val_acc: 0.9866\n",
      "Epoch 83/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0478 - acc: 0.9900 - val_loss: 0.0526 - val_acc: 0.9866\n",
      "Epoch 84/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0477 - acc: 0.9902 - val_loss: 0.0543 - val_acc: 0.9866\n",
      "Epoch 85/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0478 - acc: 0.9902 - val_loss: 0.0526 - val_acc: 0.9866\n",
      "Epoch 86/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0471 - acc: 0.9907 - val_loss: 0.0540 - val_acc: 0.9866\n",
      "Epoch 87/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0469 - acc: 0.9907 - val_loss: 0.0522 - val_acc: 0.9877\n",
      "Epoch 88/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0475 - acc: 0.9907 - val_loss: 0.0513 - val_acc: 0.9897\n",
      "Epoch 89/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0473 - acc: 0.9905 - val_loss: 0.0514 - val_acc: 0.9897\n",
      "Epoch 90/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0475 - acc: 0.9902 - val_loss: 0.0514 - val_acc: 0.9897\n",
      "Epoch 91/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0474 - acc: 0.9910 - val_loss: 0.0533 - val_acc: 0.9866\n",
      "Epoch 92/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0477 - acc: 0.9902 - val_loss: 0.0516 - val_acc: 0.9887\n",
      "Epoch 93/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0465 - acc: 0.9907 - val_loss: 0.0520 - val_acc: 0.9887\n",
      "Epoch 94/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0465 - acc: 0.9907 - val_loss: 0.0526 - val_acc: 0.9866\n",
      "Epoch 95/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0468 - acc: 0.9907 - val_loss: 0.0544 - val_acc: 0.9866\n",
      "Epoch 96/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0469 - acc: 0.9910 - val_loss: 0.0543 - val_acc: 0.9866\n",
      "Epoch 97/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0470 - acc: 0.9905 - val_loss: 0.0512 - val_acc: 0.9897\n",
      "Epoch 98/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0470 - acc: 0.9907 - val_loss: 0.0515 - val_acc: 0.9897\n",
      "Epoch 99/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0464 - acc: 0.9910 - val_loss: 0.0509 - val_acc: 0.9897\n",
      "Epoch 100/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0466 - acc: 0.9910 - val_loss: 0.0519 - val_acc: 0.9887\n",
      "Train subject 10, class FirstDigitTouch\n",
      "Train on 3888 samples, validate on 972 samples\n",
      "Epoch 1/100\n",
      "3888/3888 [==============================] - 7s 2ms/step - loss: 0.6094 - acc: 0.8391 - val_loss: 0.5897 - val_acc: 0.8837\n",
      "Epoch 2/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.5484 - acc: 0.8953 - val_loss: 0.5602 - val_acc: 0.8837\n",
      "Epoch 3/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.5233 - acc: 0.8953 - val_loss: 0.5320 - val_acc: 0.8837\n",
      "Epoch 4/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.4943 - acc: 0.8953 - val_loss: 0.4988 - val_acc: 0.8837\n",
      "Epoch 5/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.4592 - acc: 0.8953 - val_loss: 0.4522 - val_acc: 0.8837\n",
      "Epoch 6/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.4051 - acc: 0.8953 - val_loss: 0.3803 - val_acc: 0.8837\n",
      "Epoch 7/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.3273 - acc: 0.8953 - val_loss: 0.2853 - val_acc: 0.8837\n",
      "Epoch 8/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.2414 - acc: 0.8999 - val_loss: 0.2025 - val_acc: 0.9877\n",
      "Epoch 9/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.1761 - acc: 0.9640 - val_loss: 0.1495 - val_acc: 0.9877\n",
      "Epoch 10/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.1368 - acc: 0.9848 - val_loss: 0.1199 - val_acc: 0.9856\n",
      "Epoch 11/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.1132 - acc: 0.9869 - val_loss: 0.1017 - val_acc: 0.9856\n",
      "Epoch 12/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0977 - acc: 0.9866 - val_loss: 0.0899 - val_acc: 0.9856\n",
      "Epoch 13/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0893 - acc: 0.9864 - val_loss: 0.0821 - val_acc: 0.9856\n",
      "Epoch 14/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0828 - acc: 0.9866 - val_loss: 0.0774 - val_acc: 0.9856\n",
      "Epoch 15/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0778 - acc: 0.9871 - val_loss: 0.0734 - val_acc: 0.9856\n",
      "Epoch 16/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0739 - acc: 0.9874 - val_loss: 0.0699 - val_acc: 0.9856\n",
      "Epoch 17/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0712 - acc: 0.9871 - val_loss: 0.0680 - val_acc: 0.9856\n",
      "Epoch 18/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0692 - acc: 0.9874 - val_loss: 0.0658 - val_acc: 0.9877\n",
      "Epoch 19/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0671 - acc: 0.9877 - val_loss: 0.0644 - val_acc: 0.9877\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0654 - acc: 0.9874 - val_loss: 0.0632 - val_acc: 0.9877\n",
      "Epoch 21/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0640 - acc: 0.9877 - val_loss: 0.0627 - val_acc: 0.9877\n",
      "Epoch 22/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0634 - acc: 0.9877 - val_loss: 0.0617 - val_acc: 0.9877\n",
      "Epoch 23/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0621 - acc: 0.9877 - val_loss: 0.0607 - val_acc: 0.9877\n",
      "Epoch 24/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0614 - acc: 0.9877 - val_loss: 0.0599 - val_acc: 0.9877\n",
      "Epoch 25/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0601 - acc: 0.9877 - val_loss: 0.0591 - val_acc: 0.9877\n",
      "Epoch 26/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0600 - acc: 0.9877 - val_loss: 0.0587 - val_acc: 0.9877\n",
      "Epoch 27/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0594 - acc: 0.9877 - val_loss: 0.0586 - val_acc: 0.9877\n",
      "Epoch 28/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0586 - acc: 0.9877 - val_loss: 0.0586 - val_acc: 0.9877\n",
      "Epoch 29/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0589 - acc: 0.9877 - val_loss: 0.0575 - val_acc: 0.9877\n",
      "Epoch 30/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0580 - acc: 0.9877 - val_loss: 0.0569 - val_acc: 0.9877\n",
      "Epoch 31/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0577 - acc: 0.9877 - val_loss: 0.0568 - val_acc: 0.9877\n",
      "Epoch 32/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0572 - acc: 0.9877 - val_loss: 0.0562 - val_acc: 0.9877\n",
      "Epoch 33/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0572 - acc: 0.9877 - val_loss: 0.0563 - val_acc: 0.9877\n",
      "Epoch 34/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0565 - acc: 0.9877 - val_loss: 0.0556 - val_acc: 0.9877\n",
      "Epoch 35/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0558 - acc: 0.9877 - val_loss: 0.0555 - val_acc: 0.9877\n",
      "Epoch 36/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0559 - acc: 0.9877 - val_loss: 0.0550 - val_acc: 0.9877\n",
      "Epoch 37/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0556 - acc: 0.9877 - val_loss: 0.0562 - val_acc: 0.9877\n",
      "Epoch 38/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0553 - acc: 0.9877 - val_loss: 0.0548 - val_acc: 0.9877\n",
      "Epoch 39/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0553 - acc: 0.9877 - val_loss: 0.0546 - val_acc: 0.9877\n",
      "Epoch 40/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0552 - acc: 0.9877 - val_loss: 0.0548 - val_acc: 0.9877\n",
      "Epoch 41/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0546 - acc: 0.9877 - val_loss: 0.0541 - val_acc: 0.9877\n",
      "Epoch 42/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0547 - acc: 0.9877 - val_loss: 0.0548 - val_acc: 0.9877\n",
      "Epoch 43/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0544 - acc: 0.9877 - val_loss: 0.0545 - val_acc: 0.9877\n",
      "Epoch 44/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0538 - acc: 0.9877 - val_loss: 0.0539 - val_acc: 0.9877\n",
      "Epoch 45/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0535 - acc: 0.9877 - val_loss: 0.0535 - val_acc: 0.9877\n",
      "Epoch 46/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0539 - acc: 0.9877 - val_loss: 0.0530 - val_acc: 0.9877\n",
      "Epoch 47/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0540 - acc: 0.9877 - val_loss: 0.0537 - val_acc: 0.9877\n",
      "Epoch 48/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0535 - acc: 0.9877 - val_loss: 0.0537 - val_acc: 0.9877\n",
      "Epoch 49/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0526 - acc: 0.9877 - val_loss: 0.0526 - val_acc: 0.9877\n",
      "Epoch 50/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0530 - acc: 0.9877 - val_loss: 0.0529 - val_acc: 0.9877\n",
      "Epoch 51/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0527 - acc: 0.9877 - val_loss: 0.0527 - val_acc: 0.9877\n",
      "Epoch 52/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0520 - acc: 0.9877 - val_loss: 0.0521 - val_acc: 0.9877\n",
      "Epoch 53/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0526 - acc: 0.9877 - val_loss: 0.0525 - val_acc: 0.9877\n",
      "Epoch 54/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0528 - acc: 0.9877 - val_loss: 0.0522 - val_acc: 0.9877\n",
      "Epoch 55/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0523 - acc: 0.9877 - val_loss: 0.0524 - val_acc: 0.9877\n",
      "Epoch 56/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0520 - acc: 0.9877 - val_loss: 0.0516 - val_acc: 0.9877\n",
      "Epoch 57/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0520 - acc: 0.9877 - val_loss: 0.0514 - val_acc: 0.9877\n",
      "Epoch 58/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0516 - acc: 0.9877 - val_loss: 0.0525 - val_acc: 0.9877\n",
      "Epoch 59/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0515 - acc: 0.9877 - val_loss: 0.0527 - val_acc: 0.9877\n",
      "Epoch 60/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0516 - acc: 0.9877 - val_loss: 0.0518 - val_acc: 0.9877\n",
      "Epoch 61/100\n",
      "3888/3888 [==============================] - 6s 2ms/step - loss: 0.0511 - acc: 0.9877 - val_loss: 0.0521 - val_acc: 0.9877\n",
      "Epoch 62/100\n",
      " 864/3888 [=====>........................] - ETA: 4s - loss: 0.0392 - acc: 0.9919"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-e4f7b6930a1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Train subject %d, class %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msubject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCOLUMNS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbalanced_x_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sebastiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\sebastiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\sebastiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sebastiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sebastiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sebastiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1137\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sebastiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1353\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1355\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1356\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sebastiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1359\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sebastiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[1;32m-> 1340\u001b[1;33m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# models = []\n",
    "# for i in range(N_LABELS):\n",
    "#     models.append(init_cnn(WINDOW_SIZE))\n",
    "\n",
    "for subject in TRAIN_SUBJECTS:\n",
    "    prediction_total = []\n",
    "    test_data_total = []\n",
    "    train_data_paths = glob(TRAIN_DATA_PATH % (subject))\n",
    "\n",
    "    \n",
    "    x_raw, y_raw = read_training_data(train_data_paths)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_raw, y_raw, test_size=0.33, shuffle=False)\n",
    "\n",
    "    x_train, _ = preprocess_data(x_train, WINDOW_SIZE, SUBSAMPLE)\n",
    "    x_test, _ = preprocess_data(x_test, WINDOW_SIZE, SUBSAMPLE)\n",
    "    y_train = y_train[::SUBSAMPLE]\n",
    "    y_test = y_test[::SUBSAMPLE]\n",
    "    \n",
    "    for i in range(N_LABELS):\n",
    "        model = init_cnn(WINDOW_SIZE)\n",
    "        \n",
    "        balanced_x_train, balanced_y_train = remove_imbalance(x_train, y_train[:,i])\n",
    "        \n",
    "        train_labels = to_categorical(balanced_y_train, num_classes = None)\n",
    "                \n",
    "        print('Train subject %d, class %s' % (subject, COLUMNS[i]))        \n",
    "        model.fit(balanced_x_train, train_labels, verbose=1, validation_split=0.2, epochs=EPOCHS)\n",
    "    \n",
    "    \n",
    "#     for task_name, model in zip(COLUMNS, models):\n",
    "#         model.save('general_model_'+task_name+'_subject_%d.h5' % (subject))  # creates a HDF5 file 'my_model.h5'\n",
    "        predictions = predict_on_sub(x_test, model, SPLIT_SIZE, BATCH_SIZE)\n",
    "        \n",
    "        test_data_total.append(y_test[:,i][1000::BATCH_SIZE])\n",
    "        prediction_total.append(predictions)\n",
    "        \n",
    "    multiple_metric_auc_score(prediction_total, test_data_total, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01672238, 0.01672238, 0.01672238, ..., 0.99921763, 0.99920839,\n",
       "       0.99918479])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_total[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# for task_name, model in zip(COLUMNS, models):\n",
    "#     model.save('general_model_'+task_name+'.h5')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model('general_model_handstart.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# for subject in TEST_SUBJECTS:\n",
    "#     prediction_total = []\n",
    "#     test_data_total = []\n",
    "#     test_features_raw = []\n",
    "#     train_data_paths = glob(TRAIN_DATA_PATH % (subject))\n",
    "\n",
    "    \n",
    "#     x_raw, y_raw = read_training_data(train_data_paths)\n",
    "    \n",
    "#     x_raw, _ = preprocess_data(x_raw, WINDOW_SIZE, SUBSAMPLE)\n",
    "\n",
    "#     _, x_test, _, y_test = train_test_split(x_raw, y_raw[::SUBSAMPLE], test_size=0.5)\n",
    "\n",
    "    \n",
    "#     for i in range(N_LABELS):\n",
    "\n",
    "#         test_labels = to_categorical(y_test[:,i], num_classes = None)\n",
    "                \n",
    "#         print('Test subject %d, class %s' % (subject, COLUMNS[i]))                \n",
    "#         predictions = predict_on_sub(x_test, models[i], SPLIT_SIZE, BATCH_SIZE)\n",
    "        \n",
    "#         test_data_total.append(y_test[:,i][1000::BATCH_SIZE])\n",
    "#         prediction_total.append(predictions)\n",
    "        \n",
    "#     multiple_metric_auc_score(prediction_total, test_data_total, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
