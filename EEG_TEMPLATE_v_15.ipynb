{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPool2D, Dropout, Flatten\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from scipy import signal\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# constants:\n",
    "SUBSAMPLE = 100  # scales the data by this factor\n",
    "COLUMNS = ['HandStart', 'FirstDigitTouch',\n",
    "        'BothStartLoadPhase', 'LiftOff',\n",
    "        'Replace', 'BothReleased']\n",
    "SUBJECTS = range(1, 2)\n",
    "N_LABELS = 6\n",
    "\n",
    "# Below are the paths to the data. Please pay attention to the % and * signs, these are needed in the loop.\n",
    "# TRAIN_DATA_PATH = 'C:/Users/Sebastiaan/Desktop/Programming/MachineLearning/Datasets/EEG/train/subj%d_series*_data.csv'\n",
    "#The path below is for the test data used for a kaggle submission. This is not very relevant to our project.\n",
    "# TEST_DATA_PATH = 'C:/Users/Sebastiaan/Desktop/Programming/MachineLearning/Datasets/EEG/test/subj%d_series*_data.csv'\n",
    "TRAIN_DATA_PATH = 'C:/Users/bas/Documents/MachineLearning/train/subj%d_series*_data.csv' #path on my laptop\n",
    "TEST_DATA_PATH =  'C:/Users/bas/Documents/MachineLearning/test/subj%d_series*_data.csv' \n",
    "\n",
    "SUBMISSION_FOLDER = 'C:/Users/Sebastiaan/Desktop/Programming/MachineLearning/'\n",
    "SUBMISSION_NAME = 'subbmision_vu_48_sub_pca_4.csv'\n",
    "\n",
    "PCA_COMPONENTS = 0.8\n",
    "CUTT_OFF_FREQUENCY = 2\n",
    "ORDER = 4\n",
    "SAMPLE_FREQUENCY = 500\n",
    "\n",
    "EPOCHS = 10\n",
    "WINDOW_SIZE = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_training_data(data_path):\n",
    "    data = pd.read_csv(data_path)\n",
    "    event_path = data_path.replace('_data', '_events')\n",
    "    labels = pd.read_csv(event_path)\n",
    "    clean_data = data.drop(['id'], axis = 1)\n",
    "    labels = labels.drop(['id'], axis = 1)\n",
    "    return clean_data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_test_data(data_path):\n",
    "    data = pd.read_csv(data_path)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scaler_transform(data, scaler):\n",
    "    if scaler == None:\n",
    "        scaler = StandardScaler()\n",
    "        return scaler.fit_transform(data), scaler\n",
    "    else:\n",
    "        return scaler.transform(data)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def butter_worth(data, cut_off, hz, order):\n",
    "    filtered_data = np.empty(np.shape(data))\n",
    "    wn = cut_off / (hz/2)\n",
    "    b, a = signal.butter(order, wn, analog = False)\n",
    "    for i in range(len(data[0])):\n",
    "        filtered_data[:,i] = signal.lfilter(b, a, data[:,i])    \n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pca_transform(data, n_components, pca_model):\n",
    "    if pca_model == None:\n",
    "        pca = PCA(n_components, whiten = True) \n",
    "        return pca.fit_transform(data), pca\n",
    "    else:\n",
    "        return pca_model.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_training_data(train_data_paths):\n",
    "    labels_raw = []\n",
    "    features_raw = []\n",
    "    for data_path in train_data_paths:\n",
    "        data, labels = prepare_training_data(data_path)\n",
    "        features_raw.append(data)\n",
    "        labels_raw.append(labels)\n",
    "    features_raw = pd.concat(features_raw)\n",
    "    labels_raw = pd.concat(labels_raw)\n",
    "    x_train = np.asarray(features_raw.astype(float))\n",
    "    y_train = np.asarray(labels_raw.astype(float))\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_test_data(test_data_paths):\n",
    "    test_features_raw = []\n",
    "    ids = []\n",
    "    for data_path in test_data_paths:\n",
    "        data = prepare_test_data(data_path)\n",
    "        test_features_raw.append(data)\n",
    "        ids.append(np.array(data['id']))\n",
    "    test_features_raw = pd.concat(test_features_raw)\n",
    "    ids = np.concatenate(ids)\n",
    "    test_features_raw = test_features_raw.drop(['id'], axis = 1)\n",
    "    x_test = np.asarray(test_features_raw.astype(float))\n",
    "    return x_test, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(x_train, y_train, model, subsample):\n",
    "    model.fit(x_train[::subsample,:], y_train[::subsample])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_prediction(x_test, model):\n",
    "    prediction = model.predict_proba(x_test)[:,1]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def metric_auc_score(predictions, y_test, with_plot):\n",
    "    scores = []\n",
    "    legend_text = []\n",
    "    for i in range(N_LABELS):\n",
    "        fpr, tpr, _  = roc_curve(y_test[:,i], predictions[:,i], 1)\n",
    "        scores.append(roc_auc_score(y_test[:,i], predictions[:,i]))\n",
    "        legend_text.append(COLUMNS[i]+' (area = %.3f)' % (scores[i]))\n",
    "        if with_plot == True:\n",
    "            plt.plot(fpr, tpr)\n",
    "    if with_plot == True:\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curves')\n",
    "        plt.legend(legend_text)\n",
    "        plt.show()\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_metric_auc_score(predictions, y_test, with_plot):\n",
    "    fpr, tpr, _  = roc_curve(y_test, predictions, 1)\n",
    "    score = roc_auc_score(y_test, predictions)\n",
    "    print(COLUMNS[0]+'area = %.3f' % (score))\n",
    "    if with_plot == True:\n",
    "        plt.plot(fpr, tpr)\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curves')\n",
    "        plt.show()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_auc_scores(prediction_total, test_data_total, subjects, with_plot):\n",
    "    scores = []\n",
    "    for subject in subjects:\n",
    "        score = metric_auc_score(prediction_total[subject-1],\n",
    "                                 test_data_total[subject-1], with_plot)\n",
    "        scores.append(score)\n",
    "        print('Mean AUC Score of Subject %d: %.3f' % \\\n",
    "              (subject, np.mean(score)))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_submission_file(name, ids_total, prediction_total, columns, path):\n",
    "    submission = pd.DataFrame(index = np.concatenate(ids_total), columns = columns,\n",
    "                              data = np.concatenate(prediction_total))\n",
    "    submission.to_csv(path+name, index_label = 'id', float_format = '%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(x_train, y_train, image_size):\n",
    "    empty_matrix = np.expand_dims(np.zeros(np.shape(x_train[0:image_size])), axis=3)\n",
    "    while True:\n",
    "        for i in range(len(x_train)):\n",
    "            if i-image_size < 0:\n",
    "                yield np.array([empty_matrix]), np.array([y_train[i]])\n",
    "            else:\n",
    "                yield np.array([np.expand_dims(x_train[i-image_size:i],axis=3)]), np.array([y_train[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_generator(x_test, image_size):\n",
    "    empty_matrix = np.expand_dims(np.zeros(np.shape(x_test[0:image_size])), axis=3)\n",
    "    while True:\n",
    "        for i in range(len(x_test)):\n",
    "            if i-image_size < 0:\n",
    "                yield np.array([empty_matrix])\n",
    "            else:\n",
    "                yield np.array([np.expand_dims(x_test[i-image_size:i],axis=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_cnn(window):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=(window,32,1)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(50, 4)))\n",
    "    model.add(Dropout(0.25)) # Dropout 25% of the nodes of the previous layer during training\n",
    "    model.add(Flatten())     # Flatten, and add a fully connected layer\n",
    "    model.add(Dense(128, activation='relu')) \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense((2), activation='softmax')) # Last layer: 10 class nodes, with dropout\n",
    "    model.summary()\n",
    "    optimizer = Adam()\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train subject 1, class HandStart\n",
      "Train subject 1, class FirstDigitTouch\n",
      "Train subject 1, class BothStartLoadPhase\n",
      "Train subject 1, class LiftOff\n",
      "Train subject 1, class Replace\n",
      "Train subject 1, class BothReleased\n"
     ]
    }
   ],
   "source": [
    "prediction_total = []\n",
    "test_data_total = []\n",
    "ids_total = []\n",
    "for subject in SUBJECTS:\n",
    "    test_features_raw = []\n",
    "    train_data_paths = glob(TRAIN_DATA_PATH % (subject))\n",
    "    test_data_paths =  glob(TEST_DATA_PATH % (subject))\n",
    "  \n",
    "    x_train, y_train = read_training_data(train_data_paths)  \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2)\n",
    "    \n",
    "    #Below you can put preprocessing functions. You can make a decision in which method to use\n",
    "    #by commenting certain lines or not.\n",
    "#     x_train = butter_worth(x_train, CUTT_OFF_FREQUENCY, SAMPLE_FREQUENCY, ORDER)\n",
    "#     x_test = butter_worth(x_test, CUTT_OFF_FREQUENCY, SAMPLE_FREQUENCY, ORDER)\n",
    "#     x_train, pca_model = pca_transform(x_train, PCA_COMPONENTS, None)\n",
    "#     x_test = pca_transform(x_test, PCA_COMPONENTS, pca_model)\n",
    "    x_train, scaler = scaler_transform(x_train, None)\n",
    "    x_test = scaler_transform(x_test, scaler)\n",
    "    #############################################\n",
    "    \n",
    "\n",
    "    predictions = np.empty((x_test.shape[0],6))\n",
    "#     Below you define the model you want to use.\n",
    "    logreg = LogisticRegression()\n",
    "    for i in range(N_LABELS):\n",
    "        print('Train subject %d, class %s' % (subject, COLUMNS[i]))\n",
    "        model = train_model(x_train, y_train[:,i], logreg, SUBSAMPLE)\n",
    "        predictions[:,i] = make_prediction(x_test, model)\n",
    "    test_data_total.append(y_test)   \n",
    "    prediction_total.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 198, 30, 16)       160       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 196, 28, 32)       4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 3, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 672)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               86144     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 91,202\n",
      "Trainable params: 91,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = init_cnn(window=WINDOW_SIZE)\n",
    "labels = to_categorical(y_train[:,0][::SUBSAMPLE],num_classes = None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 145s - loss: 0.4279 - acc: 0.9732\n"
     ]
    }
   ],
   "source": [
    "my_generater = generator(x_train[::SUBSAMPLE], labels, 200)\n",
    "model.fit_generator(my_generater, steps_per_epoch=len(x_train[::SUBSAMPLE]), epochs=1, verbose=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# de maxpool is the size of the window that goes over the image. if its to small it takes alot of time (dimension is (V,H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test = to_categorical(y_test[:,0][::SUBSAMPLE],num_classes = None)\n",
    "\n",
    "my_test_generater = test_generator(x_test[::SUBSAMPLE], 200)\n",
    "\n",
    "predictions = model.predict_generator(my_test_generater, steps= len(y_test[:,0][::SUBSAMPLE]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HandStartarea = 0.524\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1KYDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ed8049c320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2845"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_metric_auc_score(predictions[:, 1], y_test[:,0][::SUBSAMPLE], True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = all_auc_scores(prediction_total, test_data_total, SUBJECTS, with_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Columnwise AUC ROC Score: %.3f, %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The script below is for kaggle submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################KAGGLE SUBMISSION CODE\n",
    "\n",
    "# prediction_total= []\n",
    "# ids_total = []\n",
    "# for subject in SUBJECTS:\n",
    "#     test_features_raw = []\n",
    "#     train_data_paths = glob(TRAIN_DATA_PATH % (subject))\n",
    "#     test_data_paths =  glob(TEST_DATA_PATH % (subject))\n",
    "  \n",
    "#     x_train, y_train = read_training_data(train_data_paths)\n",
    "#     x_test, ids = read_test_data(test_data_paths)\n",
    "#     ids_total.append(ids)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Below you can put preprocessing functions. You can make a decision in which method to use\n",
    "    #by commenting certain lines or not.#     x_train = butter_worth(x_train, CUTT_OFF_FREQUENCY, SAMPLE_FREQUENCY, ORDER)\n",
    "#     x_test = butter_worth(x_test, CUTT_OFF_FREQUENCY, SAMPLE_FREQUENCY, ORDER)\n",
    "#     x_train, pca_model = pca_transform(x_train, PCA_COMPONENTS, None)\n",
    "#     x_test = pca_transform(x_test, PCA_COMPONENTS, pca_model)\n",
    "#     x_train, scaler = scaler_transform(x_train, None)\n",
    "#     x_test = scaler_transform(x_test, scaler)\n",
    "#     #############################################\n",
    "    \n",
    "#     predictions = np.empty((x_test.shape[0],6))\n",
    "#     #Below you define the model you want to use.\n",
    "#     logreg = LogisticRegression()\n",
    "#     for i in range(N_LABELS):\n",
    "#         print('Train subject %d, class %s' % (subject, COLUMNS[i]))\n",
    "#         model = train_model(x_train, y_train[:,i], logreg, SUBSAMPLE)\n",
    "#         predictions[:,i] = make_prediction(x_test, model)\n",
    "        \n",
    "#     prediction_total.append(predictions)\n",
    "\n",
    "# make_submission_file(SUBMISSION_NAME, ids_total, prediction_total, COLUMNS, SUBMISSION_FOLDER)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
