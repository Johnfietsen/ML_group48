{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPool2D, Dropout, Flatten\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.utils import class_weight\n",
    "from scipy import signal\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants:\n",
    "SUBSAMPLE = 100  # scales the data by this factor\n",
    "COLUMNS = ['HandStart', 'FirstDigitTouch',\n",
    "        'BothStartLoadPhase', 'LiftOff',\n",
    "        'Replace', 'BothReleased']\n",
    "SUBJECTS = range(1, 2)\n",
    "N_LABELS = 6\n",
    "\n",
    "# Below are the paths to the data. Please pay attention to the % and * signs, these are needed in the loop.\n",
    "TRAIN_DATA_PATH = 'C:/Users/Sebastiaan/Desktop/Programming/MachineLearning/Datasets/EEG/train/subj%d_series*_data.csv'\n",
    "#The path below is for the test data used for a kaggle submission. This is not very relevant to our project.\n",
    "# TEST_DATA_PATH = 'C:/Users/Sebastiaan/Desktop/Programming/MachineLearning/Datasets/EEG/test/subj%d_series*_data.csv'\n",
    "# TRAIN_DATA_PATH = 'C:/Users/bas/Documents/MachineLearning/train/subj%d_series*_data.csv' #path on my laptop\n",
    "# TEST_DATA_PATH =  'C:/Users/bas/Documents/MachineLearning/test/subj%d_series*_data.csv' \n",
    "\n",
    "SUBMISSION_FOLDER = 'C:/Users/Sebastiaan/Desktop/Programming/MachineLearning/'\n",
    "SUBMISSION_NAME = 'subbmision_vu_48_sub_pca_4.csv'\n",
    "\n",
    "PCA_COMPONENTS = 0.8\n",
    "CUTT_OFF_FREQUENCY = 2\n",
    "ORDER = 4\n",
    "SAMPLE_FREQUENCY = 500\n",
    "\n",
    "EPOCHS = 5\n",
    "WINDOW_SIZE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_data(data_path):\n",
    "    data = pd.read_csv(data_path)\n",
    "    event_path = data_path.replace('_data', '_events')\n",
    "    labels = pd.read_csv(event_path)\n",
    "    clean_data = data.drop(['id'], axis = 1)\n",
    "    labels = labels.drop(['id'], axis = 1)\n",
    "    return clean_data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test_data(data_path):\n",
    "    data = pd.read_csv(data_path)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaler_transform(data, scaler):\n",
    "    if scaler == None:\n",
    "        scaler = StandardScaler()\n",
    "        return scaler.fit_transform(data), scaler\n",
    "    else:\n",
    "        return scaler.transform(data)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_worth(data, cut_off, hz, order):\n",
    "    filtered_data = np.empty(np.shape(data))\n",
    "    wn = cut_off / (hz/2)\n",
    "    b, a = signal.butter(order, wn, analog = False)\n",
    "    for i in range(len(data[0])):\n",
    "        filtered_data[:,i] = signal.lfilter(b, a, data[:,i])    \n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_transform(data, n_components, pca_model):\n",
    "    if pca_model == None:\n",
    "        pca = PCA(n_components, whiten = True) \n",
    "        return pca.fit_transform(data), pca\n",
    "    else:\n",
    "        return pca_model.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_training_data(train_data_paths):\n",
    "    labels_raw = []\n",
    "    features_raw = []\n",
    "    for data_path in train_data_paths:\n",
    "        data, labels = prepare_training_data(data_path)\n",
    "        features_raw.append(data)\n",
    "        labels_raw.append(labels)\n",
    "    features_raw = pd.concat(features_raw)\n",
    "    labels_raw = pd.concat(labels_raw)\n",
    "    x_train = np.asarray(features_raw.astype(float))\n",
    "    y_train = np.asarray(labels_raw.astype(float))\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_test_data(test_data_paths):\n",
    "    test_features_raw = []\n",
    "    ids = []\n",
    "    for data_path in test_data_paths:\n",
    "        data = prepare_test_data(data_path)\n",
    "        test_features_raw.append(data)\n",
    "        ids.append(np.array(data['id']))\n",
    "    test_features_raw = pd.concat(test_features_raw)\n",
    "    ids = np.concatenate(ids)\n",
    "    test_features_raw = test_features_raw.drop(['id'], axis = 1)\n",
    "    x_test = np.asarray(test_features_raw.astype(float))\n",
    "    return x_test, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x_train, y_train, model, subsample):\n",
    "    model.fit(x_train[::subsample,:], y_train[::subsample])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(x_test, model):\n",
    "    prediction = model.predict_proba(x_test)[:,1]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_auc_score(predictions, y_test, with_plot):\n",
    "    scores = []\n",
    "    legend_text = []\n",
    "    for i in range(N_LABELS):\n",
    "        fpr, tpr, _  = roc_curve(y_test[:,i], predictions[:,i], 1)\n",
    "        scores.append(roc_auc_score(y_test[:,i], predictions[:,i]))\n",
    "        legend_text.append(COLUMNS[i]+' (area = %.3f)' % (scores[i]))\n",
    "        if with_plot == True:\n",
    "            plt.plot(fpr, tpr)\n",
    "    if with_plot == True:\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curves')\n",
    "        plt.legend(legend_text)\n",
    "        plt.show()\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_metric_auc_score(predictions, y_test, with_plot):\n",
    "    fpr, tpr, _  = roc_curve(y_test, predictions, 1)\n",
    "    score = roc_auc_score(y_test, predictions)\n",
    "    print(COLUMNS[0]+' AUC score = %.3f' % (score))\n",
    "    if with_plot == True:\n",
    "        plt.plot(fpr, tpr)\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curves')\n",
    "        plt.show()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_auc_scores(prediction_total, test_data_total, subjects, with_plot):\n",
    "    scores = []\n",
    "    for subject in subjects:\n",
    "        score = metric_auc_score(prediction_total[subject-1],\n",
    "                                 test_data_total[subject-1], with_plot)\n",
    "        scores.append(score)\n",
    "        print('Mean AUC Score of Subject %d: %.3f' % \\\n",
    "              (subject, np.mean(score)))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission_file(name, ids_total, prediction_total, columns, path):\n",
    "    submission = pd.DataFrame(index = np.concatenate(ids_total), columns = columns,\n",
    "                              data = np.concatenate(prediction_total))\n",
    "    submission.to_csv(path+name, index_label = 'id', float_format = '%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_mappping(x_train, WINDOW_SIZE):\n",
    "    result = []\n",
    "    empty_matrix = np.atleast_3d(np.zeros(np.shape(x_train[0:WINDOW_SIZE])))\n",
    "    for i in range(len(x_train)):\n",
    "        if i-WINDOW_SIZE < 0:\n",
    "            result.append(empty_matrix)\n",
    "        else:\n",
    "            result.append(np.atleast_3d(x_train[i-WINDOW_SIZE:i]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_generator(x_train, y_train, WINDOW_SIZE):\n",
    "    x = image_mappping(x_train, WINDOW_SIZE)\n",
    "    while True:\n",
    "        for image, task in zip(x, y_train):\n",
    "            yield np.array([image]), np.array([task])\n",
    "\n",
    "\n",
    "# def generator(x_train, y_train, image_size):\n",
    "#     x_train = np.array_split(x_train, 10)\n",
    "#     y_train = np.array_split(y_train, 10)\n",
    "#     empty_matrix = np.expand_dims(np.zeros(np.shape(x_train[0][0:image_size])), axis=3)\n",
    "#     while True:\n",
    "#         for eeg, tasks in zip(x_train, y_train):\n",
    "#             for i in range(len(eeg)):\n",
    "#                 if i-image_size < 0:\n",
    "#                     yield np.array([empty_matrix]), np.array([tasks[i]])\n",
    "#                 else:\n",
    "#                     yield np.array([np.expand_dims(eeg[i-image_size:i],axis=3)]), np.array([tasks[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_generator(x_test, WINDOW_SIZE):\n",
    "    x = image_mappping(x_test, WINDOW_SIZE)\n",
    "    while True:\n",
    "        for image in x:\n",
    "            yield np.array([image])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_weights(y_train):\n",
    "    class_weight = class_weight.compute_class_weight('balanced', np.unique(y_train[:,0]), y_train[:,0])\n",
    "    return {0 : 1.,\n",
    "    1: class_weight[1],\n",
    "    2: class_weight[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_cnn(window):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                     input_shape=(window,32,1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense((2)))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.summary()\n",
    "    optimizer = Adam(lr=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# def init_cnn(window):\n",
    "#     model = Sequential()\n",
    "#     model.add(Conv2D(16, kernel_size=(30, 4), activation='relu', input_shape=(window,32,1)))\n",
    "#     model.add(Conv2D(32, (30, 4), activation='relu'))\n",
    "#     model.add(MaxPool2D(pool_size=(200, 4)))\n",
    "#     model.add(Dropout(0.25)) # Dropout 25% of the nodes of the previous layer during training\n",
    "#     model.add(Flatten())     # Flatten, and add a fully connected layer\n",
    "#     model.add(Dense(128, activation='relu')) \n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Dense((2), activation='softmax')) # Last layer: 10 class nodes, with dropout\n",
    "#     model.summary()\n",
    "#     optimizer = Adam(lr=0.001)\n",
    "#     model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train subject 1, class HandStart\n",
      "Train subject 1, class FirstDigitTouch\n",
      "Train subject 1, class BothStartLoadPhase\n",
      "Train subject 1, class LiftOff\n",
      "Train subject 1, class Replace\n",
      "Train subject 1, class BothReleased\n"
     ]
    }
   ],
   "source": [
    "prediction_total = []\n",
    "test_data_total = []\n",
    "ids_total = []\n",
    "for subject in SUBJECTS:\n",
    "    test_features_raw = []\n",
    "    train_data_paths = glob(TRAIN_DATA_PATH % (subject))\n",
    "#     test_data_paths =  glob(TEST_DATA_PATH % (subject))\n",
    "  \n",
    "    x_train, y_train = read_training_data(train_data_paths)  \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.5)\n",
    "    \n",
    "    x_train, scaler = scaler_transform(x_train, None)\n",
    "    x_test = scaler_transform(x_test, scaler)    \n",
    "\n",
    "#     predictions = np.empty((x_test.shape[0],6))\n",
    "# #     Below you define the model you want to use.\n",
    "#     logreg = LogisticRegression()\n",
    "#     for i in range(N_LABELS):\n",
    "#         print('Train subject %d, class %s' % (subject, COLUMNS[i]))\n",
    "#         model = train_model(x_train, y_train[:,i], logreg, SUBSAMPLE)\n",
    "#         predictions[:,i] = make_prediction(x_test, model)\n",
    "#     test_data_total.append(y_test)   \n",
    "#     prediction_total.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_31 (Conv2D)           (None, 500, 32, 32)       320       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 500, 32, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 498, 30, 32)       9248      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 498, 30, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 124, 7, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 124, 7, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 124, 7, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 124, 7, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 122, 5, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 122, 5, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 30, 1, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 30, 1, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 512)               983552    \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 1,049,570\n",
      "Trainable params: 1,049,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = init_cnn(window=WINDOW_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.0, 1: 18.17521083567595, 2: 0.5141441028525326}"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = to_categorical(y_train[:,0],num_classes = None)\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train[:,0]), y_train[:,0])\n",
    "class_weights = {0 : 1.,\n",
    "    1: class_weights[1],\n",
    "    2: class_weights[0]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 19513/711196 [..............................] - ETA: 2:06:00 - loss: 8.2719 - acc: 0.9716"
     ]
    }
   ],
   "source": [
    "my_generater = try_generator(x_train, labels, WINDOW_SIZE)\n",
    "\n",
    "model.fit_generator(my_generater, steps_per_epoch=len(x_train), epochs=20, class_weight=class_weights, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_test_generater = test_generator(x_test[::SUBSAMPLE], WINDOW_SIZE)\n",
    "predictions = model.predict_generator(my_test_generater, steps=len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [711196, 7112]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-308-58a640ac1dea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlabels_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msingle_metric_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-5ec5f08d3d17>\u001b[0m in \u001b[0;36msingle_metric_auc_score\u001b[1;34m(predictions, y_test, with_plot)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msingle_metric_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwith_plot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCOLUMNS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m' AUC score = %.3f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mwith_plot\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sebastiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[0;32m    532\u001b[0m     \"\"\"\n\u001b[0;32m    533\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[1;32m--> 534\u001b[1;33m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    535\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m     \u001b[1;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sebastiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0} format is not supported\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[0my_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sebastiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 204\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [711196, 7112]"
     ]
    }
   ],
   "source": [
    "labels_test = to_categorical(y_test[:,0],num_classes = None)\n",
    "\n",
    "score = single_metric_auc_score(predictions[:, 1], labels_test[:,0], True)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = to_categorical(y_train[:,0],num_classes = None)\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train[:,0]), y_train[:,0])\n",
    "class_weights = {0 : 1.,\n",
    "    1: class_weights[0],\n",
    "    2: class_weights[1]}\n",
    "\n",
    "my_generater = try_generator(x_train, labels, WINDOW_SIZE)\n",
    "\n",
    "model.fit_generator(my_generater, steps_per_epoch=len(x_train), epochs=20, class_weight=class_weights, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test = to_categorical(y_test[:,0],num_classes = None)\n",
    "\n",
    "score = single_metric_auc_score(predictions[:, 1], labels_test[:,0], True)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores = all_auc_scores(prediction_total, test_data_total, SUBJECTS, with_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Mean Columnwise AUC ROC Score: %.3f, %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The script below is for kaggle submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################KAGGLE SUBMISSION CODE\n",
    "\n",
    "# prediction_total= []\n",
    "# ids_total = []\n",
    "# for subject in SUBJECTS:\n",
    "#     test_features_raw = []\n",
    "#     train_data_paths = glob(TRAIN_DATA_PATH % (subject))\n",
    "#     test_data_paths =  glob(TEST_DATA_PATH % (subject))\n",
    "  \n",
    "#     x_train, y_train = read_training_data(train_data_paths)\n",
    "#     x_test, ids = read_test_data(test_data_paths)\n",
    "#     ids_total.append(ids)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Below you can put preprocessing functions. You can make a decision in which method to use\n",
    "    #by commenting certain lines or not.#     x_train = butter_worth(x_train, CUTT_OFF_FREQUENCY, SAMPLE_FREQUENCY, ORDER)\n",
    "#     x_test = butter_worth(x_test, CUTT_OFF_FREQUENCY, SAMPLE_FREQUENCY, ORDER)\n",
    "#     x_train, pca_model = pca_transform(x_train, PCA_COMPONENTS, None)\n",
    "#     x_test = pca_transform(x_test, PCA_COMPONENTS, pca_model)\n",
    "#     x_train, scaler = scaler_transform(x_train, None)\n",
    "#     x_test = scaler_transform(x_test, scaler)\n",
    "#     #############################################\n",
    "    \n",
    "#     predictions = np.empty((x_test.shape[0],6))\n",
    "#     #Below you define the model you want to use.\n",
    "#     logreg = LogisticRegression()\n",
    "#     for i in range(N_LABELS):\n",
    "#         print('Train subject %d, class %s' % (subject, COLUMNS[i]))\n",
    "#         model = train_model(x_train, y_train[:,i], logreg, SUBSAMPLE)\n",
    "#         predictions[:,i] = make_prediction(x_test, model)\n",
    "        \n",
    "#     prediction_total.append(predictions)\n",
    "\n",
    "# make_submission_file(SUBMISSION_NAME, ids_total, prediction_total, COLUMNS, SUBMISSION_FOLDER)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
