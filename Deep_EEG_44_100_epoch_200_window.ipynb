{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sebastiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam, Adadelta, SGD\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPool2D, Dropout, Flatten, Conv1D, GlobalAveragePooling1D, Convolution1D\n",
    "from keras.layers.convolutional import MaxPooling2D, MaxPooling1D\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.utils import class_weight\n",
    "from scipy import signal\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants:\n",
    "SUBSAMPLE = 10  # scales the data by this factor\n",
    "COLUMNS = ['HandStart', 'FirstDigitTouch',\n",
    "        'BothStartLoadPhase', 'LiftOff',\n",
    "        'Replace', 'BothReleased']\n",
    "TRAIN_SUBJECTS = range(9, 13)\n",
    "TEST_SUBJECTS = range(9, 13)\n",
    "N_LABELS = 6\n",
    "\n",
    "# Below are the paths to the data. Please pay attention to the % and * signs, these are needed in the loop.\n",
    "TRAIN_DATA_PATH = 'C:/Users/Sebastiaan/Desktop/Programming/MachineLearning/Datasets/EEG/train/subj%d_series*_data.csv'\n",
    "# TRAIN_DATA_PATH = 'C:/Users/bas/Documents/MachineLearning/train/subj%d_series*_data.csv'\n",
    "\n",
    "EPOCHS = 100\n",
    "WINDOW_SIZE = 200\n",
    "SPLIT_SIZE = 50\n",
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_data(data_path):\n",
    "    data = pd.read_csv(data_path)\n",
    "    event_path = data_path.replace('_data', '_events')\n",
    "    labels = pd.read_csv(event_path)\n",
    "    clean_data = data.drop(['id'], axis = 1)\n",
    "    labels = labels.drop(['id'], axis = 1)\n",
    "    return clean_data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(x_raw, WINDOW_SIZE, subsample):\n",
    "    x_raw, scaler = scaler_transform(x_raw[::subsample], None)\n",
    "    x_raw = image_mappping(x_raw, WINDOW_SIZE)\n",
    "    return x_raw, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaler_transform(data, scaler):\n",
    "    if scaler == None:\n",
    "        scaler = Normalizer()\n",
    "        return scaler.fit_transform(data), scaler\n",
    "    else:\n",
    "        return scaler.transform(data)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_training_data(train_data_paths):\n",
    "    labels_raw = []\n",
    "    features_raw = []\n",
    "    for data_path in train_data_paths:\n",
    "        data, labels = prepare_training_data(data_path)\n",
    "        features_raw.append(data)\n",
    "        labels_raw.append(labels)\n",
    "    features_raw = pd.concat(features_raw)\n",
    "    labels_raw = pd.concat(labels_raw)\n",
    "    x_train = np.asarray(features_raw.astype(float))\n",
    "    y_train = np.asarray(labels_raw.astype(float))\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_auc_score(predictions, y_test, with_plot):\n",
    "    scores = []\n",
    "    legend_text = []\n",
    "    for i in range(N_LABELS):\n",
    "        fpr, tpr, _  = roc_curve(y_test[:,i], predictions[:,i], 1)\n",
    "        scores.append(roc_auc_score(y_test[:,i], predictions[:,i]))\n",
    "        legend_text.append(COLUMNS[i]+' (area = %.3f)' % (scores[i]))\n",
    "        if with_plot == True:\n",
    "            plt.plot(fpr, tpr)\n",
    "    if with_plot == True:\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curves')\n",
    "        plt.legend(legend_text)\n",
    "        plt.show()\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_metric_auc_score(prediction_total, test_data_total, with_plot):\n",
    "    legend_text = []\n",
    "    counter = 0\n",
    "    for i in range(len(prediction_total)):\n",
    "        fpr, tpr, _  = roc_curve(test_data_total[i], prediction_total[i], pos_label=1)\n",
    "        score = roc_auc_score(test_data_total[i],prediction_total[i])\n",
    "        legend_text.append(COLUMNS[i]+' (area = %.3f)' % (score))\n",
    "        print(COLUMNS[i]+' AUC score = %.3f' % (score))\n",
    "        plt.plot(fpr, tpr)\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curves')\n",
    "        plt.legend(legend_text)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_metric_auc_score(predictions, y_test, with_plot, i):\n",
    "    fpr, tpr, _  = roc_curve(y_test, predictions, 1)\n",
    "    score = roc_auc_score(y_test, predictions)\n",
    "    print(COLUMNS[i]+' AUC score = %.3f' % (score))\n",
    "    if with_plot == True:\n",
    "        plt.plot(fpr, tpr)\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curves')\n",
    "        plt.show()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_auc_scores(prediction_total, test_data_total, subjects, with_plot):\n",
    "    scores = []\n",
    "    for subject in subjects:\n",
    "        score = metric_auc_score(prediction_total[subject-1],\n",
    "                                 test_data_total[subject-1], with_plot)\n",
    "        scores.append(score)\n",
    "        print('Mean AUC Score of Subject %d: %.3f' % \\\n",
    "              (subject, np.mean(score)))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_mappping(x_train, WINDOW_SIZE):\n",
    "    result = []\n",
    "    empty_matrix = np.zeros(np.shape(x_train[0:WINDOW_SIZE]))\n",
    "    for i in range(len(x_train)):\n",
    "        if i-WINDOW_SIZE < 0:\n",
    "            result.append(empty_matrix)\n",
    "        else:\n",
    "            result.append(x_train[i-WINDOW_SIZE:i])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_and_shuffle(labels):\n",
    "    when_task = np.where(labels == 1)\n",
    "    when_no_task = np.where(labels == 0)\n",
    "    when_no_task = when_no_task[0][0:len(when_task[0])]\n",
    "    indices = np.concatenate([when_task[0], when_no_task])\n",
    "    np.random.shuffle(indices)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_set(indices, x_train, y_train):\n",
    "    balance_x = []\n",
    "    balance_y = []\n",
    "    for index in indices:\n",
    "        balance_x.append(x_train[index])\n",
    "        balance_y.append(y_train[index])\n",
    "    return balance_x, balance_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_imbalance(x_train, y_train):\n",
    "    indices = resample_and_shuffle(y_train)\n",
    "    balanced_x_train, balanced_y_train = balance_set(indices, x_train, y_train)\n",
    "    return balanced_x_train, balanced_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_sub(x_test, model, split_size, batch_size):\n",
    "    split_size = int(len(x_test) / split_size)\n",
    "    sub_x_test = x_test[1000::batch_size]\n",
    "    batch = []\n",
    "    predictions = np.array([])\n",
    "    for i in range(len(sub_x_test)):\n",
    "        batch.append(sub_x_test[i])\n",
    "        if i+1 == len(sub_x_test):\n",
    "            return np.concatenate([predictions, model.predict(np.array(batch))[:,1]])\n",
    "        elif (i+1) % split_size == 0:\n",
    "            predictions = np.concatenate([predictions, model.predict(np.array(batch))[:,1]])\n",
    "            batch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_cnn(window):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(nb_filter=16, filter_length=3, activation='relu', input_shape=(window, 32)))\n",
    "    model.add(MaxPooling1D(3,2))\n",
    "    model.add(Conv1D(nb_filter=32, filter_length=3, activation='relu'))\n",
    "    model.add(Conv1D(nb_filter=64, filter_length=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(3,2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "#     model.summary()\n",
    "    \n",
    "    optimizer = SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)\n",
    "#     optimizer = Adam(lr=1e-6)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\sebastiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "47768 47768\n",
      "Train subject 9, class HandStart\n",
      "Train on 1752 samples, validate on 438 samples\n",
      "Epoch 1/100\n",
      "1752/1752 [==============================] - 6s 3ms/step - loss: 0.6942 - acc: 0.4943 - val_loss: 0.6941 - val_acc: 0.4863\n",
      "Epoch 2/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.6938 - acc: 0.5131 - val_loss: 0.6938 - val_acc: 0.5046\n",
      "Epoch 3/100\n",
      "1752/1752 [==============================] - 1s 318us/step - loss: 0.6941 - acc: 0.5057 - val_loss: 0.6936 - val_acc: 0.5000\n",
      "Epoch 4/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.6927 - acc: 0.5245 - val_loss: 0.6933 - val_acc: 0.5251\n",
      "Epoch 5/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.6932 - acc: 0.5166 - val_loss: 0.6931 - val_acc: 0.5160\n",
      "Epoch 6/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.6928 - acc: 0.5188 - val_loss: 0.6929 - val_acc: 0.5046\n",
      "Epoch 7/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.6944 - acc: 0.5000 - val_loss: 0.6927 - val_acc: 0.5137\n",
      "Epoch 8/100\n",
      "1752/1752 [==============================] - 1s 318us/step - loss: 0.6924 - acc: 0.5274 - val_loss: 0.6925 - val_acc: 0.5183\n",
      "Epoch 9/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.6937 - acc: 0.5091 - val_loss: 0.6923 - val_acc: 0.5205\n",
      "Epoch 10/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.6925 - acc: 0.5211 - val_loss: 0.6921 - val_acc: 0.5342\n",
      "Epoch 11/100\n",
      "1752/1752 [==============================] - 1s 344us/step - loss: 0.6923 - acc: 0.5143 - val_loss: 0.6920 - val_acc: 0.5388\n",
      "Epoch 12/100\n",
      "1752/1752 [==============================] - 1s 321us/step - loss: 0.6926 - acc: 0.5086 - val_loss: 0.6918 - val_acc: 0.5388\n",
      "Epoch 13/100\n",
      "1752/1752 [==============================] - 1s 315us/step - loss: 0.6911 - acc: 0.5303 - val_loss: 0.6916 - val_acc: 0.5457\n",
      "Epoch 14/100\n",
      "1752/1752 [==============================] - 1s 316us/step - loss: 0.6923 - acc: 0.5063 - val_loss: 0.6915 - val_acc: 0.5479\n",
      "Epoch 15/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.6926 - acc: 0.5228 - val_loss: 0.6913 - val_acc: 0.5525\n",
      "Epoch 16/100\n",
      "1752/1752 [==============================] - 1s 340us/step - loss: 0.6926 - acc: 0.5051 - val_loss: 0.6911 - val_acc: 0.5685\n",
      "Epoch 17/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.6923 - acc: 0.5223 - val_loss: 0.6909 - val_acc: 0.5594\n",
      "Epoch 18/100\n",
      "1752/1752 [==============================] - 1s 365us/step - loss: 0.6908 - acc: 0.5251 - val_loss: 0.6908 - val_acc: 0.5685\n",
      "Epoch 19/100\n",
      "1752/1752 [==============================] - 1s 359us/step - loss: 0.6907 - acc: 0.5257 - val_loss: 0.6906 - val_acc: 0.5753\n",
      "Epoch 20/100\n",
      "1752/1752 [==============================] - 1s 321us/step - loss: 0.6911 - acc: 0.5263 - val_loss: 0.6905 - val_acc: 0.5731\n",
      "Epoch 21/100\n",
      "1752/1752 [==============================] - 1s 320us/step - loss: 0.6913 - acc: 0.5257 - val_loss: 0.6903 - val_acc: 0.5822\n",
      "Epoch 22/100\n",
      "1752/1752 [==============================] - 1s 315us/step - loss: 0.6900 - acc: 0.5451 - val_loss: 0.6901 - val_acc: 0.5845\n",
      "Epoch 23/100\n",
      "1752/1752 [==============================] - 1s 344us/step - loss: 0.6912 - acc: 0.5280 - val_loss: 0.6900 - val_acc: 0.5822\n",
      "Epoch 24/100\n",
      "1752/1752 [==============================] - 1s 355us/step - loss: 0.6922 - acc: 0.5274 - val_loss: 0.6898 - val_acc: 0.5890\n",
      "Epoch 25/100\n",
      "1752/1752 [==============================] - 1s 319us/step - loss: 0.6929 - acc: 0.5057 - val_loss: 0.6896 - val_acc: 0.5822\n",
      "Epoch 26/100\n",
      "1752/1752 [==============================] - 1s 317us/step - loss: 0.6918 - acc: 0.5274 - val_loss: 0.6895 - val_acc: 0.5799\n",
      "Epoch 27/100\n",
      "1752/1752 [==============================] - 1s 316us/step - loss: 0.6926 - acc: 0.5143 - val_loss: 0.6893 - val_acc: 0.5776\n",
      "Epoch 28/100\n",
      "1752/1752 [==============================] - 1s 310us/step - loss: 0.6905 - acc: 0.5205 - val_loss: 0.6891 - val_acc: 0.5868\n",
      "Epoch 29/100\n",
      "1752/1752 [==============================] - 1s 321us/step - loss: 0.6894 - acc: 0.5377 - val_loss: 0.6889 - val_acc: 0.5936\n",
      "Epoch 30/100\n",
      "1752/1752 [==============================] - 1s 339us/step - loss: 0.6899 - acc: 0.5365 - val_loss: 0.6888 - val_acc: 0.5913\n",
      "Epoch 31/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.6890 - acc: 0.5434 - val_loss: 0.6886 - val_acc: 0.5936\n",
      "Epoch 32/100\n",
      "1752/1752 [==============================] - 1s 316us/step - loss: 0.6896 - acc: 0.5314 - val_loss: 0.6884 - val_acc: 0.6005\n",
      "Epoch 33/100\n",
      "1752/1752 [==============================] - 1s 316us/step - loss: 0.6876 - acc: 0.5616 - val_loss: 0.6882 - val_acc: 0.5982\n",
      "Epoch 34/100\n",
      "1752/1752 [==============================] - 1s 319us/step - loss: 0.6890 - acc: 0.5508 - val_loss: 0.6880 - val_acc: 0.6005\n",
      "Epoch 35/100\n",
      "1752/1752 [==============================] - 1s 318us/step - loss: 0.6903 - acc: 0.5303 - val_loss: 0.6879 - val_acc: 0.6073\n",
      "Epoch 36/100\n",
      "1752/1752 [==============================] - 1s 321us/step - loss: 0.6900 - acc: 0.5474 - val_loss: 0.6877 - val_acc: 0.6050\n",
      "Epoch 37/100\n",
      "1752/1752 [==============================] - 1s 312us/step - loss: 0.6873 - acc: 0.5542 - val_loss: 0.6875 - val_acc: 0.6210\n",
      "Epoch 38/100\n",
      "1752/1752 [==============================] - 1s 314us/step - loss: 0.6897 - acc: 0.5320 - val_loss: 0.6873 - val_acc: 0.6256\n",
      "Epoch 39/100\n",
      "1752/1752 [==============================] - 1s 320us/step - loss: 0.6867 - acc: 0.5691 - val_loss: 0.6871 - val_acc: 0.6256\n",
      "Epoch 40/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.6871 - acc: 0.5594 - val_loss: 0.6868 - val_acc: 0.6256\n",
      "Epoch 41/100\n",
      "1752/1752 [==============================] - ETA: 0s - loss: 0.6883 - acc: 0.549 - 1s 327us/step - loss: 0.6884 - acc: 0.5491 - val_loss: 0.6866 - val_acc: 0.6301\n",
      "Epoch 42/100\n",
      "1752/1752 [==============================] - 1s 318us/step - loss: 0.6885 - acc: 0.5451 - val_loss: 0.6864 - val_acc: 0.6324\n",
      "Epoch 43/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.6896 - acc: 0.5251 - val_loss: 0.6862 - val_acc: 0.6324\n",
      "Epoch 44/100\n",
      "1752/1752 [==============================] - 1s 309us/step - loss: 0.6882 - acc: 0.5565 - val_loss: 0.6860 - val_acc: 0.6347\n",
      "Epoch 45/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.6907 - acc: 0.5325 - val_loss: 0.6858 - val_acc: 0.6187\n",
      "Epoch 46/100\n",
      "1752/1752 [==============================] - 1s 348us/step - loss: 0.6875 - acc: 0.5594 - val_loss: 0.6855 - val_acc: 0.6233\n",
      "Epoch 47/100\n",
      "1752/1752 [==============================] - 1s 311us/step - loss: 0.6857 - acc: 0.5651 - val_loss: 0.6853 - val_acc: 0.6301\n",
      "Epoch 48/100\n",
      "1752/1752 [==============================] - 1s 314us/step - loss: 0.6868 - acc: 0.5656 - val_loss: 0.6850 - val_acc: 0.6301\n",
      "Epoch 49/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.6877 - acc: 0.5468 - val_loss: 0.6847 - val_acc: 0.6347\n",
      "Epoch 50/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.6857 - acc: 0.5685 - val_loss: 0.6845 - val_acc: 0.6370\n",
      "Epoch 51/100\n",
      "1752/1752 [==============================] - 1s 321us/step - loss: 0.6860 - acc: 0.5542 - val_loss: 0.6842 - val_acc: 0.6416\n",
      "Epoch 52/100\n",
      "1752/1752 [==============================] - 1s 311us/step - loss: 0.6854 - acc: 0.5656 - val_loss: 0.6839 - val_acc: 0.6416\n",
      "Epoch 53/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.6862 - acc: 0.5656 - val_loss: 0.6836 - val_acc: 0.6438\n",
      "Epoch 54/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.6863 - acc: 0.5651 - val_loss: 0.6834 - val_acc: 0.6461\n",
      "Epoch 55/100\n",
      "1752/1752 [==============================] - 1s 316us/step - loss: 0.6872 - acc: 0.5508 - val_loss: 0.6831 - val_acc: 0.6484\n",
      "Epoch 56/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.6869 - acc: 0.5725 - val_loss: 0.6828 - val_acc: 0.6507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.6865 - acc: 0.5514 - val_loss: 0.6824 - val_acc: 0.6507\n",
      "Epoch 58/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.6829 - acc: 0.5959 - val_loss: 0.6821 - val_acc: 0.6598\n",
      "Epoch 59/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.6845 - acc: 0.5839 - val_loss: 0.6818 - val_acc: 0.6530\n",
      "Epoch 60/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.6853 - acc: 0.5576 - val_loss: 0.6814 - val_acc: 0.6598\n",
      "Epoch 61/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.6841 - acc: 0.5856 - val_loss: 0.6810 - val_acc: 0.6598\n",
      "Epoch 62/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.6838 - acc: 0.5713 - val_loss: 0.6806 - val_acc: 0.6575\n",
      "Epoch 63/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.6835 - acc: 0.5833 - val_loss: 0.6802 - val_acc: 0.6644\n",
      "Epoch 64/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.6793 - acc: 0.6039 - val_loss: 0.6799 - val_acc: 0.6689\n",
      "Epoch 65/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.6826 - acc: 0.5782 - val_loss: 0.6794 - val_acc: 0.6689\n",
      "Epoch 66/100\n",
      "1752/1752 [==============================] - 1s 351us/step - loss: 0.6834 - acc: 0.5833 - val_loss: 0.6790 - val_acc: 0.6735\n",
      "Epoch 67/100\n",
      "1752/1752 [==============================] - 1s 361us/step - loss: 0.6812 - acc: 0.5850 - val_loss: 0.6786 - val_acc: 0.6689\n",
      "Epoch 68/100\n",
      "1752/1752 [==============================] - 1s 389us/step - loss: 0.6813 - acc: 0.5930 - val_loss: 0.6782 - val_acc: 0.6712\n",
      "Epoch 69/100\n",
      "1752/1752 [==============================] - 1s 353us/step - loss: 0.6808 - acc: 0.5925 - val_loss: 0.6777 - val_acc: 0.6712\n",
      "Epoch 70/100\n",
      "1752/1752 [==============================] - 1s 378us/step - loss: 0.6835 - acc: 0.5759 - val_loss: 0.6773 - val_acc: 0.6735\n",
      "Epoch 71/100\n",
      "1752/1752 [==============================] - 1s 371us/step - loss: 0.6818 - acc: 0.5850 - val_loss: 0.6769 - val_acc: 0.6758\n",
      "Epoch 72/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.6779 - acc: 0.6050 - val_loss: 0.6764 - val_acc: 0.6712\n",
      "Epoch 73/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.6795 - acc: 0.5856 - val_loss: 0.6761 - val_acc: 0.6712\n",
      "Epoch 74/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.6801 - acc: 0.5953 - val_loss: 0.6755 - val_acc: 0.6758\n",
      "Epoch 75/100\n",
      "1752/1752 [==============================] - 1s 335us/step - loss: 0.6806 - acc: 0.5902 - val_loss: 0.6751 - val_acc: 0.6735\n",
      "Epoch 76/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.6763 - acc: 0.6153 - val_loss: 0.6745 - val_acc: 0.6735\n",
      "Epoch 77/100\n",
      "1752/1752 [==============================] - 1s 319us/step - loss: 0.6795 - acc: 0.5993 - val_loss: 0.6739 - val_acc: 0.6758\n",
      "Epoch 78/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.6788 - acc: 0.5959 - val_loss: 0.6732 - val_acc: 0.6735\n",
      "Epoch 79/100\n",
      "1752/1752 [==============================] - 1s 344us/step - loss: 0.6790 - acc: 0.5862 - val_loss: 0.6728 - val_acc: 0.6735\n",
      "Epoch 80/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.6766 - acc: 0.6033 - val_loss: 0.6722 - val_acc: 0.6712\n",
      "Epoch 81/100\n",
      "1752/1752 [==============================] - 1s 348us/step - loss: 0.6754 - acc: 0.6176 - val_loss: 0.6716 - val_acc: 0.6712\n",
      "Epoch 82/100\n",
      "1752/1752 [==============================] - 1s 359us/step - loss: 0.6763 - acc: 0.5953 - val_loss: 0.6709 - val_acc: 0.6712\n",
      "Epoch 83/100\n",
      "1752/1752 [==============================] - 1s 340us/step - loss: 0.6743 - acc: 0.6107 - val_loss: 0.6702 - val_acc: 0.6758\n",
      "Epoch 84/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.6728 - acc: 0.6090 - val_loss: 0.6695 - val_acc: 0.6804\n",
      "Epoch 85/100\n",
      "1752/1752 [==============================] - 1s 345us/step - loss: 0.6786 - acc: 0.5868 - val_loss: 0.6688 - val_acc: 0.6826\n",
      "Epoch 86/100\n",
      "1752/1752 [==============================] - 1s 341us/step - loss: 0.6751 - acc: 0.6090 - val_loss: 0.6681 - val_acc: 0.6804\n",
      "Epoch 87/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.6741 - acc: 0.5982 - val_loss: 0.6674 - val_acc: 0.6804\n",
      "Epoch 88/100\n",
      "1752/1752 [==============================] - 1s 340us/step - loss: 0.6745 - acc: 0.6136 - val_loss: 0.6667 - val_acc: 0.6849\n",
      "Epoch 89/100\n",
      "1752/1752 [==============================] - 1s 357us/step - loss: 0.6711 - acc: 0.6142 - val_loss: 0.6659 - val_acc: 0.6826\n",
      "Epoch 90/100\n",
      "1752/1752 [==============================] - 1s 347us/step - loss: 0.6714 - acc: 0.6056 - val_loss: 0.6652 - val_acc: 0.6849\n",
      "Epoch 91/100\n",
      "1752/1752 [==============================] - 1s 347us/step - loss: 0.6733 - acc: 0.6113 - val_loss: 0.6644 - val_acc: 0.6826\n",
      "Epoch 92/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.6709 - acc: 0.6067 - val_loss: 0.6636 - val_acc: 0.6826\n",
      "Epoch 93/100\n",
      "1752/1752 [==============================] - 1s 350us/step - loss: 0.6695 - acc: 0.6164 - val_loss: 0.6628 - val_acc: 0.6735\n",
      "Epoch 94/100\n",
      "1752/1752 [==============================] - 1s 356us/step - loss: 0.6691 - acc: 0.6182 - val_loss: 0.6619 - val_acc: 0.6758\n",
      "Epoch 95/100\n",
      "1752/1752 [==============================] - 1s 374us/step - loss: 0.6681 - acc: 0.6204 - val_loss: 0.6611 - val_acc: 0.6781\n",
      "Epoch 96/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.6699 - acc: 0.6039 - val_loss: 0.6602 - val_acc: 0.6781\n",
      "Epoch 97/100\n",
      "1752/1752 [==============================] - 1s 353us/step - loss: 0.6698 - acc: 0.6221 - val_loss: 0.6593 - val_acc: 0.6804\n",
      "Epoch 98/100\n",
      "1752/1752 [==============================] - 1s 367us/step - loss: 0.6656 - acc: 0.6170 - val_loss: 0.6582 - val_acc: 0.6849\n",
      "Epoch 99/100\n",
      "1752/1752 [==============================] - 1s 367us/step - loss: 0.6644 - acc: 0.6307 - val_loss: 0.6573 - val_acc: 0.6781\n",
      "Epoch 100/100\n",
      "1752/1752 [==============================] - 1s 386us/step - loss: 0.6642 - acc: 0.6313 - val_loss: 0.6561 - val_acc: 0.6781\n",
      "Train on 1752 samples, validate on 438 samples\n",
      "Epoch 1/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.6621 - acc: 0.6318 - val_loss: 0.6518 - val_acc: 0.6986\n",
      "Epoch 2/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.6644 - acc: 0.6170 - val_loss: 0.6507 - val_acc: 0.7032\n",
      "Epoch 3/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.6618 - acc: 0.6290 - val_loss: 0.6496 - val_acc: 0.7100\n",
      "Epoch 4/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.6637 - acc: 0.6153 - val_loss: 0.6484 - val_acc: 0.7123\n",
      "Epoch 5/100\n",
      "1752/1752 [==============================] - 1s 338us/step - loss: 0.6583 - acc: 0.6370 - val_loss: 0.6471 - val_acc: 0.7100\n",
      "Epoch 6/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.6580 - acc: 0.6387 - val_loss: 0.6458 - val_acc: 0.7123\n",
      "Epoch 7/100\n",
      "1752/1752 [==============================] - 1s 367us/step - loss: 0.6587 - acc: 0.6273 - val_loss: 0.6446 - val_acc: 0.7123\n",
      "Epoch 8/100\n",
      "1752/1752 [==============================] - 1s 340us/step - loss: 0.6589 - acc: 0.6416 - val_loss: 0.6432 - val_acc: 0.7215\n",
      "Epoch 9/100\n",
      "1752/1752 [==============================] - 1s 363us/step - loss: 0.6549 - acc: 0.6478 - val_loss: 0.6418 - val_acc: 0.7169\n",
      "Epoch 10/100\n",
      "1752/1752 [==============================] - 1s 349us/step - loss: 0.6546 - acc: 0.6416 - val_loss: 0.6405 - val_acc: 0.7169\n",
      "Epoch 11/100\n",
      "1752/1752 [==============================] - 1s 355us/step - loss: 0.6538 - acc: 0.6398 - val_loss: 0.6391 - val_acc: 0.7169\n",
      "Epoch 12/100\n",
      "1752/1752 [==============================] - 1s 344us/step - loss: 0.6519 - acc: 0.6393 - val_loss: 0.6376 - val_acc: 0.7146\n",
      "Epoch 13/100\n",
      "1752/1752 [==============================] - 1s 363us/step - loss: 0.6518 - acc: 0.6324 - val_loss: 0.6363 - val_acc: 0.7146\n",
      "Epoch 14/100\n",
      "1752/1752 [==============================] - 1s 351us/step - loss: 0.6504 - acc: 0.6478 - val_loss: 0.6348 - val_acc: 0.7146\n",
      "Epoch 15/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.6496 - acc: 0.6467 - val_loss: 0.6333 - val_acc: 0.7123\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1752/1752 [==============================] - 1s 320us/step - loss: 0.6482 - acc: 0.6398 - val_loss: 0.6318 - val_acc: 0.7169\n",
      "Epoch 17/100\n",
      "1752/1752 [==============================] - 1s 319us/step - loss: 0.6502 - acc: 0.6370 - val_loss: 0.6305 - val_acc: 0.7146\n",
      "Epoch 18/100\n",
      "1752/1752 [==============================] - 1s 319us/step - loss: 0.6439 - acc: 0.6461 - val_loss: 0.6290 - val_acc: 0.7169\n",
      "Epoch 19/100\n",
      "1752/1752 [==============================] - 1s 319us/step - loss: 0.6468 - acc: 0.6438 - val_loss: 0.6276 - val_acc: 0.7169\n",
      "Epoch 20/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.6416 - acc: 0.6592 - val_loss: 0.6262 - val_acc: 0.7146\n",
      "Epoch 21/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.6444 - acc: 0.6398 - val_loss: 0.6248 - val_acc: 0.7146\n",
      "Epoch 22/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.6422 - acc: 0.6398 - val_loss: 0.6234 - val_acc: 0.7146\n",
      "Epoch 23/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.6394 - acc: 0.6478 - val_loss: 0.6220 - val_acc: 0.7237\n",
      "Epoch 24/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.6327 - acc: 0.6604 - val_loss: 0.6202 - val_acc: 0.7146\n",
      "Epoch 25/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.6322 - acc: 0.6581 - val_loss: 0.6187 - val_acc: 0.7146\n",
      "Epoch 26/100\n",
      "1752/1752 [==============================] - 1s 318us/step - loss: 0.6300 - acc: 0.6667 - val_loss: 0.6171 - val_acc: 0.7146\n",
      "Epoch 27/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.6349 - acc: 0.6444 - val_loss: 0.6157 - val_acc: 0.7123\n",
      "Epoch 28/100\n",
      "1752/1752 [==============================] - 1s 319us/step - loss: 0.6264 - acc: 0.6604 - val_loss: 0.6140 - val_acc: 0.7146\n",
      "Epoch 29/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.6307 - acc: 0.6575 - val_loss: 0.6127 - val_acc: 0.7169\n",
      "Epoch 30/100\n",
      "1752/1752 [==============================] - 1s 319us/step - loss: 0.6300 - acc: 0.6684 - val_loss: 0.6113 - val_acc: 0.7146\n",
      "Epoch 31/100\n",
      "1752/1752 [==============================] - 1s 320us/step - loss: 0.6295 - acc: 0.6610 - val_loss: 0.6102 - val_acc: 0.7192\n",
      "Epoch 32/100\n",
      "1752/1752 [==============================] - 1s 339us/step - loss: 0.6275 - acc: 0.6592 - val_loss: 0.6088 - val_acc: 0.7146\n",
      "Epoch 33/100\n",
      "1752/1752 [==============================] - 1s 321us/step - loss: 0.6237 - acc: 0.6604 - val_loss: 0.6075 - val_acc: 0.7123\n",
      "Epoch 34/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.6264 - acc: 0.6604 - val_loss: 0.6065 - val_acc: 0.7237\n",
      "Epoch 35/100\n",
      "1752/1752 [==============================] - 1s 320us/step - loss: 0.6273 - acc: 0.6615 - val_loss: 0.6055 - val_acc: 0.7260\n",
      "Epoch 36/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.6233 - acc: 0.6598 - val_loss: 0.6043 - val_acc: 0.7260\n",
      "Epoch 37/100\n",
      "1752/1752 [==============================] - 1s 321us/step - loss: 0.6210 - acc: 0.6718 - val_loss: 0.6032 - val_acc: 0.7215\n",
      "Epoch 38/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.6182 - acc: 0.6655 - val_loss: 0.6021 - val_acc: 0.7283\n",
      "Epoch 39/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.6178 - acc: 0.6718 - val_loss: 0.6010 - val_acc: 0.7146\n",
      "Epoch 40/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.6166 - acc: 0.6621 - val_loss: 0.5998 - val_acc: 0.7146\n",
      "Epoch 41/100\n",
      "1752/1752 [==============================] - 1s 317us/step - loss: 0.6189 - acc: 0.6672 - val_loss: 0.5987 - val_acc: 0.7146\n",
      "Epoch 42/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.6243 - acc: 0.6689 - val_loss: 0.5979 - val_acc: 0.7237\n",
      "Epoch 43/100\n",
      "1752/1752 [==============================] - 1s 321us/step - loss: 0.6145 - acc: 0.6735 - val_loss: 0.5969 - val_acc: 0.7260\n",
      "Epoch 44/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.6153 - acc: 0.6775 - val_loss: 0.5958 - val_acc: 0.7237\n",
      "Epoch 45/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.6151 - acc: 0.6741 - val_loss: 0.5948 - val_acc: 0.7260\n",
      "Epoch 46/100\n",
      "1752/1752 [==============================] - 1s 316us/step - loss: 0.6167 - acc: 0.6592 - val_loss: 0.5938 - val_acc: 0.7215\n",
      "Epoch 47/100\n",
      "1752/1752 [==============================] - 1s 321us/step - loss: 0.6101 - acc: 0.6735 - val_loss: 0.5929 - val_acc: 0.7215\n",
      "Epoch 48/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.6157 - acc: 0.6661 - val_loss: 0.5918 - val_acc: 0.7192\n",
      "Epoch 49/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.6139 - acc: 0.6689 - val_loss: 0.5909 - val_acc: 0.7237\n",
      "Epoch 50/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.6106 - acc: 0.6798 - val_loss: 0.5898 - val_acc: 0.7237\n",
      "Epoch 51/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.6127 - acc: 0.6775 - val_loss: 0.5890 - val_acc: 0.7237\n",
      "Epoch 52/100\n",
      "1752/1752 [==============================] - 1s 314us/step - loss: 0.6069 - acc: 0.6718 - val_loss: 0.5881 - val_acc: 0.7260\n",
      "Epoch 53/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.6047 - acc: 0.6804 - val_loss: 0.5871 - val_acc: 0.7260\n",
      "Epoch 54/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.6031 - acc: 0.6866 - val_loss: 0.5860 - val_acc: 0.7283\n",
      "Epoch 55/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.6059 - acc: 0.6792 - val_loss: 0.5850 - val_acc: 0.7283\n",
      "Epoch 56/100\n",
      "1752/1752 [==============================] - 1s 316us/step - loss: 0.6038 - acc: 0.6632 - val_loss: 0.5841 - val_acc: 0.7260\n",
      "Epoch 57/100\n",
      "1752/1752 [==============================] - 1s 320us/step - loss: 0.5970 - acc: 0.6855 - val_loss: 0.5830 - val_acc: 0.7283\n",
      "Epoch 58/100\n",
      "1752/1752 [==============================] - 1s 321us/step - loss: 0.6098 - acc: 0.6792 - val_loss: 0.5821 - val_acc: 0.7237\n",
      "Epoch 59/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.6034 - acc: 0.6769 - val_loss: 0.5811 - val_acc: 0.7306\n",
      "Epoch 60/100\n",
      "1752/1752 [==============================] - 1s 319us/step - loss: 0.6002 - acc: 0.6872 - val_loss: 0.5800 - val_acc: 0.7283\n",
      "Epoch 61/100\n",
      "1752/1752 [==============================] - 1s 319us/step - loss: 0.6059 - acc: 0.6815 - val_loss: 0.5792 - val_acc: 0.7283\n",
      "Epoch 62/100\n",
      "1752/1752 [==============================] - 1s 339us/step - loss: 0.5955 - acc: 0.6849 - val_loss: 0.5784 - val_acc: 0.7283\n",
      "Epoch 63/100\n",
      "1752/1752 [==============================] - 1s 321us/step - loss: 0.6001 - acc: 0.6884 - val_loss: 0.5775 - val_acc: 0.7283\n",
      "Epoch 64/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.6039 - acc: 0.6826 - val_loss: 0.5768 - val_acc: 0.7352\n",
      "Epoch 65/100\n",
      "1752/1752 [==============================] - 1s 318us/step - loss: 0.5924 - acc: 0.6889 - val_loss: 0.5757 - val_acc: 0.7329\n",
      "Epoch 66/100\n",
      "1752/1752 [==============================] - 1s 341us/step - loss: 0.5975 - acc: 0.6861 - val_loss: 0.5747 - val_acc: 0.7306\n",
      "Epoch 67/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.6007 - acc: 0.6809 - val_loss: 0.5738 - val_acc: 0.7260\n",
      "Epoch 68/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.5951 - acc: 0.6895 - val_loss: 0.5730 - val_acc: 0.7352\n",
      "Epoch 69/100\n",
      "1752/1752 [==============================] - 1s 352us/step - loss: 0.5962 - acc: 0.6861 - val_loss: 0.5721 - val_acc: 0.7374\n",
      "Epoch 70/100\n",
      "1752/1752 [==============================] - 1s 344us/step - loss: 0.5902 - acc: 0.6878 - val_loss: 0.5710 - val_acc: 0.7329\n",
      "Epoch 71/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.5968 - acc: 0.6895 - val_loss: 0.5699 - val_acc: 0.7329\n",
      "Epoch 72/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.5899 - acc: 0.6963 - val_loss: 0.5689 - val_acc: 0.7329\n",
      "Epoch 73/100\n",
      "1752/1752 [==============================] - 1s 345us/step - loss: 0.5948 - acc: 0.6946 - val_loss: 0.5682 - val_acc: 0.7352\n",
      "Epoch 74/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.5922 - acc: 0.6861 - val_loss: 0.5672 - val_acc: 0.7306\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.5908 - acc: 0.6986 - val_loss: 0.5662 - val_acc: 0.7352\n",
      "Epoch 76/100\n",
      "1752/1752 [==============================] - 1s 348us/step - loss: 0.5951 - acc: 0.6855 - val_loss: 0.5653 - val_acc: 0.7374\n",
      "Epoch 77/100\n",
      "1752/1752 [==============================] - 1s 351us/step - loss: 0.5904 - acc: 0.6929 - val_loss: 0.5647 - val_acc: 0.7420\n",
      "Epoch 78/100\n",
      "1752/1752 [==============================] - 1s 365us/step - loss: 0.5908 - acc: 0.6866 - val_loss: 0.5634 - val_acc: 0.7352\n",
      "Epoch 79/100\n",
      "1752/1752 [==============================] - 1s 374us/step - loss: 0.5853 - acc: 0.7021 - val_loss: 0.5623 - val_acc: 0.7352\n",
      "Epoch 80/100\n",
      "1752/1752 [==============================] - 1s 364us/step - loss: 0.5839 - acc: 0.6918 - val_loss: 0.5614 - val_acc: 0.7352\n",
      "Epoch 81/100\n",
      "1752/1752 [==============================] - 1s 354us/step - loss: 0.5848 - acc: 0.6918 - val_loss: 0.5604 - val_acc: 0.7397\n",
      "Epoch 82/100\n",
      "1752/1752 [==============================] - 1s 357us/step - loss: 0.5840 - acc: 0.7072 - val_loss: 0.5594 - val_acc: 0.7397\n",
      "Epoch 83/100\n",
      "1752/1752 [==============================] - 1s 350us/step - loss: 0.5793 - acc: 0.7072 - val_loss: 0.5583 - val_acc: 0.7397\n",
      "Epoch 84/100\n",
      "1752/1752 [==============================] - 1s 352us/step - loss: 0.5848 - acc: 0.6998 - val_loss: 0.5574 - val_acc: 0.7420\n",
      "Epoch 85/100\n",
      "1752/1752 [==============================] - 1s 347us/step - loss: 0.5824 - acc: 0.7026 - val_loss: 0.5566 - val_acc: 0.7420\n",
      "Epoch 86/100\n",
      "1752/1752 [==============================] - 1s 347us/step - loss: 0.5795 - acc: 0.7049 - val_loss: 0.5556 - val_acc: 0.7443\n",
      "Epoch 87/100\n",
      "1752/1752 [==============================] - 1s 347us/step - loss: 0.5855 - acc: 0.6992 - val_loss: 0.5548 - val_acc: 0.7374\n",
      "Epoch 88/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.5794 - acc: 0.6998 - val_loss: 0.5538 - val_acc: 0.7443\n",
      "Epoch 89/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.5751 - acc: 0.7100 - val_loss: 0.5528 - val_acc: 0.7443\n",
      "Epoch 90/100\n",
      "1752/1752 [==============================] - 1s 367us/step - loss: 0.5773 - acc: 0.6992 - val_loss: 0.5518 - val_acc: 0.7397\n",
      "Epoch 91/100\n",
      "1752/1752 [==============================] - 1s 367us/step - loss: 0.5777 - acc: 0.7066 - val_loss: 0.5509 - val_acc: 0.7443\n",
      "Epoch 92/100\n",
      "1752/1752 [==============================] - 1s 366us/step - loss: 0.5815 - acc: 0.7078 - val_loss: 0.5502 - val_acc: 0.7489\n",
      "Epoch 93/100\n",
      "1752/1752 [==============================] - 1s 408us/step - loss: 0.5767 - acc: 0.7026 - val_loss: 0.5494 - val_acc: 0.7397\n",
      "Epoch 94/100\n",
      "1752/1752 [==============================] - 1s 351us/step - loss: 0.5779 - acc: 0.7026 - val_loss: 0.5481 - val_acc: 0.7489\n",
      "Epoch 95/100\n",
      "1752/1752 [==============================] - 1s 337us/step - loss: 0.5821 - acc: 0.6946 - val_loss: 0.5473 - val_acc: 0.7466\n",
      "Epoch 96/100\n",
      "1752/1752 [==============================] - 1s 341us/step - loss: 0.5780 - acc: 0.7140 - val_loss: 0.5464 - val_acc: 0.7466\n",
      "Epoch 97/100\n",
      "1752/1752 [==============================] - 1s 335us/step - loss: 0.5767 - acc: 0.7049 - val_loss: 0.5455 - val_acc: 0.7489\n",
      "Epoch 98/100\n",
      "1752/1752 [==============================] - 1s 342us/step - loss: 0.5808 - acc: 0.6998 - val_loss: 0.5447 - val_acc: 0.7489\n",
      "Epoch 99/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.5763 - acc: 0.7003 - val_loss: 0.5437 - val_acc: 0.7466\n",
      "Epoch 100/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.5737 - acc: 0.7061 - val_loss: 0.5431 - val_acc: 0.7489\n",
      "Test subject 9, class HandStart\n",
      "Train subject 9, class FirstDigitTouch\n",
      "Train on 1752 samples, validate on 438 samples\n",
      "Epoch 1/100\n",
      "1752/1752 [==============================] - 1s 568us/step - loss: 0.6955 - acc: 0.4903 - val_loss: 0.6929 - val_acc: 0.5137\n",
      "Epoch 2/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.6948 - acc: 0.5177 - val_loss: 0.6925 - val_acc: 0.5251\n",
      "Epoch 3/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.6917 - acc: 0.5320 - val_loss: 0.6920 - val_acc: 0.5342\n",
      "Epoch 4/100\n",
      "1752/1752 [==============================] - 1s 341us/step - loss: 0.6937 - acc: 0.5080 - val_loss: 0.6917 - val_acc: 0.5731\n",
      "Epoch 5/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.6924 - acc: 0.5217 - val_loss: 0.6912 - val_acc: 0.5639\n",
      "Epoch 6/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.6946 - acc: 0.5006 - val_loss: 0.6908 - val_acc: 0.5434\n",
      "Epoch 7/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.6918 - acc: 0.5257 - val_loss: 0.6904 - val_acc: 0.5297\n",
      "Epoch 8/100\n",
      "1752/1752 [==============================] - 1s 338us/step - loss: 0.6898 - acc: 0.5485 - val_loss: 0.6901 - val_acc: 0.5251\n",
      "Epoch 9/100\n",
      "1752/1752 [==============================] - 1s 346us/step - loss: 0.6910 - acc: 0.5348 - val_loss: 0.6897 - val_acc: 0.5205\n",
      "Epoch 10/100\n",
      "1752/1752 [==============================] - 1s 344us/step - loss: 0.6897 - acc: 0.5371 - val_loss: 0.6893 - val_acc: 0.5068\n",
      "Epoch 11/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.6897 - acc: 0.5360 - val_loss: 0.6889 - val_acc: 0.4977\n",
      "Epoch 12/100\n",
      "1752/1752 [==============================] - 1s 335us/step - loss: 0.6897 - acc: 0.5514 - val_loss: 0.6884 - val_acc: 0.5000\n",
      "Epoch 13/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.6882 - acc: 0.5576 - val_loss: 0.6880 - val_acc: 0.5023\n",
      "Epoch 14/100\n",
      "1752/1752 [==============================] - 1s 343us/step - loss: 0.6904 - acc: 0.5268 - val_loss: 0.6875 - val_acc: 0.5068\n",
      "Epoch 15/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.6882 - acc: 0.5491 - val_loss: 0.6870 - val_acc: 0.5068\n",
      "Epoch 16/100\n",
      "1752/1752 [==============================] - 1s 349us/step - loss: 0.6892 - acc: 0.5462 - val_loss: 0.6865 - val_acc: 0.5091\n",
      "Epoch 17/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.6855 - acc: 0.5805 - val_loss: 0.6860 - val_acc: 0.5068\n",
      "Epoch 18/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.6881 - acc: 0.5462 - val_loss: 0.6854 - val_acc: 0.5137\n",
      "Epoch 19/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.6879 - acc: 0.5537 - val_loss: 0.6848 - val_acc: 0.5183\n",
      "Epoch 20/100\n",
      "1752/1752 [==============================] - 1s 349us/step - loss: 0.6850 - acc: 0.5759 - val_loss: 0.6841 - val_acc: 0.5297\n",
      "Epoch 21/100\n",
      "1752/1752 [==============================] - 1s 335us/step - loss: 0.6864 - acc: 0.5731 - val_loss: 0.6834 - val_acc: 0.5342\n",
      "Epoch 22/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.6851 - acc: 0.5622 - val_loss: 0.6827 - val_acc: 0.5342\n",
      "Epoch 23/100\n",
      "1752/1752 [==============================] - 1s 339us/step - loss: 0.6843 - acc: 0.5776 - val_loss: 0.6819 - val_acc: 0.5457\n",
      "Epoch 24/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.6850 - acc: 0.5850 - val_loss: 0.6812 - val_acc: 0.5571\n",
      "Epoch 25/100\n",
      "1752/1752 [==============================] - 1s 345us/step - loss: 0.6819 - acc: 0.5896 - val_loss: 0.6804 - val_acc: 0.5708\n",
      "Epoch 26/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.6852 - acc: 0.5782 - val_loss: 0.6796 - val_acc: 0.5753\n",
      "Epoch 27/100\n",
      "1752/1752 [==============================] - 1s 339us/step - loss: 0.6824 - acc: 0.5936 - val_loss: 0.6788 - val_acc: 0.5845\n",
      "Epoch 28/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.6829 - acc: 0.5856 - val_loss: 0.6779 - val_acc: 0.5936\n",
      "Epoch 29/100\n",
      "1752/1752 [==============================] - 1s 342us/step - loss: 0.6819 - acc: 0.5976 - val_loss: 0.6770 - val_acc: 0.6005\n",
      "Epoch 30/100\n",
      "1752/1752 [==============================] - 1s 341us/step - loss: 0.6785 - acc: 0.6164 - val_loss: 0.6760 - val_acc: 0.6142\n",
      "Epoch 31/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.6806 - acc: 0.6039 - val_loss: 0.6750 - val_acc: 0.6256\n",
      "Epoch 32/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.6796 - acc: 0.5993 - val_loss: 0.6741 - val_acc: 0.6301\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1752/1752 [==============================] - 1s 344us/step - loss: 0.6763 - acc: 0.6124 - val_loss: 0.6728 - val_acc: 0.6416\n",
      "Epoch 34/100\n",
      "1752/1752 [==============================] - 1s 335us/step - loss: 0.6777 - acc: 0.6199 - val_loss: 0.6716 - val_acc: 0.6484\n",
      "Epoch 35/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.6758 - acc: 0.6296 - val_loss: 0.6705 - val_acc: 0.6461\n",
      "Epoch 36/100\n",
      "1752/1752 [==============================] - 1s 335us/step - loss: 0.6756 - acc: 0.6387 - val_loss: 0.6692 - val_acc: 0.6598\n",
      "Epoch 37/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.6728 - acc: 0.6387 - val_loss: 0.6679 - val_acc: 0.6667\n",
      "Epoch 38/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.6720 - acc: 0.6376 - val_loss: 0.6664 - val_acc: 0.6804\n",
      "Epoch 39/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.6702 - acc: 0.6501 - val_loss: 0.6648 - val_acc: 0.6849\n",
      "Epoch 40/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.6711 - acc: 0.6410 - val_loss: 0.6634 - val_acc: 0.6849\n",
      "Epoch 41/100\n",
      "1752/1752 [==============================] - 1s 338us/step - loss: 0.6708 - acc: 0.6467 - val_loss: 0.6618 - val_acc: 0.6941\n",
      "Epoch 42/100\n",
      "1752/1752 [==============================] - 1s 343us/step - loss: 0.6690 - acc: 0.6513 - val_loss: 0.6601 - val_acc: 0.7032\n",
      "Epoch 43/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.6630 - acc: 0.6718 - val_loss: 0.6581 - val_acc: 0.7078\n",
      "Epoch 44/100\n",
      "1752/1752 [==============================] - 1s 342us/step - loss: 0.6660 - acc: 0.6592 - val_loss: 0.6562 - val_acc: 0.7146\n",
      "Epoch 45/100\n",
      "1752/1752 [==============================] - 1s 350us/step - loss: 0.6631 - acc: 0.6655 - val_loss: 0.6542 - val_acc: 0.7169\n",
      "Epoch 46/100\n",
      "1752/1752 [==============================] - 1s 346us/step - loss: 0.6628 - acc: 0.6832 - val_loss: 0.6521 - val_acc: 0.7192\n",
      "Epoch 47/100\n",
      "1752/1752 [==============================] - 1s 338us/step - loss: 0.6616 - acc: 0.6792 - val_loss: 0.6498 - val_acc: 0.7237\n",
      "Epoch 48/100\n",
      "1752/1752 [==============================] - 1s 344us/step - loss: 0.6568 - acc: 0.6884 - val_loss: 0.6473 - val_acc: 0.7306\n",
      "Epoch 49/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.6564 - acc: 0.6826 - val_loss: 0.6447 - val_acc: 0.7283\n",
      "Epoch 50/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.6519 - acc: 0.6998 - val_loss: 0.6418 - val_acc: 0.7283\n",
      "Epoch 51/100\n",
      "1752/1752 [==============================] - 1s 344us/step - loss: 0.6517 - acc: 0.6958 - val_loss: 0.6390 - val_acc: 0.7306\n",
      "Epoch 52/100\n",
      "1752/1752 [==============================] - 1s 345us/step - loss: 0.6478 - acc: 0.7146 - val_loss: 0.6358 - val_acc: 0.7352\n",
      "Epoch 53/100\n",
      "1752/1752 [==============================] - 1s 348us/step - loss: 0.6456 - acc: 0.7072 - val_loss: 0.6326 - val_acc: 0.7352\n",
      "Epoch 54/100\n",
      "1752/1752 [==============================] - 1s 410us/step - loss: 0.6422 - acc: 0.7180 - val_loss: 0.6289 - val_acc: 0.7374\n",
      "Epoch 55/100\n",
      "1752/1752 [==============================] - 1s 399us/step - loss: 0.6411 - acc: 0.7146 - val_loss: 0.6251 - val_acc: 0.7420\n",
      "Epoch 56/100\n",
      "1752/1752 [==============================] - 1s 342us/step - loss: 0.6373 - acc: 0.7215 - val_loss: 0.6212 - val_acc: 0.7420\n",
      "Epoch 57/100\n",
      "1752/1752 [==============================] - 1s 341us/step - loss: 0.6355 - acc: 0.7283 - val_loss: 0.6170 - val_acc: 0.7420\n",
      "Epoch 58/100\n",
      "1752/1752 [==============================] - 1s 342us/step - loss: 0.6322 - acc: 0.7220 - val_loss: 0.6124 - val_acc: 0.7511\n",
      "Epoch 59/100\n",
      "1752/1752 [==============================] - 1s 340us/step - loss: 0.6237 - acc: 0.7460 - val_loss: 0.6077 - val_acc: 0.7557\n",
      "Epoch 60/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.6210 - acc: 0.7432 - val_loss: 0.6024 - val_acc: 0.7603\n",
      "Epoch 61/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.6188 - acc: 0.7334 - val_loss: 0.5968 - val_acc: 0.7580\n",
      "Epoch 62/100\n",
      "1752/1752 [==============================] - 1s 343us/step - loss: 0.6114 - acc: 0.7506 - val_loss: 0.5910 - val_acc: 0.7626\n",
      "Epoch 63/100\n",
      "1752/1752 [==============================] - 1s 341us/step - loss: 0.6086 - acc: 0.7357 - val_loss: 0.5853 - val_acc: 0.7671\n",
      "Epoch 64/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.6014 - acc: 0.7500 - val_loss: 0.5787 - val_acc: 0.7671\n",
      "Epoch 65/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.6002 - acc: 0.7414 - val_loss: 0.5720 - val_acc: 0.7740\n",
      "Epoch 66/100\n",
      "1752/1752 [==============================] - 1s 345us/step - loss: 0.5874 - acc: 0.7683 - val_loss: 0.5652 - val_acc: 0.7740\n",
      "Epoch 67/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.5834 - acc: 0.7574 - val_loss: 0.5578 - val_acc: 0.7717\n",
      "Epoch 68/100\n",
      "1752/1752 [==============================] - 1s 343us/step - loss: 0.5795 - acc: 0.7608 - val_loss: 0.5502 - val_acc: 0.7785\n",
      "Epoch 69/100\n",
      "1752/1752 [==============================] - 1s 378us/step - loss: 0.5689 - acc: 0.7728 - val_loss: 0.5419 - val_acc: 0.7808\n",
      "Epoch 70/100\n",
      "1752/1752 [==============================] - 1s 357us/step - loss: 0.5596 - acc: 0.7671 - val_loss: 0.5337 - val_acc: 0.7785\n",
      "Epoch 71/100\n",
      "1752/1752 [==============================] - 1s 367us/step - loss: 0.5511 - acc: 0.7808 - val_loss: 0.5252 - val_acc: 0.7785\n",
      "Epoch 72/100\n",
      "1752/1752 [==============================] - 1s 357us/step - loss: 0.5499 - acc: 0.7751 - val_loss: 0.5177 - val_acc: 0.7877\n",
      "Epoch 73/100\n",
      "1752/1752 [==============================] - 1s 405us/step - loss: 0.5433 - acc: 0.7740 - val_loss: 0.5105 - val_acc: 0.7900\n",
      "Epoch 74/100\n",
      "1752/1752 [==============================] - 1s 351us/step - loss: 0.5367 - acc: 0.7700 - val_loss: 0.5013 - val_acc: 0.7854\n",
      "Epoch 75/100\n",
      "1752/1752 [==============================] - 1s 342us/step - loss: 0.5229 - acc: 0.7848 - val_loss: 0.4931 - val_acc: 0.7922\n",
      "Epoch 76/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.5155 - acc: 0.7865 - val_loss: 0.4866 - val_acc: 0.7945\n",
      "Epoch 77/100\n",
      "1752/1752 [==============================] - 1s 321us/step - loss: 0.5064 - acc: 0.7842 - val_loss: 0.4784 - val_acc: 0.7968\n",
      "Epoch 78/100\n",
      "1752/1752 [==============================] - 1s 343us/step - loss: 0.4916 - acc: 0.8014 - val_loss: 0.4721 - val_acc: 0.7991\n",
      "Epoch 79/100\n",
      "1752/1752 [==============================] - 1s 339us/step - loss: 0.4926 - acc: 0.7871 - val_loss: 0.4638 - val_acc: 0.7991\n",
      "Epoch 80/100\n",
      "1752/1752 [==============================] - 1s 319us/step - loss: 0.4891 - acc: 0.7900 - val_loss: 0.4594 - val_acc: 0.7991\n",
      "Epoch 81/100\n",
      "1752/1752 [==============================] - ETA: 0s - loss: 0.4708 - acc: 0.803 - 1s 324us/step - loss: 0.4762 - acc: 0.7968 - val_loss: 0.4497 - val_acc: 0.8037\n",
      "Epoch 82/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.4673 - acc: 0.8082 - val_loss: 0.4458 - val_acc: 0.8014\n",
      "Epoch 83/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.4665 - acc: 0.8019 - val_loss: 0.4397 - val_acc: 0.8082\n",
      "Epoch 84/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.4543 - acc: 0.8065 - val_loss: 0.4338 - val_acc: 0.8105\n",
      "Epoch 85/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.4470 - acc: 0.8111 - val_loss: 0.4289 - val_acc: 0.8151\n",
      "Epoch 86/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.4379 - acc: 0.8088 - val_loss: 0.4262 - val_acc: 0.8174\n",
      "Epoch 87/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.4348 - acc: 0.8151 - val_loss: 0.4207 - val_acc: 0.8151\n",
      "Epoch 88/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.4330 - acc: 0.8253 - val_loss: 0.4180 - val_acc: 0.8174\n",
      "Epoch 89/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.4220 - acc: 0.8208 - val_loss: 0.4151 - val_acc: 0.8174\n",
      "Epoch 90/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.4258 - acc: 0.8213 - val_loss: 0.4135 - val_acc: 0.8196\n",
      "Epoch 91/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.4225 - acc: 0.8253 - val_loss: 0.4089 - val_acc: 0.8196\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.4190 - acc: 0.8248 - val_loss: 0.4064 - val_acc: 0.8219\n",
      "Epoch 93/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.4053 - acc: 0.8225 - val_loss: 0.4052 - val_acc: 0.8219\n",
      "Epoch 94/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.4193 - acc: 0.8174 - val_loss: 0.4058 - val_acc: 0.8219\n",
      "Epoch 95/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.4099 - acc: 0.8259 - val_loss: 0.4015 - val_acc: 0.8288\n",
      "Epoch 96/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.4149 - acc: 0.8196 - val_loss: 0.3982 - val_acc: 0.8288\n",
      "Epoch 97/100\n",
      "1752/1752 [==============================] - 1s 321us/step - loss: 0.4098 - acc: 0.8179 - val_loss: 0.4023 - val_acc: 0.8242\n",
      "Epoch 98/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.4019 - acc: 0.8202 - val_loss: 0.3958 - val_acc: 0.8288\n",
      "Epoch 99/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.3994 - acc: 0.8288 - val_loss: 0.3923 - val_acc: 0.8265\n",
      "Epoch 100/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.3967 - acc: 0.8299 - val_loss: 0.3920 - val_acc: 0.8265\n",
      "Train on 1752 samples, validate on 438 samples\n",
      "Epoch 1/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.4159 - acc: 0.8134 - val_loss: 0.3540 - val_acc: 0.8333\n",
      "Epoch 2/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.4231 - acc: 0.8122 - val_loss: 0.3523 - val_acc: 0.8379\n",
      "Epoch 3/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.4179 - acc: 0.8151 - val_loss: 0.3507 - val_acc: 0.8379\n",
      "Epoch 4/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.4183 - acc: 0.8196 - val_loss: 0.3484 - val_acc: 0.8402\n",
      "Epoch 5/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.4200 - acc: 0.8122 - val_loss: 0.3487 - val_acc: 0.8402\n",
      "Epoch 6/100\n",
      "1752/1752 [==============================] - 1s 320us/step - loss: 0.4140 - acc: 0.8116 - val_loss: 0.3472 - val_acc: 0.8425\n",
      "Epoch 7/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.4147 - acc: 0.8196 - val_loss: 0.3430 - val_acc: 0.8470\n",
      "Epoch 8/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.4061 - acc: 0.8242 - val_loss: 0.3426 - val_acc: 0.8493\n",
      "Epoch 9/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.3980 - acc: 0.8293 - val_loss: 0.3433 - val_acc: 0.8493\n",
      "Epoch 10/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.4116 - acc: 0.8191 - val_loss: 0.3380 - val_acc: 0.8539\n",
      "Epoch 11/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.4032 - acc: 0.8208 - val_loss: 0.3358 - val_acc: 0.8607\n",
      "Epoch 12/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.4021 - acc: 0.8219 - val_loss: 0.3364 - val_acc: 0.8584\n",
      "Epoch 13/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.4110 - acc: 0.8248 - val_loss: 0.3365 - val_acc: 0.8562\n",
      "Epoch 14/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.4072 - acc: 0.8299 - val_loss: 0.3342 - val_acc: 0.8607\n",
      "Epoch 15/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.3941 - acc: 0.8311 - val_loss: 0.3316 - val_acc: 0.8630\n",
      "Epoch 16/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.3994 - acc: 0.8271 - val_loss: 0.3328 - val_acc: 0.8607\n",
      "Epoch 17/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.3908 - acc: 0.8345 - val_loss: 0.3260 - val_acc: 0.8676\n",
      "Epoch 18/100\n",
      "1752/1752 [==============================] - 1s 340us/step - loss: 0.3908 - acc: 0.8288 - val_loss: 0.3284 - val_acc: 0.8653\n",
      "Epoch 19/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.3904 - acc: 0.8396 - val_loss: 0.3264 - val_acc: 0.8653\n",
      "Epoch 20/100\n",
      "1752/1752 [==============================] - 1s 343us/step - loss: 0.3943 - acc: 0.8311 - val_loss: 0.3229 - val_acc: 0.8676\n",
      "Epoch 21/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.3842 - acc: 0.8333 - val_loss: 0.3217 - val_acc: 0.8676\n",
      "Epoch 22/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.3820 - acc: 0.8390 - val_loss: 0.3216 - val_acc: 0.8676\n",
      "Epoch 23/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.3845 - acc: 0.8362 - val_loss: 0.3240 - val_acc: 0.8676\n",
      "Epoch 24/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.3885 - acc: 0.8333 - val_loss: 0.3203 - val_acc: 0.8676\n",
      "Epoch 25/100\n",
      "1752/1752 [==============================] - 1s 335us/step - loss: 0.3884 - acc: 0.8299 - val_loss: 0.3212 - val_acc: 0.8676\n",
      "Epoch 26/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.3783 - acc: 0.8379 - val_loss: 0.3227 - val_acc: 0.8721\n",
      "Epoch 27/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.3806 - acc: 0.8339 - val_loss: 0.3221 - val_acc: 0.8699\n",
      "Epoch 28/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.3907 - acc: 0.8333 - val_loss: 0.3180 - val_acc: 0.8699\n",
      "Epoch 29/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.3787 - acc: 0.8396 - val_loss: 0.3157 - val_acc: 0.8699\n",
      "Epoch 30/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.3882 - acc: 0.8305 - val_loss: 0.3115 - val_acc: 0.8699\n",
      "Epoch 31/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.3801 - acc: 0.8356 - val_loss: 0.3157 - val_acc: 0.8699\n",
      "Epoch 32/100\n",
      "1752/1752 [==============================] - 1s 321us/step - loss: 0.3782 - acc: 0.8373 - val_loss: 0.3162 - val_acc: 0.8699\n",
      "Epoch 33/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.3653 - acc: 0.8442 - val_loss: 0.3082 - val_acc: 0.8744\n",
      "Epoch 34/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.3732 - acc: 0.8430 - val_loss: 0.3098 - val_acc: 0.8721\n",
      "Epoch 35/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.3739 - acc: 0.8425 - val_loss: 0.3048 - val_acc: 0.8744\n",
      "Epoch 36/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.3818 - acc: 0.8345 - val_loss: 0.3066 - val_acc: 0.8744\n",
      "Epoch 37/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.3695 - acc: 0.8476 - val_loss: 0.3118 - val_acc: 0.8721\n",
      "Epoch 38/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.3680 - acc: 0.8408 - val_loss: 0.3100 - val_acc: 0.8744\n",
      "Epoch 39/100\n",
      "1752/1752 [==============================] - 1s 319us/step - loss: 0.3758 - acc: 0.8373 - val_loss: 0.3079 - val_acc: 0.8721\n",
      "Epoch 40/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.3703 - acc: 0.8425 - val_loss: 0.3068 - val_acc: 0.8721\n",
      "Epoch 41/100\n",
      "1752/1752 [==============================] - 1s 342us/step - loss: 0.3728 - acc: 0.8436 - val_loss: 0.3060 - val_acc: 0.8721\n",
      "Epoch 42/100\n",
      "1752/1752 [==============================] - 1s 350us/step - loss: 0.3709 - acc: 0.8430 - val_loss: 0.3020 - val_acc: 0.8767\n",
      "Epoch 43/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.3737 - acc: 0.8419 - val_loss: 0.3018 - val_acc: 0.8744\n",
      "Epoch 44/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.3623 - acc: 0.8550 - val_loss: 0.3060 - val_acc: 0.8744\n",
      "Epoch 45/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.3600 - acc: 0.8470 - val_loss: 0.2979 - val_acc: 0.8790\n",
      "Epoch 46/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.3642 - acc: 0.8442 - val_loss: 0.2986 - val_acc: 0.8790\n",
      "Epoch 47/100\n",
      "1752/1752 [==============================] - 1s 321us/step - loss: 0.3672 - acc: 0.8476 - val_loss: 0.2939 - val_acc: 0.8836\n",
      "Epoch 48/100\n",
      "1752/1752 [==============================] - 1s 335us/step - loss: 0.3617 - acc: 0.8527 - val_loss: 0.2943 - val_acc: 0.8836\n",
      "Epoch 49/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.3572 - acc: 0.8545 - val_loss: 0.2923 - val_acc: 0.8836\n",
      "Epoch 50/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.3669 - acc: 0.8442 - val_loss: 0.2927 - val_acc: 0.8836\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.3582 - acc: 0.8590 - val_loss: 0.2936 - val_acc: 0.8858\n",
      "Epoch 52/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.3682 - acc: 0.8505 - val_loss: 0.2948 - val_acc: 0.8836\n",
      "Epoch 53/100\n",
      "1752/1752 [==============================] - 1s 338us/step - loss: 0.3631 - acc: 0.8465 - val_loss: 0.2999 - val_acc: 0.8790\n",
      "Epoch 54/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.3618 - acc: 0.8453 - val_loss: 0.2921 - val_acc: 0.8858\n",
      "Epoch 55/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.3588 - acc: 0.8539 - val_loss: 0.2959 - val_acc: 0.8836\n",
      "Epoch 56/100\n",
      "1752/1752 [==============================] - ETA: 0s - loss: 0.3579 - acc: 0.849 - 1s 329us/step - loss: 0.3571 - acc: 0.8499 - val_loss: 0.2931 - val_acc: 0.8836\n",
      "Epoch 57/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.3532 - acc: 0.8493 - val_loss: 0.2951 - val_acc: 0.8836\n",
      "Epoch 58/100\n",
      "1752/1752 [==============================] - 1s 340us/step - loss: 0.3573 - acc: 0.8556 - val_loss: 0.2959 - val_acc: 0.8836\n",
      "Epoch 59/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.3529 - acc: 0.8562 - val_loss: 0.2856 - val_acc: 0.8858\n",
      "Epoch 60/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.3479 - acc: 0.8562 - val_loss: 0.2928 - val_acc: 0.8858\n",
      "Epoch 61/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.3509 - acc: 0.8584 - val_loss: 0.2879 - val_acc: 0.8904\n",
      "Epoch 62/100\n",
      "1752/1752 [==============================] - 1s 335us/step - loss: 0.3503 - acc: 0.8550 - val_loss: 0.2891 - val_acc: 0.8881\n",
      "Epoch 63/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.3480 - acc: 0.8487 - val_loss: 0.2827 - val_acc: 0.8904\n",
      "Epoch 64/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.3487 - acc: 0.8584 - val_loss: 0.2876 - val_acc: 0.8881\n",
      "Epoch 65/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.3513 - acc: 0.8556 - val_loss: 0.2838 - val_acc: 0.8904\n",
      "Epoch 66/100\n",
      "1752/1752 [==============================] - 1s 344us/step - loss: 0.3479 - acc: 0.8499 - val_loss: 0.2840 - val_acc: 0.8904\n",
      "Epoch 67/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.3578 - acc: 0.8533 - val_loss: 0.2819 - val_acc: 0.8904\n",
      "Epoch 68/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.3407 - acc: 0.8590 - val_loss: 0.2851 - val_acc: 0.8881\n",
      "Epoch 69/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.3435 - acc: 0.8624 - val_loss: 0.2844 - val_acc: 0.8881\n",
      "Epoch 70/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.3545 - acc: 0.8493 - val_loss: 0.2814 - val_acc: 0.8904\n",
      "Epoch 71/100\n",
      "1752/1752 [==============================] - 1s 340us/step - loss: 0.3470 - acc: 0.8539 - val_loss: 0.2787 - val_acc: 0.8950\n",
      "Epoch 72/100\n",
      "1752/1752 [==============================] - 1s 321us/step - loss: 0.3309 - acc: 0.8727 - val_loss: 0.2754 - val_acc: 0.8950\n",
      "Epoch 73/100\n",
      "1752/1752 [==============================] - 1s 321us/step - loss: 0.3390 - acc: 0.8687 - val_loss: 0.2781 - val_acc: 0.8950\n",
      "Epoch 74/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.3307 - acc: 0.8704 - val_loss: 0.2784 - val_acc: 0.8927\n",
      "Epoch 75/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.3383 - acc: 0.8602 - val_loss: 0.2822 - val_acc: 0.8927\n",
      "Epoch 76/100\n",
      "1752/1752 [==============================] - 1s 339us/step - loss: 0.3363 - acc: 0.8624 - val_loss: 0.2796 - val_acc: 0.8950\n",
      "Epoch 77/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.3355 - acc: 0.8602 - val_loss: 0.2783 - val_acc: 0.8950\n",
      "Epoch 78/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.3356 - acc: 0.8567 - val_loss: 0.2739 - val_acc: 0.8950\n",
      "Epoch 79/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.3337 - acc: 0.8642 - val_loss: 0.2728 - val_acc: 0.8950\n",
      "Epoch 80/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.3318 - acc: 0.8676 - val_loss: 0.2742 - val_acc: 0.8950\n",
      "Epoch 81/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.3320 - acc: 0.8590 - val_loss: 0.2735 - val_acc: 0.8950\n",
      "Epoch 82/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.3385 - acc: 0.8613 - val_loss: 0.2790 - val_acc: 0.8927\n",
      "Epoch 83/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.3306 - acc: 0.8642 - val_loss: 0.2670 - val_acc: 0.8995\n",
      "Epoch 84/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.3266 - acc: 0.8642 - val_loss: 0.2718 - val_acc: 0.8995\n",
      "Epoch 85/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.3332 - acc: 0.8687 - val_loss: 0.2730 - val_acc: 0.8995\n",
      "Epoch 86/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.3318 - acc: 0.8687 - val_loss: 0.2727 - val_acc: 0.9018\n",
      "Epoch 87/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.3256 - acc: 0.8653 - val_loss: 0.2687 - val_acc: 0.9041\n",
      "Epoch 88/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.3227 - acc: 0.8682 - val_loss: 0.2733 - val_acc: 0.9018\n",
      "Epoch 89/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.3346 - acc: 0.8590 - val_loss: 0.2683 - val_acc: 0.9064\n",
      "Epoch 90/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.3255 - acc: 0.8647 - val_loss: 0.2683 - val_acc: 0.9064\n",
      "Epoch 91/100\n",
      "1752/1752 [==============================] - 1s 321us/step - loss: 0.3209 - acc: 0.8704 - val_loss: 0.2696 - val_acc: 0.9041\n",
      "Epoch 92/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.3212 - acc: 0.8744 - val_loss: 0.2651 - val_acc: 0.9064\n",
      "Epoch 93/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.3278 - acc: 0.8704 - val_loss: 0.2706 - val_acc: 0.9041\n",
      "Epoch 94/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.3260 - acc: 0.8682 - val_loss: 0.2610 - val_acc: 0.9064\n",
      "Epoch 95/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.3048 - acc: 0.8779 - val_loss: 0.2663 - val_acc: 0.9064\n",
      "Epoch 96/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.3160 - acc: 0.8779 - val_loss: 0.2714 - val_acc: 0.9041\n",
      "Epoch 97/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.3166 - acc: 0.8767 - val_loss: 0.2666 - val_acc: 0.9041\n",
      "Epoch 98/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.3289 - acc: 0.8687 - val_loss: 0.2636 - val_acc: 0.9041\n",
      "Epoch 99/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.3156 - acc: 0.8801 - val_loss: 0.2589 - val_acc: 0.9087\n",
      "Epoch 100/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.3154 - acc: 0.8716 - val_loss: 0.2642 - val_acc: 0.9064\n",
      "Test subject 9, class FirstDigitTouch\n",
      "Train subject 9, class BothStartLoadPhase\n",
      "Train on 1752 samples, validate on 438 samples\n",
      "Epoch 1/100\n",
      "1752/1752 [==============================] - 1s 599us/step - loss: 0.6975 - acc: 0.5040 - val_loss: 0.6932 - val_acc: 0.4886\n",
      "Epoch 2/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.6911 - acc: 0.5217 - val_loss: 0.6921 - val_acc: 0.4886\n",
      "Epoch 3/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.6936 - acc: 0.5108 - val_loss: 0.6911 - val_acc: 0.4886\n",
      "Epoch 4/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.6940 - acc: 0.5148 - val_loss: 0.6901 - val_acc: 0.4909\n",
      "Epoch 5/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.6922 - acc: 0.5103 - val_loss: 0.6892 - val_acc: 0.4954\n",
      "Epoch 6/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.6917 - acc: 0.5280 - val_loss: 0.6883 - val_acc: 0.5046\n",
      "Epoch 7/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.6915 - acc: 0.5371 - val_loss: 0.6875 - val_acc: 0.5114\n",
      "Epoch 8/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.6884 - acc: 0.5337 - val_loss: 0.6866 - val_acc: 0.5251\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1752/1752 [==============================] - 1s 320us/step - loss: 0.6910 - acc: 0.5257 - val_loss: 0.6856 - val_acc: 0.5342\n",
      "Epoch 10/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.6893 - acc: 0.5205 - val_loss: 0.6846 - val_acc: 0.5571\n",
      "Epoch 11/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.6844 - acc: 0.5691 - val_loss: 0.6835 - val_acc: 0.5822\n",
      "Epoch 12/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.6847 - acc: 0.5542 - val_loss: 0.6824 - val_acc: 0.5936\n",
      "Epoch 13/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.6868 - acc: 0.5571 - val_loss: 0.6814 - val_acc: 0.6119\n",
      "Epoch 14/100\n",
      "1752/1752 [==============================] - 1s 347us/step - loss: 0.6851 - acc: 0.5497 - val_loss: 0.6803 - val_acc: 0.6073\n",
      "Epoch 15/100\n",
      "1752/1752 [==============================] - 1s 335us/step - loss: 0.6835 - acc: 0.5502 - val_loss: 0.6791 - val_acc: 0.6142\n",
      "Epoch 16/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.6856 - acc: 0.5457 - val_loss: 0.6779 - val_acc: 0.6256\n",
      "Epoch 17/100\n",
      "1752/1752 [==============================] - 1s 344us/step - loss: 0.6850 - acc: 0.5502 - val_loss: 0.6767 - val_acc: 0.6347\n",
      "Epoch 18/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.6808 - acc: 0.5559 - val_loss: 0.6754 - val_acc: 0.6416\n",
      "Epoch 19/100\n",
      "1752/1752 [==============================] - 1s 341us/step - loss: 0.6819 - acc: 0.5736 - val_loss: 0.6739 - val_acc: 0.6484\n",
      "Epoch 20/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.6780 - acc: 0.5919 - val_loss: 0.6724 - val_acc: 0.6575\n",
      "Epoch 21/100\n",
      "1752/1752 [==============================] - 1s 347us/step - loss: 0.6815 - acc: 0.5753 - val_loss: 0.6709 - val_acc: 0.6621\n",
      "Epoch 22/100\n",
      "1752/1752 [==============================] - 1s 338us/step - loss: 0.6801 - acc: 0.5828 - val_loss: 0.6693 - val_acc: 0.6712\n",
      "Epoch 23/100\n",
      "1752/1752 [==============================] - 1s 346us/step - loss: 0.6787 - acc: 0.5862 - val_loss: 0.6676 - val_acc: 0.6781\n",
      "Epoch 24/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.6784 - acc: 0.5765 - val_loss: 0.6660 - val_acc: 0.6781\n",
      "Epoch 25/100\n",
      "1752/1752 [==============================] - 1s 342us/step - loss: 0.6738 - acc: 0.6045 - val_loss: 0.6641 - val_acc: 0.6781\n",
      "Epoch 26/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.6742 - acc: 0.6050 - val_loss: 0.6622 - val_acc: 0.6781\n",
      "Epoch 27/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.6694 - acc: 0.6273 - val_loss: 0.6599 - val_acc: 0.6804\n",
      "Epoch 28/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.6701 - acc: 0.6216 - val_loss: 0.6577 - val_acc: 0.6941\n",
      "Epoch 29/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.6677 - acc: 0.6244 - val_loss: 0.6551 - val_acc: 0.6963\n",
      "Epoch 30/100\n",
      "1752/1752 [==============================] - 1s 339us/step - loss: 0.6700 - acc: 0.6159 - val_loss: 0.6526 - val_acc: 0.7009\n",
      "Epoch 31/100\n",
      "1752/1752 [==============================] - 1s 337us/step - loss: 0.6644 - acc: 0.6347 - val_loss: 0.6496 - val_acc: 0.7055\n",
      "Epoch 32/100\n",
      "1752/1752 [==============================] - 1s 339us/step - loss: 0.6602 - acc: 0.6301 - val_loss: 0.6465 - val_acc: 0.7032\n",
      "Epoch 33/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.6575 - acc: 0.6444 - val_loss: 0.6432 - val_acc: 0.7078\n",
      "Epoch 34/100\n",
      "1752/1752 [==============================] - 1s 346us/step - loss: 0.6550 - acc: 0.6627 - val_loss: 0.6396 - val_acc: 0.7078\n",
      "Epoch 35/100\n",
      "1752/1752 [==============================] - 1s 338us/step - loss: 0.6554 - acc: 0.6644 - val_loss: 0.6356 - val_acc: 0.7237\n",
      "Epoch 36/100\n",
      "1752/1752 [==============================] - 1s 342us/step - loss: 0.6483 - acc: 0.6684 - val_loss: 0.6312 - val_acc: 0.7306\n",
      "Epoch 37/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.6459 - acc: 0.6809 - val_loss: 0.6265 - val_acc: 0.7329\n",
      "Epoch 38/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.6445 - acc: 0.6707 - val_loss: 0.6214 - val_acc: 0.7374\n",
      "Epoch 39/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.6374 - acc: 0.6918 - val_loss: 0.6158 - val_acc: 0.7489\n",
      "Epoch 40/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.6331 - acc: 0.7049 - val_loss: 0.6096 - val_acc: 0.7580\n",
      "Epoch 41/100\n",
      "1752/1752 [==============================] - 1s 338us/step - loss: 0.6295 - acc: 0.7021 - val_loss: 0.6032 - val_acc: 0.7603\n",
      "Epoch 42/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.6222 - acc: 0.7220 - val_loss: 0.5960 - val_acc: 0.7626\n",
      "Epoch 43/100\n",
      "1752/1752 [==============================] - 1s 347us/step - loss: 0.6175 - acc: 0.7203 - val_loss: 0.5881 - val_acc: 0.7671\n",
      "Epoch 44/100\n",
      "1752/1752 [==============================] - 1s 341us/step - loss: 0.6124 - acc: 0.7255 - val_loss: 0.5803 - val_acc: 0.7785\n",
      "Epoch 45/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.6024 - acc: 0.7471 - val_loss: 0.5714 - val_acc: 0.7877\n",
      "Epoch 46/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.5943 - acc: 0.7426 - val_loss: 0.5627 - val_acc: 0.7900\n",
      "Epoch 47/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.5848 - acc: 0.7574 - val_loss: 0.5529 - val_acc: 0.7991\n",
      "Epoch 48/100\n",
      "1752/1752 [==============================] - 1s 340us/step - loss: 0.5757 - acc: 0.7705 - val_loss: 0.5427 - val_acc: 0.8082\n",
      "Epoch 49/100\n",
      "1752/1752 [==============================] - 1s 339us/step - loss: 0.5658 - acc: 0.7705 - val_loss: 0.5323 - val_acc: 0.8082\n",
      "Epoch 50/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.5564 - acc: 0.7717 - val_loss: 0.5215 - val_acc: 0.8128\n",
      "Epoch 51/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.5475 - acc: 0.7848 - val_loss: 0.5107 - val_acc: 0.8196\n",
      "Epoch 52/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.5315 - acc: 0.7877 - val_loss: 0.4986 - val_acc: 0.8219\n",
      "Epoch 53/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.5356 - acc: 0.7768 - val_loss: 0.4883 - val_acc: 0.8265\n",
      "Epoch 54/100\n",
      "1752/1752 [==============================] - 1s 339us/step - loss: 0.5195 - acc: 0.7848 - val_loss: 0.4782 - val_acc: 0.8311\n",
      "Epoch 55/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.5075 - acc: 0.7865 - val_loss: 0.4715 - val_acc: 0.8174\n",
      "Epoch 56/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.5046 - acc: 0.8002 - val_loss: 0.4607 - val_acc: 0.8288\n",
      "Epoch 57/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.4922 - acc: 0.8002 - val_loss: 0.4537 - val_acc: 0.8265\n",
      "Epoch 58/100\n",
      "1752/1752 [==============================] - 1s 343us/step - loss: 0.4795 - acc: 0.8076 - val_loss: 0.4458 - val_acc: 0.8265\n",
      "Epoch 59/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.4809 - acc: 0.8054 - val_loss: 0.4383 - val_acc: 0.8356\n",
      "Epoch 60/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.4733 - acc: 0.8094 - val_loss: 0.4336 - val_acc: 0.8288\n",
      "Epoch 61/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.4677 - acc: 0.8196 - val_loss: 0.4281 - val_acc: 0.8333\n",
      "Epoch 62/100\n",
      "1752/1752 [==============================] - 1s 342us/step - loss: 0.4607 - acc: 0.8139 - val_loss: 0.4238 - val_acc: 0.8311\n",
      "Epoch 63/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.4507 - acc: 0.8116 - val_loss: 0.4176 - val_acc: 0.8333\n",
      "Epoch 64/100\n",
      "1752/1752 [==============================] - 1s 340us/step - loss: 0.4496 - acc: 0.8156 - val_loss: 0.4142 - val_acc: 0.8379\n",
      "Epoch 65/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.4518 - acc: 0.8065 - val_loss: 0.4118 - val_acc: 0.8356\n",
      "Epoch 66/100\n",
      "1752/1752 [==============================] - 1s 340us/step - loss: 0.4342 - acc: 0.8362 - val_loss: 0.4081 - val_acc: 0.8379\n",
      "Epoch 67/100\n",
      "1752/1752 [==============================] - 1s 335us/step - loss: 0.4414 - acc: 0.8202 - val_loss: 0.4030 - val_acc: 0.8447\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1752/1752 [==============================] - 1s 338us/step - loss: 0.4324 - acc: 0.8322 - val_loss: 0.3994 - val_acc: 0.8425\n",
      "Epoch 69/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.4316 - acc: 0.8271 - val_loss: 0.3979 - val_acc: 0.8425\n",
      "Epoch 70/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.4301 - acc: 0.8168 - val_loss: 0.3957 - val_acc: 0.8425\n",
      "Epoch 71/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.4237 - acc: 0.8293 - val_loss: 0.3954 - val_acc: 0.8425\n",
      "Epoch 72/100\n",
      "1752/1752 [==============================] - 1s 335us/step - loss: 0.4227 - acc: 0.8339 - val_loss: 0.3944 - val_acc: 0.8425\n",
      "Epoch 73/100\n",
      "1752/1752 [==============================] - 1s 351us/step - loss: 0.4165 - acc: 0.8333 - val_loss: 0.3897 - val_acc: 0.8447\n",
      "Epoch 74/100\n",
      "1752/1752 [==============================] - 1s 346us/step - loss: 0.4171 - acc: 0.8345 - val_loss: 0.3899 - val_acc: 0.8402\n",
      "Epoch 75/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.4185 - acc: 0.8413 - val_loss: 0.3857 - val_acc: 0.8470\n",
      "Epoch 76/100\n",
      "1752/1752 [==============================] - 1s 337us/step - loss: 0.4071 - acc: 0.8373 - val_loss: 0.3875 - val_acc: 0.8425\n",
      "Epoch 77/100\n",
      "1752/1752 [==============================] - 1s 338us/step - loss: 0.4016 - acc: 0.8470 - val_loss: 0.3866 - val_acc: 0.8425\n",
      "Epoch 78/100\n",
      "1752/1752 [==============================] - 1s 341us/step - loss: 0.4083 - acc: 0.8408 - val_loss: 0.3817 - val_acc: 0.8493\n",
      "Epoch 79/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.4003 - acc: 0.8362 - val_loss: 0.3831 - val_acc: 0.8447\n",
      "Epoch 80/100\n",
      "1752/1752 [==============================] - 1s 342us/step - loss: 0.4047 - acc: 0.8345 - val_loss: 0.3782 - val_acc: 0.8562\n",
      "Epoch 81/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.3971 - acc: 0.8390 - val_loss: 0.3766 - val_acc: 0.8562\n",
      "Epoch 82/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.3917 - acc: 0.8459 - val_loss: 0.3753 - val_acc: 0.8562\n",
      "Epoch 83/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.3875 - acc: 0.8442 - val_loss: 0.3761 - val_acc: 0.8539\n",
      "Epoch 84/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.3893 - acc: 0.8408 - val_loss: 0.3745 - val_acc: 0.8562\n",
      "Epoch 85/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.3922 - acc: 0.8413 - val_loss: 0.3749 - val_acc: 0.8516\n",
      "Epoch 86/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.3867 - acc: 0.8442 - val_loss: 0.3708 - val_acc: 0.8539\n",
      "Epoch 87/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.4038 - acc: 0.8373 - val_loss: 0.3722 - val_acc: 0.8562\n",
      "Epoch 88/100\n",
      "1752/1752 [==============================] - 1s 342us/step - loss: 0.3854 - acc: 0.8447 - val_loss: 0.3702 - val_acc: 0.8539\n",
      "Epoch 89/100\n",
      "1752/1752 [==============================] - 1s 341us/step - loss: 0.3761 - acc: 0.8476 - val_loss: 0.3700 - val_acc: 0.8539\n",
      "Epoch 90/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.3933 - acc: 0.8487 - val_loss: 0.3677 - val_acc: 0.8493\n",
      "Epoch 91/100\n",
      "1752/1752 [==============================] - 1s 335us/step - loss: 0.3919 - acc: 0.8505 - val_loss: 0.3663 - val_acc: 0.8493\n",
      "Epoch 92/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.3876 - acc: 0.8413 - val_loss: 0.3655 - val_acc: 0.8493\n",
      "Epoch 93/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.3850 - acc: 0.8419 - val_loss: 0.3651 - val_acc: 0.8516\n",
      "Epoch 94/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.3884 - acc: 0.8470 - val_loss: 0.3651 - val_acc: 0.8516\n",
      "Epoch 95/100\n",
      "1752/1752 [==============================] - 1s 341us/step - loss: 0.3824 - acc: 0.8476 - val_loss: 0.3637 - val_acc: 0.8516\n",
      "Epoch 96/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.3705 - acc: 0.8545 - val_loss: 0.3626 - val_acc: 0.8516\n",
      "Epoch 97/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.3724 - acc: 0.8470 - val_loss: 0.3605 - val_acc: 0.8493\n",
      "Epoch 98/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.3826 - acc: 0.8579 - val_loss: 0.3620 - val_acc: 0.8516\n",
      "Epoch 99/100\n",
      "1752/1752 [==============================] - 1s 335us/step - loss: 0.3787 - acc: 0.8442 - val_loss: 0.3623 - val_acc: 0.8516\n",
      "Epoch 100/100\n",
      "1752/1752 [==============================] - 1s 344us/step - loss: 0.3755 - acc: 0.8493 - val_loss: 0.3583 - val_acc: 0.8516\n",
      "Train on 1752 samples, validate on 438 samples\n",
      "Epoch 1/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.4082 - acc: 0.8345 - val_loss: 0.3500 - val_acc: 0.8721\n",
      "Epoch 2/100\n",
      "1752/1752 [==============================] - 1s 337us/step - loss: 0.4133 - acc: 0.8248 - val_loss: 0.3490 - val_acc: 0.8744\n",
      "Epoch 3/100\n",
      "1752/1752 [==============================] - 1s 337us/step - loss: 0.4079 - acc: 0.8350 - val_loss: 0.3493 - val_acc: 0.8744\n",
      "Epoch 4/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.4181 - acc: 0.8253 - val_loss: 0.3465 - val_acc: 0.8744\n",
      "Epoch 5/100\n",
      "1752/1752 [==============================] - 1s 335us/step - loss: 0.4180 - acc: 0.8253 - val_loss: 0.3458 - val_acc: 0.8744\n",
      "Epoch 6/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.4145 - acc: 0.8293 - val_loss: 0.3466 - val_acc: 0.8721\n",
      "Epoch 7/100\n",
      "1752/1752 [==============================] - 1s 342us/step - loss: 0.3909 - acc: 0.8293 - val_loss: 0.3485 - val_acc: 0.8721\n",
      "Epoch 8/100\n",
      "1752/1752 [==============================] - 1s 342us/step - loss: 0.3966 - acc: 0.8339 - val_loss: 0.3430 - val_acc: 0.8767\n",
      "Epoch 9/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.4047 - acc: 0.8339 - val_loss: 0.3435 - val_acc: 0.8744\n",
      "Epoch 10/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.4020 - acc: 0.8299 - val_loss: 0.3422 - val_acc: 0.8767\n",
      "Epoch 11/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.4083 - acc: 0.8293 - val_loss: 0.3411 - val_acc: 0.8790\n",
      "Epoch 12/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.3988 - acc: 0.8299 - val_loss: 0.3393 - val_acc: 0.8767\n",
      "Epoch 13/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.4091 - acc: 0.8293 - val_loss: 0.3403 - val_acc: 0.8767\n",
      "Epoch 14/100\n",
      "1752/1752 [==============================] - 1s 339us/step - loss: 0.4012 - acc: 0.8288 - val_loss: 0.3381 - val_acc: 0.8767\n",
      "Epoch 15/100\n",
      "1752/1752 [==============================] - 1s 338us/step - loss: 0.3935 - acc: 0.8385 - val_loss: 0.3359 - val_acc: 0.8767\n",
      "Epoch 16/100\n",
      "1752/1752 [==============================] - 1s 338us/step - loss: 0.4020 - acc: 0.8311 - val_loss: 0.3353 - val_acc: 0.8744\n",
      "Epoch 17/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.3914 - acc: 0.8482 - val_loss: 0.3357 - val_acc: 0.8767\n",
      "Epoch 18/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.3953 - acc: 0.8390 - val_loss: 0.3346 - val_acc: 0.8767\n",
      "Epoch 19/100\n",
      "1752/1752 [==============================] - 1s 342us/step - loss: 0.3909 - acc: 0.8379 - val_loss: 0.3327 - val_acc: 0.8744\n",
      "Epoch 20/100\n",
      "1752/1752 [==============================] - 1s 340us/step - loss: 0.3975 - acc: 0.8328 - val_loss: 0.3323 - val_acc: 0.8767\n",
      "Epoch 21/100\n",
      "1752/1752 [==============================] - 1s 342us/step - loss: 0.3865 - acc: 0.8396 - val_loss: 0.3341 - val_acc: 0.8813\n",
      "Epoch 22/100\n",
      "1752/1752 [==============================] - 1s 337us/step - loss: 0.3909 - acc: 0.8545 - val_loss: 0.3303 - val_acc: 0.8790\n",
      "Epoch 23/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.3818 - acc: 0.8493 - val_loss: 0.3308 - val_acc: 0.8790\n",
      "Epoch 24/100\n",
      "1752/1752 [==============================] - 1s 340us/step - loss: 0.3843 - acc: 0.8396 - val_loss: 0.3319 - val_acc: 0.8790\n",
      "Epoch 25/100\n",
      "1752/1752 [==============================] - 1s 338us/step - loss: 0.3798 - acc: 0.8430 - val_loss: 0.3290 - val_acc: 0.8790\n",
      "Epoch 26/100\n",
      "1752/1752 [==============================] - 1s 335us/step - loss: 0.3886 - acc: 0.8373 - val_loss: 0.3284 - val_acc: 0.8790\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1752/1752 [==============================] - 1s 343us/step - loss: 0.3880 - acc: 0.8436 - val_loss: 0.3287 - val_acc: 0.8767\n",
      "Epoch 28/100\n",
      "1752/1752 [==============================] - 1s 358us/step - loss: 0.3865 - acc: 0.8419 - val_loss: 0.3258 - val_acc: 0.8836\n",
      "Epoch 29/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.3769 - acc: 0.8453 - val_loss: 0.3275 - val_acc: 0.8813\n",
      "Epoch 30/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.3753 - acc: 0.8425 - val_loss: 0.3260 - val_acc: 0.8767\n",
      "Epoch 31/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.3738 - acc: 0.8430 - val_loss: 0.3246 - val_acc: 0.8813\n",
      "Epoch 32/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.3778 - acc: 0.8402 - val_loss: 0.3242 - val_acc: 0.8767\n",
      "Epoch 33/100\n",
      "1752/1752 [==============================] - 1s 340us/step - loss: 0.3760 - acc: 0.8459 - val_loss: 0.3214 - val_acc: 0.8813\n",
      "Epoch 34/100\n",
      "1752/1752 [==============================] - 1s 349us/step - loss: 0.3741 - acc: 0.8430 - val_loss: 0.3214 - val_acc: 0.8836\n",
      "Epoch 35/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.3777 - acc: 0.8413 - val_loss: 0.3228 - val_acc: 0.8790\n",
      "Epoch 36/100\n",
      "1752/1752 [==============================] - 1s 341us/step - loss: 0.3756 - acc: 0.8453 - val_loss: 0.3179 - val_acc: 0.8836\n",
      "Epoch 37/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.3740 - acc: 0.8442 - val_loss: 0.3182 - val_acc: 0.8836\n",
      "Epoch 38/100\n",
      "1752/1752 [==============================] - 1s 335us/step - loss: 0.3670 - acc: 0.8584 - val_loss: 0.3192 - val_acc: 0.8790\n",
      "Epoch 39/100\n",
      "1752/1752 [==============================] - 1s 337us/step - loss: 0.3675 - acc: 0.8510 - val_loss: 0.3190 - val_acc: 0.8790\n",
      "Epoch 40/100\n",
      "1752/1752 [==============================] - 1s 337us/step - loss: 0.3667 - acc: 0.8476 - val_loss: 0.3167 - val_acc: 0.8836\n",
      "Epoch 41/100\n",
      "1752/1752 [==============================] - 1s 340us/step - loss: 0.3704 - acc: 0.8476 - val_loss: 0.3142 - val_acc: 0.8858\n",
      "Epoch 42/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.3688 - acc: 0.8442 - val_loss: 0.3142 - val_acc: 0.8881\n",
      "Epoch 43/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.3615 - acc: 0.8487 - val_loss: 0.3139 - val_acc: 0.8836\n",
      "Epoch 44/100\n",
      "1752/1752 [==============================] - 1s 338us/step - loss: 0.3621 - acc: 0.8425 - val_loss: 0.3144 - val_acc: 0.8836\n",
      "Epoch 45/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.3710 - acc: 0.8505 - val_loss: 0.3124 - val_acc: 0.8858\n",
      "Epoch 46/100\n",
      "1752/1752 [==============================] - 1s 339us/step - loss: 0.3649 - acc: 0.8516 - val_loss: 0.3116 - val_acc: 0.8858\n",
      "Epoch 47/100\n",
      "1752/1752 [==============================] - 1s 342us/step - loss: 0.3734 - acc: 0.8545 - val_loss: 0.3099 - val_acc: 0.8858\n",
      "Epoch 48/100\n",
      "1752/1752 [==============================] - 1s 350us/step - loss: 0.3659 - acc: 0.8510 - val_loss: 0.3112 - val_acc: 0.8858\n",
      "Epoch 49/100\n",
      "1752/1752 [==============================] - 1s 344us/step - loss: 0.3654 - acc: 0.8545 - val_loss: 0.3106 - val_acc: 0.8881\n",
      "Epoch 50/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.3625 - acc: 0.8550 - val_loss: 0.3095 - val_acc: 0.8836\n",
      "Epoch 51/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.3589 - acc: 0.8562 - val_loss: 0.3081 - val_acc: 0.8858\n",
      "Epoch 52/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.3583 - acc: 0.8556 - val_loss: 0.3078 - val_acc: 0.8858\n",
      "Epoch 53/100\n",
      "1752/1752 [==============================] - 1s 337us/step - loss: 0.3612 - acc: 0.8579 - val_loss: 0.3069 - val_acc: 0.8858\n",
      "Epoch 54/100\n",
      "1752/1752 [==============================] - 1s 337us/step - loss: 0.3667 - acc: 0.8430 - val_loss: 0.3062 - val_acc: 0.8858\n",
      "Epoch 55/100\n",
      "1752/1752 [==============================] - 1s 340us/step - loss: 0.3499 - acc: 0.8573 - val_loss: 0.3077 - val_acc: 0.8836\n",
      "Epoch 56/100\n",
      "1752/1752 [==============================] - 1s 341us/step - loss: 0.3577 - acc: 0.8584 - val_loss: 0.3047 - val_acc: 0.8858\n",
      "Epoch 57/100\n",
      "1752/1752 [==============================] - 1s 337us/step - loss: 0.3612 - acc: 0.8539 - val_loss: 0.3039 - val_acc: 0.8858\n",
      "Epoch 58/100\n",
      "1752/1752 [==============================] - 1s 340us/step - loss: 0.3435 - acc: 0.8636 - val_loss: 0.3029 - val_acc: 0.8858\n",
      "Epoch 59/100\n",
      "1752/1752 [==============================] - 1s 337us/step - loss: 0.3568 - acc: 0.8590 - val_loss: 0.3025 - val_acc: 0.8858\n",
      "Epoch 60/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.3614 - acc: 0.8562 - val_loss: 0.3001 - val_acc: 0.8858\n",
      "Epoch 61/100\n",
      "1752/1752 [==============================] - 1s 338us/step - loss: 0.3507 - acc: 0.8516 - val_loss: 0.2998 - val_acc: 0.8858\n",
      "Epoch 62/100\n",
      "1752/1752 [==============================] - 1s 337us/step - loss: 0.3440 - acc: 0.8659 - val_loss: 0.2987 - val_acc: 0.8858\n",
      "Epoch 63/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.3439 - acc: 0.8619 - val_loss: 0.3003 - val_acc: 0.8881\n",
      "Epoch 64/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.3551 - acc: 0.8624 - val_loss: 0.2983 - val_acc: 0.8881\n",
      "Epoch 65/100\n",
      "1752/1752 [==============================] - 1s 337us/step - loss: 0.3333 - acc: 0.8687 - val_loss: 0.2963 - val_acc: 0.8881\n",
      "Epoch 66/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.3439 - acc: 0.8676 - val_loss: 0.2963 - val_acc: 0.8858\n",
      "Epoch 67/100\n",
      "1752/1752 [==============================] - 1s 346us/step - loss: 0.3391 - acc: 0.8653 - val_loss: 0.2949 - val_acc: 0.8881\n",
      "Epoch 68/100\n",
      "1752/1752 [==============================] - 1s 351us/step - loss: 0.3446 - acc: 0.8670 - val_loss: 0.2935 - val_acc: 0.8904\n",
      "Epoch 69/100\n",
      "1752/1752 [==============================] - 1s 357us/step - loss: 0.3386 - acc: 0.8733 - val_loss: 0.2946 - val_acc: 0.8927\n",
      "Epoch 70/100\n",
      "1752/1752 [==============================] - 1s 347us/step - loss: 0.3466 - acc: 0.8590 - val_loss: 0.2927 - val_acc: 0.8927\n",
      "Epoch 71/100\n",
      "1752/1752 [==============================] - 1s 343us/step - loss: 0.3373 - acc: 0.8584 - val_loss: 0.2928 - val_acc: 0.8950\n",
      "Epoch 72/100\n",
      "1752/1752 [==============================] - 1s 385us/step - loss: 0.3352 - acc: 0.8687 - val_loss: 0.2922 - val_acc: 0.8927\n",
      "Epoch 73/100\n",
      "1752/1752 [==============================] - 1s 356us/step - loss: 0.3393 - acc: 0.8579 - val_loss: 0.2916 - val_acc: 0.8927\n",
      "Epoch 74/100\n",
      "1752/1752 [==============================] - 1s 363us/step - loss: 0.3422 - acc: 0.8630 - val_loss: 0.2918 - val_acc: 0.8927\n",
      "Epoch 75/100\n",
      "1752/1752 [==============================] - 1s 341us/step - loss: 0.3391 - acc: 0.8642 - val_loss: 0.2891 - val_acc: 0.8950\n",
      "Epoch 76/100\n",
      "1752/1752 [==============================] - 1s 353us/step - loss: 0.3399 - acc: 0.8596 - val_loss: 0.2892 - val_acc: 0.8927\n",
      "Epoch 77/100\n",
      "1752/1752 [==============================] - 1s 343us/step - loss: 0.3432 - acc: 0.8624 - val_loss: 0.2893 - val_acc: 0.8927\n",
      "Epoch 78/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.3338 - acc: 0.8716 - val_loss: 0.2874 - val_acc: 0.8973\n",
      "Epoch 79/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.3368 - acc: 0.8664 - val_loss: 0.2860 - val_acc: 0.8973\n",
      "Epoch 80/100\n",
      "1752/1752 [==============================] - 1s 320us/step - loss: 0.3343 - acc: 0.8647 - val_loss: 0.2863 - val_acc: 0.8950\n",
      "Epoch 81/100\n",
      "1752/1752 [==============================] - 1s 343us/step - loss: 0.3358 - acc: 0.8653 - val_loss: 0.2859 - val_acc: 0.8973\n",
      "Epoch 82/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.3276 - acc: 0.8699 - val_loss: 0.2842 - val_acc: 0.8950\n",
      "Epoch 83/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.3297 - acc: 0.8659 - val_loss: 0.2837 - val_acc: 0.8973\n",
      "Epoch 84/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.3301 - acc: 0.8704 - val_loss: 0.2830 - val_acc: 0.8973\n",
      "Epoch 85/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.3269 - acc: 0.8704 - val_loss: 0.2845 - val_acc: 0.8973\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1752/1752 [==============================] - 1s 339us/step - loss: 0.3191 - acc: 0.8750 - val_loss: 0.2825 - val_acc: 0.8995\n",
      "Epoch 87/100\n",
      "1752/1752 [==============================] - 1s 339us/step - loss: 0.3294 - acc: 0.8670 - val_loss: 0.2841 - val_acc: 0.8995\n",
      "Epoch 88/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.3189 - acc: 0.8716 - val_loss: 0.2811 - val_acc: 0.9018\n",
      "Epoch 89/100\n",
      "1752/1752 [==============================] - 1s 337us/step - loss: 0.3269 - acc: 0.8687 - val_loss: 0.2802 - val_acc: 0.8995\n",
      "Epoch 90/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.3257 - acc: 0.8653 - val_loss: 0.2783 - val_acc: 0.8973\n",
      "Epoch 91/100\n",
      "1752/1752 [==============================] - 1s 339us/step - loss: 0.3244 - acc: 0.8704 - val_loss: 0.2804 - val_acc: 0.8973\n",
      "Epoch 92/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.3226 - acc: 0.8704 - val_loss: 0.2781 - val_acc: 0.8995\n",
      "Epoch 93/100\n",
      "1752/1752 [==============================] - 1s 339us/step - loss: 0.3131 - acc: 0.8807 - val_loss: 0.2767 - val_acc: 0.8973\n",
      "Epoch 94/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.3276 - acc: 0.8642 - val_loss: 0.2759 - val_acc: 0.8973\n",
      "Epoch 95/100\n",
      "1752/1752 [==============================] - 1s 339us/step - loss: 0.3187 - acc: 0.8801 - val_loss: 0.2738 - val_acc: 0.8995\n",
      "Epoch 96/100\n",
      "1752/1752 [==============================] - 1s 335us/step - loss: 0.3159 - acc: 0.8767 - val_loss: 0.2744 - val_acc: 0.8995\n",
      "Epoch 97/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.3257 - acc: 0.8704 - val_loss: 0.2736 - val_acc: 0.8973\n",
      "Epoch 98/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.3173 - acc: 0.8721 - val_loss: 0.2733 - val_acc: 0.8995\n",
      "Epoch 99/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.3184 - acc: 0.8721 - val_loss: 0.2728 - val_acc: 0.9018\n",
      "Epoch 100/100\n",
      "1752/1752 [==============================] - 1s 340us/step - loss: 0.3132 - acc: 0.8801 - val_loss: 0.2698 - val_acc: 0.9018\n",
      "Test subject 9, class BothStartLoadPhase\n",
      "Train subject 9, class LiftOff\n",
      "Train on 1751 samples, validate on 438 samples\n",
      "Epoch 1/100\n",
      "1751/1751 [==============================] - 1s 791us/step - loss: 0.6987 - acc: 0.5049 - val_loss: 0.6935 - val_acc: 0.4886\n",
      "Epoch 2/100\n",
      "1751/1751 [==============================] - 1s 332us/step - loss: 0.6986 - acc: 0.5060 - val_loss: 0.6917 - val_acc: 0.4954\n",
      "Epoch 3/100\n",
      "1751/1751 [==============================] - 1s 335us/step - loss: 0.6959 - acc: 0.4934 - val_loss: 0.6904 - val_acc: 0.5114\n",
      "Epoch 4/100\n",
      "1751/1751 [==============================] - 1s 334us/step - loss: 0.6928 - acc: 0.5031 - val_loss: 0.6894 - val_acc: 0.5639\n",
      "Epoch 5/100\n",
      "1751/1751 [==============================] - 1s 354us/step - loss: 0.6896 - acc: 0.5151 - val_loss: 0.6885 - val_acc: 0.6301\n",
      "Epoch 6/100\n",
      "1751/1751 [==============================] - 1s 355us/step - loss: 0.6909 - acc: 0.5157 - val_loss: 0.6878 - val_acc: 0.6164\n",
      "Epoch 7/100\n",
      "1751/1751 [==============================] - 1s 349us/step - loss: 0.6923 - acc: 0.5248 - val_loss: 0.6872 - val_acc: 0.6279\n",
      "Epoch 8/100\n",
      "1751/1751 [==============================] - 1s 356us/step - loss: 0.6926 - acc: 0.5049 - val_loss: 0.6867 - val_acc: 0.5913\n",
      "Epoch 9/100\n",
      "1751/1751 [==============================] - 1s 350us/step - loss: 0.6909 - acc: 0.5111 - val_loss: 0.6861 - val_acc: 0.5845\n",
      "Epoch 10/100\n",
      "1751/1751 [==============================] - 1s 344us/step - loss: 0.6898 - acc: 0.5186 - val_loss: 0.6856 - val_acc: 0.5708\n",
      "Epoch 11/100\n",
      "1751/1751 [==============================] - 1s 344us/step - loss: 0.6890 - acc: 0.5408 - val_loss: 0.6850 - val_acc: 0.5639\n",
      "Epoch 12/100\n",
      "1751/1751 [==============================] - 1s 340us/step - loss: 0.6885 - acc: 0.5420 - val_loss: 0.6844 - val_acc: 0.5639\n",
      "Epoch 13/100\n",
      "1751/1751 [==============================] - 1s 338us/step - loss: 0.6866 - acc: 0.5745 - val_loss: 0.6838 - val_acc: 0.5662\n",
      "Epoch 14/100\n",
      "1751/1751 [==============================] - 1s 344us/step - loss: 0.6880 - acc: 0.5528 - val_loss: 0.6832 - val_acc: 0.5662\n",
      "Epoch 15/100\n",
      "1751/1751 [==============================] - 1s 337us/step - loss: 0.6863 - acc: 0.5597 - val_loss: 0.6825 - val_acc: 0.5731\n",
      "Epoch 16/100\n",
      "1751/1751 [==============================] - 1s 338us/step - loss: 0.6859 - acc: 0.5682 - val_loss: 0.6818 - val_acc: 0.5708\n",
      "Epoch 17/100\n",
      "1751/1751 [==============================] - 1s 346us/step - loss: 0.6860 - acc: 0.5688 - val_loss: 0.6810 - val_acc: 0.5868\n",
      "Epoch 18/100\n",
      "1751/1751 [==============================] - 1s 345us/step - loss: 0.6829 - acc: 0.5791 - val_loss: 0.6803 - val_acc: 0.5913\n",
      "Epoch 19/100\n",
      "1751/1751 [==============================] - 1s 333us/step - loss: 0.6839 - acc: 0.5957 - val_loss: 0.6796 - val_acc: 0.5982\n",
      "Epoch 20/100\n",
      "1751/1751 [==============================] - 1s 339us/step - loss: 0.6823 - acc: 0.5780 - val_loss: 0.6787 - val_acc: 0.6027\n",
      "Epoch 21/100\n",
      "1751/1751 [==============================] - 1s 344us/step - loss: 0.6827 - acc: 0.5882 - val_loss: 0.6779 - val_acc: 0.6050\n",
      "Epoch 22/100\n",
      "1751/1751 [==============================] - 1s 337us/step - loss: 0.6803 - acc: 0.5905 - val_loss: 0.6770 - val_acc: 0.6050\n",
      "Epoch 23/100\n",
      "1751/1751 [==============================] - 1s 336us/step - loss: 0.6803 - acc: 0.5979 - val_loss: 0.6762 - val_acc: 0.6096\n",
      "Epoch 24/100\n",
      "1751/1751 [==============================] - 1s 339us/step - loss: 0.6824 - acc: 0.5791 - val_loss: 0.6753 - val_acc: 0.6119\n",
      "Epoch 25/100\n",
      "1751/1751 [==============================] - 1s 337us/step - loss: 0.6786 - acc: 0.5962 - val_loss: 0.6743 - val_acc: 0.6164\n",
      "Epoch 26/100\n",
      "1751/1751 [==============================] - 1s 337us/step - loss: 0.6794 - acc: 0.6122 - val_loss: 0.6733 - val_acc: 0.6279\n",
      "Epoch 27/100\n",
      "1751/1751 [==============================] - 1s 351us/step - loss: 0.6773 - acc: 0.6088 - val_loss: 0.6722 - val_acc: 0.6484\n",
      "Epoch 28/100\n",
      "1751/1751 [==============================] - 1s 363us/step - loss: 0.6776 - acc: 0.5997 - val_loss: 0.6709 - val_acc: 0.6575\n",
      "Epoch 29/100\n",
      "1751/1751 [==============================] - 1s 361us/step - loss: 0.6762 - acc: 0.6299 - val_loss: 0.6697 - val_acc: 0.6621\n",
      "Epoch 30/100\n",
      "1751/1751 [==============================] - 1s 346us/step - loss: 0.6735 - acc: 0.6151 - val_loss: 0.6684 - val_acc: 0.6644\n",
      "Epoch 31/100\n",
      "1751/1751 [==============================] - 1s 331us/step - loss: 0.6768 - acc: 0.6111 - val_loss: 0.6671 - val_acc: 0.6712\n",
      "Epoch 32/100\n",
      "1751/1751 [==============================] - 1s 337us/step - loss: 0.6720 - acc: 0.6436 - val_loss: 0.6656 - val_acc: 0.6735\n",
      "Epoch 33/100\n",
      "1751/1751 [==============================] - 1s 336us/step - loss: 0.6701 - acc: 0.6551 - val_loss: 0.6641 - val_acc: 0.6781\n",
      "Epoch 34/100\n",
      "1751/1751 [==============================] - 1s 337us/step - loss: 0.6695 - acc: 0.6294 - val_loss: 0.6625 - val_acc: 0.6918\n",
      "Epoch 35/100\n",
      "1751/1751 [==============================] - 1s 335us/step - loss: 0.6682 - acc: 0.6533 - val_loss: 0.6607 - val_acc: 0.7009\n",
      "Epoch 36/100\n",
      "1751/1751 [==============================] - 1s 329us/step - loss: 0.6646 - acc: 0.6653 - val_loss: 0.6588 - val_acc: 0.7055\n",
      "Epoch 37/100\n",
      "1751/1751 [==============================] - 1s 336us/step - loss: 0.6627 - acc: 0.6739 - val_loss: 0.6568 - val_acc: 0.7169\n",
      "Epoch 38/100\n",
      "1751/1751 [==============================] - 1s 336us/step - loss: 0.6660 - acc: 0.6533 - val_loss: 0.6547 - val_acc: 0.7192\n",
      "Epoch 39/100\n",
      "1751/1751 [==============================] - 1s 336us/step - loss: 0.6591 - acc: 0.6785 - val_loss: 0.6524 - val_acc: 0.7169\n",
      "Epoch 40/100\n",
      "1751/1751 [==============================] - 1s 342us/step - loss: 0.6592 - acc: 0.6670 - val_loss: 0.6500 - val_acc: 0.7169\n",
      "Epoch 41/100\n",
      "1751/1751 [==============================] - 1s 333us/step - loss: 0.6570 - acc: 0.6728 - val_loss: 0.6473 - val_acc: 0.7237\n",
      "Epoch 42/100\n",
      "1751/1751 [==============================] - 1s 333us/step - loss: 0.6568 - acc: 0.6790 - val_loss: 0.6445 - val_acc: 0.7374\n",
      "Epoch 43/100\n",
      "1751/1751 [==============================] - 1s 340us/step - loss: 0.6553 - acc: 0.6773 - val_loss: 0.6417 - val_acc: 0.7489\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1751/1751 [==============================] - 1s 333us/step - loss: 0.6513 - acc: 0.6916 - val_loss: 0.6385 - val_acc: 0.7671\n",
      "Epoch 45/100\n",
      "1751/1751 [==============================] - 1s 342us/step - loss: 0.6439 - acc: 0.7184 - val_loss: 0.6348 - val_acc: 0.7648\n",
      "Epoch 46/100\n",
      "1751/1751 [==============================] - 1s 340us/step - loss: 0.6490 - acc: 0.6865 - val_loss: 0.6313 - val_acc: 0.7603\n",
      "Epoch 47/100\n",
      "1751/1751 [==============================] - 1s 330us/step - loss: 0.6435 - acc: 0.7059 - val_loss: 0.6275 - val_acc: 0.7626\n",
      "Epoch 48/100\n",
      "1751/1751 [==============================] - 1s 341us/step - loss: 0.6382 - acc: 0.7105 - val_loss: 0.6234 - val_acc: 0.7694\n",
      "Epoch 49/100\n",
      "1751/1751 [==============================] - 1s 326us/step - loss: 0.6356 - acc: 0.7196 - val_loss: 0.6190 - val_acc: 0.7763\n",
      "Epoch 50/100\n",
      "1751/1751 [==============================] - 1s 333us/step - loss: 0.6291 - acc: 0.7447 - val_loss: 0.6142 - val_acc: 0.7808\n",
      "Epoch 51/100\n",
      "1751/1751 [==============================] - 1s 332us/step - loss: 0.6279 - acc: 0.7202 - val_loss: 0.6090 - val_acc: 0.7922\n",
      "Epoch 52/100\n",
      "1751/1751 [==============================] - 1s 337us/step - loss: 0.6203 - acc: 0.7424 - val_loss: 0.6038 - val_acc: 0.7877\n",
      "Epoch 53/100\n",
      "1751/1751 [==============================] - 1s 344us/step - loss: 0.6179 - acc: 0.7367 - val_loss: 0.5980 - val_acc: 0.7968\n",
      "Epoch 54/100\n",
      "1751/1751 [==============================] - 1s 327us/step - loss: 0.6092 - acc: 0.7550 - val_loss: 0.5923 - val_acc: 0.7922\n",
      "Epoch 55/100\n",
      "1751/1751 [==============================] - 1s 334us/step - loss: 0.6062 - acc: 0.7459 - val_loss: 0.5862 - val_acc: 0.7922\n",
      "Epoch 56/100\n",
      "1751/1751 [==============================] - 1s 336us/step - loss: 0.6002 - acc: 0.7624 - val_loss: 0.5791 - val_acc: 0.7945\n",
      "Epoch 57/100\n",
      "1751/1751 [==============================] - 1s 334us/step - loss: 0.5932 - acc: 0.7681 - val_loss: 0.5717 - val_acc: 0.7922\n",
      "Epoch 58/100\n",
      "1751/1751 [==============================] - 1s 336us/step - loss: 0.5869 - acc: 0.7681 - val_loss: 0.5642 - val_acc: 0.7968\n",
      "Epoch 59/100\n",
      "1751/1751 [==============================] - 1s 333us/step - loss: 0.5784 - acc: 0.7658 - val_loss: 0.5566 - val_acc: 0.7968\n",
      "Epoch 60/100\n",
      "1751/1751 [==============================] - 1s 333us/step - loss: 0.5693 - acc: 0.7807 - val_loss: 0.5474 - val_acc: 0.8014\n",
      "Epoch 61/100\n",
      "1751/1751 [==============================] - 1s 333us/step - loss: 0.5648 - acc: 0.7756 - val_loss: 0.5391 - val_acc: 0.8059\n",
      "Epoch 62/100\n",
      "1751/1751 [==============================] - 1s 335us/step - loss: 0.5567 - acc: 0.7744 - val_loss: 0.5311 - val_acc: 0.8037\n",
      "Epoch 63/100\n",
      "1751/1751 [==============================] - 1s 341us/step - loss: 0.5425 - acc: 0.7944 - val_loss: 0.5226 - val_acc: 0.8037\n",
      "Epoch 64/100\n",
      "1751/1751 [==============================] - 1s 331us/step - loss: 0.5355 - acc: 0.7830 - val_loss: 0.5135 - val_acc: 0.8059\n",
      "Epoch 65/100\n",
      "1751/1751 [==============================] - 1s 333us/step - loss: 0.5242 - acc: 0.7967 - val_loss: 0.5036 - val_acc: 0.8082\n",
      "Epoch 66/100\n",
      "1751/1751 [==============================] - 1s 332us/step - loss: 0.5243 - acc: 0.7853 - val_loss: 0.4954 - val_acc: 0.8105\n",
      "Epoch 67/100\n",
      "1751/1751 [==============================] - 1s 328us/step - loss: 0.5037 - acc: 0.7961 - val_loss: 0.4869 - val_acc: 0.8105\n",
      "Epoch 68/100\n",
      "1751/1751 [==============================] - 1s 329us/step - loss: 0.4935 - acc: 0.8064 - val_loss: 0.4819 - val_acc: 0.8082\n",
      "Epoch 69/100\n",
      "1751/1751 [==============================] - 1s 335us/step - loss: 0.4897 - acc: 0.8064 - val_loss: 0.4710 - val_acc: 0.8105\n",
      "Epoch 70/100\n",
      "1751/1751 [==============================] - 1s 343us/step - loss: 0.4885 - acc: 0.7995 - val_loss: 0.4662 - val_acc: 0.8082\n",
      "Epoch 71/100\n",
      "1751/1751 [==============================] - 1s 332us/step - loss: 0.4712 - acc: 0.8053 - val_loss: 0.4573 - val_acc: 0.8082\n",
      "Epoch 72/100\n",
      "1751/1751 [==============================] - 1s 344us/step - loss: 0.4648 - acc: 0.8115 - val_loss: 0.4505 - val_acc: 0.8128\n",
      "Epoch 73/100\n",
      "1751/1751 [==============================] - 1s 343us/step - loss: 0.4595 - acc: 0.8098 - val_loss: 0.4448 - val_acc: 0.8128\n",
      "Epoch 74/100\n",
      "1751/1751 [==============================] - 1s 336us/step - loss: 0.4520 - acc: 0.8161 - val_loss: 0.4388 - val_acc: 0.8128\n",
      "Epoch 75/100\n",
      "1751/1751 [==============================] - 1s 339us/step - loss: 0.4471 - acc: 0.8104 - val_loss: 0.4311 - val_acc: 0.8151\n",
      "Epoch 76/100\n",
      "1751/1751 [==============================] - 1s 336us/step - loss: 0.4446 - acc: 0.8087 - val_loss: 0.4277 - val_acc: 0.8128\n",
      "Epoch 77/100\n",
      "1751/1751 [==============================] - 1s 336us/step - loss: 0.4360 - acc: 0.8144 - val_loss: 0.4230 - val_acc: 0.8196\n",
      "Epoch 78/100\n",
      "1751/1751 [==============================] - 1s 329us/step - loss: 0.4294 - acc: 0.8184 - val_loss: 0.4195 - val_acc: 0.8174\n",
      "Epoch 79/100\n",
      "1751/1751 [==============================] - 1s 327us/step - loss: 0.4241 - acc: 0.8298 - val_loss: 0.4166 - val_acc: 0.8174\n",
      "Epoch 80/100\n",
      "1751/1751 [==============================] - 1s 328us/step - loss: 0.4260 - acc: 0.8184 - val_loss: 0.4139 - val_acc: 0.8196\n",
      "Epoch 81/100\n",
      "1751/1751 [==============================] - 1s 339us/step - loss: 0.4157 - acc: 0.8258 - val_loss: 0.4106 - val_acc: 0.8219\n",
      "Epoch 82/100\n",
      "1751/1751 [==============================] - 1s 337us/step - loss: 0.4144 - acc: 0.8241 - val_loss: 0.4095 - val_acc: 0.8242\n",
      "Epoch 83/100\n",
      "1751/1751 [==============================] - 1s 332us/step - loss: 0.4105 - acc: 0.8258 - val_loss: 0.4040 - val_acc: 0.8265\n",
      "Epoch 84/100\n",
      "1751/1751 [==============================] - 1s 336us/step - loss: 0.4030 - acc: 0.8298 - val_loss: 0.4001 - val_acc: 0.8356\n",
      "Epoch 85/100\n",
      "1751/1751 [==============================] - 1s 339us/step - loss: 0.4098 - acc: 0.8224 - val_loss: 0.3993 - val_acc: 0.8333\n",
      "Epoch 86/100\n",
      "1751/1751 [==============================] - 1s 330us/step - loss: 0.4083 - acc: 0.8247 - val_loss: 0.3996 - val_acc: 0.8311\n",
      "Epoch 87/100\n",
      "1751/1751 [==============================] - 1s 334us/step - loss: 0.4010 - acc: 0.8241 - val_loss: 0.3985 - val_acc: 0.8311\n",
      "Epoch 88/100\n",
      "1751/1751 [==============================] - 1s 336us/step - loss: 0.3946 - acc: 0.8361 - val_loss: 0.3957 - val_acc: 0.8311\n",
      "Epoch 89/100\n",
      "1751/1751 [==============================] - 1s 332us/step - loss: 0.3979 - acc: 0.8429 - val_loss: 0.3936 - val_acc: 0.8333\n",
      "Epoch 90/100\n",
      "1751/1751 [==============================] - 1s 337us/step - loss: 0.3889 - acc: 0.8372 - val_loss: 0.3870 - val_acc: 0.8379\n",
      "Epoch 91/100\n",
      "1751/1751 [==============================] - 1s 338us/step - loss: 0.3894 - acc: 0.8287 - val_loss: 0.3892 - val_acc: 0.8379\n",
      "Epoch 92/100\n",
      "1751/1751 [==============================] - 1s 334us/step - loss: 0.3890 - acc: 0.8384 - val_loss: 0.3855 - val_acc: 0.8379\n",
      "Epoch 93/100\n",
      "1751/1751 [==============================] - 1s 341us/step - loss: 0.3805 - acc: 0.8418 - val_loss: 0.3780 - val_acc: 0.8402\n",
      "Epoch 94/100\n",
      "1751/1751 [==============================] - 1s 336us/step - loss: 0.3801 - acc: 0.8361 - val_loss: 0.3842 - val_acc: 0.8379\n",
      "Epoch 95/100\n",
      "1751/1751 [==============================] - 1s 335us/step - loss: 0.3893 - acc: 0.8321 - val_loss: 0.3741 - val_acc: 0.8425\n",
      "Epoch 96/100\n",
      "1751/1751 [==============================] - 1s 335us/step - loss: 0.3757 - acc: 0.8447 - val_loss: 0.3771 - val_acc: 0.8379\n",
      "Epoch 97/100\n",
      "1751/1751 [==============================] - 1s 331us/step - loss: 0.3750 - acc: 0.8435 - val_loss: 0.3727 - val_acc: 0.8402\n",
      "Epoch 98/100\n",
      "1751/1751 [==============================] - 1s 342us/step - loss: 0.3641 - acc: 0.8458 - val_loss: 0.3754 - val_acc: 0.8425\n",
      "Epoch 99/100\n",
      "1751/1751 [==============================] - 1s 339us/step - loss: 0.3722 - acc: 0.8464 - val_loss: 0.3712 - val_acc: 0.8447\n",
      "Epoch 100/100\n",
      "1751/1751 [==============================] - 1s 334us/step - loss: 0.3788 - acc: 0.8384 - val_loss: 0.3683 - val_acc: 0.8447\n",
      "Train on 1751 samples, validate on 438 samples\n",
      "Epoch 1/100\n",
      "1751/1751 [==============================] - 1s 326us/step - loss: 0.3945 - acc: 0.8304 - val_loss: 0.3816 - val_acc: 0.8265\n",
      "Epoch 2/100\n",
      "1751/1751 [==============================] - 1s 333us/step - loss: 0.3984 - acc: 0.8292 - val_loss: 0.3796 - val_acc: 0.8288\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1751/1751 [==============================] - 1s 325us/step - loss: 0.3897 - acc: 0.8292 - val_loss: 0.3772 - val_acc: 0.8311\n",
      "Epoch 4/100\n",
      "1751/1751 [==============================] - 1s 330us/step - loss: 0.3911 - acc: 0.8350 - val_loss: 0.3770 - val_acc: 0.8311\n",
      "Epoch 5/100\n",
      "1751/1751 [==============================] - 1s 334us/step - loss: 0.3846 - acc: 0.8407 - val_loss: 0.3758 - val_acc: 0.8288\n",
      "Epoch 6/100\n",
      "1751/1751 [==============================] - 1s 335us/step - loss: 0.3887 - acc: 0.8327 - val_loss: 0.3753 - val_acc: 0.8288\n",
      "Epoch 7/100\n",
      "1751/1751 [==============================] - 1s 323us/step - loss: 0.3876 - acc: 0.8327 - val_loss: 0.3714 - val_acc: 0.8356\n",
      "Epoch 8/100\n",
      "1751/1751 [==============================] - 1s 332us/step - loss: 0.3815 - acc: 0.8292 - val_loss: 0.3699 - val_acc: 0.8333\n",
      "Epoch 9/100\n",
      "1751/1751 [==============================] - 1s 333us/step - loss: 0.3780 - acc: 0.8475 - val_loss: 0.3661 - val_acc: 0.8356\n",
      "Epoch 10/100\n",
      "1751/1751 [==============================] - 1s 326us/step - loss: 0.3884 - acc: 0.8412 - val_loss: 0.3671 - val_acc: 0.8333\n",
      "Epoch 11/100\n",
      "1751/1751 [==============================] - 1s 328us/step - loss: 0.3729 - acc: 0.8481 - val_loss: 0.3649 - val_acc: 0.8356\n",
      "Epoch 12/100\n",
      "1751/1751 [==============================] - 1s 333us/step - loss: 0.3726 - acc: 0.8384 - val_loss: 0.3639 - val_acc: 0.8311\n",
      "Epoch 13/100\n",
      "1751/1751 [==============================] - 1s 339us/step - loss: 0.3693 - acc: 0.8378 - val_loss: 0.3618 - val_acc: 0.8356\n",
      "Epoch 14/100\n",
      "1751/1751 [==============================] - 1s 331us/step - loss: 0.3779 - acc: 0.8361 - val_loss: 0.3609 - val_acc: 0.8356\n",
      "Epoch 15/100\n",
      "1751/1751 [==============================] - 1s 335us/step - loss: 0.3704 - acc: 0.8407 - val_loss: 0.3592 - val_acc: 0.8356\n",
      "Epoch 16/100\n",
      "1751/1751 [==============================] - 1s 340us/step - loss: 0.3633 - acc: 0.8498 - val_loss: 0.3586 - val_acc: 0.8356\n",
      "Epoch 17/100\n",
      "1751/1751 [==============================] - 1s 333us/step - loss: 0.3610 - acc: 0.8487 - val_loss: 0.3567 - val_acc: 0.8379\n",
      "Epoch 18/100\n",
      "1751/1751 [==============================] - 1s 346us/step - loss: 0.3710 - acc: 0.8412 - val_loss: 0.3562 - val_acc: 0.8333\n",
      "Epoch 19/100\n",
      "1751/1751 [==============================] - 1s 333us/step - loss: 0.3556 - acc: 0.8492 - val_loss: 0.3547 - val_acc: 0.8356\n",
      "Epoch 20/100\n",
      "1751/1751 [==============================] - 1s 342us/step - loss: 0.3569 - acc: 0.8521 - val_loss: 0.3531 - val_acc: 0.8356\n",
      "Epoch 21/100\n",
      "1751/1751 [==============================] - 1s 338us/step - loss: 0.3606 - acc: 0.8532 - val_loss: 0.3513 - val_acc: 0.8379\n",
      "Epoch 22/100\n",
      "1751/1751 [==============================] - 1s 336us/step - loss: 0.3644 - acc: 0.8469 - val_loss: 0.3485 - val_acc: 0.8425\n",
      "Epoch 23/100\n",
      "1751/1751 [==============================] - 1s 344us/step - loss: 0.3455 - acc: 0.8567 - val_loss: 0.3476 - val_acc: 0.8425\n",
      "Epoch 24/100\n",
      "1751/1751 [==============================] - 1s 339us/step - loss: 0.3509 - acc: 0.8447 - val_loss: 0.3492 - val_acc: 0.8333\n",
      "Epoch 25/100\n",
      "1751/1751 [==============================] - 1s 334us/step - loss: 0.3446 - acc: 0.8612 - val_loss: 0.3462 - val_acc: 0.8379\n",
      "Epoch 26/100\n",
      "1751/1751 [==============================] - 1s 330us/step - loss: 0.3430 - acc: 0.8567 - val_loss: 0.3446 - val_acc: 0.8402\n",
      "Epoch 27/100\n",
      "1751/1751 [==============================] - 1s 335us/step - loss: 0.3497 - acc: 0.8555 - val_loss: 0.3441 - val_acc: 0.8425\n",
      "Epoch 28/100\n",
      "1751/1751 [==============================] - 1s 336us/step - loss: 0.3510 - acc: 0.8521 - val_loss: 0.3422 - val_acc: 0.8425\n",
      "Epoch 29/100\n",
      "1751/1751 [==============================] - 1s 337us/step - loss: 0.3381 - acc: 0.8584 - val_loss: 0.3404 - val_acc: 0.8425\n",
      "Epoch 30/100\n",
      "1751/1751 [==============================] - 1s 333us/step - loss: 0.3360 - acc: 0.8629 - val_loss: 0.3439 - val_acc: 0.8402\n",
      "Epoch 31/100\n",
      "1751/1751 [==============================] - 1s 329us/step - loss: 0.3311 - acc: 0.8635 - val_loss: 0.3395 - val_acc: 0.8425\n",
      "Epoch 32/100\n",
      "1751/1751 [==============================] - 1s 339us/step - loss: 0.3310 - acc: 0.8595 - val_loss: 0.3399 - val_acc: 0.8402\n",
      "Epoch 33/100\n",
      "1751/1751 [==============================] - 1s 341us/step - loss: 0.3338 - acc: 0.8578 - val_loss: 0.3373 - val_acc: 0.8425\n",
      "Epoch 34/100\n",
      "1751/1751 [==============================] - 1s 363us/step - loss: 0.3350 - acc: 0.8521 - val_loss: 0.3386 - val_acc: 0.8447\n",
      "Epoch 35/100\n",
      "1751/1751 [==============================] - 1s 356us/step - loss: 0.3305 - acc: 0.8567 - val_loss: 0.3367 - val_acc: 0.8447\n",
      "Epoch 36/100\n",
      "1751/1751 [==============================] - 1s 348us/step - loss: 0.3258 - acc: 0.8732 - val_loss: 0.3336 - val_acc: 0.8470\n",
      "Epoch 37/100\n",
      "1751/1751 [==============================] - 1s 342us/step - loss: 0.3296 - acc: 0.8555 - val_loss: 0.3333 - val_acc: 0.8470\n",
      "Epoch 38/100\n",
      "1751/1751 [==============================] - 1s 338us/step - loss: 0.3213 - acc: 0.8658 - val_loss: 0.3312 - val_acc: 0.8493\n",
      "Epoch 39/100\n",
      "1751/1751 [==============================] - 1s 331us/step - loss: 0.3257 - acc: 0.8646 - val_loss: 0.3307 - val_acc: 0.8493\n",
      "Epoch 40/100\n",
      "1751/1751 [==============================] - 1s 328us/step - loss: 0.3335 - acc: 0.8612 - val_loss: 0.3302 - val_acc: 0.8493\n",
      "Epoch 41/100\n",
      "1751/1751 [==============================] - 1s 332us/step - loss: 0.3188 - acc: 0.8681 - val_loss: 0.3284 - val_acc: 0.8539\n",
      "Epoch 42/100\n",
      "1751/1751 [==============================] - 1s 341us/step - loss: 0.3170 - acc: 0.8749 - val_loss: 0.3274 - val_acc: 0.8562\n",
      "Epoch 43/100\n",
      "1751/1751 [==============================] - 1s 346us/step - loss: 0.3172 - acc: 0.8704 - val_loss: 0.3281 - val_acc: 0.8539\n",
      "Epoch 44/100\n",
      "1751/1751 [==============================] - 1s 349us/step - loss: 0.3118 - acc: 0.8698 - val_loss: 0.3253 - val_acc: 0.8562\n",
      "Epoch 45/100\n",
      "1751/1751 [==============================] - 1s 363us/step - loss: 0.3113 - acc: 0.8755 - val_loss: 0.3270 - val_acc: 0.8562\n",
      "Epoch 46/100\n",
      "1751/1751 [==============================] - 1s 361us/step - loss: 0.3187 - acc: 0.8726 - val_loss: 0.3258 - val_acc: 0.8562\n",
      "Epoch 47/100\n",
      "1751/1751 [==============================] - 1s 371us/step - loss: 0.3102 - acc: 0.8709 - val_loss: 0.3235 - val_acc: 0.8562\n",
      "Epoch 48/100\n",
      "1751/1751 [==============================] - 1s 355us/step - loss: 0.3022 - acc: 0.8789 - val_loss: 0.3228 - val_acc: 0.8562\n",
      "Epoch 49/100\n",
      "1751/1751 [==============================] - 1s 367us/step - loss: 0.3025 - acc: 0.8846 - val_loss: 0.3231 - val_acc: 0.8562\n",
      "Epoch 50/100\n",
      "1751/1751 [==============================] - 1s 335us/step - loss: 0.3177 - acc: 0.8664 - val_loss: 0.3208 - val_acc: 0.8562\n",
      "Epoch 51/100\n",
      "1751/1751 [==============================] - 1s 335us/step - loss: 0.3008 - acc: 0.8738 - val_loss: 0.3209 - val_acc: 0.8562\n",
      "Epoch 52/100\n",
      "1751/1751 [==============================] - 1s 341us/step - loss: 0.3069 - acc: 0.8778 - val_loss: 0.3196 - val_acc: 0.8562\n",
      "Epoch 53/100\n",
      "1751/1751 [==============================] - 1s 336us/step - loss: 0.3066 - acc: 0.8761 - val_loss: 0.3178 - val_acc: 0.8607\n",
      "Epoch 54/100\n",
      "1751/1751 [==============================] - 1s 341us/step - loss: 0.3033 - acc: 0.8812 - val_loss: 0.3174 - val_acc: 0.8584\n",
      "Epoch 55/100\n",
      "1751/1751 [==============================] - 1s 329us/step - loss: 0.3010 - acc: 0.8761 - val_loss: 0.3160 - val_acc: 0.8607\n",
      "Epoch 56/100\n",
      "1751/1751 [==============================] - 1s 346us/step - loss: 0.2915 - acc: 0.8829 - val_loss: 0.3151 - val_acc: 0.8607\n",
      "Epoch 57/100\n",
      "1751/1751 [==============================] - 1s 374us/step - loss: 0.3023 - acc: 0.8732 - val_loss: 0.3141 - val_acc: 0.8630\n",
      "Epoch 58/100\n",
      "1751/1751 [==============================] - 1s 368us/step - loss: 0.2965 - acc: 0.8829 - val_loss: 0.3123 - val_acc: 0.8653\n",
      "Epoch 59/100\n",
      "1751/1751 [==============================] - 1s 375us/step - loss: 0.2979 - acc: 0.8801 - val_loss: 0.3135 - val_acc: 0.8584\n",
      "Epoch 60/100\n",
      "1751/1751 [==============================] - 1s 398us/step - loss: 0.2928 - acc: 0.8806 - val_loss: 0.3122 - val_acc: 0.8630\n",
      "Epoch 61/100\n",
      "1751/1751 [==============================] - 1s 394us/step - loss: 0.2936 - acc: 0.8829 - val_loss: 0.3144 - val_acc: 0.8584\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1751/1751 [==============================] - 1s 346us/step - loss: 0.2909 - acc: 0.8898 - val_loss: 0.3112 - val_acc: 0.8653\n",
      "Epoch 63/100\n",
      "1751/1751 [==============================] - 1s 352us/step - loss: 0.2951 - acc: 0.8812 - val_loss: 0.3106 - val_acc: 0.8630\n",
      "Epoch 64/100\n",
      "1751/1751 [==============================] - 1s 346us/step - loss: 0.2902 - acc: 0.8824 - val_loss: 0.3086 - val_acc: 0.8699\n",
      "Epoch 65/100\n",
      "1751/1751 [==============================] - 1s 333us/step - loss: 0.2857 - acc: 0.8881 - val_loss: 0.3069 - val_acc: 0.8699\n",
      "Epoch 66/100\n",
      "1751/1751 [==============================] - 1s 349us/step - loss: 0.2862 - acc: 0.8841 - val_loss: 0.3070 - val_acc: 0.8699\n",
      "Epoch 67/100\n",
      "1751/1751 [==============================] - 1s 348us/step - loss: 0.2824 - acc: 0.8886 - val_loss: 0.3081 - val_acc: 0.8676\n",
      "Epoch 68/100\n",
      "1751/1751 [==============================] - 1s 362us/step - loss: 0.2808 - acc: 0.8841 - val_loss: 0.3049 - val_acc: 0.8721\n",
      "Epoch 69/100\n",
      "1751/1751 [==============================] - 1s 353us/step - loss: 0.2910 - acc: 0.8858 - val_loss: 0.3046 - val_acc: 0.8744\n",
      "Epoch 70/100\n",
      "1751/1751 [==============================] - 1s 347us/step - loss: 0.2776 - acc: 0.8898 - val_loss: 0.3021 - val_acc: 0.8790\n",
      "Epoch 71/100\n",
      "1751/1751 [==============================] - 1s 344us/step - loss: 0.2804 - acc: 0.8846 - val_loss: 0.3027 - val_acc: 0.8767\n",
      "Epoch 72/100\n",
      "1751/1751 [==============================] - 1s 343us/step - loss: 0.2788 - acc: 0.8915 - val_loss: 0.3011 - val_acc: 0.8790\n",
      "Epoch 73/100\n",
      "1751/1751 [==============================] - 1s 351us/step - loss: 0.2766 - acc: 0.8921 - val_loss: 0.3020 - val_acc: 0.8767\n",
      "Epoch 74/100\n",
      "1751/1751 [==============================] - 1s 366us/step - loss: 0.2764 - acc: 0.8909 - val_loss: 0.3000 - val_acc: 0.8813\n",
      "Epoch 75/100\n",
      "1751/1751 [==============================] - 1s 371us/step - loss: 0.2785 - acc: 0.8966 - val_loss: 0.3023 - val_acc: 0.8676\n",
      "Epoch 76/100\n",
      "1751/1751 [==============================] - 1s 360us/step - loss: 0.2766 - acc: 0.8926 - val_loss: 0.2996 - val_acc: 0.8790\n",
      "Epoch 77/100\n",
      "1751/1751 [==============================] - 1s 369us/step - loss: 0.2725 - acc: 0.8909 - val_loss: 0.2994 - val_acc: 0.8790\n",
      "Epoch 78/100\n",
      "1751/1751 [==============================] - 1s 341us/step - loss: 0.2730 - acc: 0.8864 - val_loss: 0.2984 - val_acc: 0.8813\n",
      "Epoch 79/100\n",
      "1751/1751 [==============================] - 1s 356us/step - loss: 0.2700 - acc: 0.8961 - val_loss: 0.2999 - val_acc: 0.8767\n",
      "Epoch 80/100\n",
      "1751/1751 [==============================] - 1s 398us/step - loss: 0.2582 - acc: 0.9018 - val_loss: 0.2969 - val_acc: 0.8858\n",
      "Epoch 81/100\n",
      "1751/1751 [==============================] - 1s 351us/step - loss: 0.2759 - acc: 0.8961 - val_loss: 0.2954 - val_acc: 0.8904\n",
      "Epoch 82/100\n",
      "1751/1751 [==============================] - 1s 363us/step - loss: 0.2690 - acc: 0.8915 - val_loss: 0.2957 - val_acc: 0.8858\n",
      "Epoch 83/100\n",
      "1751/1751 [==============================] - 1s 352us/step - loss: 0.2755 - acc: 0.8932 - val_loss: 0.2963 - val_acc: 0.8790\n",
      "Epoch 84/100\n",
      "1751/1751 [==============================] - 1s 395us/step - loss: 0.2672 - acc: 0.8932 - val_loss: 0.2955 - val_acc: 0.8790\n",
      "Epoch 85/100\n",
      "1751/1751 [==============================] - 1s 407us/step - loss: 0.2728 - acc: 0.8949 - val_loss: 0.2936 - val_acc: 0.8881\n",
      "Epoch 86/100\n",
      "1751/1751 [==============================] - 1s 389us/step - loss: 0.2674 - acc: 0.8966 - val_loss: 0.2939 - val_acc: 0.8881\n",
      "Epoch 87/100\n",
      "1751/1751 [==============================] - 1s 371us/step - loss: 0.2534 - acc: 0.9086 - val_loss: 0.2916 - val_acc: 0.8904\n",
      "Epoch 88/100\n",
      "1751/1751 [==============================] - 1s 389us/step - loss: 0.2582 - acc: 0.8955 - val_loss: 0.2907 - val_acc: 0.8881\n",
      "Epoch 89/100\n",
      "1751/1751 [==============================] - 1s 380us/step - loss: 0.2613 - acc: 0.9046 - val_loss: 0.2915 - val_acc: 0.8904\n",
      "Epoch 90/100\n",
      "1751/1751 [==============================] - 1s 359us/step - loss: 0.2673 - acc: 0.8943 - val_loss: 0.2905 - val_acc: 0.8904\n",
      "Epoch 91/100\n",
      "1751/1751 [==============================] - 1s 404us/step - loss: 0.2571 - acc: 0.9001 - val_loss: 0.2902 - val_acc: 0.8904\n",
      "Epoch 92/100\n",
      "1751/1751 [==============================] - 1s 393us/step - loss: 0.2566 - acc: 0.9006 - val_loss: 0.2907 - val_acc: 0.8927\n",
      "Epoch 93/100\n",
      "1751/1751 [==============================] - 1s 363us/step - loss: 0.2550 - acc: 0.9092 - val_loss: 0.2894 - val_acc: 0.8904\n",
      "Epoch 94/100\n",
      "1751/1751 [==============================] - 1s 352us/step - loss: 0.2514 - acc: 0.8978 - val_loss: 0.2892 - val_acc: 0.8881\n",
      "Epoch 95/100\n",
      "1751/1751 [==============================] - 1s 340us/step - loss: 0.2571 - acc: 0.8983 - val_loss: 0.2876 - val_acc: 0.8904\n",
      "Epoch 96/100\n",
      "1751/1751 [==============================] - 1s 369us/step - loss: 0.2475 - acc: 0.9029 - val_loss: 0.2869 - val_acc: 0.8904\n",
      "Epoch 97/100\n",
      "1751/1751 [==============================] - 1s 391us/step - loss: 0.2450 - acc: 0.9109 - val_loss: 0.2859 - val_acc: 0.8950\n",
      "Epoch 98/100\n",
      "1751/1751 [==============================] - 1s 322us/step - loss: 0.2587 - acc: 0.8978 - val_loss: 0.2879 - val_acc: 0.8881\n",
      "Epoch 99/100\n",
      "1751/1751 [==============================] - 1s 391us/step - loss: 0.2448 - acc: 0.9063 - val_loss: 0.2849 - val_acc: 0.8927\n",
      "Epoch 100/100\n",
      "1751/1751 [==============================] - 1s 409us/step - loss: 0.2486 - acc: 0.9046 - val_loss: 0.2851 - val_acc: 0.8927\n",
      "Test subject 9, class LiftOff\n",
      "Train subject 9, class Replace\n",
      "Train on 1752 samples, validate on 438 samples\n",
      "Epoch 1/100\n",
      "1752/1752 [==============================] - 1s 657us/step - loss: 0.6932 - acc: 0.4932 - val_loss: 0.6908 - val_acc: 0.5822\n",
      "Epoch 2/100\n",
      "1752/1752 [==============================] - 1s 380us/step - loss: 0.6891 - acc: 0.5474 - val_loss: 0.6901 - val_acc: 0.5776\n",
      "Epoch 3/100\n",
      "1752/1752 [==============================] - 1s 401us/step - loss: 0.6908 - acc: 0.5251 - val_loss: 0.6895 - val_acc: 0.5913\n",
      "Epoch 4/100\n",
      "1752/1752 [==============================] - 1s 418us/step - loss: 0.6926 - acc: 0.5046 - val_loss: 0.6889 - val_acc: 0.5868\n",
      "Epoch 5/100\n",
      "1752/1752 [==============================] - 1s 368us/step - loss: 0.6909 - acc: 0.5183 - val_loss: 0.6882 - val_acc: 0.5936\n",
      "Epoch 6/100\n",
      "1752/1752 [==============================] - 1s 345us/step - loss: 0.6895 - acc: 0.5388 - val_loss: 0.6876 - val_acc: 0.6119\n",
      "Epoch 7/100\n",
      "1752/1752 [==============================] - 1s 364us/step - loss: 0.6890 - acc: 0.5257 - val_loss: 0.6869 - val_acc: 0.6279\n",
      "Epoch 8/100\n",
      "1752/1752 [==============================] - 1s 370us/step - loss: 0.6895 - acc: 0.5348 - val_loss: 0.6862 - val_acc: 0.6370\n",
      "Epoch 9/100\n",
      "1752/1752 [==============================] - 1s 399us/step - loss: 0.6855 - acc: 0.5736 - val_loss: 0.6854 - val_acc: 0.6438\n",
      "Epoch 10/100\n",
      "1752/1752 [==============================] - 1s 388us/step - loss: 0.6870 - acc: 0.5571 - val_loss: 0.6847 - val_acc: 0.6461\n",
      "Epoch 11/100\n",
      "1752/1752 [==============================] - 1s 364us/step - loss: 0.6872 - acc: 0.5702 - val_loss: 0.6839 - val_acc: 0.6575\n",
      "Epoch 12/100\n",
      "1752/1752 [==============================] - 1s 382us/step - loss: 0.6834 - acc: 0.5822 - val_loss: 0.6831 - val_acc: 0.6598\n",
      "Epoch 13/100\n",
      "1752/1752 [==============================] - 1s 369us/step - loss: 0.6858 - acc: 0.5731 - val_loss: 0.6822 - val_acc: 0.6689\n",
      "Epoch 14/100\n",
      "1752/1752 [==============================] - 1s 373us/step - loss: 0.6841 - acc: 0.5685 - val_loss: 0.6813 - val_acc: 0.6689\n",
      "Epoch 15/100\n",
      "1752/1752 [==============================] - 1s 352us/step - loss: 0.6833 - acc: 0.5731 - val_loss: 0.6802 - val_acc: 0.6667\n",
      "Epoch 16/100\n",
      "1752/1752 [==============================] - 1s 364us/step - loss: 0.6816 - acc: 0.5902 - val_loss: 0.6790 - val_acc: 0.6689\n",
      "Epoch 17/100\n",
      "1752/1752 [==============================] - 1s 393us/step - loss: 0.6813 - acc: 0.5845 - val_loss: 0.6779 - val_acc: 0.6644\n",
      "Epoch 18/100\n",
      "1752/1752 [==============================] - 1s 358us/step - loss: 0.6805 - acc: 0.5930 - val_loss: 0.6768 - val_acc: 0.6598\n",
      "Epoch 19/100\n",
      "1752/1752 [==============================] - 1s 361us/step - loss: 0.6808 - acc: 0.5868 - val_loss: 0.6756 - val_acc: 0.6667\n",
      "Epoch 20/100\n",
      "1752/1752 [==============================] - 1s 387us/step - loss: 0.6788 - acc: 0.6050 - val_loss: 0.6743 - val_acc: 0.6781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.6756 - acc: 0.6090 - val_loss: 0.6729 - val_acc: 0.6735\n",
      "Epoch 22/100\n",
      "1752/1752 [==============================] - 1s 339us/step - loss: 0.6774 - acc: 0.6033 - val_loss: 0.6716 - val_acc: 0.6712\n",
      "Epoch 23/100\n",
      "1752/1752 [==============================] - 1s 384us/step - loss: 0.6751 - acc: 0.6199 - val_loss: 0.6701 - val_acc: 0.6781\n",
      "Epoch 24/100\n",
      "1752/1752 [==============================] - 1s 370us/step - loss: 0.6757 - acc: 0.6107 - val_loss: 0.6687 - val_acc: 0.6895\n",
      "Epoch 25/100\n",
      "1752/1752 [==============================] - 1s 353us/step - loss: 0.6727 - acc: 0.6301 - val_loss: 0.6670 - val_acc: 0.6941\n",
      "Epoch 26/100\n",
      "1752/1752 [==============================] - 1s 397us/step - loss: 0.6710 - acc: 0.6307 - val_loss: 0.6652 - val_acc: 0.6918\n",
      "Epoch 27/100\n",
      "1752/1752 [==============================] - 1s 376us/step - loss: 0.6707 - acc: 0.6330 - val_loss: 0.6634 - val_acc: 0.6986\n",
      "Epoch 28/100\n",
      "1752/1752 [==============================] - 1s 362us/step - loss: 0.6680 - acc: 0.6473 - val_loss: 0.6615 - val_acc: 0.7032\n",
      "Epoch 29/100\n",
      "1752/1752 [==============================] - 1s 348us/step - loss: 0.6646 - acc: 0.6444 - val_loss: 0.6594 - val_acc: 0.7009\n",
      "Epoch 30/100\n",
      "1752/1752 [==============================] - 1s 358us/step - loss: 0.6673 - acc: 0.6358 - val_loss: 0.6573 - val_acc: 0.7009\n",
      "Epoch 31/100\n",
      "1752/1752 [==============================] - 1s 362us/step - loss: 0.6631 - acc: 0.6518 - val_loss: 0.6552 - val_acc: 0.7055\n",
      "Epoch 32/100\n",
      "1752/1752 [==============================] - 1s 427us/step - loss: 0.6613 - acc: 0.6570 - val_loss: 0.6528 - val_acc: 0.7078\n",
      "Epoch 33/100\n",
      "1752/1752 [==============================] - 1s 376us/step - loss: 0.6587 - acc: 0.6604 - val_loss: 0.6502 - val_acc: 0.7032\n",
      "Epoch 34/100\n",
      "1752/1752 [==============================] - 1s 346us/step - loss: 0.6571 - acc: 0.6678 - val_loss: 0.6475 - val_acc: 0.7009\n",
      "Epoch 35/100\n",
      "1752/1752 [==============================] - 1s 371us/step - loss: 0.6555 - acc: 0.6570 - val_loss: 0.6448 - val_acc: 0.7009\n",
      "Epoch 36/100\n",
      "1752/1752 [==============================] - 1s 392us/step - loss: 0.6552 - acc: 0.6638 - val_loss: 0.6421 - val_acc: 0.7032\n",
      "Epoch 37/100\n",
      "1752/1752 [==============================] - 1s 373us/step - loss: 0.6532 - acc: 0.6655 - val_loss: 0.6392 - val_acc: 0.7078\n",
      "Epoch 38/100\n",
      "1752/1752 [==============================] - 1s 369us/step - loss: 0.6471 - acc: 0.6804 - val_loss: 0.6357 - val_acc: 0.7055\n",
      "Epoch 39/100\n",
      "1752/1752 [==============================] - 1s 353us/step - loss: 0.6439 - acc: 0.6924 - val_loss: 0.6320 - val_acc: 0.7055\n",
      "Epoch 40/100\n",
      "1752/1752 [==============================] - 1s 371us/step - loss: 0.6432 - acc: 0.6809 - val_loss: 0.6286 - val_acc: 0.7078\n",
      "Epoch 41/100\n",
      "1752/1752 [==============================] - 1s 396us/step - loss: 0.6374 - acc: 0.6912 - val_loss: 0.6246 - val_acc: 0.7100\n",
      "Epoch 42/100\n",
      "1752/1752 [==============================] - 1s 363us/step - loss: 0.6369 - acc: 0.6747 - val_loss: 0.6208 - val_acc: 0.7123\n",
      "Epoch 43/100\n",
      "1752/1752 [==============================] - 1s 354us/step - loss: 0.6353 - acc: 0.6769 - val_loss: 0.6167 - val_acc: 0.7192\n",
      "Epoch 44/100\n",
      "1752/1752 [==============================] - 1s 386us/step - loss: 0.6295 - acc: 0.6992 - val_loss: 0.6124 - val_acc: 0.7192\n",
      "Epoch 45/100\n",
      "1752/1752 [==============================] - 1s 373us/step - loss: 0.6253 - acc: 0.6958 - val_loss: 0.6083 - val_acc: 0.7237\n",
      "Epoch 46/100\n",
      "1752/1752 [==============================] - 1s 361us/step - loss: 0.6210 - acc: 0.6946 - val_loss: 0.6037 - val_acc: 0.7283\n",
      "Epoch 47/100\n",
      "1752/1752 [==============================] - 1s 371us/step - loss: 0.6139 - acc: 0.6958 - val_loss: 0.5985 - val_acc: 0.7306\n",
      "Epoch 48/100\n",
      "1752/1752 [==============================] - 1s 364us/step - loss: 0.6145 - acc: 0.7003 - val_loss: 0.5936 - val_acc: 0.7306\n",
      "Epoch 49/100\n",
      "1752/1752 [==============================] - 1s 378us/step - loss: 0.6069 - acc: 0.7152 - val_loss: 0.5886 - val_acc: 0.7374\n",
      "Epoch 50/100\n",
      "1752/1752 [==============================] - 1s 381us/step - loss: 0.6048 - acc: 0.7158 - val_loss: 0.5835 - val_acc: 0.7352\n",
      "Epoch 51/100\n",
      "1752/1752 [==============================] - 1s 390us/step - loss: 0.5948 - acc: 0.7123 - val_loss: 0.5778 - val_acc: 0.7374\n",
      "Epoch 52/100\n",
      "1752/1752 [==============================] - 1s 391us/step - loss: 0.5934 - acc: 0.7192 - val_loss: 0.5726 - val_acc: 0.7374\n",
      "Epoch 53/100\n",
      "1752/1752 [==============================] - 1s 352us/step - loss: 0.5882 - acc: 0.7226 - val_loss: 0.5670 - val_acc: 0.7420\n",
      "Epoch 54/100\n",
      "1752/1752 [==============================] - 1s 352us/step - loss: 0.5834 - acc: 0.7197 - val_loss: 0.5623 - val_acc: 0.7420\n",
      "Epoch 55/100\n",
      "1752/1752 [==============================] - 1s 373us/step - loss: 0.5789 - acc: 0.7243 - val_loss: 0.5569 - val_acc: 0.7466\n",
      "Epoch 56/100\n",
      "1752/1752 [==============================] - 1s 368us/step - loss: 0.5709 - acc: 0.7369 - val_loss: 0.5517 - val_acc: 0.7511\n",
      "Epoch 57/100\n",
      "1752/1752 [==============================] - 1s 353us/step - loss: 0.5643 - acc: 0.7300 - val_loss: 0.5462 - val_acc: 0.7534\n",
      "Epoch 58/100\n",
      "1752/1752 [==============================] - 1s 356us/step - loss: 0.5585 - acc: 0.7289 - val_loss: 0.5406 - val_acc: 0.7534\n",
      "Epoch 59/100\n",
      "1752/1752 [==============================] - 1s 352us/step - loss: 0.5535 - acc: 0.7403 - val_loss: 0.5350 - val_acc: 0.7557\n",
      "Epoch 60/100\n",
      "1752/1752 [==============================] - 1s 435us/step - loss: 0.5529 - acc: 0.7346 - val_loss: 0.5294 - val_acc: 0.7511\n",
      "Epoch 61/100\n",
      "1752/1752 [==============================] - 1s 364us/step - loss: 0.5520 - acc: 0.7329 - val_loss: 0.5250 - val_acc: 0.7534\n",
      "Epoch 62/100\n",
      "1752/1752 [==============================] - 1s 377us/step - loss: 0.5463 - acc: 0.7374 - val_loss: 0.5194 - val_acc: 0.7557\n",
      "Epoch 63/100\n",
      "1752/1752 [==============================] - 1s 365us/step - loss: 0.5377 - acc: 0.7426 - val_loss: 0.5141 - val_acc: 0.7557\n",
      "Epoch 64/100\n",
      "1752/1752 [==============================] - 1s 355us/step - loss: 0.5315 - acc: 0.7523 - val_loss: 0.5090 - val_acc: 0.7557\n",
      "Epoch 65/100\n",
      "1752/1752 [==============================] - 1s 352us/step - loss: 0.5306 - acc: 0.7483 - val_loss: 0.5048 - val_acc: 0.7603\n",
      "Epoch 66/100\n",
      "1752/1752 [==============================] - 1s 370us/step - loss: 0.5200 - acc: 0.7568 - val_loss: 0.4987 - val_acc: 0.7603\n",
      "Epoch 67/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.5179 - acc: 0.7540 - val_loss: 0.4939 - val_acc: 0.7626\n",
      "Epoch 68/100\n",
      "1752/1752 [==============================] - 1s 337us/step - loss: 0.5183 - acc: 0.7500 - val_loss: 0.4893 - val_acc: 0.7603\n",
      "Epoch 69/100\n",
      "1752/1752 [==============================] - 1s 393us/step - loss: 0.5186 - acc: 0.7506 - val_loss: 0.4847 - val_acc: 0.7626\n",
      "Epoch 70/100\n",
      "1752/1752 [==============================] - 1s 371us/step - loss: 0.5096 - acc: 0.7574 - val_loss: 0.4805 - val_acc: 0.7626\n",
      "Epoch 71/100\n",
      "1752/1752 [==============================] - 1s 340us/step - loss: 0.4990 - acc: 0.7666 - val_loss: 0.4762 - val_acc: 0.7648\n",
      "Epoch 72/100\n",
      "1752/1752 [==============================] - 1s 358us/step - loss: 0.5016 - acc: 0.7614 - val_loss: 0.4719 - val_acc: 0.7694\n",
      "Epoch 73/100\n",
      "1752/1752 [==============================] - 1s 373us/step - loss: 0.4989 - acc: 0.7603 - val_loss: 0.4680 - val_acc: 0.7763\n",
      "Epoch 74/100\n",
      "1752/1752 [==============================] - 1s 378us/step - loss: 0.4875 - acc: 0.7745 - val_loss: 0.4644 - val_acc: 0.7785\n",
      "Epoch 75/100\n",
      "1752/1752 [==============================] - 1s 411us/step - loss: 0.4854 - acc: 0.7711 - val_loss: 0.4603 - val_acc: 0.7785\n",
      "Epoch 76/100\n",
      "1752/1752 [==============================] - 1s 373us/step - loss: 0.4806 - acc: 0.7700 - val_loss: 0.4558 - val_acc: 0.7763\n",
      "Epoch 77/100\n",
      "1752/1752 [==============================] - 1s 363us/step - loss: 0.4720 - acc: 0.7803 - val_loss: 0.4527 - val_acc: 0.7922\n",
      "Epoch 78/100\n",
      "1752/1752 [==============================] - 1s 356us/step - loss: 0.4761 - acc: 0.7814 - val_loss: 0.4485 - val_acc: 0.7831\n",
      "Epoch 79/100\n",
      "1752/1752 [==============================] - 1s 341us/step - loss: 0.4814 - acc: 0.7723 - val_loss: 0.4452 - val_acc: 0.7968\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1752/1752 [==============================] - 1s 357us/step - loss: 0.4672 - acc: 0.7865 - val_loss: 0.4416 - val_acc: 0.7945\n",
      "Epoch 81/100\n",
      "1752/1752 [==============================] - 1s 348us/step - loss: 0.4643 - acc: 0.7860 - val_loss: 0.4394 - val_acc: 0.8105\n",
      "Epoch 82/100\n",
      "1752/1752 [==============================] - 1s 341us/step - loss: 0.4670 - acc: 0.7848 - val_loss: 0.4360 - val_acc: 0.8128\n",
      "Epoch 83/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.4625 - acc: 0.7854 - val_loss: 0.4332 - val_acc: 0.8151\n",
      "Epoch 84/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.4567 - acc: 0.7894 - val_loss: 0.4316 - val_acc: 0.8128\n",
      "Epoch 85/100\n",
      "1752/1752 [==============================] - 1s 339us/step - loss: 0.4653 - acc: 0.7837 - val_loss: 0.4265 - val_acc: 0.8082\n",
      "Epoch 86/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.4512 - acc: 0.7974 - val_loss: 0.4255 - val_acc: 0.8174\n",
      "Epoch 87/100\n",
      "1752/1752 [==============================] - 1s 337us/step - loss: 0.4560 - acc: 0.7985 - val_loss: 0.4216 - val_acc: 0.8151\n",
      "Epoch 88/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.4474 - acc: 0.7894 - val_loss: 0.4204 - val_acc: 0.8174\n",
      "Epoch 89/100\n",
      "1752/1752 [==============================] - 1s 341us/step - loss: 0.4578 - acc: 0.7968 - val_loss: 0.4169 - val_acc: 0.8174\n",
      "Epoch 90/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.4469 - acc: 0.7974 - val_loss: 0.4140 - val_acc: 0.8151\n",
      "Epoch 91/100\n",
      "1752/1752 [==============================] - 1s 359us/step - loss: 0.4408 - acc: 0.7997 - val_loss: 0.4126 - val_acc: 0.8174\n",
      "Epoch 92/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.4383 - acc: 0.7968 - val_loss: 0.4135 - val_acc: 0.8174\n",
      "Epoch 93/100\n",
      "1752/1752 [==============================] - 1s 343us/step - loss: 0.4428 - acc: 0.8094 - val_loss: 0.4095 - val_acc: 0.8174\n",
      "Epoch 94/100\n",
      "1752/1752 [==============================] - 1s 350us/step - loss: 0.4293 - acc: 0.8196 - val_loss: 0.4063 - val_acc: 0.8196\n",
      "Epoch 95/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.4274 - acc: 0.8128 - val_loss: 0.4055 - val_acc: 0.8174\n",
      "Epoch 96/100\n",
      "1752/1752 [==============================] - 1s 344us/step - loss: 0.4296 - acc: 0.8076 - val_loss: 0.4028 - val_acc: 0.8196\n",
      "Epoch 97/100\n",
      "1752/1752 [==============================] - 1s 340us/step - loss: 0.4381 - acc: 0.8025 - val_loss: 0.4023 - val_acc: 0.8196\n",
      "Epoch 98/100\n",
      "1752/1752 [==============================] - 1s 342us/step - loss: 0.4288 - acc: 0.8076 - val_loss: 0.4027 - val_acc: 0.8151\n",
      "Epoch 99/100\n",
      "1752/1752 [==============================] - 1s 335us/step - loss: 0.4309 - acc: 0.8174 - val_loss: 0.3997 - val_acc: 0.8174\n",
      "Epoch 100/100\n",
      "1752/1752 [==============================] - 1s 340us/step - loss: 0.4284 - acc: 0.8151 - val_loss: 0.3955 - val_acc: 0.8174\n",
      "Train on 1752 samples, validate on 438 samples\n",
      "Epoch 1/100\n",
      "1752/1752 [==============================] - 1s 340us/step - loss: 0.4243 - acc: 0.8122 - val_loss: 0.3357 - val_acc: 0.8676\n",
      "Epoch 2/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.4294 - acc: 0.8168 - val_loss: 0.3348 - val_acc: 0.8676\n",
      "Epoch 3/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.4154 - acc: 0.8105 - val_loss: 0.3374 - val_acc: 0.8607\n",
      "Epoch 4/100\n",
      "1752/1752 [==============================] - 1s 344us/step - loss: 0.4195 - acc: 0.8088 - val_loss: 0.3354 - val_acc: 0.8630\n",
      "Epoch 5/100\n",
      "1752/1752 [==============================] - 1s 341us/step - loss: 0.4056 - acc: 0.8111 - val_loss: 0.3312 - val_acc: 0.8676\n",
      "Epoch 6/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.4110 - acc: 0.8162 - val_loss: 0.3308 - val_acc: 0.8676\n",
      "Epoch 7/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.4105 - acc: 0.8265 - val_loss: 0.3250 - val_acc: 0.8744\n",
      "Epoch 8/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.4054 - acc: 0.8202 - val_loss: 0.3250 - val_acc: 0.8721\n",
      "Epoch 9/100\n",
      "1752/1752 [==============================] - 1s 346us/step - loss: 0.4104 - acc: 0.8185 - val_loss: 0.3213 - val_acc: 0.8767\n",
      "Epoch 10/100\n",
      "1752/1752 [==============================] - 1s 355us/step - loss: 0.4039 - acc: 0.8185 - val_loss: 0.3215 - val_acc: 0.8767\n",
      "Epoch 11/100\n",
      "1752/1752 [==============================] - 1s 348us/step - loss: 0.4004 - acc: 0.8259 - val_loss: 0.3247 - val_acc: 0.8630\n",
      "Epoch 12/100\n",
      "1752/1752 [==============================] - 1s 349us/step - loss: 0.3973 - acc: 0.8213 - val_loss: 0.3269 - val_acc: 0.8653\n",
      "Epoch 13/100\n",
      "1752/1752 [==============================] - 1s 337us/step - loss: 0.3977 - acc: 0.8185 - val_loss: 0.3181 - val_acc: 0.8721\n",
      "Epoch 14/100\n",
      "1752/1752 [==============================] - 1s 340us/step - loss: 0.3906 - acc: 0.8271 - val_loss: 0.3235 - val_acc: 0.8676\n",
      "Epoch 15/100\n",
      "1752/1752 [==============================] - 1s 345us/step - loss: 0.3943 - acc: 0.8213 - val_loss: 0.3224 - val_acc: 0.8676\n",
      "Epoch 16/100\n",
      "1752/1752 [==============================] - 1s 343us/step - loss: 0.3886 - acc: 0.8265 - val_loss: 0.3180 - val_acc: 0.8721\n",
      "Epoch 17/100\n",
      "1752/1752 [==============================] - 1s 373us/step - loss: 0.3979 - acc: 0.8225 - val_loss: 0.3200 - val_acc: 0.8767\n",
      "Epoch 18/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.3966 - acc: 0.8191 - val_loss: 0.3130 - val_acc: 0.8699\n",
      "Epoch 19/100\n",
      "1752/1752 [==============================] - 1s 351us/step - loss: 0.3797 - acc: 0.8368 - val_loss: 0.3095 - val_acc: 0.8744\n",
      "Epoch 20/100\n",
      "1752/1752 [==============================] - 1s 342us/step - loss: 0.3838 - acc: 0.8288 - val_loss: 0.3097 - val_acc: 0.8721\n",
      "Epoch 21/100\n",
      "1752/1752 [==============================] - 1s 372us/step - loss: 0.3748 - acc: 0.8339 - val_loss: 0.3050 - val_acc: 0.8767\n",
      "Epoch 22/100\n",
      "1752/1752 [==============================] - 1s 343us/step - loss: 0.3851 - acc: 0.8362 - val_loss: 0.3100 - val_acc: 0.8790\n",
      "Epoch 23/100\n",
      "1752/1752 [==============================] - 1s 361us/step - loss: 0.3767 - acc: 0.8385 - val_loss: 0.3044 - val_acc: 0.8790\n",
      "Epoch 24/100\n",
      "1752/1752 [==============================] - 1s 348us/step - loss: 0.3756 - acc: 0.8390 - val_loss: 0.3017 - val_acc: 0.8767\n",
      "Epoch 25/100\n",
      "1752/1752 [==============================] - 1s 347us/step - loss: 0.3806 - acc: 0.8390 - val_loss: 0.2997 - val_acc: 0.8744\n",
      "Epoch 26/100\n",
      "1752/1752 [==============================] - 1s 335us/step - loss: 0.3687 - acc: 0.8408 - val_loss: 0.3031 - val_acc: 0.8858\n",
      "Epoch 27/100\n",
      "1752/1752 [==============================] - 1s 338us/step - loss: 0.3763 - acc: 0.8350 - val_loss: 0.3048 - val_acc: 0.8836\n",
      "Epoch 28/100\n",
      "1752/1752 [==============================] - 1s 340us/step - loss: 0.3684 - acc: 0.8465 - val_loss: 0.3001 - val_acc: 0.8881\n",
      "Epoch 29/100\n",
      "1752/1752 [==============================] - 1s 344us/step - loss: 0.3670 - acc: 0.8447 - val_loss: 0.3019 - val_acc: 0.8858\n",
      "Epoch 30/100\n",
      "1752/1752 [==============================] - 1s 345us/step - loss: 0.3675 - acc: 0.8339 - val_loss: 0.3005 - val_acc: 0.8881\n",
      "Epoch 31/100\n",
      "1752/1752 [==============================] - 1s 341us/step - loss: 0.3791 - acc: 0.8253 - val_loss: 0.2937 - val_acc: 0.8858\n",
      "Epoch 32/100\n",
      "1752/1752 [==============================] - 1s 349us/step - loss: 0.3733 - acc: 0.8390 - val_loss: 0.2968 - val_acc: 0.8858\n",
      "Epoch 33/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.3601 - acc: 0.8493 - val_loss: 0.2928 - val_acc: 0.8881\n",
      "Epoch 34/100\n",
      "1752/1752 [==============================] - 1s 343us/step - loss: 0.3547 - acc: 0.8556 - val_loss: 0.2956 - val_acc: 0.8836\n",
      "Epoch 35/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.3495 - acc: 0.8413 - val_loss: 0.2888 - val_acc: 0.8904\n",
      "Epoch 36/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.3600 - acc: 0.8499 - val_loss: 0.2864 - val_acc: 0.8904\n",
      "Epoch 37/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.3485 - acc: 0.8522 - val_loss: 0.2907 - val_acc: 0.8858\n",
      "Epoch 38/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.3537 - acc: 0.8453 - val_loss: 0.2839 - val_acc: 0.8927\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1752/1752 [==============================] - 1s 321us/step - loss: 0.3395 - acc: 0.8550 - val_loss: 0.2882 - val_acc: 0.8881\n",
      "Epoch 40/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.3430 - acc: 0.8522 - val_loss: 0.2868 - val_acc: 0.8881\n",
      "Epoch 41/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.3499 - acc: 0.8482 - val_loss: 0.2851 - val_acc: 0.8881\n",
      "Epoch 42/100\n",
      "1752/1752 [==============================] - 1s 344us/step - loss: 0.3471 - acc: 0.8459 - val_loss: 0.2833 - val_acc: 0.8881\n",
      "Epoch 43/100\n",
      "1752/1752 [==============================] - 1s 363us/step - loss: 0.3460 - acc: 0.8573 - val_loss: 0.2833 - val_acc: 0.8881\n",
      "Epoch 44/100\n",
      "1752/1752 [==============================] - 1s 347us/step - loss: 0.3404 - acc: 0.8573 - val_loss: 0.2786 - val_acc: 0.8950\n",
      "Epoch 45/100\n",
      "1752/1752 [==============================] - 1s 355us/step - loss: 0.3424 - acc: 0.8596 - val_loss: 0.2786 - val_acc: 0.8950\n",
      "Epoch 46/100\n",
      "1752/1752 [==============================] - 1s 356us/step - loss: 0.3384 - acc: 0.8573 - val_loss: 0.2797 - val_acc: 0.8927\n",
      "Epoch 47/100\n",
      "1752/1752 [==============================] - 1s 349us/step - loss: 0.3399 - acc: 0.8556 - val_loss: 0.2770 - val_acc: 0.8927\n",
      "Epoch 48/100\n",
      "1752/1752 [==============================] - 1s 350us/step - loss: 0.3346 - acc: 0.8590 - val_loss: 0.2768 - val_acc: 0.8950\n",
      "Epoch 49/100\n",
      "1752/1752 [==============================] - 1s 353us/step - loss: 0.3335 - acc: 0.8619 - val_loss: 0.2739 - val_acc: 0.8950\n",
      "Epoch 50/100\n",
      "1752/1752 [==============================] - 1s 358us/step - loss: 0.3275 - acc: 0.8642 - val_loss: 0.2748 - val_acc: 0.8973\n",
      "Epoch 51/100\n",
      "1752/1752 [==============================] - 1s 341us/step - loss: 0.3264 - acc: 0.8636 - val_loss: 0.2712 - val_acc: 0.8950\n",
      "Epoch 52/100\n",
      "1752/1752 [==============================] - 1s 378us/step - loss: 0.3256 - acc: 0.8670 - val_loss: 0.2724 - val_acc: 0.8973\n",
      "Epoch 53/100\n",
      "1752/1752 [==============================] - 1s 407us/step - loss: 0.3292 - acc: 0.8647 - val_loss: 0.2724 - val_acc: 0.8973\n",
      "Epoch 54/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.3246 - acc: 0.8636 - val_loss: 0.2694 - val_acc: 0.8973\n",
      "Epoch 55/100\n",
      "1752/1752 [==============================] - 1s 362us/step - loss: 0.3258 - acc: 0.8659 - val_loss: 0.2749 - val_acc: 0.8973\n",
      "Epoch 56/100\n",
      "1752/1752 [==============================] - 1s 375us/step - loss: 0.3233 - acc: 0.8630 - val_loss: 0.2719 - val_acc: 0.9018\n",
      "Epoch 57/100\n",
      "1752/1752 [==============================] - 1s 355us/step - loss: 0.3303 - acc: 0.8613 - val_loss: 0.2654 - val_acc: 0.8973\n",
      "Epoch 58/100\n",
      "1752/1752 [==============================] - 1s 370us/step - loss: 0.3188 - acc: 0.8630 - val_loss: 0.2658 - val_acc: 0.8973\n",
      "Epoch 59/100\n",
      "1752/1752 [==============================] - 1s 391us/step - loss: 0.3212 - acc: 0.8676 - val_loss: 0.2626 - val_acc: 0.8973\n",
      "Epoch 60/100\n",
      "1752/1752 [==============================] - 1s 372us/step - loss: 0.3244 - acc: 0.8636 - val_loss: 0.2625 - val_acc: 0.8973\n",
      "Epoch 61/100\n",
      "1752/1752 [==============================] - 1s 364us/step - loss: 0.3157 - acc: 0.8750 - val_loss: 0.2627 - val_acc: 0.9018\n",
      "Epoch 62/100\n",
      "1752/1752 [==============================] - 1s 343us/step - loss: 0.3230 - acc: 0.8630 - val_loss: 0.2636 - val_acc: 0.9018\n",
      "Epoch 63/100\n",
      "1752/1752 [==============================] - 1s 352us/step - loss: 0.3214 - acc: 0.8659 - val_loss: 0.2702 - val_acc: 0.8995\n",
      "Epoch 64/100\n",
      "1752/1752 [==============================] - 1s 367us/step - loss: 0.3121 - acc: 0.8647 - val_loss: 0.2579 - val_acc: 0.8995\n",
      "Epoch 65/100\n",
      "1752/1752 [==============================] - 1s 359us/step - loss: 0.3092 - acc: 0.8693 - val_loss: 0.2581 - val_acc: 0.8995\n",
      "Epoch 66/100\n",
      "1752/1752 [==============================] - 1s 348us/step - loss: 0.3063 - acc: 0.8721 - val_loss: 0.2582 - val_acc: 0.9041\n",
      "Epoch 67/100\n",
      "1752/1752 [==============================] - 1s 343us/step - loss: 0.3074 - acc: 0.8761 - val_loss: 0.2560 - val_acc: 0.9018\n",
      "Epoch 68/100\n",
      "1752/1752 [==============================] - 1s 340us/step - loss: 0.3123 - acc: 0.8693 - val_loss: 0.2582 - val_acc: 0.9064\n",
      "Epoch 69/100\n",
      "1752/1752 [==============================] - 1s 393us/step - loss: 0.3105 - acc: 0.8721 - val_loss: 0.2563 - val_acc: 0.9064\n",
      "Epoch 70/100\n",
      "1752/1752 [==============================] - 1s 368us/step - loss: 0.3091 - acc: 0.8659 - val_loss: 0.2532 - val_acc: 0.9064\n",
      "Epoch 71/100\n",
      "1752/1752 [==============================] - 1s 370us/step - loss: 0.3058 - acc: 0.8773 - val_loss: 0.2513 - val_acc: 0.9087\n",
      "Epoch 72/100\n",
      "1752/1752 [==============================] - 1s 346us/step - loss: 0.3075 - acc: 0.8727 - val_loss: 0.2516 - val_acc: 0.9087\n",
      "Epoch 73/100\n",
      "1752/1752 [==============================] - 1s 381us/step - loss: 0.3047 - acc: 0.8699 - val_loss: 0.2493 - val_acc: 0.9087\n",
      "Epoch 74/100\n",
      "1752/1752 [==============================] - 1s 340us/step - loss: 0.3030 - acc: 0.8779 - val_loss: 0.2497 - val_acc: 0.9087\n",
      "Epoch 75/100\n",
      "1752/1752 [==============================] - 1s 358us/step - loss: 0.2958 - acc: 0.8807 - val_loss: 0.2507 - val_acc: 0.9087\n",
      "Epoch 76/100\n",
      "1752/1752 [==============================] - 1s 393us/step - loss: 0.3027 - acc: 0.8739 - val_loss: 0.2535 - val_acc: 0.9087\n",
      "Epoch 77/100\n",
      "1752/1752 [==============================] - 1s 373us/step - loss: 0.2955 - acc: 0.8836 - val_loss: 0.2512 - val_acc: 0.9087\n",
      "Epoch 78/100\n",
      "1752/1752 [==============================] - 1s 352us/step - loss: 0.3004 - acc: 0.8801 - val_loss: 0.2475 - val_acc: 0.9110\n",
      "Epoch 79/100\n",
      "1752/1752 [==============================] - 1s 360us/step - loss: 0.2948 - acc: 0.8756 - val_loss: 0.2445 - val_acc: 0.9087\n",
      "Epoch 80/100\n",
      "1752/1752 [==============================] - 1s 352us/step - loss: 0.2966 - acc: 0.8773 - val_loss: 0.2497 - val_acc: 0.9087\n",
      "Epoch 81/100\n",
      "1752/1752 [==============================] - 1s 340us/step - loss: 0.2965 - acc: 0.8773 - val_loss: 0.2497 - val_acc: 0.9087\n",
      "Epoch 82/100\n",
      "1752/1752 [==============================] - 1s 358us/step - loss: 0.2927 - acc: 0.8830 - val_loss: 0.2405 - val_acc: 0.9110\n",
      "Epoch 83/100\n",
      "1752/1752 [==============================] - 1s 370us/step - loss: 0.2929 - acc: 0.8779 - val_loss: 0.2463 - val_acc: 0.9110\n",
      "Epoch 84/100\n",
      "1752/1752 [==============================] - 1s 350us/step - loss: 0.2908 - acc: 0.8836 - val_loss: 0.2442 - val_acc: 0.9110\n",
      "Epoch 85/100\n",
      "1752/1752 [==============================] - 1s 360us/step - loss: 0.2898 - acc: 0.8830 - val_loss: 0.2424 - val_acc: 0.9110\n",
      "Epoch 86/100\n",
      "1752/1752 [==============================] - 1s 346us/step - loss: 0.2904 - acc: 0.8779 - val_loss: 0.2417 - val_acc: 0.9110\n",
      "Epoch 87/100\n",
      "1752/1752 [==============================] - 1s 379us/step - loss: 0.2793 - acc: 0.8830 - val_loss: 0.2376 - val_acc: 0.9132\n",
      "Epoch 88/100\n",
      "1752/1752 [==============================] - 1s 369us/step - loss: 0.2813 - acc: 0.8836 - val_loss: 0.2422 - val_acc: 0.9110\n",
      "Epoch 89/100\n",
      "1752/1752 [==============================] - 1s 355us/step - loss: 0.2898 - acc: 0.8790 - val_loss: 0.2382 - val_acc: 0.9110\n",
      "Epoch 90/100\n",
      "1752/1752 [==============================] - 1s 395us/step - loss: 0.2903 - acc: 0.8824 - val_loss: 0.2337 - val_acc: 0.9155\n",
      "Epoch 91/100\n",
      "1752/1752 [==============================] - 1s 387us/step - loss: 0.2793 - acc: 0.8858 - val_loss: 0.2397 - val_acc: 0.9110\n",
      "Epoch 92/100\n",
      "1752/1752 [==============================] - 1s 399us/step - loss: 0.2853 - acc: 0.8807 - val_loss: 0.2351 - val_acc: 0.9155\n",
      "Epoch 93/100\n",
      "1752/1752 [==============================] - 1s 388us/step - loss: 0.2832 - acc: 0.8841 - val_loss: 0.2378 - val_acc: 0.9110\n",
      "Epoch 94/100\n",
      "1752/1752 [==============================] - 1s 355us/step - loss: 0.2849 - acc: 0.8881 - val_loss: 0.2334 - val_acc: 0.9155\n",
      "Epoch 95/100\n",
      "1752/1752 [==============================] - 1s 348us/step - loss: 0.2790 - acc: 0.8864 - val_loss: 0.2322 - val_acc: 0.9155\n",
      "Epoch 96/100\n",
      "1752/1752 [==============================] - 1s 360us/step - loss: 0.2722 - acc: 0.8847 - val_loss: 0.2328 - val_acc: 0.9155\n",
      "Epoch 97/100\n",
      "1752/1752 [==============================] - 1s 382us/step - loss: 0.2765 - acc: 0.8881 - val_loss: 0.2322 - val_acc: 0.9155\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1752/1752 [==============================] - 1s 355us/step - loss: 0.2812 - acc: 0.8830 - val_loss: 0.2326 - val_acc: 0.9155\n",
      "Epoch 99/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.2662 - acc: 0.8967 - val_loss: 0.2339 - val_acc: 0.9132\n",
      "Epoch 100/100\n",
      "1752/1752 [==============================] - 1s 349us/step - loss: 0.2694 - acc: 0.8916 - val_loss: 0.2320 - val_acc: 0.9155\n",
      "Test subject 9, class Replace\n",
      "Train subject 9, class BothReleased\n",
      "Train on 1752 samples, validate on 438 samples\n",
      "Epoch 1/100\n",
      "1752/1752 [==============================] - 1s 709us/step - loss: 0.6940 - acc: 0.4903 - val_loss: 0.6916 - val_acc: 0.5183\n",
      "Epoch 2/100\n",
      "1752/1752 [==============================] - 1s 357us/step - loss: 0.6939 - acc: 0.5137 - val_loss: 0.6912 - val_acc: 0.5183\n",
      "Epoch 3/100\n",
      "1752/1752 [==============================] - 1s 369us/step - loss: 0.6936 - acc: 0.4954 - val_loss: 0.6909 - val_acc: 0.5183\n",
      "Epoch 4/100\n",
      "1752/1752 [==============================] - 1s 376us/step - loss: 0.6929 - acc: 0.5063 - val_loss: 0.6906 - val_acc: 0.5183\n",
      "Epoch 5/100\n",
      "1752/1752 [==============================] - 1s 388us/step - loss: 0.6937 - acc: 0.5034 - val_loss: 0.6903 - val_acc: 0.5183\n",
      "Epoch 6/100\n",
      "1752/1752 [==============================] - 1s 379us/step - loss: 0.6928 - acc: 0.5108 - val_loss: 0.6899 - val_acc: 0.5228\n",
      "Epoch 7/100\n",
      "1752/1752 [==============================] - 1s 363us/step - loss: 0.6940 - acc: 0.5051 - val_loss: 0.6896 - val_acc: 0.5228\n",
      "Epoch 8/100\n",
      "1752/1752 [==============================] - 1s 371us/step - loss: 0.6908 - acc: 0.5177 - val_loss: 0.6892 - val_acc: 0.5251\n",
      "Epoch 9/100\n",
      "1752/1752 [==============================] - 1s 387us/step - loss: 0.6915 - acc: 0.5320 - val_loss: 0.6889 - val_acc: 0.5251\n",
      "Epoch 10/100\n",
      "1752/1752 [==============================] - 1s 355us/step - loss: 0.6917 - acc: 0.5137 - val_loss: 0.6886 - val_acc: 0.5274\n",
      "Epoch 11/100\n",
      "1752/1752 [==============================] - 1s 397us/step - loss: 0.6905 - acc: 0.5217 - val_loss: 0.6883 - val_acc: 0.5297\n",
      "Epoch 12/100\n",
      "1752/1752 [==============================] - 1s 373us/step - loss: 0.6920 - acc: 0.5137 - val_loss: 0.6879 - val_acc: 0.5342\n",
      "Epoch 13/100\n",
      "1752/1752 [==============================] - 1s 359us/step - loss: 0.6912 - acc: 0.5297 - val_loss: 0.6875 - val_acc: 0.5388\n",
      "Epoch 14/100\n",
      "1752/1752 [==============================] - 1s 373us/step - loss: 0.6890 - acc: 0.5388 - val_loss: 0.6871 - val_acc: 0.5411\n",
      "Epoch 15/100\n",
      "1752/1752 [==============================] - 1s 379us/step - loss: 0.6903 - acc: 0.5228 - val_loss: 0.6866 - val_acc: 0.5411\n",
      "Epoch 16/100\n",
      "1752/1752 [==============================] - 1s 391us/step - loss: 0.6901 - acc: 0.5211 - val_loss: 0.6863 - val_acc: 0.5457\n",
      "Epoch 17/100\n",
      "1752/1752 [==============================] - 1s 409us/step - loss: 0.6886 - acc: 0.5320 - val_loss: 0.6859 - val_acc: 0.5502\n",
      "Epoch 18/100\n",
      "1752/1752 [==============================] - 1s 364us/step - loss: 0.6876 - acc: 0.5519 - val_loss: 0.6855 - val_acc: 0.5502\n",
      "Epoch 19/100\n",
      "1752/1752 [==============================] - 1s 379us/step - loss: 0.6894 - acc: 0.5297 - val_loss: 0.6850 - val_acc: 0.5571\n",
      "Epoch 20/100\n",
      "1752/1752 [==============================] - 1s 381us/step - loss: 0.6872 - acc: 0.5388 - val_loss: 0.6846 - val_acc: 0.5594\n",
      "Epoch 21/100\n",
      "1752/1752 [==============================] - 1s 360us/step - loss: 0.6870 - acc: 0.5548 - val_loss: 0.6841 - val_acc: 0.5662\n",
      "Epoch 22/100\n",
      "1752/1752 [==============================] - 1s 400us/step - loss: 0.6844 - acc: 0.5594 - val_loss: 0.6836 - val_acc: 0.5685\n",
      "Epoch 23/100\n",
      "1752/1752 [==============================] - 1s 362us/step - loss: 0.6870 - acc: 0.5531 - val_loss: 0.6831 - val_acc: 0.5753\n",
      "Epoch 24/100\n",
      "1752/1752 [==============================] - 1s 354us/step - loss: 0.6852 - acc: 0.5639 - val_loss: 0.6826 - val_acc: 0.5731\n",
      "Epoch 25/100\n",
      "1752/1752 [==============================] - 1s 384us/step - loss: 0.6859 - acc: 0.5662 - val_loss: 0.6821 - val_acc: 0.5776\n",
      "Epoch 26/100\n",
      "1752/1752 [==============================] - 1s 415us/step - loss: 0.6845 - acc: 0.5691 - val_loss: 0.6815 - val_acc: 0.5799\n",
      "Epoch 27/100\n",
      "1752/1752 [==============================] - 1s 370us/step - loss: 0.6846 - acc: 0.5571 - val_loss: 0.6808 - val_acc: 0.5913\n",
      "Epoch 28/100\n",
      "1752/1752 [==============================] - 1s 351us/step - loss: 0.6834 - acc: 0.5839 - val_loss: 0.6802 - val_acc: 0.6027\n",
      "Epoch 29/100\n",
      "1752/1752 [==============================] - 1s 373us/step - loss: 0.6823 - acc: 0.5913 - val_loss: 0.6795 - val_acc: 0.6073\n",
      "Epoch 30/100\n",
      "1752/1752 [==============================] - 1s 371us/step - loss: 0.6828 - acc: 0.5696 - val_loss: 0.6788 - val_acc: 0.6073\n",
      "Epoch 31/100\n",
      "1752/1752 [==============================] - 1s 362us/step - loss: 0.6825 - acc: 0.5805 - val_loss: 0.6781 - val_acc: 0.6096\n",
      "Epoch 32/100\n",
      "1752/1752 [==============================] - 1s 380us/step - loss: 0.6815 - acc: 0.5850 - val_loss: 0.6773 - val_acc: 0.6142\n",
      "Epoch 33/100\n",
      "1752/1752 [==============================] - 1s 372us/step - loss: 0.6808 - acc: 0.5896 - val_loss: 0.6765 - val_acc: 0.6142\n",
      "Epoch 34/100\n",
      "1752/1752 [==============================] - 1s 372us/step - loss: 0.6820 - acc: 0.5816 - val_loss: 0.6757 - val_acc: 0.6142\n",
      "Epoch 35/100\n",
      "1752/1752 [==============================] - 1s 378us/step - loss: 0.6805 - acc: 0.5902 - val_loss: 0.6748 - val_acc: 0.6279\n",
      "Epoch 36/100\n",
      "1752/1752 [==============================] - 1s 400us/step - loss: 0.6768 - acc: 0.6016 - val_loss: 0.6739 - val_acc: 0.6301\n",
      "Epoch 37/100\n",
      "1752/1752 [==============================] - 1s 421us/step - loss: 0.6774 - acc: 0.6045 - val_loss: 0.6729 - val_acc: 0.6324\n",
      "Epoch 38/100\n",
      "1752/1752 [==============================] - 1s 378us/step - loss: 0.6758 - acc: 0.6130 - val_loss: 0.6719 - val_acc: 0.6416\n",
      "Epoch 39/100\n",
      "1752/1752 [==============================] - 1s 364us/step - loss: 0.6755 - acc: 0.6182 - val_loss: 0.6709 - val_acc: 0.6416\n",
      "Epoch 40/100\n",
      "1752/1752 [==============================] - 1s 418us/step - loss: 0.6745 - acc: 0.6113 - val_loss: 0.6699 - val_acc: 0.6484\n",
      "Epoch 41/100\n",
      "1752/1752 [==============================] - 1s 400us/step - loss: 0.6725 - acc: 0.6341 - val_loss: 0.6687 - val_acc: 0.6484\n",
      "Epoch 42/100\n",
      "1752/1752 [==============================] - 1s 371us/step - loss: 0.6714 - acc: 0.6341 - val_loss: 0.6675 - val_acc: 0.6575\n",
      "Epoch 43/100\n",
      "1752/1752 [==============================] - 1s 372us/step - loss: 0.6709 - acc: 0.6233 - val_loss: 0.6663 - val_acc: 0.6621\n",
      "Epoch 44/100\n",
      "1752/1752 [==============================] - 1s 400us/step - loss: 0.6717 - acc: 0.6313 - val_loss: 0.6650 - val_acc: 0.6621\n",
      "Epoch 45/100\n",
      "1752/1752 [==============================] - 1s 418us/step - loss: 0.6676 - acc: 0.6438 - val_loss: 0.6636 - val_acc: 0.6621\n",
      "Epoch 46/100\n",
      "1752/1752 [==============================] - 1s 354us/step - loss: 0.6674 - acc: 0.6490 - val_loss: 0.6622 - val_acc: 0.6598\n",
      "Epoch 47/100\n",
      "1752/1752 [==============================] - 1s 354us/step - loss: 0.6643 - acc: 0.6467 - val_loss: 0.6606 - val_acc: 0.6575\n",
      "Epoch 48/100\n",
      "1752/1752 [==============================] - 1s 389us/step - loss: 0.6605 - acc: 0.6678 - val_loss: 0.6589 - val_acc: 0.6644\n",
      "Epoch 49/100\n",
      "1752/1752 [==============================] - 1s 427us/step - loss: 0.6607 - acc: 0.6387 - val_loss: 0.6571 - val_acc: 0.6621\n",
      "Epoch 50/100\n",
      "1752/1752 [==============================] - 1s 373us/step - loss: 0.6595 - acc: 0.6592 - val_loss: 0.6553 - val_acc: 0.6621\n",
      "Epoch 51/100\n",
      "1752/1752 [==============================] - 1s 382us/step - loss: 0.6609 - acc: 0.6530 - val_loss: 0.6534 - val_acc: 0.6644\n",
      "Epoch 52/100\n",
      "1752/1752 [==============================] - 1s 369us/step - loss: 0.6549 - acc: 0.6644 - val_loss: 0.6514 - val_acc: 0.6598\n",
      "Epoch 53/100\n",
      "1752/1752 [==============================] - 1s 379us/step - loss: 0.6543 - acc: 0.6712 - val_loss: 0.6491 - val_acc: 0.6621\n",
      "Epoch 54/100\n",
      "1752/1752 [==============================] - 1s 373us/step - loss: 0.6530 - acc: 0.6684 - val_loss: 0.6468 - val_acc: 0.6667\n",
      "Epoch 55/100\n",
      "1752/1752 [==============================] - 1s 448us/step - loss: 0.6495 - acc: 0.6775 - val_loss: 0.6444 - val_acc: 0.6667\n",
      "Epoch 56/100\n",
      "1752/1752 [==============================] - 1s 400us/step - loss: 0.6483 - acc: 0.6752 - val_loss: 0.6418 - val_acc: 0.6689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "1752/1752 [==============================] - 1s 370us/step - loss: 0.6429 - acc: 0.6769 - val_loss: 0.6391 - val_acc: 0.6735\n",
      "Epoch 58/100\n",
      "1752/1752 [==============================] - 1s 417us/step - loss: 0.6456 - acc: 0.6627 - val_loss: 0.6363 - val_acc: 0.6758\n",
      "Epoch 59/100\n",
      "1752/1752 [==============================] - 1s 391us/step - loss: 0.6372 - acc: 0.6924 - val_loss: 0.6332 - val_acc: 0.6826\n",
      "Epoch 60/100\n",
      "1752/1752 [==============================] - 1s 413us/step - loss: 0.6382 - acc: 0.6884 - val_loss: 0.6301 - val_acc: 0.6849\n",
      "Epoch 61/100\n",
      "1752/1752 [==============================] - 1s 436us/step - loss: 0.6339 - acc: 0.6975 - val_loss: 0.6269 - val_acc: 0.6872\n",
      "Epoch 62/100\n",
      "1752/1752 [==============================] - 1s 420us/step - loss: 0.6299 - acc: 0.6992 - val_loss: 0.6234 - val_acc: 0.6895\n",
      "Epoch 63/100\n",
      "1752/1752 [==============================] - 1s 364us/step - loss: 0.6258 - acc: 0.6889 - val_loss: 0.6196 - val_acc: 0.6963\n",
      "Epoch 64/100\n",
      "1752/1752 [==============================] - 1s 365us/step - loss: 0.6242 - acc: 0.7112 - val_loss: 0.6158 - val_acc: 0.7078\n",
      "Epoch 65/100\n",
      "1752/1752 [==============================] - 1s 384us/step - loss: 0.6218 - acc: 0.7066 - val_loss: 0.6117 - val_acc: 0.7078\n",
      "Epoch 66/100\n",
      "1752/1752 [==============================] - 1s 360us/step - loss: 0.6164 - acc: 0.7083 - val_loss: 0.6074 - val_acc: 0.7100\n",
      "Epoch 67/100\n",
      "1752/1752 [==============================] - 1s 364us/step - loss: 0.6112 - acc: 0.7123 - val_loss: 0.6028 - val_acc: 0.7146\n",
      "Epoch 68/100\n",
      "1752/1752 [==============================] - 1s 365us/step - loss: 0.6059 - acc: 0.7232 - val_loss: 0.5983 - val_acc: 0.7146\n",
      "Epoch 69/100\n",
      "1752/1752 [==============================] - 1s 346us/step - loss: 0.6019 - acc: 0.7237 - val_loss: 0.5935 - val_acc: 0.7123\n",
      "Epoch 70/100\n",
      "1752/1752 [==============================] - 1s 391us/step - loss: 0.5948 - acc: 0.7226 - val_loss: 0.5881 - val_acc: 0.7169\n",
      "Epoch 71/100\n",
      "1752/1752 [==============================] - 1s 400us/step - loss: 0.5916 - acc: 0.7283 - val_loss: 0.5833 - val_acc: 0.7192\n",
      "Epoch 72/100\n",
      "1752/1752 [==============================] - 1s 367us/step - loss: 0.5907 - acc: 0.7249 - val_loss: 0.5779 - val_acc: 0.7237\n",
      "Epoch 73/100\n",
      "1752/1752 [==============================] - 1s 393us/step - loss: 0.5815 - acc: 0.7386 - val_loss: 0.5729 - val_acc: 0.7215\n",
      "Epoch 74/100\n",
      "1752/1752 [==============================] - 1s 373us/step - loss: 0.5749 - acc: 0.7300 - val_loss: 0.5675 - val_acc: 0.7260\n",
      "Epoch 75/100\n",
      "1752/1752 [==============================] - 1s 409us/step - loss: 0.5684 - acc: 0.7420 - val_loss: 0.5622 - val_acc: 0.7306\n",
      "Epoch 76/100\n",
      "1752/1752 [==============================] - 1s 399us/step - loss: 0.5659 - acc: 0.7420 - val_loss: 0.5557 - val_acc: 0.7374\n",
      "Epoch 77/100\n",
      "1752/1752 [==============================] - 1s 391us/step - loss: 0.5603 - acc: 0.7397 - val_loss: 0.5505 - val_acc: 0.7397\n",
      "Epoch 78/100\n",
      "1752/1752 [==============================] - 1s 370us/step - loss: 0.5519 - acc: 0.7420 - val_loss: 0.5455 - val_acc: 0.7420\n",
      "Epoch 79/100\n",
      "1752/1752 [==============================] - 1s 374us/step - loss: 0.5498 - acc: 0.7414 - val_loss: 0.5402 - val_acc: 0.7443\n",
      "Epoch 80/100\n",
      "1752/1752 [==============================] - 1s 416us/step - loss: 0.5483 - acc: 0.7551 - val_loss: 0.5356 - val_acc: 0.7443\n",
      "Epoch 81/100\n",
      "1752/1752 [==============================] - 1s 390us/step - loss: 0.5397 - acc: 0.7529 - val_loss: 0.5303 - val_acc: 0.7466\n",
      "Epoch 82/100\n",
      "1752/1752 [==============================] - 1s 371us/step - loss: 0.5389 - acc: 0.7471 - val_loss: 0.5272 - val_acc: 0.7466\n",
      "Epoch 83/100\n",
      "1752/1752 [==============================] - 1s 382us/step - loss: 0.5291 - acc: 0.7477 - val_loss: 0.5214 - val_acc: 0.7466\n",
      "Epoch 84/100\n",
      "1752/1752 [==============================] - 1s 361us/step - loss: 0.5216 - acc: 0.7517 - val_loss: 0.5191 - val_acc: 0.7489\n",
      "Epoch 85/100\n",
      "1752/1752 [==============================] - 1s 410us/step - loss: 0.5143 - acc: 0.7591 - val_loss: 0.5144 - val_acc: 0.7511\n",
      "Epoch 86/100\n",
      "1752/1752 [==============================] - 1s 352us/step - loss: 0.5158 - acc: 0.7540 - val_loss: 0.5106 - val_acc: 0.7511\n",
      "Epoch 87/100\n",
      "1752/1752 [==============================] - 1s 391us/step - loss: 0.5105 - acc: 0.7546 - val_loss: 0.5070 - val_acc: 0.7534\n",
      "Epoch 88/100\n",
      "1752/1752 [==============================] - 1s 391us/step - loss: 0.5061 - acc: 0.7694 - val_loss: 0.5024 - val_acc: 0.7626\n",
      "Epoch 89/100\n",
      "1752/1752 [==============================] - 1s 387us/step - loss: 0.5027 - acc: 0.7603 - val_loss: 0.4978 - val_acc: 0.7648\n",
      "Epoch 90/100\n",
      "1752/1752 [==============================] - 1s 355us/step - loss: 0.4988 - acc: 0.7694 - val_loss: 0.4950 - val_acc: 0.7671\n",
      "Epoch 91/100\n",
      "1752/1752 [==============================] - 1s 410us/step - loss: 0.5012 - acc: 0.7603 - val_loss: 0.4943 - val_acc: 0.7648\n",
      "Epoch 92/100\n",
      "1752/1752 [==============================] - 1s 361us/step - loss: 0.4985 - acc: 0.7677 - val_loss: 0.4898 - val_acc: 0.7740\n",
      "Epoch 93/100\n",
      "1752/1752 [==============================] - 1s 382us/step - loss: 0.4920 - acc: 0.7688 - val_loss: 0.4911 - val_acc: 0.7671\n",
      "Epoch 94/100\n",
      "1752/1752 [==============================] - 1s 351us/step - loss: 0.4872 - acc: 0.7683 - val_loss: 0.4839 - val_acc: 0.7717\n",
      "Epoch 95/100\n",
      "1752/1752 [==============================] - 1s 382us/step - loss: 0.4816 - acc: 0.7723 - val_loss: 0.4800 - val_acc: 0.7671\n",
      "Epoch 96/100\n",
      "1752/1752 [==============================] - 1s 370us/step - loss: 0.4827 - acc: 0.7700 - val_loss: 0.4856 - val_acc: 0.7763\n",
      "Epoch 97/100\n",
      "1752/1752 [==============================] - 1s 373us/step - loss: 0.4803 - acc: 0.7683 - val_loss: 0.4791 - val_acc: 0.7808\n",
      "Epoch 98/100\n",
      "1752/1752 [==============================] - 1s 409us/step - loss: 0.4780 - acc: 0.7745 - val_loss: 0.4755 - val_acc: 0.7763\n",
      "Epoch 99/100\n",
      "1752/1752 [==============================] - 1s 399us/step - loss: 0.4766 - acc: 0.7871 - val_loss: 0.4734 - val_acc: 0.7740\n",
      "Epoch 100/100\n",
      "1752/1752 [==============================] - 1s 389us/step - loss: 0.4815 - acc: 0.7711 - val_loss: 0.4712 - val_acc: 0.7740\n",
      "Train on 1752 samples, validate on 438 samples\n",
      "Epoch 1/100\n",
      "1752/1752 [==============================] - 1s 373us/step - loss: 0.5006 - acc: 0.7671 - val_loss: 0.4699 - val_acc: 0.7740\n",
      "Epoch 2/100\n",
      "1752/1752 [==============================] - 1s 391us/step - loss: 0.5005 - acc: 0.7546 - val_loss: 0.4688 - val_acc: 0.7740\n",
      "Epoch 3/100\n",
      "1752/1752 [==============================] - 1s 361us/step - loss: 0.4879 - acc: 0.7660 - val_loss: 0.4712 - val_acc: 0.7717\n",
      "Epoch 4/100\n",
      "1752/1752 [==============================] - 1s 364us/step - loss: 0.4971 - acc: 0.7745 - val_loss: 0.4688 - val_acc: 0.7717\n",
      "Epoch 5/100\n",
      "1752/1752 [==============================] - 1s 378us/step - loss: 0.4877 - acc: 0.7705 - val_loss: 0.4659 - val_acc: 0.7763\n",
      "Epoch 6/100\n",
      "1752/1752 [==============================] - 1s 373us/step - loss: 0.4763 - acc: 0.7763 - val_loss: 0.4648 - val_acc: 0.7763\n",
      "Epoch 7/100\n",
      "1752/1752 [==============================] - 1s 361us/step - loss: 0.4796 - acc: 0.7688 - val_loss: 0.4631 - val_acc: 0.7831\n",
      "Epoch 8/100\n",
      "1752/1752 [==============================] - 1s 343us/step - loss: 0.4847 - acc: 0.7671 - val_loss: 0.4607 - val_acc: 0.7831\n",
      "Epoch 9/100\n",
      "1752/1752 [==============================] - 1s 400us/step - loss: 0.4735 - acc: 0.7723 - val_loss: 0.4607 - val_acc: 0.7831\n",
      "Epoch 10/100\n",
      "1752/1752 [==============================] - 1s 367us/step - loss: 0.4781 - acc: 0.7660 - val_loss: 0.4574 - val_acc: 0.7900\n",
      "Epoch 11/100\n",
      "1752/1752 [==============================] - 1s 383us/step - loss: 0.4836 - acc: 0.7700 - val_loss: 0.4585 - val_acc: 0.7808\n",
      "Epoch 12/100\n",
      "1752/1752 [==============================] - 1s 400us/step - loss: 0.4694 - acc: 0.7785 - val_loss: 0.4603 - val_acc: 0.7808\n",
      "Epoch 13/100\n",
      "1752/1752 [==============================] - 1s 391us/step - loss: 0.4692 - acc: 0.7803 - val_loss: 0.4598 - val_acc: 0.7785\n",
      "Epoch 14/100\n",
      "1752/1752 [==============================] - 1s 383us/step - loss: 0.4776 - acc: 0.7757 - val_loss: 0.4581 - val_acc: 0.7808\n",
      "Epoch 15/100\n",
      "1752/1752 [==============================] - 1s 381us/step - loss: 0.4694 - acc: 0.7780 - val_loss: 0.4552 - val_acc: 0.7831\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1752/1752 [==============================] - 1s 370us/step - loss: 0.4705 - acc: 0.7723 - val_loss: 0.4545 - val_acc: 0.7831\n",
      "Epoch 17/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.4631 - acc: 0.7900 - val_loss: 0.4559 - val_acc: 0.7763\n",
      "Epoch 18/100\n",
      "1752/1752 [==============================] - 1s 376us/step - loss: 0.4635 - acc: 0.7905 - val_loss: 0.4496 - val_acc: 0.7922\n",
      "Epoch 19/100\n",
      "1752/1752 [==============================] - 1s 393us/step - loss: 0.4623 - acc: 0.7745 - val_loss: 0.4510 - val_acc: 0.7854\n",
      "Epoch 20/100\n",
      "1752/1752 [==============================] - 1s 343us/step - loss: 0.4607 - acc: 0.7865 - val_loss: 0.4548 - val_acc: 0.7785\n",
      "Epoch 21/100\n",
      "1752/1752 [==============================] - 1s 409us/step - loss: 0.4458 - acc: 0.7797 - val_loss: 0.4508 - val_acc: 0.7854\n",
      "Epoch 22/100\n",
      "1752/1752 [==============================] - 1s 412us/step - loss: 0.4571 - acc: 0.7900 - val_loss: 0.4517 - val_acc: 0.7831\n",
      "Epoch 23/100\n",
      "1752/1752 [==============================] - 1s 378us/step - loss: 0.4527 - acc: 0.7917 - val_loss: 0.4468 - val_acc: 0.7854\n",
      "Epoch 24/100\n",
      "1752/1752 [==============================] - 1s 355us/step - loss: 0.4636 - acc: 0.7854 - val_loss: 0.4455 - val_acc: 0.7922\n",
      "Epoch 25/100\n",
      "1752/1752 [==============================] - 1s 352us/step - loss: 0.4469 - acc: 0.7877 - val_loss: 0.4486 - val_acc: 0.7831\n",
      "Epoch 26/100\n",
      "1752/1752 [==============================] - 1s 399us/step - loss: 0.4477 - acc: 0.7985 - val_loss: 0.4460 - val_acc: 0.7854\n",
      "Epoch 27/100\n",
      "1752/1752 [==============================] - 1s 379us/step - loss: 0.4578 - acc: 0.7894 - val_loss: 0.4438 - val_acc: 0.7945\n",
      "Epoch 28/100\n",
      "1752/1752 [==============================] - 1s 382us/step - loss: 0.4451 - acc: 0.7974 - val_loss: 0.4440 - val_acc: 0.7877\n",
      "Epoch 29/100\n",
      "1752/1752 [==============================] - 1s 428us/step - loss: 0.4412 - acc: 0.8008 - val_loss: 0.4468 - val_acc: 0.7831\n",
      "Epoch 30/100\n",
      "1752/1752 [==============================] - 1s 402us/step - loss: 0.4457 - acc: 0.7974 - val_loss: 0.4446 - val_acc: 0.7854\n",
      "Epoch 31/100\n",
      "1752/1752 [==============================] - 1s 387us/step - loss: 0.4235 - acc: 0.7957 - val_loss: 0.4383 - val_acc: 0.7900\n",
      "Epoch 32/100\n",
      "1752/1752 [==============================] - 1s 373us/step - loss: 0.4274 - acc: 0.8151 - val_loss: 0.4351 - val_acc: 0.8037\n",
      "Epoch 33/100\n",
      "1752/1752 [==============================] - 1s 382us/step - loss: 0.4263 - acc: 0.7968 - val_loss: 0.4451 - val_acc: 0.7831\n",
      "Epoch 34/100\n",
      "1752/1752 [==============================] - 1s 369us/step - loss: 0.4396 - acc: 0.7997 - val_loss: 0.4411 - val_acc: 0.7831\n",
      "Epoch 35/100\n",
      "1752/1752 [==============================] - 1s 409us/step - loss: 0.4240 - acc: 0.8088 - val_loss: 0.4367 - val_acc: 0.7922\n",
      "Epoch 36/100\n",
      "1752/1752 [==============================] - 1s 411us/step - loss: 0.4343 - acc: 0.8111 - val_loss: 0.4361 - val_acc: 0.7922\n",
      "Epoch 37/100\n",
      "1752/1752 [==============================] - 1s 381us/step - loss: 0.4224 - acc: 0.8105 - val_loss: 0.4347 - val_acc: 0.7922\n",
      "Epoch 38/100\n",
      "1752/1752 [==============================] - 1s 363us/step - loss: 0.4200 - acc: 0.8094 - val_loss: 0.4364 - val_acc: 0.7808\n",
      "Epoch 39/100\n",
      "1752/1752 [==============================] - 1s 379us/step - loss: 0.4175 - acc: 0.8082 - val_loss: 0.4323 - val_acc: 0.7922\n",
      "Epoch 40/100\n",
      "1752/1752 [==============================] - 1s 352us/step - loss: 0.4225 - acc: 0.8116 - val_loss: 0.4325 - val_acc: 0.7900\n",
      "Epoch 41/100\n",
      "1752/1752 [==============================] - 1s 391us/step - loss: 0.4251 - acc: 0.8019 - val_loss: 0.4329 - val_acc: 0.7877\n",
      "Epoch 42/100\n",
      "1752/1752 [==============================] - 1s 382us/step - loss: 0.4132 - acc: 0.8151 - val_loss: 0.4339 - val_acc: 0.7900\n",
      "Epoch 43/100\n",
      "1752/1752 [==============================] - 1s 382us/step - loss: 0.3978 - acc: 0.8185 - val_loss: 0.4304 - val_acc: 0.7900\n",
      "Epoch 44/100\n",
      "1752/1752 [==============================] - 1s 384us/step - loss: 0.4127 - acc: 0.8156 - val_loss: 0.4279 - val_acc: 0.7900\n",
      "Epoch 45/100\n",
      "1752/1752 [==============================] - 1s 401us/step - loss: 0.4059 - acc: 0.8094 - val_loss: 0.4241 - val_acc: 0.7991\n",
      "Epoch 46/100\n",
      "1752/1752 [==============================] - 1s 364us/step - loss: 0.4087 - acc: 0.8282 - val_loss: 0.4248 - val_acc: 0.7900\n",
      "Epoch 47/100\n",
      "1752/1752 [==============================] - 1s 361us/step - loss: 0.4006 - acc: 0.8242 - val_loss: 0.4240 - val_acc: 0.7900\n",
      "Epoch 48/100\n",
      "1752/1752 [==============================] - 1s 377us/step - loss: 0.4017 - acc: 0.8225 - val_loss: 0.4156 - val_acc: 0.8037\n",
      "Epoch 49/100\n",
      "1752/1752 [==============================] - 1s 375us/step - loss: 0.3967 - acc: 0.8305 - val_loss: 0.4180 - val_acc: 0.8014\n",
      "Epoch 50/100\n",
      "1752/1752 [==============================] - 1s 382us/step - loss: 0.3961 - acc: 0.8191 - val_loss: 0.4208 - val_acc: 0.7922\n",
      "Epoch 51/100\n",
      "1752/1752 [==============================] - ETA: 0s - loss: 0.3937 - acc: 0.825 - 1s 437us/step - loss: 0.3862 - acc: 0.8305 - val_loss: 0.4279 - val_acc: 0.7968\n",
      "Epoch 52/100\n",
      "1752/1752 [==============================] - 1s 380us/step - loss: 0.3873 - acc: 0.8265 - val_loss: 0.4178 - val_acc: 0.7991\n",
      "Epoch 53/100\n",
      "1752/1752 [==============================] - 1s 381us/step - loss: 0.3946 - acc: 0.8213 - val_loss: 0.4103 - val_acc: 0.8037\n",
      "Epoch 54/100\n",
      "1752/1752 [==============================] - 1s 418us/step - loss: 0.3934 - acc: 0.8219 - val_loss: 0.4161 - val_acc: 0.8014\n",
      "Epoch 55/100\n",
      "1752/1752 [==============================] - 1s 387us/step - loss: 0.3751 - acc: 0.8379 - val_loss: 0.4118 - val_acc: 0.8059\n",
      "Epoch 56/100\n",
      "1752/1752 [==============================] - 1s 399us/step - loss: 0.3847 - acc: 0.8373 - val_loss: 0.4114 - val_acc: 0.8082\n",
      "Epoch 57/100\n",
      "1752/1752 [==============================] - 1s 404us/step - loss: 0.3836 - acc: 0.8225 - val_loss: 0.4133 - val_acc: 0.8082\n",
      "Epoch 58/100\n",
      "1752/1752 [==============================] - 1s 365us/step - loss: 0.3715 - acc: 0.8345 - val_loss: 0.4097 - val_acc: 0.8105\n",
      "Epoch 59/100\n",
      "1752/1752 [==============================] - 1s 408us/step - loss: 0.3719 - acc: 0.8379 - val_loss: 0.4050 - val_acc: 0.8105\n",
      "Epoch 60/100\n",
      "1752/1752 [==============================] - 1s 378us/step - loss: 0.3685 - acc: 0.8333 - val_loss: 0.4091 - val_acc: 0.8082\n",
      "Epoch 61/100\n",
      "1752/1752 [==============================] - 1s 382us/step - loss: 0.3789 - acc: 0.8373 - val_loss: 0.4034 - val_acc: 0.8128\n",
      "Epoch 62/100\n",
      "1752/1752 [==============================] - 1s 363us/step - loss: 0.3674 - acc: 0.8385 - val_loss: 0.4106 - val_acc: 0.8105\n",
      "Epoch 63/100\n",
      "1752/1752 [==============================] - 1s 407us/step - loss: 0.3744 - acc: 0.8316 - val_loss: 0.4083 - val_acc: 0.8151\n",
      "Epoch 64/100\n",
      "1752/1752 [==============================] - 1s 353us/step - loss: 0.3629 - acc: 0.8470 - val_loss: 0.4000 - val_acc: 0.8174\n",
      "Epoch 65/100\n",
      "1752/1752 [==============================] - 1s 380us/step - loss: 0.3685 - acc: 0.8419 - val_loss: 0.3944 - val_acc: 0.8151\n",
      "Epoch 66/100\n",
      "1752/1752 [==============================] - 1s 356us/step - loss: 0.3611 - acc: 0.8510 - val_loss: 0.4006 - val_acc: 0.8151\n",
      "Epoch 67/100\n",
      "1752/1752 [==============================] - 1s 377us/step - loss: 0.3641 - acc: 0.8459 - val_loss: 0.3903 - val_acc: 0.8196\n",
      "Epoch 68/100\n",
      "1752/1752 [==============================] - 1s 383us/step - loss: 0.3647 - acc: 0.8373 - val_loss: 0.3918 - val_acc: 0.8219\n",
      "Epoch 69/100\n",
      "1752/1752 [==============================] - 1s 379us/step - loss: 0.3531 - acc: 0.8487 - val_loss: 0.3935 - val_acc: 0.8174\n",
      "Epoch 70/100\n",
      "1752/1752 [==============================] - 1s 413us/step - loss: 0.3568 - acc: 0.8425 - val_loss: 0.3931 - val_acc: 0.8219\n",
      "Epoch 71/100\n",
      "1752/1752 [==============================] - 1s 343us/step - loss: 0.3521 - acc: 0.8487 - val_loss: 0.3932 - val_acc: 0.8219\n",
      "Epoch 72/100\n",
      "1752/1752 [==============================] - 1s 360us/step - loss: 0.3500 - acc: 0.8487 - val_loss: 0.3986 - val_acc: 0.8174\n",
      "Epoch 73/100\n",
      "1752/1752 [==============================] - 1s 400us/step - loss: 0.3426 - acc: 0.8613 - val_loss: 0.3979 - val_acc: 0.8174\n",
      "Epoch 74/100\n",
      "1752/1752 [==============================] - 1s 385us/step - loss: 0.3445 - acc: 0.8545 - val_loss: 0.3926 - val_acc: 0.8196\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1752/1752 [==============================] - 1s 375us/step - loss: 0.3444 - acc: 0.8493 - val_loss: 0.3906 - val_acc: 0.8196\n",
      "Epoch 76/100\n",
      "1752/1752 [==============================] - 1s 364us/step - loss: 0.3445 - acc: 0.8533 - val_loss: 0.3839 - val_acc: 0.8242\n",
      "Epoch 77/100\n",
      "1752/1752 [==============================] - 1s 399us/step - loss: 0.3416 - acc: 0.8499 - val_loss: 0.3874 - val_acc: 0.8242\n",
      "Epoch 78/100\n",
      "1752/1752 [==============================] - 1s 395us/step - loss: 0.3439 - acc: 0.8550 - val_loss: 0.3790 - val_acc: 0.8288\n",
      "Epoch 79/100\n",
      "1752/1752 [==============================] - 1s 355us/step - loss: 0.3428 - acc: 0.8447 - val_loss: 0.3798 - val_acc: 0.8265\n",
      "Epoch 80/100\n",
      "1752/1752 [==============================] - 1s 391us/step - loss: 0.3278 - acc: 0.8624 - val_loss: 0.3779 - val_acc: 0.8242\n",
      "Epoch 81/100\n",
      "1752/1752 [==============================] - 1s 370us/step - loss: 0.3274 - acc: 0.8573 - val_loss: 0.3844 - val_acc: 0.8242\n",
      "Epoch 82/100\n",
      "1752/1752 [==============================] - 1s 401us/step - loss: 0.3312 - acc: 0.8550 - val_loss: 0.3808 - val_acc: 0.8265\n",
      "Epoch 83/100\n",
      "1752/1752 [==============================] - 1s 370us/step - loss: 0.3347 - acc: 0.8596 - val_loss: 0.3819 - val_acc: 0.8311\n",
      "Epoch 84/100\n",
      "1752/1752 [==============================] - 1s 362us/step - loss: 0.3234 - acc: 0.8704 - val_loss: 0.3756 - val_acc: 0.8242\n",
      "Epoch 85/100\n",
      "1752/1752 [==============================] - 1s 381us/step - loss: 0.3246 - acc: 0.8664 - val_loss: 0.3775 - val_acc: 0.8311\n",
      "Epoch 86/100\n",
      "1752/1752 [==============================] - 1s 378us/step - loss: 0.3276 - acc: 0.8642 - val_loss: 0.3785 - val_acc: 0.8311\n",
      "Epoch 87/100\n",
      "1752/1752 [==============================] - 1s 382us/step - loss: 0.3251 - acc: 0.8676 - val_loss: 0.3797 - val_acc: 0.8311\n",
      "Epoch 88/100\n",
      "1752/1752 [==============================] - 1s 409us/step - loss: 0.3198 - acc: 0.8636 - val_loss: 0.3775 - val_acc: 0.8311\n",
      "Epoch 89/100\n",
      "1752/1752 [==============================] - 1s 373us/step - loss: 0.3179 - acc: 0.8636 - val_loss: 0.3754 - val_acc: 0.8333\n",
      "Epoch 90/100\n",
      "1752/1752 [==============================] - 1s 361us/step - loss: 0.3216 - acc: 0.8653 - val_loss: 0.3860 - val_acc: 0.8402\n",
      "Epoch 91/100\n",
      "1752/1752 [==============================] - 1s 355us/step - loss: 0.3167 - acc: 0.8710 - val_loss: 0.3702 - val_acc: 0.8379\n",
      "Epoch 92/100\n",
      "1752/1752 [==============================] - 1s 346us/step - loss: 0.3189 - acc: 0.8590 - val_loss: 0.3700 - val_acc: 0.8379\n",
      "Epoch 93/100\n",
      "1752/1752 [==============================] - 1s 353us/step - loss: 0.3079 - acc: 0.8704 - val_loss: 0.3681 - val_acc: 0.8402\n",
      "Epoch 94/100\n",
      "1752/1752 [==============================] - 1s 348us/step - loss: 0.3099 - acc: 0.8733 - val_loss: 0.3761 - val_acc: 0.8402\n",
      "Epoch 95/100\n",
      "1752/1752 [==============================] - 1s 362us/step - loss: 0.3087 - acc: 0.8733 - val_loss: 0.3611 - val_acc: 0.8356\n",
      "Epoch 96/100\n",
      "1752/1752 [==============================] - 1s 364us/step - loss: 0.3097 - acc: 0.8750 - val_loss: 0.3640 - val_acc: 0.8402\n",
      "Epoch 97/100\n",
      "1752/1752 [==============================] - 1s 345us/step - loss: 0.3017 - acc: 0.8739 - val_loss: 0.3645 - val_acc: 0.8402\n",
      "Epoch 98/100\n",
      "1752/1752 [==============================] - 1s 382us/step - loss: 0.2949 - acc: 0.8847 - val_loss: 0.3691 - val_acc: 0.8470\n",
      "Epoch 99/100\n",
      "1752/1752 [==============================] - 1s 347us/step - loss: 0.3058 - acc: 0.8721 - val_loss: 0.3667 - val_acc: 0.8470\n",
      "Epoch 100/100\n",
      "1752/1752 [==============================] - 1s 346us/step - loss: 0.3023 - acc: 0.8699 - val_loss: 0.3665 - val_acc: 0.8470\n",
      "Test subject 9, class BothReleased\n",
      "HandStart AUC score = 0.677\n",
      "FirstDigitTouch AUC score = 0.897\n",
      "BothStartLoadPhase AUC score = 0.906\n",
      "LiftOff AUC score = 0.903\n",
      "Replace AUC score = 0.884\n",
      "BothReleased AUC score = 0.809\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49069 49069\n",
      "Train subject 10, class HandStart\n",
      "Train on 1944 samples, validate on 486 samples\n",
      "Epoch 1/100\n",
      "1944/1944 [==============================] - 1s 733us/step - loss: 0.6973 - acc: 0.5005 - val_loss: 0.6920 - val_acc: 0.5123\n",
      "Epoch 2/100\n",
      "1944/1944 [==============================] - 1s 362us/step - loss: 0.6962 - acc: 0.5051 - val_loss: 0.6913 - val_acc: 0.5185\n",
      "Epoch 3/100\n",
      "1944/1944 [==============================] - 1s 358us/step - loss: 0.6957 - acc: 0.4928 - val_loss: 0.6907 - val_acc: 0.5329\n",
      "Epoch 4/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.6946 - acc: 0.5098 - val_loss: 0.6902 - val_acc: 0.5741\n",
      "Epoch 5/100\n",
      "1944/1944 [==============================] - 1s 361us/step - loss: 0.6955 - acc: 0.5072 - val_loss: 0.6898 - val_acc: 0.5556\n",
      "Epoch 6/100\n",
      "1944/1944 [==============================] - 1s 380us/step - loss: 0.6936 - acc: 0.5206 - val_loss: 0.6893 - val_acc: 0.5556\n",
      "Epoch 7/100\n",
      "1944/1944 [==============================] - 1s 411us/step - loss: 0.6928 - acc: 0.5144 - val_loss: 0.6889 - val_acc: 0.5720\n",
      "Epoch 8/100\n",
      "1944/1944 [==============================] - 1s 364us/step - loss: 0.6911 - acc: 0.5195 - val_loss: 0.6886 - val_acc: 0.5617\n",
      "Epoch 9/100\n",
      "1944/1944 [==============================] - 1s 364us/step - loss: 0.6940 - acc: 0.5031 - val_loss: 0.6881 - val_acc: 0.5823\n",
      "Epoch 10/100\n",
      "1944/1944 [==============================] - 1s 377us/step - loss: 0.6908 - acc: 0.5190 - val_loss: 0.6877 - val_acc: 0.5844\n",
      "Epoch 11/100\n",
      "1944/1944 [==============================] - 1s 397us/step - loss: 0.6898 - acc: 0.5267 - val_loss: 0.6873 - val_acc: 0.5988\n",
      "Epoch 12/100\n",
      "1944/1944 [==============================] - 1s 367us/step - loss: 0.6927 - acc: 0.5093 - val_loss: 0.6869 - val_acc: 0.6070\n",
      "Epoch 13/100\n",
      "1944/1944 [==============================] - 1s 385us/step - loss: 0.6921 - acc: 0.5298 - val_loss: 0.6864 - val_acc: 0.6008\n",
      "Epoch 14/100\n",
      "1944/1944 [==============================] - 1s 388us/step - loss: 0.6894 - acc: 0.5396 - val_loss: 0.6860 - val_acc: 0.6029\n",
      "Epoch 15/100\n",
      "1944/1944 [==============================] - 1s 384us/step - loss: 0.6916 - acc: 0.5237 - val_loss: 0.6856 - val_acc: 0.6029\n",
      "Epoch 16/100\n",
      "1944/1944 [==============================] - 1s 413us/step - loss: 0.6878 - acc: 0.5381 - val_loss: 0.6851 - val_acc: 0.6049\n",
      "Epoch 17/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.6887 - acc: 0.5514 - val_loss: 0.6847 - val_acc: 0.6111\n",
      "Epoch 18/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.6859 - acc: 0.5751 - val_loss: 0.6841 - val_acc: 0.6132\n",
      "Epoch 19/100\n",
      "1944/1944 [==============================] - 1s 359us/step - loss: 0.6887 - acc: 0.5319 - val_loss: 0.6837 - val_acc: 0.6255\n",
      "Epoch 20/100\n",
      "1944/1944 [==============================] - 1s 370us/step - loss: 0.6877 - acc: 0.5566 - val_loss: 0.6832 - val_acc: 0.6317\n",
      "Epoch 21/100\n",
      "1944/1944 [==============================] - 1s 374us/step - loss: 0.6870 - acc: 0.5607 - val_loss: 0.6827 - val_acc: 0.6399\n",
      "Epoch 22/100\n",
      "1944/1944 [==============================] - 1s 422us/step - loss: 0.6842 - acc: 0.5766 - val_loss: 0.6821 - val_acc: 0.6461\n",
      "Epoch 23/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.6875 - acc: 0.5448 - val_loss: 0.6817 - val_acc: 0.6461\n",
      "Epoch 24/100\n",
      "1944/1944 [==============================] - 1s 395us/step - loss: 0.6886 - acc: 0.5448 - val_loss: 0.6812 - val_acc: 0.6502\n",
      "Epoch 25/100\n",
      "1944/1944 [==============================] - 1s 369us/step - loss: 0.6833 - acc: 0.5818 - val_loss: 0.6805 - val_acc: 0.6626\n",
      "Epoch 26/100\n",
      "1944/1944 [==============================] - 1s 370us/step - loss: 0.6847 - acc: 0.5684 - val_loss: 0.6800 - val_acc: 0.6687\n",
      "Epoch 27/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.6835 - acc: 0.5797 - val_loss: 0.6794 - val_acc: 0.6728\n",
      "Epoch 28/100\n",
      "1944/1944 [==============================] - 1s 394us/step - loss: 0.6846 - acc: 0.5653 - val_loss: 0.6788 - val_acc: 0.6728\n",
      "Epoch 29/100\n",
      "1944/1944 [==============================] - 1s 360us/step - loss: 0.6815 - acc: 0.5947 - val_loss: 0.6781 - val_acc: 0.6728\n",
      "Epoch 30/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.6821 - acc: 0.5854 - val_loss: 0.6774 - val_acc: 0.6770\n",
      "Epoch 31/100\n",
      "1944/1944 [==============================] - 1s 362us/step - loss: 0.6795 - acc: 0.6008 - val_loss: 0.6767 - val_acc: 0.6790\n",
      "Epoch 32/100\n",
      "1944/1944 [==============================] - 1s 385us/step - loss: 0.6809 - acc: 0.5885 - val_loss: 0.6759 - val_acc: 0.6790\n",
      "Epoch 33/100\n",
      "1944/1944 [==============================] - 1s 379us/step - loss: 0.6805 - acc: 0.5900 - val_loss: 0.6751 - val_acc: 0.6831\n",
      "Epoch 34/100\n",
      "1944/1944 [==============================] - 1s 385us/step - loss: 0.6769 - acc: 0.6157 - val_loss: 0.6742 - val_acc: 0.6955\n",
      "Epoch 35/100\n",
      "1944/1944 [==============================] - 1s 391us/step - loss: 0.6783 - acc: 0.6049 - val_loss: 0.6733 - val_acc: 0.6975\n",
      "Epoch 36/100\n",
      "1944/1944 [==============================] - 1s 444us/step - loss: 0.6790 - acc: 0.5941 - val_loss: 0.6724 - val_acc: 0.6955\n",
      "Epoch 37/100\n",
      "1944/1944 [==============================] - 1s 420us/step - loss: 0.6763 - acc: 0.5962 - val_loss: 0.6714 - val_acc: 0.6955\n",
      "Epoch 38/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.6774 - acc: 0.5947 - val_loss: 0.6703 - val_acc: 0.6934\n",
      "Epoch 39/100\n",
      "1944/1944 [==============================] - 1s 363us/step - loss: 0.6773 - acc: 0.5972 - val_loss: 0.6694 - val_acc: 0.6914\n",
      "Epoch 40/100\n",
      "1944/1944 [==============================] - 1s 420us/step - loss: 0.6747 - acc: 0.6229 - val_loss: 0.6683 - val_acc: 0.6975\n",
      "Epoch 41/100\n",
      "1944/1944 [==============================] - 1s 369us/step - loss: 0.6731 - acc: 0.6142 - val_loss: 0.6671 - val_acc: 0.7037\n",
      "Epoch 42/100\n",
      "1944/1944 [==============================] - 1s 369us/step - loss: 0.6723 - acc: 0.6132 - val_loss: 0.6659 - val_acc: 0.7037\n",
      "Epoch 43/100\n",
      "1944/1944 [==============================] - 1s 379us/step - loss: 0.6718 - acc: 0.6152 - val_loss: 0.6645 - val_acc: 0.7058\n",
      "Epoch 44/100\n",
      "1944/1944 [==============================] - 1s 373us/step - loss: 0.6696 - acc: 0.6301 - val_loss: 0.6631 - val_acc: 0.7058\n",
      "Epoch 45/100\n",
      "1944/1944 [==============================] - 1s 379us/step - loss: 0.6711 - acc: 0.6116 - val_loss: 0.6617 - val_acc: 0.7016\n",
      "Epoch 46/100\n",
      "1944/1944 [==============================] - 1s 387us/step - loss: 0.6663 - acc: 0.6348 - val_loss: 0.6603 - val_acc: 0.7016\n",
      "Epoch 47/100\n",
      "1944/1944 [==============================] - 1s 372us/step - loss: 0.6679 - acc: 0.6332 - val_loss: 0.6587 - val_acc: 0.6934\n",
      "Epoch 48/100\n",
      "1944/1944 [==============================] - 1s 399us/step - loss: 0.6650 - acc: 0.6379 - val_loss: 0.6571 - val_acc: 0.6996\n",
      "Epoch 49/100\n",
      "1944/1944 [==============================] - 1s 422us/step - loss: 0.6634 - acc: 0.6435 - val_loss: 0.6554 - val_acc: 0.7058\n",
      "Epoch 50/100\n",
      "1944/1944 [==============================] - 1s 363us/step - loss: 0.6634 - acc: 0.6456 - val_loss: 0.6536 - val_acc: 0.7037\n",
      "Epoch 51/100\n",
      "1944/1944 [==============================] - 1s 366us/step - loss: 0.6608 - acc: 0.6430 - val_loss: 0.6517 - val_acc: 0.7058\n",
      "Epoch 52/100\n",
      "1944/1944 [==============================] - 1s 364us/step - loss: 0.6554 - acc: 0.6728 - val_loss: 0.6496 - val_acc: 0.7058\n",
      "Epoch 53/100\n",
      "1944/1944 [==============================] - 1s 364us/step - loss: 0.6565 - acc: 0.6487 - val_loss: 0.6475 - val_acc: 0.7016\n",
      "Epoch 54/100\n",
      "1944/1944 [==============================] - 1s 360us/step - loss: 0.6581 - acc: 0.6409 - val_loss: 0.6455 - val_acc: 0.6996\n",
      "Epoch 55/100\n",
      "1944/1944 [==============================] - 1s 385us/step - loss: 0.6518 - acc: 0.6590 - val_loss: 0.6432 - val_acc: 0.6975\n",
      "Epoch 56/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.6510 - acc: 0.6600 - val_loss: 0.6409 - val_acc: 0.7037\n",
      "Epoch 57/100\n",
      "1944/1944 [==============================] - 1s 371us/step - loss: 0.6530 - acc: 0.6507 - val_loss: 0.6385 - val_acc: 0.6914\n",
      "Epoch 58/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.6470 - acc: 0.6620 - val_loss: 0.6360 - val_acc: 0.6914\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.6423 - acc: 0.6641 - val_loss: 0.6333 - val_acc: 0.6934\n",
      "Epoch 60/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.6443 - acc: 0.6553 - val_loss: 0.6306 - val_acc: 0.6955\n",
      "Epoch 61/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.6399 - acc: 0.6759 - val_loss: 0.6278 - val_acc: 0.6975\n",
      "Epoch 62/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.6352 - acc: 0.6852 - val_loss: 0.6249 - val_acc: 0.6996\n",
      "Epoch 63/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.6344 - acc: 0.6662 - val_loss: 0.6218 - val_acc: 0.6996\n",
      "Epoch 64/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.6314 - acc: 0.6713 - val_loss: 0.6186 - val_acc: 0.6975\n",
      "Epoch 65/100\n",
      "1944/1944 [==============================] - 1s 337us/step - loss: 0.6227 - acc: 0.6857 - val_loss: 0.6154 - val_acc: 0.6996\n",
      "Epoch 66/100\n",
      "1944/1944 [==============================] - 1s 334us/step - loss: 0.6209 - acc: 0.6790 - val_loss: 0.6120 - val_acc: 0.6996\n",
      "Epoch 67/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.6193 - acc: 0.6944 - val_loss: 0.6088 - val_acc: 0.6914\n",
      "Epoch 68/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.6179 - acc: 0.6847 - val_loss: 0.6055 - val_acc: 0.6934\n",
      "Epoch 69/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.6144 - acc: 0.6908 - val_loss: 0.6022 - val_acc: 0.6893\n",
      "Epoch 70/100\n",
      "1944/1944 [==============================] - 1s 336us/step - loss: 0.6127 - acc: 0.6883 - val_loss: 0.5987 - val_acc: 0.6914\n",
      "Epoch 71/100\n",
      "1944/1944 [==============================] - 1s 336us/step - loss: 0.6039 - acc: 0.6842 - val_loss: 0.5955 - val_acc: 0.6955\n",
      "Epoch 72/100\n",
      "1944/1944 [==============================] - 1s 336us/step - loss: 0.6016 - acc: 0.6944 - val_loss: 0.5923 - val_acc: 0.6975\n",
      "Epoch 73/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.6040 - acc: 0.6821 - val_loss: 0.5893 - val_acc: 0.6955\n",
      "Epoch 74/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.5967 - acc: 0.7016 - val_loss: 0.5859 - val_acc: 0.6934\n",
      "Epoch 75/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.5965 - acc: 0.6826 - val_loss: 0.5831 - val_acc: 0.6955\n",
      "Epoch 76/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.5906 - acc: 0.7011 - val_loss: 0.5813 - val_acc: 0.6975\n",
      "Epoch 77/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.5899 - acc: 0.7006 - val_loss: 0.5779 - val_acc: 0.7016\n",
      "Epoch 78/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.5859 - acc: 0.6950 - val_loss: 0.5751 - val_acc: 0.7016\n",
      "Epoch 79/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.5877 - acc: 0.6847 - val_loss: 0.5726 - val_acc: 0.7016\n",
      "Epoch 80/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.5766 - acc: 0.7042 - val_loss: 0.5705 - val_acc: 0.7016\n",
      "Epoch 81/100\n",
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.5823 - acc: 0.6955 - val_loss: 0.5682 - val_acc: 0.7058\n",
      "Epoch 82/100\n",
      "1944/1944 [==============================] - 1s 336us/step - loss: 0.5722 - acc: 0.7063 - val_loss: 0.5661 - val_acc: 0.7037\n",
      "Epoch 83/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.5746 - acc: 0.7119 - val_loss: 0.5638 - val_acc: 0.7078\n",
      "Epoch 84/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.5706 - acc: 0.6986 - val_loss: 0.5617 - val_acc: 0.7078\n",
      "Epoch 85/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.5765 - acc: 0.6950 - val_loss: 0.5601 - val_acc: 0.7058\n",
      "Epoch 86/100\n",
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.5707 - acc: 0.6965 - val_loss: 0.5582 - val_acc: 0.7099\n",
      "Epoch 87/100\n",
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.5658 - acc: 0.7078 - val_loss: 0.5565 - val_acc: 0.7099\n",
      "Epoch 88/100\n",
      "1944/1944 [==============================] - 1s 336us/step - loss: 0.5660 - acc: 0.7063 - val_loss: 0.5547 - val_acc: 0.7119\n",
      "Epoch 89/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.5635 - acc: 0.7078 - val_loss: 0.5532 - val_acc: 0.7140\n",
      "Epoch 90/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.5625 - acc: 0.7130 - val_loss: 0.5519 - val_acc: 0.7099\n",
      "Epoch 91/100\n",
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.5591 - acc: 0.7047 - val_loss: 0.5500 - val_acc: 0.7119\n",
      "Epoch 92/100\n",
      "1944/1944 [==============================] - 1s 337us/step - loss: 0.5605 - acc: 0.7119 - val_loss: 0.5487 - val_acc: 0.7119\n",
      "Epoch 93/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.5584 - acc: 0.7058 - val_loss: 0.5470 - val_acc: 0.7202\n",
      "Epoch 94/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.5578 - acc: 0.7119 - val_loss: 0.5456 - val_acc: 0.7140\n",
      "Epoch 95/100\n",
      "1944/1944 [==============================] - 1s 361us/step - loss: 0.5480 - acc: 0.7181 - val_loss: 0.5441 - val_acc: 0.7202\n",
      "Epoch 96/100\n",
      "1944/1944 [==============================] - 1s 429us/step - loss: 0.5517 - acc: 0.7099 - val_loss: 0.5427 - val_acc: 0.7202\n",
      "Epoch 97/100\n",
      "1944/1944 [==============================] - 1s 386us/step - loss: 0.5479 - acc: 0.7160 - val_loss: 0.5412 - val_acc: 0.7202\n",
      "Epoch 98/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.5485 - acc: 0.7114 - val_loss: 0.5398 - val_acc: 0.7222\n",
      "Epoch 99/100\n",
      "1944/1944 [==============================] - 1s 360us/step - loss: 0.5471 - acc: 0.7124 - val_loss: 0.5383 - val_acc: 0.7222\n",
      "Epoch 100/100\n",
      "1944/1944 [==============================] - 1s 376us/step - loss: 0.5392 - acc: 0.7130 - val_loss: 0.5368 - val_acc: 0.7222\n",
      "Train on 1944 samples, validate on 486 samples\n",
      "Epoch 1/100\n",
      "1944/1944 [==============================] - 1s 364us/step - loss: 0.5701 - acc: 0.7083 - val_loss: 0.5427 - val_acc: 0.7099\n",
      "Epoch 2/100\n",
      "1944/1944 [==============================] - 1s 362us/step - loss: 0.5698 - acc: 0.7027 - val_loss: 0.5405 - val_acc: 0.7099\n",
      "Epoch 3/100\n",
      "1944/1944 [==============================] - 1s 389us/step - loss: 0.5627 - acc: 0.7094 - val_loss: 0.5380 - val_acc: 0.7119\n",
      "Epoch 4/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.5635 - acc: 0.7114 - val_loss: 0.5354 - val_acc: 0.7119\n",
      "Epoch 5/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.5649 - acc: 0.7058 - val_loss: 0.5338 - val_acc: 0.7140\n",
      "Epoch 6/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.5622 - acc: 0.7176 - val_loss: 0.5356 - val_acc: 0.7140\n",
      "Epoch 7/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.5558 - acc: 0.7145 - val_loss: 0.5315 - val_acc: 0.7140\n",
      "Epoch 8/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.5541 - acc: 0.7130 - val_loss: 0.5298 - val_acc: 0.7140\n",
      "Epoch 9/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.5548 - acc: 0.7135 - val_loss: 0.5280 - val_acc: 0.7140\n",
      "Epoch 10/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.5538 - acc: 0.7130 - val_loss: 0.5266 - val_acc: 0.7140\n",
      "Epoch 11/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.5508 - acc: 0.7207 - val_loss: 0.5254 - val_acc: 0.7181\n",
      "Epoch 12/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.5566 - acc: 0.7145 - val_loss: 0.5254 - val_acc: 0.7181\n",
      "Epoch 13/100\n",
      "1944/1944 [==============================] - 1s 363us/step - loss: 0.5475 - acc: 0.7248 - val_loss: 0.5225 - val_acc: 0.7222\n",
      "Epoch 14/100\n",
      "1944/1944 [==============================] - 1s 356us/step - loss: 0.5529 - acc: 0.7202 - val_loss: 0.5214 - val_acc: 0.7243\n",
      "Epoch 15/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.5458 - acc: 0.7212 - val_loss: 0.5214 - val_acc: 0.7222\n",
      "Epoch 16/100\n",
      "1944/1944 [==============================] - 1s 359us/step - loss: 0.5449 - acc: 0.7212 - val_loss: 0.5182 - val_acc: 0.7263\n",
      "Epoch 17/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.5492 - acc: 0.7191 - val_loss: 0.5192 - val_acc: 0.7263\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.5416 - acc: 0.7248 - val_loss: 0.5143 - val_acc: 0.7346\n",
      "Epoch 19/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.5451 - acc: 0.7212 - val_loss: 0.5119 - val_acc: 0.7387\n",
      "Epoch 20/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.5425 - acc: 0.7227 - val_loss: 0.5127 - val_acc: 0.7305\n",
      "Epoch 21/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.5376 - acc: 0.7279 - val_loss: 0.5091 - val_acc: 0.7387\n",
      "Epoch 22/100\n",
      "1944/1944 [==============================] - 1s 337us/step - loss: 0.5407 - acc: 0.7233 - val_loss: 0.5092 - val_acc: 0.7387\n",
      "Epoch 23/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.5432 - acc: 0.7176 - val_loss: 0.5064 - val_acc: 0.7449\n",
      "Epoch 24/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.5386 - acc: 0.7233 - val_loss: 0.5085 - val_acc: 0.7407\n",
      "Epoch 25/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.5338 - acc: 0.7371 - val_loss: 0.5089 - val_acc: 0.7325\n",
      "Epoch 26/100\n",
      "1944/1944 [==============================] - 1s 336us/step - loss: 0.5410 - acc: 0.7171 - val_loss: 0.5021 - val_acc: 0.7510\n",
      "Epoch 27/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.5271 - acc: 0.7356 - val_loss: 0.5039 - val_acc: 0.7449\n",
      "Epoch 28/100\n",
      "1944/1944 [==============================] - 1s 360us/step - loss: 0.5289 - acc: 0.7269 - val_loss: 0.5055 - val_acc: 0.7346\n",
      "Epoch 29/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.5327 - acc: 0.7382 - val_loss: 0.5044 - val_acc: 0.7387\n",
      "Epoch 30/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.5307 - acc: 0.7335 - val_loss: 0.4956 - val_acc: 0.7551\n",
      "Epoch 31/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.5242 - acc: 0.7413 - val_loss: 0.4994 - val_acc: 0.7551\n",
      "Epoch 32/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.5273 - acc: 0.7233 - val_loss: 0.4972 - val_acc: 0.7510\n",
      "Epoch 33/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.5257 - acc: 0.7346 - val_loss: 0.4945 - val_acc: 0.7531\n",
      "Epoch 34/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.5280 - acc: 0.7315 - val_loss: 0.4910 - val_acc: 0.7572\n",
      "Epoch 35/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.5185 - acc: 0.7449 - val_loss: 0.4938 - val_acc: 0.7593\n",
      "Epoch 36/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.5216 - acc: 0.7366 - val_loss: 0.4896 - val_acc: 0.7572\n",
      "Epoch 37/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.5154 - acc: 0.7325 - val_loss: 0.4890 - val_acc: 0.7613\n",
      "Epoch 38/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.5159 - acc: 0.7397 - val_loss: 0.4854 - val_acc: 0.7613\n",
      "Epoch 39/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.5120 - acc: 0.7443 - val_loss: 0.4886 - val_acc: 0.7613\n",
      "Epoch 40/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.5126 - acc: 0.7382 - val_loss: 0.4893 - val_acc: 0.7613\n",
      "Epoch 41/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.5098 - acc: 0.7449 - val_loss: 0.4901 - val_acc: 0.7675\n",
      "Epoch 42/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.5061 - acc: 0.7474 - val_loss: 0.4831 - val_acc: 0.7634\n",
      "Epoch 43/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.5071 - acc: 0.7428 - val_loss: 0.4804 - val_acc: 0.7675\n",
      "Epoch 44/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.5090 - acc: 0.7500 - val_loss: 0.4826 - val_acc: 0.7675\n",
      "Epoch 45/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.5115 - acc: 0.7335 - val_loss: 0.4785 - val_acc: 0.7675\n",
      "Epoch 46/100\n",
      "1944/1944 [==============================] - 1s 361us/step - loss: 0.5054 - acc: 0.7485 - val_loss: 0.4791 - val_acc: 0.7737\n",
      "Epoch 47/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.4995 - acc: 0.7500 - val_loss: 0.4794 - val_acc: 0.7716\n",
      "Epoch 48/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.5070 - acc: 0.7387 - val_loss: 0.4770 - val_acc: 0.7737\n",
      "Epoch 49/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.5043 - acc: 0.7371 - val_loss: 0.4769 - val_acc: 0.7757\n",
      "Epoch 50/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.5037 - acc: 0.7521 - val_loss: 0.4727 - val_acc: 0.7716\n",
      "Epoch 51/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.4967 - acc: 0.7490 - val_loss: 0.4726 - val_acc: 0.7778\n",
      "Epoch 52/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.4930 - acc: 0.7449 - val_loss: 0.4685 - val_acc: 0.7716\n",
      "Epoch 53/100\n",
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.4994 - acc: 0.7567 - val_loss: 0.4716 - val_acc: 0.7819\n",
      "Epoch 54/100\n",
      "1944/1944 [==============================] - 1s 360us/step - loss: 0.4926 - acc: 0.7526 - val_loss: 0.4728 - val_acc: 0.7819\n",
      "Epoch 55/100\n",
      "1944/1944 [==============================] - 1s 368us/step - loss: 0.4872 - acc: 0.7623 - val_loss: 0.4642 - val_acc: 0.7798\n",
      "Epoch 56/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.4972 - acc: 0.7479 - val_loss: 0.4638 - val_acc: 0.7757\n",
      "Epoch 57/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.4932 - acc: 0.7500 - val_loss: 0.4665 - val_acc: 0.7819\n",
      "Epoch 58/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.4938 - acc: 0.7593 - val_loss: 0.4671 - val_acc: 0.7840\n",
      "Epoch 59/100\n",
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.4991 - acc: 0.7423 - val_loss: 0.4635 - val_acc: 0.7798\n",
      "Epoch 60/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.4868 - acc: 0.7659 - val_loss: 0.4657 - val_acc: 0.7819\n",
      "Epoch 61/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.4826 - acc: 0.7577 - val_loss: 0.4635 - val_acc: 0.7840\n",
      "Epoch 62/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.4870 - acc: 0.7572 - val_loss: 0.4602 - val_acc: 0.7819\n",
      "Epoch 63/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.4909 - acc: 0.7567 - val_loss: 0.4604 - val_acc: 0.7840\n",
      "Epoch 64/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.4933 - acc: 0.7515 - val_loss: 0.4613 - val_acc: 0.7840\n",
      "Epoch 65/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.4883 - acc: 0.7521 - val_loss: 0.4597 - val_acc: 0.7840\n",
      "Epoch 66/100\n",
      "1944/1944 [==============================] - 1s 363us/step - loss: 0.4780 - acc: 0.7639 - val_loss: 0.4604 - val_acc: 0.7860\n",
      "Epoch 67/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.4789 - acc: 0.7680 - val_loss: 0.4549 - val_acc: 0.7860\n",
      "Epoch 68/100\n",
      "1944/1944 [==============================] - 1s 360us/step - loss: 0.4770 - acc: 0.7649 - val_loss: 0.4524 - val_acc: 0.7860\n",
      "Epoch 69/100\n",
      "1944/1944 [==============================] - 1s 356us/step - loss: 0.4753 - acc: 0.7634 - val_loss: 0.4524 - val_acc: 0.7881\n",
      "Epoch 70/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.4827 - acc: 0.7582 - val_loss: 0.4594 - val_acc: 0.7881\n",
      "Epoch 71/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.4762 - acc: 0.7541 - val_loss: 0.4510 - val_acc: 0.7901\n",
      "Epoch 72/100\n",
      "1944/1944 [==============================] - 1s 359us/step - loss: 0.4792 - acc: 0.7654 - val_loss: 0.4490 - val_acc: 0.7942\n",
      "Epoch 73/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.4767 - acc: 0.7675 - val_loss: 0.4487 - val_acc: 0.7963\n",
      "Epoch 74/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.4723 - acc: 0.7659 - val_loss: 0.4507 - val_acc: 0.7984\n",
      "Epoch 75/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.4688 - acc: 0.7654 - val_loss: 0.4469 - val_acc: 0.8004\n",
      "Epoch 76/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.4776 - acc: 0.7613 - val_loss: 0.4481 - val_acc: 0.7942\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.4672 - acc: 0.7659 - val_loss: 0.4465 - val_acc: 0.7963\n",
      "Epoch 78/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.4647 - acc: 0.7762 - val_loss: 0.4482 - val_acc: 0.7963\n",
      "Epoch 79/100\n",
      "1944/1944 [==============================] - 1s 358us/step - loss: 0.4664 - acc: 0.7685 - val_loss: 0.4445 - val_acc: 0.7984\n",
      "Epoch 80/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.4617 - acc: 0.7695 - val_loss: 0.4443 - val_acc: 0.7984\n",
      "Epoch 81/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.4653 - acc: 0.7716 - val_loss: 0.4483 - val_acc: 0.7984\n",
      "Epoch 82/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.4636 - acc: 0.7665 - val_loss: 0.4461 - val_acc: 0.8025\n",
      "Epoch 83/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.4634 - acc: 0.7726 - val_loss: 0.4414 - val_acc: 0.8025\n",
      "Epoch 84/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.4620 - acc: 0.7742 - val_loss: 0.4407 - val_acc: 0.8086\n",
      "Epoch 85/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.4655 - acc: 0.7716 - val_loss: 0.4421 - val_acc: 0.8045\n",
      "Epoch 86/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.4571 - acc: 0.7695 - val_loss: 0.4369 - val_acc: 0.8128\n",
      "Epoch 87/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.4568 - acc: 0.7793 - val_loss: 0.4441 - val_acc: 0.7984\n",
      "Epoch 88/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.4630 - acc: 0.7742 - val_loss: 0.4340 - val_acc: 0.8189\n",
      "Epoch 89/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.4567 - acc: 0.7783 - val_loss: 0.4412 - val_acc: 0.8066\n",
      "Epoch 90/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.4621 - acc: 0.7711 - val_loss: 0.4327 - val_acc: 0.8169\n",
      "Epoch 91/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.4601 - acc: 0.7721 - val_loss: 0.4365 - val_acc: 0.8066\n",
      "Epoch 92/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.4476 - acc: 0.7881 - val_loss: 0.4426 - val_acc: 0.7901\n",
      "Epoch 93/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.4658 - acc: 0.7680 - val_loss: 0.4345 - val_acc: 0.8086\n",
      "Epoch 94/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.4601 - acc: 0.7639 - val_loss: 0.4369 - val_acc: 0.8086\n",
      "Epoch 95/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.4503 - acc: 0.7798 - val_loss: 0.4292 - val_acc: 0.8169\n",
      "Epoch 96/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.4487 - acc: 0.7886 - val_loss: 0.4290 - val_acc: 0.8189\n",
      "Epoch 97/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.4438 - acc: 0.7834 - val_loss: 0.4251 - val_acc: 0.8169\n",
      "Epoch 98/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.4510 - acc: 0.7865 - val_loss: 0.4294 - val_acc: 0.8169\n",
      "Epoch 99/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.4424 - acc: 0.7829 - val_loss: 0.4300 - val_acc: 0.8128\n",
      "Epoch 100/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.4513 - acc: 0.7819 - val_loss: 0.4252 - val_acc: 0.8189\n",
      "Test subject 10, class HandStart\n",
      "Train subject 10, class FirstDigitTouch\n",
      "Train on 1944 samples, validate on 486 samples\n",
      "Epoch 1/100\n",
      "1944/1944 [==============================] - 1s 735us/step - loss: 0.6973 - acc: 0.4938 - val_loss: 0.6887 - val_acc: 0.6070\n",
      "Epoch 2/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.6933 - acc: 0.5185 - val_loss: 0.6890 - val_acc: 0.6235\n",
      "Epoch 3/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.6928 - acc: 0.5170 - val_loss: 0.6891 - val_acc: 0.5926\n",
      "Epoch 4/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.6934 - acc: 0.5154 - val_loss: 0.6888 - val_acc: 0.5576\n",
      "Epoch 5/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.6882 - acc: 0.5453 - val_loss: 0.6886 - val_acc: 0.5329\n",
      "Epoch 6/100\n",
      "1944/1944 [==============================] - 1s 364us/step - loss: 0.6901 - acc: 0.5355 - val_loss: 0.6882 - val_acc: 0.5370\n",
      "Epoch 7/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.6912 - acc: 0.5175 - val_loss: 0.6877 - val_acc: 0.5432\n",
      "Epoch 8/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.6873 - acc: 0.5628 - val_loss: 0.6871 - val_acc: 0.5473\n",
      "Epoch 9/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.6865 - acc: 0.5581 - val_loss: 0.6862 - val_acc: 0.5700\n",
      "Epoch 10/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.6895 - acc: 0.5288 - val_loss: 0.6856 - val_acc: 0.5720\n",
      "Epoch 11/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.6883 - acc: 0.5473 - val_loss: 0.6847 - val_acc: 0.5905\n",
      "Epoch 12/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.6845 - acc: 0.5581 - val_loss: 0.6840 - val_acc: 0.5967\n",
      "Epoch 13/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.6872 - acc: 0.5458 - val_loss: 0.6831 - val_acc: 0.6008\n",
      "Epoch 14/100\n",
      "1944/1944 [==============================] - 1s 358us/step - loss: 0.6837 - acc: 0.5664 - val_loss: 0.6823 - val_acc: 0.6132\n",
      "Epoch 15/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.6840 - acc: 0.5694 - val_loss: 0.6812 - val_acc: 0.6379\n",
      "Epoch 16/100\n",
      "1944/1944 [==============================] - 1s 356us/step - loss: 0.6825 - acc: 0.5761 - val_loss: 0.6800 - val_acc: 0.6543\n",
      "Epoch 17/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.6797 - acc: 0.5916 - val_loss: 0.6791 - val_acc: 0.6626\n",
      "Epoch 18/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.6810 - acc: 0.5823 - val_loss: 0.6779 - val_acc: 0.6667\n",
      "Epoch 19/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.6808 - acc: 0.5833 - val_loss: 0.6770 - val_acc: 0.6626\n",
      "Epoch 20/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.6758 - acc: 0.5957 - val_loss: 0.6756 - val_acc: 0.6646\n",
      "Epoch 21/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.6773 - acc: 0.5977 - val_loss: 0.6743 - val_acc: 0.6626\n",
      "Epoch 22/100\n",
      "1944/1944 [==============================] - 1s 367us/step - loss: 0.6796 - acc: 0.5802 - val_loss: 0.6730 - val_acc: 0.6728\n",
      "Epoch 23/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.6777 - acc: 0.6008 - val_loss: 0.6717 - val_acc: 0.6749\n",
      "Epoch 24/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.6752 - acc: 0.6116 - val_loss: 0.6702 - val_acc: 0.6770\n",
      "Epoch 25/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.6745 - acc: 0.6055 - val_loss: 0.6687 - val_acc: 0.6811\n",
      "Epoch 26/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.6726 - acc: 0.6055 - val_loss: 0.6666 - val_acc: 0.6811\n",
      "Epoch 27/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.6729 - acc: 0.6091 - val_loss: 0.6646 - val_acc: 0.6852\n",
      "Epoch 28/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.6707 - acc: 0.6085 - val_loss: 0.6628 - val_acc: 0.6852\n",
      "Epoch 29/100\n",
      "1944/1944 [==============================] - 1s 361us/step - loss: 0.6678 - acc: 0.6286 - val_loss: 0.6608 - val_acc: 0.6852\n",
      "Epoch 30/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.6664 - acc: 0.6379 - val_loss: 0.6589 - val_acc: 0.6872\n",
      "Epoch 31/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.6669 - acc: 0.6183 - val_loss: 0.6564 - val_acc: 0.6893\n",
      "Epoch 32/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.6606 - acc: 0.6415 - val_loss: 0.6539 - val_acc: 0.6893\n",
      "Epoch 33/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.6576 - acc: 0.6512 - val_loss: 0.6514 - val_acc: 0.6893\n",
      "Epoch 34/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.6582 - acc: 0.6512 - val_loss: 0.6484 - val_acc: 0.6914\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.6561 - acc: 0.6456 - val_loss: 0.6452 - val_acc: 0.6934\n",
      "Epoch 36/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.6536 - acc: 0.6641 - val_loss: 0.6423 - val_acc: 0.6914\n",
      "Epoch 37/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.6481 - acc: 0.6759 - val_loss: 0.6383 - val_acc: 0.6975\n",
      "Epoch 38/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.6424 - acc: 0.6821 - val_loss: 0.6347 - val_acc: 0.6975\n",
      "Epoch 39/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.6444 - acc: 0.6728 - val_loss: 0.6307 - val_acc: 0.6996\n",
      "Epoch 40/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.6401 - acc: 0.6744 - val_loss: 0.6263 - val_acc: 0.7058\n",
      "Epoch 41/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.6365 - acc: 0.6821 - val_loss: 0.6210 - val_acc: 0.7078\n",
      "Epoch 42/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.6330 - acc: 0.6960 - val_loss: 0.6171 - val_acc: 0.7160\n",
      "Epoch 43/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.6270 - acc: 0.6944 - val_loss: 0.6115 - val_acc: 0.7140\n",
      "Epoch 44/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.6223 - acc: 0.6970 - val_loss: 0.6064 - val_acc: 0.7243\n",
      "Epoch 45/100\n",
      "1944/1944 [==============================] - 1s 361us/step - loss: 0.6175 - acc: 0.7042 - val_loss: 0.6002 - val_acc: 0.7263\n",
      "Epoch 46/100\n",
      "1944/1944 [==============================] - 1s 356us/step - loss: 0.6142 - acc: 0.7109 - val_loss: 0.5937 - val_acc: 0.7263\n",
      "Epoch 47/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.6046 - acc: 0.7253 - val_loss: 0.5869 - val_acc: 0.7325\n",
      "Epoch 48/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.5983 - acc: 0.7341 - val_loss: 0.5781 - val_acc: 0.7469\n",
      "Epoch 49/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.5926 - acc: 0.7284 - val_loss: 0.5701 - val_acc: 0.7490\n",
      "Epoch 50/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.5828 - acc: 0.7438 - val_loss: 0.5635 - val_acc: 0.7428\n",
      "Epoch 51/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.5776 - acc: 0.7526 - val_loss: 0.5515 - val_acc: 0.7551\n",
      "Epoch 52/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.5675 - acc: 0.7397 - val_loss: 0.5420 - val_acc: 0.7634\n",
      "Epoch 53/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.5609 - acc: 0.7639 - val_loss: 0.5338 - val_acc: 0.7675\n",
      "Epoch 54/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.5532 - acc: 0.7665 - val_loss: 0.5241 - val_acc: 0.7737\n",
      "Epoch 55/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.5426 - acc: 0.7670 - val_loss: 0.5150 - val_acc: 0.7840\n",
      "Epoch 56/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.5318 - acc: 0.7726 - val_loss: 0.5017 - val_acc: 0.7901\n",
      "Epoch 57/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.5246 - acc: 0.7747 - val_loss: 0.4888 - val_acc: 0.8004\n",
      "Epoch 58/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.5094 - acc: 0.7783 - val_loss: 0.4802 - val_acc: 0.8045\n",
      "Epoch 59/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.5085 - acc: 0.7803 - val_loss: 0.4701 - val_acc: 0.8128\n",
      "Epoch 60/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.4913 - acc: 0.7937 - val_loss: 0.4584 - val_acc: 0.8189\n",
      "Epoch 61/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.4844 - acc: 0.7973 - val_loss: 0.4472 - val_acc: 0.8230\n",
      "Epoch 62/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.4808 - acc: 0.7896 - val_loss: 0.4377 - val_acc: 0.8251\n",
      "Epoch 63/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.4708 - acc: 0.7978 - val_loss: 0.4279 - val_acc: 0.8292\n",
      "Epoch 64/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.4626 - acc: 0.7999 - val_loss: 0.4200 - val_acc: 0.8313\n",
      "Epoch 65/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.4523 - acc: 0.8128 - val_loss: 0.4154 - val_acc: 0.8313\n",
      "Epoch 66/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.4470 - acc: 0.8076 - val_loss: 0.4046 - val_acc: 0.8395\n",
      "Epoch 67/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.4431 - acc: 0.8081 - val_loss: 0.3969 - val_acc: 0.8457\n",
      "Epoch 68/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.4351 - acc: 0.8174 - val_loss: 0.3937 - val_acc: 0.8436\n",
      "Epoch 69/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.4330 - acc: 0.8112 - val_loss: 0.3858 - val_acc: 0.8539\n",
      "Epoch 70/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.4176 - acc: 0.8189 - val_loss: 0.3835 - val_acc: 0.8498\n",
      "Epoch 71/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.4267 - acc: 0.8107 - val_loss: 0.3796 - val_acc: 0.8498\n",
      "Epoch 72/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.4171 - acc: 0.8194 - val_loss: 0.3718 - val_acc: 0.8539\n",
      "Epoch 73/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.4141 - acc: 0.8179 - val_loss: 0.3676 - val_acc: 0.8560\n",
      "Epoch 74/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.4007 - acc: 0.8302 - val_loss: 0.3614 - val_acc: 0.8580\n",
      "Epoch 75/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.4110 - acc: 0.8169 - val_loss: 0.3618 - val_acc: 0.8560\n",
      "Epoch 76/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.4039 - acc: 0.8215 - val_loss: 0.3562 - val_acc: 0.8642\n",
      "Epoch 77/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.3934 - acc: 0.8292 - val_loss: 0.3519 - val_acc: 0.8642\n",
      "Epoch 78/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.3903 - acc: 0.8323 - val_loss: 0.3517 - val_acc: 0.8642\n",
      "Epoch 79/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.3893 - acc: 0.8323 - val_loss: 0.3475 - val_acc: 0.8683\n",
      "Epoch 80/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.3775 - acc: 0.8369 - val_loss: 0.3441 - val_acc: 0.8704\n",
      "Epoch 81/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.3844 - acc: 0.8328 - val_loss: 0.3414 - val_acc: 0.8704\n",
      "Epoch 82/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.3804 - acc: 0.8431 - val_loss: 0.3401 - val_acc: 0.8724\n",
      "Epoch 83/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.3762 - acc: 0.8374 - val_loss: 0.3398 - val_acc: 0.8745\n",
      "Epoch 84/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.3832 - acc: 0.8349 - val_loss: 0.3330 - val_acc: 0.8786\n",
      "Epoch 85/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.3670 - acc: 0.8421 - val_loss: 0.3309 - val_acc: 0.8827\n",
      "Epoch 86/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.3662 - acc: 0.8493 - val_loss: 0.3285 - val_acc: 0.8848\n",
      "Epoch 87/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.3637 - acc: 0.8462 - val_loss: 0.3266 - val_acc: 0.8827\n",
      "Epoch 88/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.3627 - acc: 0.8519 - val_loss: 0.3243 - val_acc: 0.8827\n",
      "Epoch 89/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.3681 - acc: 0.8410 - val_loss: 0.3215 - val_acc: 0.8868\n",
      "Epoch 90/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.3535 - acc: 0.8534 - val_loss: 0.3209 - val_acc: 0.8868\n",
      "Epoch 91/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.3593 - acc: 0.8544 - val_loss: 0.3186 - val_acc: 0.8909\n",
      "Epoch 92/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.3566 - acc: 0.8493 - val_loss: 0.3176 - val_acc: 0.8889\n",
      "Epoch 93/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.3518 - acc: 0.8508 - val_loss: 0.3152 - val_acc: 0.8909\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.3550 - acc: 0.8565 - val_loss: 0.3106 - val_acc: 0.8951\n",
      "Epoch 95/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.3481 - acc: 0.8498 - val_loss: 0.3110 - val_acc: 0.8909\n",
      "Epoch 96/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.3500 - acc: 0.8513 - val_loss: 0.3109 - val_acc: 0.8868\n",
      "Epoch 97/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.3416 - acc: 0.8529 - val_loss: 0.3093 - val_acc: 0.8868\n",
      "Epoch 98/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.3447 - acc: 0.8575 - val_loss: 0.3052 - val_acc: 0.8971\n",
      "Epoch 99/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.3371 - acc: 0.8508 - val_loss: 0.3045 - val_acc: 0.8951\n",
      "Epoch 100/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.3356 - acc: 0.8575 - val_loss: 0.3045 - val_acc: 0.8909\n",
      "Train on 1944 samples, validate on 486 samples\n",
      "Epoch 1/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.3515 - acc: 0.8596 - val_loss: 0.3273 - val_acc: 0.8765\n",
      "Epoch 2/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.3445 - acc: 0.8657 - val_loss: 0.3269 - val_acc: 0.8724\n",
      "Epoch 3/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.3468 - acc: 0.8632 - val_loss: 0.3248 - val_acc: 0.8745\n",
      "Epoch 4/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.3453 - acc: 0.8673 - val_loss: 0.3217 - val_acc: 0.8807\n",
      "Epoch 5/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.3435 - acc: 0.8657 - val_loss: 0.3197 - val_acc: 0.8807\n",
      "Epoch 6/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.3336 - acc: 0.8750 - val_loss: 0.3189 - val_acc: 0.8765\n",
      "Epoch 7/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.3358 - acc: 0.8765 - val_loss: 0.3189 - val_acc: 0.8807\n",
      "Epoch 8/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.3344 - acc: 0.8729 - val_loss: 0.3165 - val_acc: 0.8807\n",
      "Epoch 9/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.3290 - acc: 0.8771 - val_loss: 0.3152 - val_acc: 0.8807\n",
      "Epoch 10/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.3251 - acc: 0.8781 - val_loss: 0.3151 - val_acc: 0.8827\n",
      "Epoch 11/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.3234 - acc: 0.8791 - val_loss: 0.3110 - val_acc: 0.8868\n",
      "Epoch 12/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.3305 - acc: 0.8750 - val_loss: 0.3095 - val_acc: 0.8868\n",
      "Epoch 13/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.3156 - acc: 0.8827 - val_loss: 0.3077 - val_acc: 0.8909\n",
      "Epoch 14/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.3213 - acc: 0.8868 - val_loss: 0.3077 - val_acc: 0.8889\n",
      "Epoch 15/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.3229 - acc: 0.8771 - val_loss: 0.3088 - val_acc: 0.8868\n",
      "Epoch 16/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.3187 - acc: 0.8765 - val_loss: 0.3086 - val_acc: 0.8868\n",
      "Epoch 17/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.3110 - acc: 0.8791 - val_loss: 0.3059 - val_acc: 0.8889\n",
      "Epoch 18/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.3119 - acc: 0.8832 - val_loss: 0.3054 - val_acc: 0.8889\n",
      "Epoch 19/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.3192 - acc: 0.8822 - val_loss: 0.3043 - val_acc: 0.8889\n",
      "Epoch 20/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.3111 - acc: 0.8832 - val_loss: 0.3051 - val_acc: 0.8848\n",
      "Epoch 21/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.3036 - acc: 0.8889 - val_loss: 0.3028 - val_acc: 0.8909\n",
      "Epoch 22/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.3037 - acc: 0.8930 - val_loss: 0.3034 - val_acc: 0.8889\n",
      "Epoch 23/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.3004 - acc: 0.8951 - val_loss: 0.3008 - val_acc: 0.8848\n",
      "Epoch 24/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.3051 - acc: 0.8858 - val_loss: 0.3003 - val_acc: 0.8848\n",
      "Epoch 25/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.2949 - acc: 0.8951 - val_loss: 0.2999 - val_acc: 0.8889\n",
      "Epoch 26/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.3071 - acc: 0.8868 - val_loss: 0.2972 - val_acc: 0.8889\n",
      "Epoch 27/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.3044 - acc: 0.8863 - val_loss: 0.2962 - val_acc: 0.8868\n",
      "Epoch 28/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.2949 - acc: 0.8956 - val_loss: 0.2973 - val_acc: 0.8848\n",
      "Epoch 29/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.2995 - acc: 0.8987 - val_loss: 0.2947 - val_acc: 0.8848\n",
      "Epoch 30/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.2996 - acc: 0.8930 - val_loss: 0.2934 - val_acc: 0.8909\n",
      "Epoch 31/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.2935 - acc: 0.8879 - val_loss: 0.2932 - val_acc: 0.8868\n",
      "Epoch 32/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.2954 - acc: 0.8915 - val_loss: 0.2932 - val_acc: 0.8868\n",
      "Epoch 33/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.2917 - acc: 0.8951 - val_loss: 0.2923 - val_acc: 0.8868\n",
      "Epoch 34/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.2912 - acc: 0.8935 - val_loss: 0.2915 - val_acc: 0.8868\n",
      "Epoch 35/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.2895 - acc: 0.8884 - val_loss: 0.2904 - val_acc: 0.8889\n",
      "Epoch 36/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.2905 - acc: 0.8930 - val_loss: 0.2896 - val_acc: 0.8889\n",
      "Epoch 37/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.2892 - acc: 0.8971 - val_loss: 0.2891 - val_acc: 0.8889\n",
      "Epoch 38/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.2913 - acc: 0.8930 - val_loss: 0.2887 - val_acc: 0.8909\n",
      "Epoch 39/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.2940 - acc: 0.8971 - val_loss: 0.2886 - val_acc: 0.8909\n",
      "Epoch 40/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.2857 - acc: 0.8945 - val_loss: 0.2873 - val_acc: 0.8930\n",
      "Epoch 41/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.2794 - acc: 0.8961 - val_loss: 0.2896 - val_acc: 0.8909\n",
      "Epoch 42/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.2878 - acc: 0.8971 - val_loss: 0.2857 - val_acc: 0.8951\n",
      "Epoch 43/100\n",
      "1944/1944 [==============================] - 1s 371us/step - loss: 0.2789 - acc: 0.9007 - val_loss: 0.2865 - val_acc: 0.8930\n",
      "Epoch 44/100\n",
      "1944/1944 [==============================] - 1s 361us/step - loss: 0.2872 - acc: 0.8976 - val_loss: 0.2850 - val_acc: 0.8951\n",
      "Epoch 45/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.2814 - acc: 0.8971 - val_loss: 0.2846 - val_acc: 0.8930\n",
      "Epoch 46/100\n",
      "1944/1944 [==============================] - 1s 358us/step - loss: 0.2802 - acc: 0.8951 - val_loss: 0.2835 - val_acc: 0.8951\n",
      "Epoch 47/100\n",
      "1944/1944 [==============================] - 1s 367us/step - loss: 0.2810 - acc: 0.8945 - val_loss: 0.2833 - val_acc: 0.8951\n",
      "Epoch 48/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.2848 - acc: 0.8956 - val_loss: 0.2849 - val_acc: 0.8951\n",
      "Epoch 49/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.2727 - acc: 0.9033 - val_loss: 0.2838 - val_acc: 0.8930\n",
      "Epoch 50/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.2741 - acc: 0.8961 - val_loss: 0.2838 - val_acc: 0.8951\n",
      "Epoch 51/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.2770 - acc: 0.9028 - val_loss: 0.2836 - val_acc: 0.8951\n",
      "Epoch 52/100\n",
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.2816 - acc: 0.8915 - val_loss: 0.2806 - val_acc: 0.8971\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.2736 - acc: 0.9012 - val_loss: 0.2816 - val_acc: 0.8971\n",
      "Epoch 54/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.2717 - acc: 0.9017 - val_loss: 0.2789 - val_acc: 0.8992\n",
      "Epoch 55/100\n",
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.2721 - acc: 0.8945 - val_loss: 0.2809 - val_acc: 0.8992\n",
      "Epoch 56/100\n",
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.2733 - acc: 0.9002 - val_loss: 0.2783 - val_acc: 0.8992\n",
      "Epoch 57/100\n",
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.2793 - acc: 0.8987 - val_loss: 0.2768 - val_acc: 0.8992\n",
      "Epoch 58/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.2720 - acc: 0.9053 - val_loss: 0.2777 - val_acc: 0.8992\n",
      "Epoch 59/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.2684 - acc: 0.9028 - val_loss: 0.2783 - val_acc: 0.8992\n",
      "Epoch 60/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.2679 - acc: 0.9053 - val_loss: 0.2789 - val_acc: 0.8992\n",
      "Epoch 61/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.2665 - acc: 0.9059 - val_loss: 0.2767 - val_acc: 0.9012\n",
      "Epoch 62/100\n",
      "1944/1944 [==============================] - 1s 336us/step - loss: 0.2710 - acc: 0.9007 - val_loss: 0.2742 - val_acc: 0.8971\n",
      "Epoch 63/100\n",
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.2678 - acc: 0.9033 - val_loss: 0.2756 - val_acc: 0.9012\n",
      "Epoch 64/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.2660 - acc: 0.9007 - val_loss: 0.2748 - val_acc: 0.9012\n",
      "Epoch 65/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.2675 - acc: 0.9028 - val_loss: 0.2745 - val_acc: 0.9012\n",
      "Epoch 66/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.2651 - acc: 0.9059 - val_loss: 0.2752 - val_acc: 0.8992\n",
      "Epoch 67/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.2655 - acc: 0.9023 - val_loss: 0.2735 - val_acc: 0.9012\n",
      "Epoch 68/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.2653 - acc: 0.9023 - val_loss: 0.2727 - val_acc: 0.8992\n",
      "Epoch 69/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.2745 - acc: 0.9002 - val_loss: 0.2712 - val_acc: 0.8971\n",
      "Epoch 70/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.2546 - acc: 0.9069 - val_loss: 0.2718 - val_acc: 0.8992\n",
      "Epoch 71/100\n",
      "1944/1944 [==============================] - 1s 336us/step - loss: 0.2681 - acc: 0.9028 - val_loss: 0.2718 - val_acc: 0.8971\n",
      "Epoch 72/100\n",
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.2613 - acc: 0.9028 - val_loss: 0.2712 - val_acc: 0.8992\n",
      "Epoch 73/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.2565 - acc: 0.9069 - val_loss: 0.2707 - val_acc: 0.8951\n",
      "Epoch 74/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.2554 - acc: 0.9110 - val_loss: 0.2706 - val_acc: 0.8992\n",
      "Epoch 75/100\n",
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.2582 - acc: 0.9084 - val_loss: 0.2698 - val_acc: 0.8992\n",
      "Epoch 76/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.2597 - acc: 0.9064 - val_loss: 0.2684 - val_acc: 0.8951\n",
      "Epoch 77/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.2567 - acc: 0.9053 - val_loss: 0.2706 - val_acc: 0.8992\n",
      "Epoch 78/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.2576 - acc: 0.9079 - val_loss: 0.2688 - val_acc: 0.8992\n",
      "Epoch 79/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.2537 - acc: 0.9048 - val_loss: 0.2684 - val_acc: 0.8992\n",
      "Epoch 80/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.2538 - acc: 0.9105 - val_loss: 0.2689 - val_acc: 0.8992\n",
      "Epoch 81/100\n",
      "1944/1944 [==============================] - 1s 336us/step - loss: 0.2637 - acc: 0.9120 - val_loss: 0.2670 - val_acc: 0.8992\n",
      "Epoch 82/100\n",
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.2604 - acc: 0.9110 - val_loss: 0.2667 - val_acc: 0.8971\n",
      "Epoch 83/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.2555 - acc: 0.9074 - val_loss: 0.2656 - val_acc: 0.8951\n",
      "Epoch 84/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.2518 - acc: 0.9162 - val_loss: 0.2668 - val_acc: 0.8992\n",
      "Epoch 85/100\n",
      "1944/1944 [==============================] - 1s 334us/step - loss: 0.2608 - acc: 0.9084 - val_loss: 0.2656 - val_acc: 0.8992\n",
      "Epoch 86/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.2603 - acc: 0.9064 - val_loss: 0.2654 - val_acc: 0.8992\n",
      "Epoch 87/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.2569 - acc: 0.9079 - val_loss: 0.2666 - val_acc: 0.8992\n",
      "Epoch 88/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.2534 - acc: 0.9095 - val_loss: 0.2647 - val_acc: 0.8992\n",
      "Epoch 89/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.2589 - acc: 0.9043 - val_loss: 0.2653 - val_acc: 0.8992\n",
      "Epoch 90/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.2551 - acc: 0.9090 - val_loss: 0.2641 - val_acc: 0.8971\n",
      "Epoch 91/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.2571 - acc: 0.9074 - val_loss: 0.2644 - val_acc: 0.8992\n",
      "Epoch 92/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.2441 - acc: 0.9084 - val_loss: 0.2641 - val_acc: 0.8992\n",
      "Epoch 93/100\n",
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.2503 - acc: 0.9100 - val_loss: 0.2624 - val_acc: 0.9012\n",
      "Epoch 94/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.2507 - acc: 0.9069 - val_loss: 0.2625 - val_acc: 0.9012\n",
      "Epoch 95/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.2502 - acc: 0.9090 - val_loss: 0.2629 - val_acc: 0.9012\n",
      "Epoch 96/100\n",
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.2495 - acc: 0.9084 - val_loss: 0.2625 - val_acc: 0.9012\n",
      "Epoch 97/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.2505 - acc: 0.9105 - val_loss: 0.2615 - val_acc: 0.9012\n",
      "Epoch 98/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.2466 - acc: 0.9115 - val_loss: 0.2610 - val_acc: 0.9012\n",
      "Epoch 99/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.2477 - acc: 0.9120 - val_loss: 0.2605 - val_acc: 0.9012\n",
      "Epoch 100/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.2486 - acc: 0.9105 - val_loss: 0.2594 - val_acc: 0.9012\n",
      "Test subject 10, class FirstDigitTouch\n",
      "Train subject 10, class BothStartLoadPhase\n",
      "Train on 1944 samples, validate on 486 samples\n",
      "Epoch 1/100\n",
      "1944/1944 [==============================] - 1s 745us/step - loss: 0.6961 - acc: 0.4959 - val_loss: 0.6963 - val_acc: 0.4856\n",
      "Epoch 2/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.6948 - acc: 0.4949 - val_loss: 0.6953 - val_acc: 0.4856\n",
      "Epoch 3/100\n",
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.6925 - acc: 0.4954 - val_loss: 0.6944 - val_acc: 0.4856\n",
      "Epoch 4/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.6948 - acc: 0.4892 - val_loss: 0.6936 - val_acc: 0.4877\n",
      "Epoch 5/100\n",
      "1944/1944 [==============================] - 1s 334us/step - loss: 0.6920 - acc: 0.5067 - val_loss: 0.6930 - val_acc: 0.4897\n",
      "Epoch 6/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.6920 - acc: 0.5010 - val_loss: 0.6923 - val_acc: 0.5226\n",
      "Epoch 7/100\n",
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.6920 - acc: 0.5082 - val_loss: 0.6917 - val_acc: 0.5329\n",
      "Epoch 8/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.6919 - acc: 0.5077 - val_loss: 0.6911 - val_acc: 0.5473\n",
      "Epoch 9/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.6886 - acc: 0.5448 - val_loss: 0.6906 - val_acc: 0.5658\n",
      "Epoch 10/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.6907 - acc: 0.5273 - val_loss: 0.6900 - val_acc: 0.5823\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 334us/step - loss: 0.6907 - acc: 0.5185 - val_loss: 0.6895 - val_acc: 0.5988\n",
      "Epoch 12/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.6903 - acc: 0.5221 - val_loss: 0.6889 - val_acc: 0.6235\n",
      "Epoch 13/100\n",
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.6895 - acc: 0.5432 - val_loss: 0.6884 - val_acc: 0.6214\n",
      "Epoch 14/100\n",
      "1944/1944 [==============================] - 1s 334us/step - loss: 0.6888 - acc: 0.5535 - val_loss: 0.6879 - val_acc: 0.6152\n",
      "Epoch 15/100\n",
      "1944/1944 [==============================] - 1s 334us/step - loss: 0.6875 - acc: 0.5612 - val_loss: 0.6874 - val_acc: 0.6111\n",
      "Epoch 16/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.6887 - acc: 0.5504 - val_loss: 0.6869 - val_acc: 0.6111\n",
      "Epoch 17/100\n",
      "1944/1944 [==============================] - 1s 362us/step - loss: 0.6879 - acc: 0.5612 - val_loss: 0.6863 - val_acc: 0.6193\n",
      "Epoch 18/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.6869 - acc: 0.5730 - val_loss: 0.6858 - val_acc: 0.6358\n",
      "Epoch 19/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.6867 - acc: 0.5736 - val_loss: 0.6853 - val_acc: 0.6420\n",
      "Epoch 20/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.6852 - acc: 0.5890 - val_loss: 0.6847 - val_acc: 0.6420\n",
      "Epoch 21/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.6845 - acc: 0.5957 - val_loss: 0.6841 - val_acc: 0.6543\n",
      "Epoch 22/100\n",
      "1944/1944 [==============================] - 1s 334us/step - loss: 0.6852 - acc: 0.5802 - val_loss: 0.6834 - val_acc: 0.6564\n",
      "Epoch 23/100\n",
      "1944/1944 [==============================] - 1s 360us/step - loss: 0.6832 - acc: 0.5972 - val_loss: 0.6828 - val_acc: 0.6605\n",
      "Epoch 24/100\n",
      "1944/1944 [==============================] - 1s 387us/step - loss: 0.6831 - acc: 0.6111 - val_loss: 0.6821 - val_acc: 0.6646\n",
      "Epoch 25/100\n",
      "1944/1944 [==============================] - 1s 391us/step - loss: 0.6824 - acc: 0.6106 - val_loss: 0.6814 - val_acc: 0.6646\n",
      "Epoch 26/100\n",
      "1944/1944 [==============================] - 1s 367us/step - loss: 0.6834 - acc: 0.5957 - val_loss: 0.6808 - val_acc: 0.6667\n",
      "Epoch 27/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.6808 - acc: 0.6276 - val_loss: 0.6800 - val_acc: 0.6728\n",
      "Epoch 28/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.6807 - acc: 0.6235 - val_loss: 0.6792 - val_acc: 0.6770\n",
      "Epoch 29/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.6796 - acc: 0.6343 - val_loss: 0.6784 - val_acc: 0.6790\n",
      "Epoch 30/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.6796 - acc: 0.6209 - val_loss: 0.6776 - val_acc: 0.6811\n",
      "Epoch 31/100\n",
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.6789 - acc: 0.6229 - val_loss: 0.6767 - val_acc: 0.6872\n",
      "Epoch 32/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.6760 - acc: 0.6569 - val_loss: 0.6757 - val_acc: 0.6852\n",
      "Epoch 33/100\n",
      "1944/1944 [==============================] - 1s 368us/step - loss: 0.6766 - acc: 0.6440 - val_loss: 0.6747 - val_acc: 0.6872\n",
      "Epoch 34/100\n",
      "1944/1944 [==============================] - 1s 379us/step - loss: 0.6753 - acc: 0.6445 - val_loss: 0.6737 - val_acc: 0.6852\n",
      "Epoch 35/100\n",
      "1944/1944 [==============================] - 1s 366us/step - loss: 0.6759 - acc: 0.6461 - val_loss: 0.6726 - val_acc: 0.6893\n",
      "Epoch 36/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.6733 - acc: 0.6502 - val_loss: 0.6714 - val_acc: 0.6934\n",
      "Epoch 37/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.6727 - acc: 0.6574 - val_loss: 0.6701 - val_acc: 0.6955\n",
      "Epoch 38/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.6713 - acc: 0.6533 - val_loss: 0.6688 - val_acc: 0.6996\n",
      "Epoch 39/100\n",
      "1944/1944 [==============================] - 1s 356us/step - loss: 0.6707 - acc: 0.6687 - val_loss: 0.6674 - val_acc: 0.7016\n",
      "Epoch 40/100\n",
      "1944/1944 [==============================] - 1s 373us/step - loss: 0.6671 - acc: 0.6667 - val_loss: 0.6658 - val_acc: 0.7037\n",
      "Epoch 41/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.6688 - acc: 0.6692 - val_loss: 0.6644 - val_acc: 0.7016\n",
      "Epoch 42/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.6661 - acc: 0.6713 - val_loss: 0.6627 - val_acc: 0.7058\n",
      "Epoch 43/100\n",
      "1944/1944 [==============================] - 1s 366us/step - loss: 0.6649 - acc: 0.6847 - val_loss: 0.6609 - val_acc: 0.7140\n",
      "Epoch 44/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.6614 - acc: 0.6975 - val_loss: 0.6589 - val_acc: 0.7160\n",
      "Epoch 45/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.6619 - acc: 0.6867 - val_loss: 0.6569 - val_acc: 0.7243\n",
      "Epoch 46/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.6583 - acc: 0.7011 - val_loss: 0.6546 - val_acc: 0.7305\n",
      "Epoch 47/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.6567 - acc: 0.6903 - val_loss: 0.6522 - val_acc: 0.7387\n",
      "Epoch 48/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.6551 - acc: 0.7083 - val_loss: 0.6496 - val_acc: 0.7387\n",
      "Epoch 49/100\n",
      "1944/1944 [==============================] - 1s 358us/step - loss: 0.6545 - acc: 0.7088 - val_loss: 0.6470 - val_acc: 0.7510\n",
      "Epoch 50/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.6478 - acc: 0.7186 - val_loss: 0.6440 - val_acc: 0.7654\n",
      "Epoch 51/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.6448 - acc: 0.7222 - val_loss: 0.6407 - val_acc: 0.7695\n",
      "Epoch 52/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.6432 - acc: 0.7258 - val_loss: 0.6373 - val_acc: 0.7675\n",
      "Epoch 53/100\n",
      "1944/1944 [==============================] - 1s 360us/step - loss: 0.6421 - acc: 0.7320 - val_loss: 0.6335 - val_acc: 0.7695\n",
      "Epoch 54/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.6360 - acc: 0.7299 - val_loss: 0.6293 - val_acc: 0.7798\n",
      "Epoch 55/100\n",
      "1944/1944 [==============================] - 1s 362us/step - loss: 0.6321 - acc: 0.7443 - val_loss: 0.6249 - val_acc: 0.7860\n",
      "Epoch 56/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.6286 - acc: 0.7382 - val_loss: 0.6200 - val_acc: 0.7881\n",
      "Epoch 57/100\n",
      "1944/1944 [==============================] - 1s 359us/step - loss: 0.6234 - acc: 0.7521 - val_loss: 0.6147 - val_acc: 0.7922\n",
      "Epoch 58/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.6206 - acc: 0.7577 - val_loss: 0.6088 - val_acc: 0.8045\n",
      "Epoch 59/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.6122 - acc: 0.7613 - val_loss: 0.6025 - val_acc: 0.8086\n",
      "Epoch 60/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.6074 - acc: 0.7603 - val_loss: 0.5954 - val_acc: 0.8148\n",
      "Epoch 61/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.5974 - acc: 0.7721 - val_loss: 0.5873 - val_acc: 0.8169\n",
      "Epoch 62/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.5885 - acc: 0.7845 - val_loss: 0.5785 - val_acc: 0.8230\n",
      "Epoch 63/100\n",
      "1944/1944 [==============================] - 1s 372us/step - loss: 0.5831 - acc: 0.7865 - val_loss: 0.5693 - val_acc: 0.8251\n",
      "Epoch 64/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.5755 - acc: 0.7912 - val_loss: 0.5591 - val_acc: 0.8272\n",
      "Epoch 65/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.5643 - acc: 0.8102 - val_loss: 0.5479 - val_acc: 0.8333\n",
      "Epoch 66/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.5548 - acc: 0.8020 - val_loss: 0.5366 - val_acc: 0.8292\n",
      "Epoch 67/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.5456 - acc: 0.8009 - val_loss: 0.5240 - val_acc: 0.8313\n",
      "Epoch 68/100\n",
      "1944/1944 [==============================] - 1s 367us/step - loss: 0.5329 - acc: 0.8009 - val_loss: 0.5104 - val_acc: 0.8374\n",
      "Epoch 69/100\n",
      "1944/1944 [==============================] - 1s 370us/step - loss: 0.5228 - acc: 0.8009 - val_loss: 0.4975 - val_acc: 0.8313\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 361us/step - loss: 0.5053 - acc: 0.8225 - val_loss: 0.4835 - val_acc: 0.8354\n",
      "Epoch 71/100\n",
      "1944/1944 [==============================] - 1s 360us/step - loss: 0.4983 - acc: 0.8122 - val_loss: 0.4706 - val_acc: 0.8354\n",
      "Epoch 72/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.4812 - acc: 0.8333 - val_loss: 0.4570 - val_acc: 0.8416\n",
      "Epoch 73/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.4755 - acc: 0.8174 - val_loss: 0.4424 - val_acc: 0.8477\n",
      "Epoch 74/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.4604 - acc: 0.8395 - val_loss: 0.4326 - val_acc: 0.8436\n",
      "Epoch 75/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.4516 - acc: 0.8344 - val_loss: 0.4207 - val_acc: 0.8457\n",
      "Epoch 76/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.4448 - acc: 0.8236 - val_loss: 0.4110 - val_acc: 0.8416\n",
      "Epoch 77/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.4303 - acc: 0.8318 - val_loss: 0.3999 - val_acc: 0.8477\n",
      "Epoch 78/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.4319 - acc: 0.8318 - val_loss: 0.3914 - val_acc: 0.8580\n",
      "Epoch 79/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.4207 - acc: 0.8313 - val_loss: 0.3826 - val_acc: 0.8601\n",
      "Epoch 80/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.4090 - acc: 0.8519 - val_loss: 0.3776 - val_acc: 0.8601\n",
      "Epoch 81/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.4073 - acc: 0.8513 - val_loss: 0.3704 - val_acc: 0.8621\n",
      "Epoch 82/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.4001 - acc: 0.8477 - val_loss: 0.3666 - val_acc: 0.8580\n",
      "Epoch 83/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.4034 - acc: 0.8416 - val_loss: 0.3639 - val_acc: 0.8519\n",
      "Epoch 84/100\n",
      "1944/1944 [==============================] - 1s 334us/step - loss: 0.3944 - acc: 0.8472 - val_loss: 0.3576 - val_acc: 0.8560\n",
      "Epoch 85/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.3853 - acc: 0.8503 - val_loss: 0.3540 - val_acc: 0.8560\n",
      "Epoch 86/100\n",
      "1944/1944 [==============================] - 1s 336us/step - loss: 0.3877 - acc: 0.8503 - val_loss: 0.3499 - val_acc: 0.8580\n",
      "Epoch 87/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.3857 - acc: 0.8483 - val_loss: 0.3448 - val_acc: 0.8642\n",
      "Epoch 88/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.3916 - acc: 0.8477 - val_loss: 0.3446 - val_acc: 0.8560\n",
      "Epoch 89/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.3788 - acc: 0.8472 - val_loss: 0.3389 - val_acc: 0.8642\n",
      "Epoch 90/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.3782 - acc: 0.8488 - val_loss: 0.3379 - val_acc: 0.8621\n",
      "Epoch 91/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.3739 - acc: 0.8596 - val_loss: 0.3356 - val_acc: 0.8621\n",
      "Epoch 92/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.3739 - acc: 0.8529 - val_loss: 0.3326 - val_acc: 0.8642\n",
      "Epoch 93/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.3704 - acc: 0.8591 - val_loss: 0.3314 - val_acc: 0.8621\n",
      "Epoch 94/100\n",
      "1944/1944 [==============================] - 1s 337us/step - loss: 0.3621 - acc: 0.8477 - val_loss: 0.3287 - val_acc: 0.8663\n",
      "Epoch 95/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.3692 - acc: 0.8555 - val_loss: 0.3281 - val_acc: 0.8642\n",
      "Epoch 96/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.3667 - acc: 0.8560 - val_loss: 0.3266 - val_acc: 0.8704\n",
      "Epoch 97/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.3683 - acc: 0.8534 - val_loss: 0.3248 - val_acc: 0.8786\n",
      "Epoch 98/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.3632 - acc: 0.8508 - val_loss: 0.3250 - val_acc: 0.8745\n",
      "Epoch 99/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.3598 - acc: 0.8621 - val_loss: 0.3222 - val_acc: 0.8807\n",
      "Epoch 100/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.3602 - acc: 0.8611 - val_loss: 0.3216 - val_acc: 0.8786\n",
      "Train on 1944 samples, validate on 486 samples\n",
      "Epoch 1/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.3440 - acc: 0.8781 - val_loss: 0.3209 - val_acc: 0.8724\n",
      "Epoch 2/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.3467 - acc: 0.8765 - val_loss: 0.3191 - val_acc: 0.8724\n",
      "Epoch 3/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.3423 - acc: 0.8755 - val_loss: 0.3177 - val_acc: 0.8724\n",
      "Epoch 4/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.3427 - acc: 0.8843 - val_loss: 0.3157 - val_acc: 0.8745\n",
      "Epoch 5/100\n",
      "1944/1944 [==============================] - 1s 334us/step - loss: 0.3384 - acc: 0.8796 - val_loss: 0.3143 - val_acc: 0.8724\n",
      "Epoch 6/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.3430 - acc: 0.8879 - val_loss: 0.3126 - val_acc: 0.8765\n",
      "Epoch 7/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.3365 - acc: 0.8843 - val_loss: 0.3115 - val_acc: 0.8724\n",
      "Epoch 8/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.3276 - acc: 0.8894 - val_loss: 0.3100 - val_acc: 0.8724\n",
      "Epoch 9/100\n",
      "1944/1944 [==============================] - 1s 337us/step - loss: 0.3293 - acc: 0.8873 - val_loss: 0.3088 - val_acc: 0.8724\n",
      "Epoch 10/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.3369 - acc: 0.8868 - val_loss: 0.3075 - val_acc: 0.8724\n",
      "Epoch 11/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.3277 - acc: 0.8837 - val_loss: 0.3065 - val_acc: 0.8724\n",
      "Epoch 12/100\n",
      "1944/1944 [==============================] - 1s 334us/step - loss: 0.3225 - acc: 0.8981 - val_loss: 0.3062 - val_acc: 0.8724\n",
      "Epoch 13/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.3221 - acc: 0.8909 - val_loss: 0.3044 - val_acc: 0.8704\n",
      "Epoch 14/100\n",
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.3262 - acc: 0.8945 - val_loss: 0.3020 - val_acc: 0.8765\n",
      "Epoch 15/100\n",
      "1944/1944 [==============================] - 1s 356us/step - loss: 0.3244 - acc: 0.8925 - val_loss: 0.3020 - val_acc: 0.8745\n",
      "Epoch 16/100\n",
      "1944/1944 [==============================] - 1s 378us/step - loss: 0.3201 - acc: 0.8925 - val_loss: 0.2999 - val_acc: 0.8765\n",
      "Epoch 17/100\n",
      "1944/1944 [==============================] - 1s 365us/step - loss: 0.3292 - acc: 0.8889 - val_loss: 0.2987 - val_acc: 0.8786\n",
      "Epoch 18/100\n",
      "1944/1944 [==============================] - 1s 382us/step - loss: 0.3231 - acc: 0.8920 - val_loss: 0.2974 - val_acc: 0.8807\n",
      "Epoch 19/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.3181 - acc: 0.8945 - val_loss: 0.2964 - val_acc: 0.8786\n",
      "Epoch 20/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.3230 - acc: 0.8894 - val_loss: 0.2960 - val_acc: 0.8765\n",
      "Epoch 21/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.3116 - acc: 0.9002 - val_loss: 0.2952 - val_acc: 0.8745\n",
      "Epoch 22/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.3225 - acc: 0.8909 - val_loss: 0.2941 - val_acc: 0.8745\n",
      "Epoch 23/100\n",
      "1944/1944 [==============================] - 1s 358us/step - loss: 0.3207 - acc: 0.8945 - val_loss: 0.2930 - val_acc: 0.8765\n",
      "Epoch 24/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.3149 - acc: 0.8987 - val_loss: 0.2921 - val_acc: 0.8786\n",
      "Epoch 25/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.3126 - acc: 0.8925 - val_loss: 0.2907 - val_acc: 0.8786\n",
      "Epoch 26/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.3141 - acc: 0.9012 - val_loss: 0.2897 - val_acc: 0.8786\n",
      "Epoch 27/100\n",
      "1944/1944 [==============================] - 1s 337us/step - loss: 0.3159 - acc: 0.8940 - val_loss: 0.2893 - val_acc: 0.8807\n",
      "Epoch 28/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.3162 - acc: 0.8925 - val_loss: 0.2886 - val_acc: 0.8848\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.3092 - acc: 0.8997 - val_loss: 0.2873 - val_acc: 0.8827\n",
      "Epoch 30/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.3042 - acc: 0.9038 - val_loss: 0.2868 - val_acc: 0.8827\n",
      "Epoch 31/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.3214 - acc: 0.8940 - val_loss: 0.2857 - val_acc: 0.8848\n",
      "Epoch 32/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.3074 - acc: 0.8956 - val_loss: 0.2854 - val_acc: 0.8848\n",
      "Epoch 33/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.3023 - acc: 0.9038 - val_loss: 0.2849 - val_acc: 0.8889\n",
      "Epoch 34/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.3051 - acc: 0.9048 - val_loss: 0.2834 - val_acc: 0.8868\n",
      "Epoch 35/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.3098 - acc: 0.8935 - val_loss: 0.2833 - val_acc: 0.8889\n",
      "Epoch 36/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.3015 - acc: 0.8976 - val_loss: 0.2821 - val_acc: 0.8889\n",
      "Epoch 37/100\n",
      "1944/1944 [==============================] - 1s 371us/step - loss: 0.3045 - acc: 0.9059 - val_loss: 0.2809 - val_acc: 0.8909\n",
      "Epoch 38/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.3033 - acc: 0.9048 - val_loss: 0.2804 - val_acc: 0.8909\n",
      "Epoch 39/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.2984 - acc: 0.9053 - val_loss: 0.2803 - val_acc: 0.8909\n",
      "Epoch 40/100\n",
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.2999 - acc: 0.9007 - val_loss: 0.2790 - val_acc: 0.8909\n",
      "Epoch 41/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.3005 - acc: 0.9033 - val_loss: 0.2778 - val_acc: 0.8909\n",
      "Epoch 42/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.3059 - acc: 0.9002 - val_loss: 0.2769 - val_acc: 0.8951\n",
      "Epoch 43/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.3056 - acc: 0.8961 - val_loss: 0.2763 - val_acc: 0.8930\n",
      "Epoch 44/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.2997 - acc: 0.8992 - val_loss: 0.2764 - val_acc: 0.8909\n",
      "Epoch 45/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.2944 - acc: 0.9079 - val_loss: 0.2757 - val_acc: 0.8909\n",
      "Epoch 46/100\n",
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.2947 - acc: 0.9069 - val_loss: 0.2749 - val_acc: 0.8909\n",
      "Epoch 47/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.2942 - acc: 0.9002 - val_loss: 0.2751 - val_acc: 0.8909\n",
      "Epoch 48/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.2990 - acc: 0.9079 - val_loss: 0.2746 - val_acc: 0.8909\n",
      "Epoch 49/100\n",
      "1944/1944 [==============================] - 1s 362us/step - loss: 0.2955 - acc: 0.9033 - val_loss: 0.2736 - val_acc: 0.8909\n",
      "Epoch 50/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.2973 - acc: 0.9043 - val_loss: 0.2719 - val_acc: 0.8951\n",
      "Epoch 51/100\n",
      "1944/1944 [==============================] - 1s 364us/step - loss: 0.2855 - acc: 0.9079 - val_loss: 0.2723 - val_acc: 0.8930\n",
      "Epoch 52/100\n",
      "1944/1944 [==============================] - 1s 364us/step - loss: 0.2987 - acc: 0.9048 - val_loss: 0.2705 - val_acc: 0.8951\n",
      "Epoch 53/100\n",
      "1944/1944 [==============================] - 1s 366us/step - loss: 0.2889 - acc: 0.9074 - val_loss: 0.2715 - val_acc: 0.8951\n",
      "Epoch 54/100\n",
      "1944/1944 [==============================] - 1s 369us/step - loss: 0.2883 - acc: 0.9064 - val_loss: 0.2710 - val_acc: 0.8951\n",
      "Epoch 55/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.2858 - acc: 0.9141 - val_loss: 0.2690 - val_acc: 0.8971\n",
      "Epoch 56/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.2881 - acc: 0.9105 - val_loss: 0.2682 - val_acc: 0.8971\n",
      "Epoch 57/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.2922 - acc: 0.9059 - val_loss: 0.2675 - val_acc: 0.8971\n",
      "Epoch 58/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.2855 - acc: 0.9131 - val_loss: 0.2675 - val_acc: 0.8971\n",
      "Epoch 59/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.2912 - acc: 0.9079 - val_loss: 0.2664 - val_acc: 0.8992\n",
      "Epoch 60/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.2931 - acc: 0.9028 - val_loss: 0.2665 - val_acc: 0.8992\n",
      "Epoch 61/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.2922 - acc: 0.9064 - val_loss: 0.2657 - val_acc: 0.8992\n",
      "Epoch 62/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.2966 - acc: 0.9043 - val_loss: 0.2668 - val_acc: 0.8971\n",
      "Epoch 63/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.2832 - acc: 0.9033 - val_loss: 0.2666 - val_acc: 0.8971\n",
      "Epoch 64/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.2833 - acc: 0.9105 - val_loss: 0.2644 - val_acc: 0.8992\n",
      "Epoch 65/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.2834 - acc: 0.9105 - val_loss: 0.2646 - val_acc: 0.8971\n",
      "Epoch 66/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.2876 - acc: 0.9090 - val_loss: 0.2638 - val_acc: 0.8971\n",
      "Epoch 67/100\n",
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.2795 - acc: 0.9074 - val_loss: 0.2623 - val_acc: 0.9012\n",
      "Epoch 68/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.2843 - acc: 0.9059 - val_loss: 0.2630 - val_acc: 0.8971\n",
      "Epoch 69/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.2914 - acc: 0.9064 - val_loss: 0.2617 - val_acc: 0.8971\n",
      "Epoch 70/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.2835 - acc: 0.9069 - val_loss: 0.2619 - val_acc: 0.8971\n",
      "Epoch 71/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.2801 - acc: 0.9120 - val_loss: 0.2608 - val_acc: 0.8992\n",
      "Epoch 72/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.2747 - acc: 0.9141 - val_loss: 0.2603 - val_acc: 0.8992\n",
      "Epoch 73/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.2835 - acc: 0.9084 - val_loss: 0.2600 - val_acc: 0.8992\n",
      "Epoch 74/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.2785 - acc: 0.9033 - val_loss: 0.2598 - val_acc: 0.8971\n",
      "Epoch 75/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.2780 - acc: 0.9069 - val_loss: 0.2599 - val_acc: 0.8951\n",
      "Epoch 76/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.2821 - acc: 0.9079 - val_loss: 0.2592 - val_acc: 0.8951\n",
      "Epoch 77/100\n",
      "1944/1944 [==============================] - 1s 358us/step - loss: 0.2840 - acc: 0.9131 - val_loss: 0.2581 - val_acc: 0.8971\n",
      "Epoch 78/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.2786 - acc: 0.9095 - val_loss: 0.2576 - val_acc: 0.8971\n",
      "Epoch 79/100\n",
      "1944/1944 [==============================] - 1s 337us/step - loss: 0.2860 - acc: 0.9105 - val_loss: 0.2574 - val_acc: 0.8992\n",
      "Epoch 80/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.2745 - acc: 0.9100 - val_loss: 0.2572 - val_acc: 0.9012\n",
      "Epoch 81/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.2791 - acc: 0.9136 - val_loss: 0.2571 - val_acc: 0.8992\n",
      "Epoch 82/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.2727 - acc: 0.9146 - val_loss: 0.2566 - val_acc: 0.8992\n",
      "Epoch 83/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.2765 - acc: 0.9064 - val_loss: 0.2551 - val_acc: 0.8992\n",
      "Epoch 84/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.2823 - acc: 0.9115 - val_loss: 0.2569 - val_acc: 0.9053\n",
      "Epoch 85/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.2722 - acc: 0.9146 - val_loss: 0.2563 - val_acc: 0.9053\n",
      "Epoch 86/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.2742 - acc: 0.9131 - val_loss: 0.2549 - val_acc: 0.8971\n",
      "Epoch 87/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.2705 - acc: 0.9146 - val_loss: 0.2545 - val_acc: 0.9012\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.2759 - acc: 0.9095 - val_loss: 0.2539 - val_acc: 0.9033\n",
      "Epoch 89/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.2714 - acc: 0.9187 - val_loss: 0.2530 - val_acc: 0.9033\n",
      "Epoch 90/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.2727 - acc: 0.9172 - val_loss: 0.2535 - val_acc: 0.9095\n",
      "Epoch 91/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.2824 - acc: 0.9120 - val_loss: 0.2543 - val_acc: 0.9095\n",
      "Epoch 92/100\n",
      "1944/1944 [==============================] - 1s 375us/step - loss: 0.2680 - acc: 0.9167 - val_loss: 0.2521 - val_acc: 0.9033\n",
      "Epoch 93/100\n",
      "1944/1944 [==============================] - 1s 379us/step - loss: 0.2706 - acc: 0.9167 - val_loss: 0.2522 - val_acc: 0.9115\n",
      "Epoch 94/100\n",
      "1944/1944 [==============================] - 1s 367us/step - loss: 0.2690 - acc: 0.9115 - val_loss: 0.2528 - val_acc: 0.9136\n",
      "Epoch 95/100\n",
      "1944/1944 [==============================] - 1s 364us/step - loss: 0.2691 - acc: 0.9198 - val_loss: 0.2514 - val_acc: 0.9115\n",
      "Epoch 96/100\n",
      "1944/1944 [==============================] - 1s 362us/step - loss: 0.2695 - acc: 0.9105 - val_loss: 0.2508 - val_acc: 0.9095\n",
      "Epoch 97/100\n",
      "1944/1944 [==============================] - 1s 364us/step - loss: 0.2723 - acc: 0.9136 - val_loss: 0.2516 - val_acc: 0.9136\n",
      "Epoch 98/100\n",
      "1944/1944 [==============================] - 1s 360us/step - loss: 0.2729 - acc: 0.9208 - val_loss: 0.2501 - val_acc: 0.9115\n",
      "Epoch 99/100\n",
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.2678 - acc: 0.9156 - val_loss: 0.2486 - val_acc: 0.9012\n",
      "Epoch 100/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.2699 - acc: 0.9131 - val_loss: 0.2483 - val_acc: 0.9095\n",
      "Test subject 10, class BothStartLoadPhase\n",
      "Train subject 10, class LiftOff\n",
      "Train on 1944 samples, validate on 486 samples\n",
      "Epoch 1/100\n",
      "1944/1944 [==============================] - 2s 774us/step - loss: 0.6951 - acc: 0.4907 - val_loss: 0.6952 - val_acc: 0.4835\n",
      "Epoch 2/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.6960 - acc: 0.4666 - val_loss: 0.6949 - val_acc: 0.4877\n",
      "Epoch 3/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.6948 - acc: 0.4959 - val_loss: 0.6947 - val_acc: 0.4918\n",
      "Epoch 4/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.6953 - acc: 0.4799 - val_loss: 0.6944 - val_acc: 0.5021\n",
      "Epoch 5/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.6942 - acc: 0.4928 - val_loss: 0.6942 - val_acc: 0.5041\n",
      "Epoch 6/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.6942 - acc: 0.4805 - val_loss: 0.6940 - val_acc: 0.5062\n",
      "Epoch 7/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.6950 - acc: 0.4805 - val_loss: 0.6937 - val_acc: 0.5103\n",
      "Epoch 8/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.6932 - acc: 0.5021 - val_loss: 0.6935 - val_acc: 0.5103\n",
      "Epoch 9/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.6942 - acc: 0.4835 - val_loss: 0.6933 - val_acc: 0.5062\n",
      "Epoch 10/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.6936 - acc: 0.5046 - val_loss: 0.6930 - val_acc: 0.5062\n",
      "Epoch 11/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.6922 - acc: 0.4949 - val_loss: 0.6928 - val_acc: 0.5082\n",
      "Epoch 12/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.6925 - acc: 0.5041 - val_loss: 0.6926 - val_acc: 0.5103\n",
      "Epoch 13/100\n",
      "1944/1944 [==============================] - 1s 366us/step - loss: 0.6929 - acc: 0.5190 - val_loss: 0.6924 - val_acc: 0.5021\n",
      "Epoch 14/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.6923 - acc: 0.5206 - val_loss: 0.6922 - val_acc: 0.5082\n",
      "Epoch 15/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.6924 - acc: 0.5123 - val_loss: 0.6919 - val_acc: 0.5144\n",
      "Epoch 16/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.6934 - acc: 0.4871 - val_loss: 0.6917 - val_acc: 0.5185\n",
      "Epoch 17/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.6917 - acc: 0.5201 - val_loss: 0.6915 - val_acc: 0.5288\n",
      "Epoch 18/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.6925 - acc: 0.4995 - val_loss: 0.6912 - val_acc: 0.5453\n",
      "Epoch 19/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.6908 - acc: 0.5278 - val_loss: 0.6910 - val_acc: 0.5535\n",
      "Epoch 20/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.6907 - acc: 0.5360 - val_loss: 0.6907 - val_acc: 0.5535\n",
      "Epoch 21/100\n",
      "1944/1944 [==============================] - 1s 366us/step - loss: 0.6902 - acc: 0.5334 - val_loss: 0.6905 - val_acc: 0.5638\n",
      "Epoch 22/100\n",
      "1944/1944 [==============================] - 1s 358us/step - loss: 0.6900 - acc: 0.5298 - val_loss: 0.6902 - val_acc: 0.5638\n",
      "Epoch 23/100\n",
      "1944/1944 [==============================] - 1s 366us/step - loss: 0.6912 - acc: 0.5489 - val_loss: 0.6899 - val_acc: 0.5658\n",
      "Epoch 24/100\n",
      "1944/1944 [==============================] - 1s 363us/step - loss: 0.6908 - acc: 0.5381 - val_loss: 0.6897 - val_acc: 0.5658\n",
      "Epoch 25/100\n",
      "1944/1944 [==============================] - 1s 359us/step - loss: 0.6904 - acc: 0.5329 - val_loss: 0.6894 - val_acc: 0.5761\n",
      "Epoch 26/100\n",
      "1944/1944 [==============================] - 1s 363us/step - loss: 0.6906 - acc: 0.5381 - val_loss: 0.6892 - val_acc: 0.5761\n",
      "Epoch 27/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.6900 - acc: 0.5381 - val_loss: 0.6889 - val_acc: 0.5885\n",
      "Epoch 28/100\n",
      "1944/1944 [==============================] - 1s 364us/step - loss: 0.6908 - acc: 0.5298 - val_loss: 0.6886 - val_acc: 0.5905\n",
      "Epoch 29/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.6891 - acc: 0.5360 - val_loss: 0.6884 - val_acc: 0.5926\n",
      "Epoch 30/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.6889 - acc: 0.5566 - val_loss: 0.6881 - val_acc: 0.5967\n",
      "Epoch 31/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.6890 - acc: 0.5628 - val_loss: 0.6878 - val_acc: 0.6029\n",
      "Epoch 32/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.6884 - acc: 0.5653 - val_loss: 0.6875 - val_acc: 0.6008\n",
      "Epoch 33/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.6884 - acc: 0.5509 - val_loss: 0.6872 - val_acc: 0.6049\n",
      "Epoch 34/100\n",
      "1944/1944 [==============================] - 1s 336us/step - loss: 0.6881 - acc: 0.5612 - val_loss: 0.6868 - val_acc: 0.6111\n",
      "Epoch 35/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.6879 - acc: 0.5730 - val_loss: 0.6865 - val_acc: 0.6132\n",
      "Epoch 36/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.6870 - acc: 0.5653 - val_loss: 0.6862 - val_acc: 0.6132\n",
      "Epoch 37/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.6874 - acc: 0.5633 - val_loss: 0.6858 - val_acc: 0.6193\n",
      "Epoch 38/100\n",
      "1944/1944 [==============================] - 1s 337us/step - loss: 0.6879 - acc: 0.5592 - val_loss: 0.6855 - val_acc: 0.6193\n",
      "Epoch 39/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.6875 - acc: 0.5607 - val_loss: 0.6851 - val_acc: 0.6276\n",
      "Epoch 40/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.6859 - acc: 0.5736 - val_loss: 0.6847 - val_acc: 0.6214\n",
      "Epoch 41/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.6852 - acc: 0.5777 - val_loss: 0.6843 - val_acc: 0.6235\n",
      "Epoch 42/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.6846 - acc: 0.5910 - val_loss: 0.6839 - val_acc: 0.6235\n",
      "Epoch 43/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.6856 - acc: 0.5766 - val_loss: 0.6835 - val_acc: 0.6235\n",
      "Epoch 44/100\n",
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.6857 - acc: 0.5679 - val_loss: 0.6831 - val_acc: 0.6193\n",
      "Epoch 45/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.6854 - acc: 0.5921 - val_loss: 0.6826 - val_acc: 0.6193\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.6839 - acc: 0.5957 - val_loss: 0.6822 - val_acc: 0.6255\n",
      "Epoch 47/100\n",
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.6834 - acc: 0.6044 - val_loss: 0.6817 - val_acc: 0.6296\n",
      "Epoch 48/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.6849 - acc: 0.5900 - val_loss: 0.6812 - val_acc: 0.6317\n",
      "Epoch 49/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.6840 - acc: 0.5998 - val_loss: 0.6807 - val_acc: 0.6337\n",
      "Epoch 50/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.6814 - acc: 0.6065 - val_loss: 0.6802 - val_acc: 0.6337\n",
      "Epoch 51/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.6810 - acc: 0.6121 - val_loss: 0.6796 - val_acc: 0.6358\n",
      "Epoch 52/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.6810 - acc: 0.6116 - val_loss: 0.6790 - val_acc: 0.6379\n",
      "Epoch 53/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.6804 - acc: 0.6013 - val_loss: 0.6784 - val_acc: 0.6379\n",
      "Epoch 54/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.6794 - acc: 0.6296 - val_loss: 0.6778 - val_acc: 0.6399\n",
      "Epoch 55/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.6797 - acc: 0.6168 - val_loss: 0.6771 - val_acc: 0.6440\n",
      "Epoch 56/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.6798 - acc: 0.6152 - val_loss: 0.6765 - val_acc: 0.6440\n",
      "Epoch 57/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.6787 - acc: 0.6291 - val_loss: 0.6758 - val_acc: 0.6440\n",
      "Epoch 58/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.6770 - acc: 0.6219 - val_loss: 0.6751 - val_acc: 0.6440\n",
      "Epoch 59/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.6780 - acc: 0.6193 - val_loss: 0.6743 - val_acc: 0.6461\n",
      "Epoch 60/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.6759 - acc: 0.6363 - val_loss: 0.6736 - val_acc: 0.6461\n",
      "Epoch 61/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.6747 - acc: 0.6291 - val_loss: 0.6727 - val_acc: 0.6440\n",
      "Epoch 62/100\n",
      "1944/1944 [==============================] - 1s 360us/step - loss: 0.6744 - acc: 0.6543 - val_loss: 0.6719 - val_acc: 0.6440\n",
      "Epoch 63/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.6726 - acc: 0.6445 - val_loss: 0.6710 - val_acc: 0.6420\n",
      "Epoch 64/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.6712 - acc: 0.6440 - val_loss: 0.6700 - val_acc: 0.6420\n",
      "Epoch 65/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.6710 - acc: 0.6487 - val_loss: 0.6691 - val_acc: 0.6420\n",
      "Epoch 66/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.6686 - acc: 0.6605 - val_loss: 0.6680 - val_acc: 0.6502\n",
      "Epoch 67/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.6698 - acc: 0.6435 - val_loss: 0.6669 - val_acc: 0.6523\n",
      "Epoch 68/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.6679 - acc: 0.6574 - val_loss: 0.6658 - val_acc: 0.6605\n",
      "Epoch 69/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.6661 - acc: 0.6708 - val_loss: 0.6646 - val_acc: 0.6605\n",
      "Epoch 70/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.6652 - acc: 0.6600 - val_loss: 0.6633 - val_acc: 0.6626\n",
      "Epoch 71/100\n",
      "1944/1944 [==============================] - 1s 337us/step - loss: 0.6648 - acc: 0.6523 - val_loss: 0.6621 - val_acc: 0.6667\n",
      "Epoch 72/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.6629 - acc: 0.6590 - val_loss: 0.6607 - val_acc: 0.6646\n",
      "Epoch 73/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.6624 - acc: 0.6595 - val_loss: 0.6594 - val_acc: 0.6646\n",
      "Epoch 74/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.6599 - acc: 0.6559 - val_loss: 0.6579 - val_acc: 0.6667\n",
      "Epoch 75/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.6568 - acc: 0.6718 - val_loss: 0.6563 - val_acc: 0.6646\n",
      "Epoch 76/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.6567 - acc: 0.6749 - val_loss: 0.6546 - val_acc: 0.6687\n",
      "Epoch 77/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.6563 - acc: 0.6677 - val_loss: 0.6529 - val_acc: 0.6770\n",
      "Epoch 78/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.6523 - acc: 0.6759 - val_loss: 0.6510 - val_acc: 0.6749\n",
      "Epoch 79/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.6515 - acc: 0.6734 - val_loss: 0.6492 - val_acc: 0.6749\n",
      "Epoch 80/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.6482 - acc: 0.6754 - val_loss: 0.6471 - val_acc: 0.6770\n",
      "Epoch 81/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.6465 - acc: 0.6780 - val_loss: 0.6450 - val_acc: 0.6728\n",
      "Epoch 82/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.6438 - acc: 0.6785 - val_loss: 0.6427 - val_acc: 0.6728\n",
      "Epoch 83/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.6414 - acc: 0.6836 - val_loss: 0.6403 - val_acc: 0.6790\n",
      "Epoch 84/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.6382 - acc: 0.6847 - val_loss: 0.6379 - val_acc: 0.6790\n",
      "Epoch 85/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.6350 - acc: 0.6970 - val_loss: 0.6353 - val_acc: 0.6893\n",
      "Epoch 86/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.6344 - acc: 0.6919 - val_loss: 0.6326 - val_acc: 0.6872\n",
      "Epoch 87/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.6307 - acc: 0.7006 - val_loss: 0.6298 - val_acc: 0.6893\n",
      "Epoch 88/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.6251 - acc: 0.7088 - val_loss: 0.6269 - val_acc: 0.6914\n",
      "Epoch 89/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.6266 - acc: 0.6929 - val_loss: 0.6237 - val_acc: 0.6914\n",
      "Epoch 90/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.6182 - acc: 0.7058 - val_loss: 0.6204 - val_acc: 0.6872\n",
      "Epoch 91/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.6152 - acc: 0.7094 - val_loss: 0.6168 - val_acc: 0.6955\n",
      "Epoch 92/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.6113 - acc: 0.7145 - val_loss: 0.6131 - val_acc: 0.6975\n",
      "Epoch 93/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.6092 - acc: 0.7114 - val_loss: 0.6092 - val_acc: 0.7016\n",
      "Epoch 94/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.6035 - acc: 0.7284 - val_loss: 0.6052 - val_acc: 0.7037\n",
      "Epoch 95/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.6021 - acc: 0.7068 - val_loss: 0.6009 - val_acc: 0.7016\n",
      "Epoch 96/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.5965 - acc: 0.7083 - val_loss: 0.5965 - val_acc: 0.7058\n",
      "Epoch 97/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.5859 - acc: 0.7371 - val_loss: 0.5918 - val_acc: 0.7058\n",
      "Epoch 98/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.5807 - acc: 0.7371 - val_loss: 0.5870 - val_acc: 0.7058\n",
      "Epoch 99/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.5736 - acc: 0.7479 - val_loss: 0.5817 - val_acc: 0.7140\n",
      "Epoch 100/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.5707 - acc: 0.7423 - val_loss: 0.5766 - val_acc: 0.7160\n",
      "Train on 1944 samples, validate on 486 samples\n",
      "Epoch 1/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.5673 - acc: 0.7361 - val_loss: 0.5692 - val_acc: 0.7263\n",
      "Epoch 2/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.5583 - acc: 0.7562 - val_loss: 0.5634 - val_acc: 0.7325\n",
      "Epoch 3/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.5550 - acc: 0.7474 - val_loss: 0.5574 - val_acc: 0.7305\n",
      "Epoch 4/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.5470 - acc: 0.7515 - val_loss: 0.5512 - val_acc: 0.7366\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.5413 - acc: 0.7474 - val_loss: 0.5448 - val_acc: 0.7428\n",
      "Epoch 6/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.5377 - acc: 0.7469 - val_loss: 0.5383 - val_acc: 0.7449\n",
      "Epoch 7/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.5292 - acc: 0.7541 - val_loss: 0.5318 - val_acc: 0.7407\n",
      "Epoch 8/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.5217 - acc: 0.7608 - val_loss: 0.5248 - val_acc: 0.7469\n",
      "Epoch 9/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.5078 - acc: 0.7737 - val_loss: 0.5182 - val_acc: 0.7428\n",
      "Epoch 10/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.5013 - acc: 0.7783 - val_loss: 0.5112 - val_acc: 0.7490\n",
      "Epoch 11/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.4982 - acc: 0.7809 - val_loss: 0.5049 - val_acc: 0.7490\n",
      "Epoch 12/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.4850 - acc: 0.7881 - val_loss: 0.4980 - val_acc: 0.7551\n",
      "Epoch 13/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.4781 - acc: 0.7948 - val_loss: 0.4917 - val_acc: 0.7716\n",
      "Epoch 14/100\n",
      "1944/1944 [==============================] - 1s 356us/step - loss: 0.4786 - acc: 0.7906 - val_loss: 0.4855 - val_acc: 0.7942\n",
      "Epoch 15/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.4691 - acc: 0.8025 - val_loss: 0.4792 - val_acc: 0.7963\n",
      "Epoch 16/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.4617 - acc: 0.8035 - val_loss: 0.4739 - val_acc: 0.8004\n",
      "Epoch 17/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.4507 - acc: 0.8081 - val_loss: 0.4673 - val_acc: 0.8045\n",
      "Epoch 18/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.4485 - acc: 0.8112 - val_loss: 0.4620 - val_acc: 0.8066\n",
      "Epoch 19/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.4362 - acc: 0.8122 - val_loss: 0.4567 - val_acc: 0.8128\n",
      "Epoch 20/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.4361 - acc: 0.8210 - val_loss: 0.4515 - val_acc: 0.8148\n",
      "Epoch 21/100\n",
      "1944/1944 [==============================] - 1s 362us/step - loss: 0.4279 - acc: 0.8215 - val_loss: 0.4473 - val_acc: 0.8148\n",
      "Epoch 22/100\n",
      "1944/1944 [==============================] - 1s 378us/step - loss: 0.4321 - acc: 0.8200 - val_loss: 0.4416 - val_acc: 0.8210\n",
      "Epoch 23/100\n",
      "1944/1944 [==============================] - 1s 374us/step - loss: 0.4211 - acc: 0.8220 - val_loss: 0.4377 - val_acc: 0.8189\n",
      "Epoch 24/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.4152 - acc: 0.8292 - val_loss: 0.4347 - val_acc: 0.8148\n",
      "Epoch 25/100\n",
      "1944/1944 [==============================] - 1s 363us/step - loss: 0.4092 - acc: 0.8272 - val_loss: 0.4300 - val_acc: 0.8189\n",
      "Epoch 26/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.4049 - acc: 0.8287 - val_loss: 0.4273 - val_acc: 0.8148\n",
      "Epoch 27/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.4047 - acc: 0.8282 - val_loss: 0.4227 - val_acc: 0.8189\n",
      "Epoch 28/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.3985 - acc: 0.8359 - val_loss: 0.4196 - val_acc: 0.8189\n",
      "Epoch 29/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.4016 - acc: 0.8338 - val_loss: 0.4159 - val_acc: 0.8210\n",
      "Epoch 30/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.3912 - acc: 0.8385 - val_loss: 0.4131 - val_acc: 0.8189\n",
      "Epoch 31/100\n",
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.3815 - acc: 0.8400 - val_loss: 0.4094 - val_acc: 0.8272\n",
      "Epoch 32/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.3862 - acc: 0.8338 - val_loss: 0.4072 - val_acc: 0.8230\n",
      "Epoch 33/100\n",
      "1944/1944 [==============================] - 1s 360us/step - loss: 0.3870 - acc: 0.8452 - val_loss: 0.4054 - val_acc: 0.8210\n",
      "Epoch 34/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.3854 - acc: 0.8421 - val_loss: 0.4017 - val_acc: 0.8230\n",
      "Epoch 35/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.3758 - acc: 0.8395 - val_loss: 0.3989 - val_acc: 0.8251\n",
      "Epoch 36/100\n",
      "1944/1944 [==============================] - 1s 358us/step - loss: 0.3773 - acc: 0.8421 - val_loss: 0.3975 - val_acc: 0.8313\n",
      "Epoch 37/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.3712 - acc: 0.8467 - val_loss: 0.3939 - val_acc: 0.8333\n",
      "Epoch 38/100\n",
      "1944/1944 [==============================] - 1s 361us/step - loss: 0.3684 - acc: 0.8493 - val_loss: 0.3905 - val_acc: 0.8354\n",
      "Epoch 39/100\n",
      "1944/1944 [==============================] - 1s 421us/step - loss: 0.3655 - acc: 0.8452 - val_loss: 0.3893 - val_acc: 0.8374\n",
      "Epoch 40/100\n",
      "1944/1944 [==============================] - 1s 398us/step - loss: 0.3664 - acc: 0.8452 - val_loss: 0.3869 - val_acc: 0.8374\n",
      "Epoch 41/100\n",
      "1944/1944 [==============================] - 1s 361us/step - loss: 0.3639 - acc: 0.8462 - val_loss: 0.3839 - val_acc: 0.8436\n",
      "Epoch 42/100\n",
      "1944/1944 [==============================] - 1s 367us/step - loss: 0.3578 - acc: 0.8467 - val_loss: 0.3823 - val_acc: 0.8477\n",
      "Epoch 43/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.3652 - acc: 0.8513 - val_loss: 0.3834 - val_acc: 0.8436\n",
      "Epoch 44/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.3523 - acc: 0.8596 - val_loss: 0.3767 - val_acc: 0.8539\n",
      "Epoch 45/100\n",
      "1944/1944 [==============================] - 1s 359us/step - loss: 0.3571 - acc: 0.8519 - val_loss: 0.3763 - val_acc: 0.8498\n",
      "Epoch 46/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.3511 - acc: 0.8596 - val_loss: 0.3728 - val_acc: 0.8539\n",
      "Epoch 47/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.3517 - acc: 0.8508 - val_loss: 0.3699 - val_acc: 0.8539\n",
      "Epoch 48/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.3431 - acc: 0.8529 - val_loss: 0.3689 - val_acc: 0.8539\n",
      "Epoch 49/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.3375 - acc: 0.8663 - val_loss: 0.3663 - val_acc: 0.8560\n",
      "Epoch 50/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.3342 - acc: 0.8688 - val_loss: 0.3632 - val_acc: 0.8560\n",
      "Epoch 51/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.3356 - acc: 0.8678 - val_loss: 0.3626 - val_acc: 0.8560\n",
      "Epoch 52/100\n",
      "1944/1944 [==============================] - 1s 364us/step - loss: 0.3406 - acc: 0.8601 - val_loss: 0.3624 - val_acc: 0.8539\n",
      "Epoch 53/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.3423 - acc: 0.8580 - val_loss: 0.3579 - val_acc: 0.8580\n",
      "Epoch 54/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.3375 - acc: 0.8570 - val_loss: 0.3565 - val_acc: 0.8580\n",
      "Epoch 55/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.3327 - acc: 0.8642 - val_loss: 0.3561 - val_acc: 0.8580\n",
      "Epoch 56/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.3296 - acc: 0.8709 - val_loss: 0.3539 - val_acc: 0.8580\n",
      "Epoch 57/100\n",
      "1944/1944 [==============================] - 1s 360us/step - loss: 0.3370 - acc: 0.8663 - val_loss: 0.3514 - val_acc: 0.8560\n",
      "Epoch 58/100\n",
      "1944/1944 [==============================] - 1s 356us/step - loss: 0.3279 - acc: 0.8668 - val_loss: 0.3509 - val_acc: 0.8560\n",
      "Epoch 59/100\n",
      "1944/1944 [==============================] - 1s 360us/step - loss: 0.3232 - acc: 0.8678 - val_loss: 0.3507 - val_acc: 0.8560\n",
      "Epoch 60/100\n",
      "1944/1944 [==============================] - 1s 370us/step - loss: 0.3228 - acc: 0.8652 - val_loss: 0.3466 - val_acc: 0.8601\n",
      "Epoch 61/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.3213 - acc: 0.8724 - val_loss: 0.3441 - val_acc: 0.8621\n",
      "Epoch 62/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.3289 - acc: 0.8642 - val_loss: 0.3422 - val_acc: 0.8621\n",
      "Epoch 63/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.3194 - acc: 0.8729 - val_loss: 0.3434 - val_acc: 0.8642\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.3195 - acc: 0.8729 - val_loss: 0.3386 - val_acc: 0.8601\n",
      "Epoch 65/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.3171 - acc: 0.8745 - val_loss: 0.3390 - val_acc: 0.8663\n",
      "Epoch 66/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.3254 - acc: 0.8740 - val_loss: 0.3386 - val_acc: 0.8642\n",
      "Epoch 67/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.3125 - acc: 0.8776 - val_loss: 0.3370 - val_acc: 0.8663\n",
      "Epoch 68/100\n",
      "1944/1944 [==============================] - 1s 362us/step - loss: 0.3144 - acc: 0.8704 - val_loss: 0.3333 - val_acc: 0.8621\n",
      "Epoch 69/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.3129 - acc: 0.8765 - val_loss: 0.3322 - val_acc: 0.8621\n",
      "Epoch 70/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.3177 - acc: 0.8735 - val_loss: 0.3329 - val_acc: 0.8663\n",
      "Epoch 71/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.3113 - acc: 0.8786 - val_loss: 0.3291 - val_acc: 0.8642\n",
      "Epoch 72/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.3018 - acc: 0.8853 - val_loss: 0.3299 - val_acc: 0.8683\n",
      "Epoch 73/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.2995 - acc: 0.8807 - val_loss: 0.3274 - val_acc: 0.8663\n",
      "Epoch 74/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.3052 - acc: 0.8760 - val_loss: 0.3301 - val_acc: 0.8724\n",
      "Epoch 75/100\n",
      "1944/1944 [==============================] - 1s 380us/step - loss: 0.3088 - acc: 0.8801 - val_loss: 0.3270 - val_acc: 0.8724\n",
      "Epoch 76/100\n",
      "1944/1944 [==============================] - 1s 361us/step - loss: 0.3082 - acc: 0.8822 - val_loss: 0.3262 - val_acc: 0.8724\n",
      "Epoch 77/100\n",
      "1944/1944 [==============================] - 1s 356us/step - loss: 0.3053 - acc: 0.8807 - val_loss: 0.3249 - val_acc: 0.8724\n",
      "Epoch 78/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.3010 - acc: 0.8812 - val_loss: 0.3242 - val_acc: 0.8724\n",
      "Epoch 79/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.3009 - acc: 0.8801 - val_loss: 0.3207 - val_acc: 0.8745\n",
      "Epoch 80/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.3092 - acc: 0.8812 - val_loss: 0.3201 - val_acc: 0.8765\n",
      "Epoch 81/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.2959 - acc: 0.8873 - val_loss: 0.3191 - val_acc: 0.8765\n",
      "Epoch 82/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.2958 - acc: 0.8858 - val_loss: 0.3201 - val_acc: 0.8765\n",
      "Epoch 83/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.3057 - acc: 0.8786 - val_loss: 0.3175 - val_acc: 0.8786\n",
      "Epoch 84/100\n",
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.2949 - acc: 0.8884 - val_loss: 0.3170 - val_acc: 0.8765\n",
      "Epoch 85/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.2981 - acc: 0.8858 - val_loss: 0.3154 - val_acc: 0.8807\n",
      "Epoch 86/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.2947 - acc: 0.8822 - val_loss: 0.3182 - val_acc: 0.8786\n",
      "Epoch 87/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.2885 - acc: 0.8899 - val_loss: 0.3162 - val_acc: 0.8765\n",
      "Epoch 88/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.2931 - acc: 0.8884 - val_loss: 0.3139 - val_acc: 0.8786\n",
      "Epoch 89/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.2997 - acc: 0.8827 - val_loss: 0.3130 - val_acc: 0.8786\n",
      "Epoch 90/100\n",
      "1944/1944 [==============================] - 1s 358us/step - loss: 0.2847 - acc: 0.8945 - val_loss: 0.3098 - val_acc: 0.8827\n",
      "Epoch 91/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.2917 - acc: 0.8904 - val_loss: 0.3117 - val_acc: 0.8827\n",
      "Epoch 92/100\n",
      "1944/1944 [==============================] - 1s 359us/step - loss: 0.2897 - acc: 0.8915 - val_loss: 0.3089 - val_acc: 0.8807\n",
      "Epoch 93/100\n",
      "1944/1944 [==============================] - 1s 375us/step - loss: 0.2866 - acc: 0.8945 - val_loss: 0.3107 - val_acc: 0.8827\n",
      "Epoch 94/100\n",
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.2813 - acc: 0.8925 - val_loss: 0.3117 - val_acc: 0.8807\n",
      "Epoch 95/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.2919 - acc: 0.8873 - val_loss: 0.3097 - val_acc: 0.8827\n",
      "Epoch 96/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.2800 - acc: 0.8940 - val_loss: 0.3061 - val_acc: 0.8848\n",
      "Epoch 97/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.2918 - acc: 0.8935 - val_loss: 0.3048 - val_acc: 0.8848\n",
      "Epoch 98/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.2863 - acc: 0.8945 - val_loss: 0.3051 - val_acc: 0.8848\n",
      "Epoch 99/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.2815 - acc: 0.8981 - val_loss: 0.3068 - val_acc: 0.8827\n",
      "Epoch 100/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.2828 - acc: 0.8935 - val_loss: 0.3049 - val_acc: 0.8848\n",
      "Test subject 10, class LiftOff\n",
      "Train subject 10, class Replace\n",
      "Train on 1944 samples, validate on 486 samples\n",
      "Epoch 1/100\n",
      "1944/1944 [==============================] - 2s 821us/step - loss: 0.6936 - acc: 0.5026 - val_loss: 0.6905 - val_acc: 0.5391\n",
      "Epoch 2/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.6917 - acc: 0.5247 - val_loss: 0.6903 - val_acc: 0.5370\n",
      "Epoch 3/100\n",
      "1944/1944 [==============================] - 1s 373us/step - loss: 0.6927 - acc: 0.5000 - val_loss: 0.6900 - val_acc: 0.5391\n",
      "Epoch 4/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.6919 - acc: 0.5144 - val_loss: 0.6898 - val_acc: 0.5473\n",
      "Epoch 5/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.6921 - acc: 0.5175 - val_loss: 0.6896 - val_acc: 0.5576\n",
      "Epoch 6/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.6914 - acc: 0.5216 - val_loss: 0.6893 - val_acc: 0.5576\n",
      "Epoch 7/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.6929 - acc: 0.5082 - val_loss: 0.6890 - val_acc: 0.5720\n",
      "Epoch 8/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.6918 - acc: 0.5201 - val_loss: 0.6887 - val_acc: 0.5988\n",
      "Epoch 9/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.6897 - acc: 0.5386 - val_loss: 0.6883 - val_acc: 0.6070\n",
      "Epoch 10/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.6900 - acc: 0.5437 - val_loss: 0.6880 - val_acc: 0.6111\n",
      "Epoch 11/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.6904 - acc: 0.5396 - val_loss: 0.6876 - val_acc: 0.6070\n",
      "Epoch 12/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.6898 - acc: 0.5396 - val_loss: 0.6873 - val_acc: 0.6111\n",
      "Epoch 13/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.6898 - acc: 0.5458 - val_loss: 0.6869 - val_acc: 0.6152\n",
      "Epoch 14/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.6894 - acc: 0.5602 - val_loss: 0.6866 - val_acc: 0.6132\n",
      "Epoch 15/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.6905 - acc: 0.5365 - val_loss: 0.6862 - val_acc: 0.6173\n",
      "Epoch 16/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.6894 - acc: 0.5345 - val_loss: 0.6858 - val_acc: 0.6173\n",
      "Epoch 17/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.6885 - acc: 0.5540 - val_loss: 0.6854 - val_acc: 0.6193\n",
      "Epoch 18/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.6890 - acc: 0.5586 - val_loss: 0.6850 - val_acc: 0.6337\n",
      "Epoch 19/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.6881 - acc: 0.5561 - val_loss: 0.6845 - val_acc: 0.6399\n",
      "Epoch 20/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.6879 - acc: 0.5473 - val_loss: 0.6840 - val_acc: 0.6420\n",
      "Epoch 21/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.6889 - acc: 0.5463 - val_loss: 0.6835 - val_acc: 0.6481\n",
      "Epoch 22/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.6875 - acc: 0.5417 - val_loss: 0.6830 - val_acc: 0.6481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100\n",
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.6869 - acc: 0.5705 - val_loss: 0.6824 - val_acc: 0.6440\n",
      "Epoch 24/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.6876 - acc: 0.5566 - val_loss: 0.6820 - val_acc: 0.6502\n",
      "Epoch 25/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.6863 - acc: 0.5710 - val_loss: 0.6813 - val_acc: 0.6626\n",
      "Epoch 26/100\n",
      "1944/1944 [==============================] - 1s 358us/step - loss: 0.6873 - acc: 0.5638 - val_loss: 0.6808 - val_acc: 0.6564\n",
      "Epoch 27/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.6847 - acc: 0.5694 - val_loss: 0.6802 - val_acc: 0.6543\n",
      "Epoch 28/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.6849 - acc: 0.5838 - val_loss: 0.6795 - val_acc: 0.6584\n",
      "Epoch 29/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.6849 - acc: 0.5880 - val_loss: 0.6787 - val_acc: 0.6687\n",
      "Epoch 30/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.6835 - acc: 0.5972 - val_loss: 0.6779 - val_acc: 0.6749\n",
      "Epoch 31/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.6827 - acc: 0.5926 - val_loss: 0.6771 - val_acc: 0.6728\n",
      "Epoch 32/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.6839 - acc: 0.5859 - val_loss: 0.6763 - val_acc: 0.6728\n",
      "Epoch 33/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.6826 - acc: 0.5880 - val_loss: 0.6754 - val_acc: 0.6749\n",
      "Epoch 34/100\n",
      "1944/1944 [==============================] - 1s 359us/step - loss: 0.6829 - acc: 0.5859 - val_loss: 0.6745 - val_acc: 0.6831\n",
      "Epoch 35/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.6825 - acc: 0.5947 - val_loss: 0.6736 - val_acc: 0.6852\n",
      "Epoch 36/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.6810 - acc: 0.5967 - val_loss: 0.6725 - val_acc: 0.6831\n",
      "Epoch 37/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.6798 - acc: 0.6142 - val_loss: 0.6715 - val_acc: 0.6790\n",
      "Epoch 38/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.6810 - acc: 0.5952 - val_loss: 0.6703 - val_acc: 0.6811\n",
      "Epoch 39/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.6767 - acc: 0.6240 - val_loss: 0.6691 - val_acc: 0.6811\n",
      "Epoch 40/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.6770 - acc: 0.6420 - val_loss: 0.6679 - val_acc: 0.6770\n",
      "Epoch 41/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.6748 - acc: 0.6348 - val_loss: 0.6664 - val_acc: 0.6831\n",
      "Epoch 42/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.6756 - acc: 0.6373 - val_loss: 0.6651 - val_acc: 0.6914\n",
      "Epoch 43/100\n",
      "1944/1944 [==============================] - 1s 359us/step - loss: 0.6740 - acc: 0.6363 - val_loss: 0.6636 - val_acc: 0.6914\n",
      "Epoch 44/100\n",
      "1944/1944 [==============================] - 1s 359us/step - loss: 0.6733 - acc: 0.6322 - val_loss: 0.6619 - val_acc: 0.6893\n",
      "Epoch 45/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.6728 - acc: 0.6389 - val_loss: 0.6603 - val_acc: 0.6914\n",
      "Epoch 46/100\n",
      "1944/1944 [==============================] - 1s 365us/step - loss: 0.6708 - acc: 0.6548 - val_loss: 0.6585 - val_acc: 0.6955\n",
      "Epoch 47/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.6713 - acc: 0.6399 - val_loss: 0.6566 - val_acc: 0.6975\n",
      "Epoch 48/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.6675 - acc: 0.6600 - val_loss: 0.6546 - val_acc: 0.6996\n",
      "Epoch 49/100\n",
      "1944/1944 [==============================] - 1s 365us/step - loss: 0.6668 - acc: 0.6512 - val_loss: 0.6527 - val_acc: 0.6996\n",
      "Epoch 50/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.6661 - acc: 0.6605 - val_loss: 0.6506 - val_acc: 0.7016\n",
      "Epoch 51/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.6638 - acc: 0.6641 - val_loss: 0.6484 - val_acc: 0.7058\n",
      "Epoch 52/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.6596 - acc: 0.6713 - val_loss: 0.6460 - val_acc: 0.7058\n",
      "Epoch 53/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.6587 - acc: 0.6698 - val_loss: 0.6434 - val_acc: 0.7058\n",
      "Epoch 54/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.6577 - acc: 0.6662 - val_loss: 0.6407 - val_acc: 0.7058\n",
      "Epoch 55/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.6540 - acc: 0.6816 - val_loss: 0.6379 - val_acc: 0.7099\n",
      "Epoch 56/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.6538 - acc: 0.6821 - val_loss: 0.6351 - val_acc: 0.7181\n",
      "Epoch 57/100\n",
      "1944/1944 [==============================] - 1s 365us/step - loss: 0.6509 - acc: 0.6806 - val_loss: 0.6323 - val_acc: 0.7263\n",
      "Epoch 58/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.6473 - acc: 0.6914 - val_loss: 0.6286 - val_acc: 0.7263\n",
      "Epoch 59/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.6444 - acc: 0.6970 - val_loss: 0.6254 - val_acc: 0.7346\n",
      "Epoch 60/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.6429 - acc: 0.6898 - val_loss: 0.6222 - val_acc: 0.7387\n",
      "Epoch 61/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.6425 - acc: 0.6857 - val_loss: 0.6183 - val_acc: 0.7407\n",
      "Epoch 62/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.6364 - acc: 0.6944 - val_loss: 0.6152 - val_acc: 0.7284\n",
      "Epoch 63/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.6332 - acc: 0.6955 - val_loss: 0.6109 - val_acc: 0.7284\n",
      "Epoch 64/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.6300 - acc: 0.7032 - val_loss: 0.6069 - val_acc: 0.7284\n",
      "Epoch 65/100\n",
      "1944/1944 [==============================] - 1s 363us/step - loss: 0.6260 - acc: 0.7099 - val_loss: 0.6030 - val_acc: 0.7284\n",
      "Epoch 66/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.6196 - acc: 0.6980 - val_loss: 0.5975 - val_acc: 0.7346\n",
      "Epoch 67/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.6179 - acc: 0.7052 - val_loss: 0.5928 - val_acc: 0.7346\n",
      "Epoch 68/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.6135 - acc: 0.7124 - val_loss: 0.5895 - val_acc: 0.7263\n",
      "Epoch 69/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.6118 - acc: 0.7130 - val_loss: 0.5832 - val_acc: 0.7387\n",
      "Epoch 70/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.6053 - acc: 0.7135 - val_loss: 0.5795 - val_acc: 0.7346\n",
      "Epoch 71/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.6012 - acc: 0.7212 - val_loss: 0.5735 - val_acc: 0.7387\n",
      "Epoch 72/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.5963 - acc: 0.7263 - val_loss: 0.5683 - val_acc: 0.7387\n",
      "Epoch 73/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.5937 - acc: 0.7207 - val_loss: 0.5649 - val_acc: 0.7490\n",
      "Epoch 74/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.5851 - acc: 0.7305 - val_loss: 0.5595 - val_acc: 0.7531\n",
      "Epoch 75/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.5792 - acc: 0.7320 - val_loss: 0.5542 - val_acc: 0.7551\n",
      "Epoch 76/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.5749 - acc: 0.7284 - val_loss: 0.5493 - val_acc: 0.7613\n",
      "Epoch 77/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.5727 - acc: 0.7227 - val_loss: 0.5445 - val_acc: 0.7675\n",
      "Epoch 78/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.5676 - acc: 0.7371 - val_loss: 0.5367 - val_acc: 0.7551\n",
      "Epoch 79/100\n",
      "1944/1944 [==============================] - 1s 361us/step - loss: 0.5575 - acc: 0.7351 - val_loss: 0.5344 - val_acc: 0.7695\n",
      "Epoch 80/100\n",
      "1944/1944 [==============================] - 1s 369us/step - loss: 0.5570 - acc: 0.7387 - val_loss: 0.5298 - val_acc: 0.7675\n",
      "Epoch 81/100\n",
      "1944/1944 [==============================] - 1s 361us/step - loss: 0.5501 - acc: 0.7474 - val_loss: 0.5253 - val_acc: 0.7695\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 359us/step - loss: 0.5487 - acc: 0.7454 - val_loss: 0.5215 - val_acc: 0.7675\n",
      "Epoch 83/100\n",
      "1944/1944 [==============================] - 1s 377us/step - loss: 0.5413 - acc: 0.7454 - val_loss: 0.5180 - val_acc: 0.7675\n",
      "Epoch 84/100\n",
      "1944/1944 [==============================] - 1s 360us/step - loss: 0.5382 - acc: 0.7474 - val_loss: 0.5147 - val_acc: 0.7716\n",
      "Epoch 85/100\n",
      "1944/1944 [==============================] - 1s 376us/step - loss: 0.5346 - acc: 0.7510 - val_loss: 0.5076 - val_acc: 0.7695\n",
      "Epoch 86/100\n",
      "1944/1944 [==============================] - 1s 381us/step - loss: 0.5308 - acc: 0.7546 - val_loss: 0.5042 - val_acc: 0.7716\n",
      "Epoch 87/100\n",
      "1944/1944 [==============================] - 1s 361us/step - loss: 0.5253 - acc: 0.7495 - val_loss: 0.5004 - val_acc: 0.7716\n",
      "Epoch 88/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.5191 - acc: 0.7557 - val_loss: 0.4993 - val_acc: 0.7716\n",
      "Epoch 89/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.5145 - acc: 0.7618 - val_loss: 0.4924 - val_acc: 0.7716\n",
      "Epoch 90/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.5119 - acc: 0.7618 - val_loss: 0.4890 - val_acc: 0.7757\n",
      "Epoch 91/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.5057 - acc: 0.7685 - val_loss: 0.4877 - val_acc: 0.7716\n",
      "Epoch 92/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.4969 - acc: 0.7726 - val_loss: 0.4865 - val_acc: 0.7675\n",
      "Epoch 93/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.5037 - acc: 0.7639 - val_loss: 0.4873 - val_acc: 0.7593\n",
      "Epoch 94/100\n",
      "1944/1944 [==============================] - 1s 367us/step - loss: 0.4963 - acc: 0.7675 - val_loss: 0.4825 - val_acc: 0.7634\n",
      "Epoch 95/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.4921 - acc: 0.7721 - val_loss: 0.4806 - val_acc: 0.7634\n",
      "Epoch 96/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.4888 - acc: 0.7711 - val_loss: 0.4771 - val_acc: 0.7654\n",
      "Epoch 97/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.4885 - acc: 0.7762 - val_loss: 0.4714 - val_acc: 0.7737\n",
      "Epoch 98/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.4836 - acc: 0.7762 - val_loss: 0.4692 - val_acc: 0.7757\n",
      "Epoch 99/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.4807 - acc: 0.7762 - val_loss: 0.4713 - val_acc: 0.7778\n",
      "Epoch 100/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.4776 - acc: 0.7767 - val_loss: 0.4651 - val_acc: 0.7737\n",
      "Train on 1944 samples, validate on 486 samples\n",
      "Epoch 1/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.4619 - acc: 0.7932 - val_loss: 0.4325 - val_acc: 0.7984\n",
      "Epoch 2/100\n",
      "1944/1944 [==============================] - 1s 367us/step - loss: 0.4544 - acc: 0.7994 - val_loss: 0.4292 - val_acc: 0.7984\n",
      "Epoch 3/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.4503 - acc: 0.7989 - val_loss: 0.4279 - val_acc: 0.8004\n",
      "Epoch 4/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.4468 - acc: 0.8030 - val_loss: 0.4230 - val_acc: 0.8045\n",
      "Epoch 5/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.4448 - acc: 0.7994 - val_loss: 0.4199 - val_acc: 0.8066\n",
      "Epoch 6/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.4426 - acc: 0.8061 - val_loss: 0.4171 - val_acc: 0.8086\n",
      "Epoch 7/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.4354 - acc: 0.8097 - val_loss: 0.4200 - val_acc: 0.8128\n",
      "Epoch 8/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.4343 - acc: 0.8076 - val_loss: 0.4123 - val_acc: 0.8210\n",
      "Epoch 9/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.4324 - acc: 0.8050 - val_loss: 0.4082 - val_acc: 0.8086\n",
      "Epoch 10/100\n",
      "1944/1944 [==============================] - 1s 367us/step - loss: 0.4263 - acc: 0.8045 - val_loss: 0.4054 - val_acc: 0.8086\n",
      "Epoch 11/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.4252 - acc: 0.8143 - val_loss: 0.4028 - val_acc: 0.8107\n",
      "Epoch 12/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.4192 - acc: 0.8158 - val_loss: 0.4011 - val_acc: 0.8292\n",
      "Epoch 13/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.4141 - acc: 0.8179 - val_loss: 0.3979 - val_acc: 0.8333\n",
      "Epoch 14/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.4136 - acc: 0.8256 - val_loss: 0.3957 - val_acc: 0.8354\n",
      "Epoch 15/100\n",
      "1944/1944 [==============================] - 1s 356us/step - loss: 0.4134 - acc: 0.8205 - val_loss: 0.3936 - val_acc: 0.8354\n",
      "Epoch 16/100\n",
      "1944/1944 [==============================] - 1s 356us/step - loss: 0.4066 - acc: 0.8225 - val_loss: 0.3930 - val_acc: 0.8333\n",
      "Epoch 17/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.4038 - acc: 0.8225 - val_loss: 0.3907 - val_acc: 0.8292\n",
      "Epoch 18/100\n",
      "1944/1944 [==============================] - 1s 369us/step - loss: 0.4043 - acc: 0.8200 - val_loss: 0.3847 - val_acc: 0.8374\n",
      "Epoch 19/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.4049 - acc: 0.8225 - val_loss: 0.3818 - val_acc: 0.8416\n",
      "Epoch 20/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.3972 - acc: 0.8287 - val_loss: 0.3796 - val_acc: 0.8457\n",
      "Epoch 21/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.3931 - acc: 0.8302 - val_loss: 0.3778 - val_acc: 0.8374\n",
      "Epoch 22/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.3947 - acc: 0.8297 - val_loss: 0.3756 - val_acc: 0.8395\n",
      "Epoch 23/100\n",
      "1944/1944 [==============================] - 1s 360us/step - loss: 0.3910 - acc: 0.8246 - val_loss: 0.3721 - val_acc: 0.8477\n",
      "Epoch 24/100\n",
      "1944/1944 [==============================] - 1s 364us/step - loss: 0.3890 - acc: 0.8318 - val_loss: 0.3701 - val_acc: 0.8477\n",
      "Epoch 25/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.3884 - acc: 0.8277 - val_loss: 0.3680 - val_acc: 0.8498\n",
      "Epoch 26/100\n",
      "1944/1944 [==============================] - 1s 364us/step - loss: 0.3814 - acc: 0.8364 - val_loss: 0.3667 - val_acc: 0.8560\n",
      "Epoch 27/100\n",
      "1944/1944 [==============================] - 1s 386us/step - loss: 0.3910 - acc: 0.8272 - val_loss: 0.3661 - val_acc: 0.8457\n",
      "Epoch 28/100\n",
      "1944/1944 [==============================] - 1s 374us/step - loss: 0.3762 - acc: 0.8328 - val_loss: 0.3602 - val_acc: 0.8519\n",
      "Epoch 29/100\n",
      "1944/1944 [==============================] - 1s 392us/step - loss: 0.3696 - acc: 0.8441 - val_loss: 0.3662 - val_acc: 0.8354\n",
      "Epoch 30/100\n",
      "1944/1944 [==============================] - 1s 375us/step - loss: 0.3734 - acc: 0.8426 - val_loss: 0.3555 - val_acc: 0.8539\n",
      "Epoch 31/100\n",
      "1944/1944 [==============================] - 1s 398us/step - loss: 0.3728 - acc: 0.8410 - val_loss: 0.3583 - val_acc: 0.8457\n",
      "Epoch 32/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.3682 - acc: 0.8421 - val_loss: 0.3517 - val_acc: 0.8539\n",
      "Epoch 33/100\n",
      "1944/1944 [==============================] - 1s 359us/step - loss: 0.3674 - acc: 0.8452 - val_loss: 0.3499 - val_acc: 0.8560\n",
      "Epoch 34/100\n",
      "1944/1944 [==============================] - 1s 356us/step - loss: 0.3699 - acc: 0.8369 - val_loss: 0.3582 - val_acc: 0.8333\n",
      "Epoch 35/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.3601 - acc: 0.8462 - val_loss: 0.3465 - val_acc: 0.8560\n",
      "Epoch 36/100\n",
      "1944/1944 [==============================] - 1s 359us/step - loss: 0.3652 - acc: 0.8447 - val_loss: 0.3478 - val_acc: 0.8477\n",
      "Epoch 37/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.3555 - acc: 0.8447 - val_loss: 0.3437 - val_acc: 0.8519\n",
      "Epoch 38/100\n",
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.3545 - acc: 0.8483 - val_loss: 0.3424 - val_acc: 0.8519\n",
      "Epoch 39/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.3457 - acc: 0.8462 - val_loss: 0.3379 - val_acc: 0.8580\n",
      "Epoch 40/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.3491 - acc: 0.8467 - val_loss: 0.3380 - val_acc: 0.8539\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.3531 - acc: 0.8431 - val_loss: 0.3324 - val_acc: 0.8642\n",
      "Epoch 42/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.3460 - acc: 0.8513 - val_loss: 0.3326 - val_acc: 0.8601\n",
      "Epoch 43/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.3420 - acc: 0.8539 - val_loss: 0.3291 - val_acc: 0.8621\n",
      "Epoch 44/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.3440 - acc: 0.8493 - val_loss: 0.3282 - val_acc: 0.8601\n",
      "Epoch 45/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.3446 - acc: 0.8549 - val_loss: 0.3255 - val_acc: 0.8663\n",
      "Epoch 46/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.3385 - acc: 0.8549 - val_loss: 0.3250 - val_acc: 0.8642\n",
      "Epoch 47/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.3331 - acc: 0.8524 - val_loss: 0.3213 - val_acc: 0.8663\n",
      "Epoch 48/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.3338 - acc: 0.8570 - val_loss: 0.3191 - val_acc: 0.8724\n",
      "Epoch 49/100\n",
      "1944/1944 [==============================] - 1s 413us/step - loss: 0.3355 - acc: 0.8555 - val_loss: 0.3192 - val_acc: 0.8683\n",
      "Epoch 50/100\n",
      "1944/1944 [==============================] - 1s 405us/step - loss: 0.3322 - acc: 0.8534 - val_loss: 0.3161 - val_acc: 0.8683\n",
      "Epoch 51/100\n",
      "1944/1944 [==============================] - 1s 398us/step - loss: 0.3289 - acc: 0.8513 - val_loss: 0.3209 - val_acc: 0.8621\n",
      "Epoch 52/100\n",
      "1944/1944 [==============================] - 1s 361us/step - loss: 0.3237 - acc: 0.8647 - val_loss: 0.3173 - val_acc: 0.8642\n",
      "Epoch 53/100\n",
      "1944/1944 [==============================] - 1s 363us/step - loss: 0.3194 - acc: 0.8585 - val_loss: 0.3167 - val_acc: 0.8642\n",
      "Epoch 54/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.3183 - acc: 0.8596 - val_loss: 0.3165 - val_acc: 0.8683\n",
      "Epoch 55/100\n",
      "1944/1944 [==============================] - 1s 363us/step - loss: 0.3185 - acc: 0.8632 - val_loss: 0.3161 - val_acc: 0.8683\n",
      "Epoch 56/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.3161 - acc: 0.8673 - val_loss: 0.3090 - val_acc: 0.8724\n",
      "Epoch 57/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.3177 - acc: 0.8601 - val_loss: 0.3128 - val_acc: 0.8704\n",
      "Epoch 58/100\n",
      "1944/1944 [==============================] - 1s 356us/step - loss: 0.3158 - acc: 0.8642 - val_loss: 0.3074 - val_acc: 0.8704\n",
      "Epoch 59/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.3129 - acc: 0.8632 - val_loss: 0.3043 - val_acc: 0.8704\n",
      "Epoch 60/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.3094 - acc: 0.8693 - val_loss: 0.3040 - val_acc: 0.8724\n",
      "Epoch 61/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.3036 - acc: 0.8693 - val_loss: 0.3025 - val_acc: 0.8704\n",
      "Epoch 62/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.3067 - acc: 0.8647 - val_loss: 0.3003 - val_acc: 0.8724\n",
      "Epoch 63/100\n",
      "1944/1944 [==============================] - 1s 368us/step - loss: 0.3060 - acc: 0.8663 - val_loss: 0.2993 - val_acc: 0.8745\n",
      "Epoch 64/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.3014 - acc: 0.8745 - val_loss: 0.3029 - val_acc: 0.8724\n",
      "Epoch 65/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.3044 - acc: 0.8755 - val_loss: 0.3012 - val_acc: 0.8786\n",
      "Epoch 66/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.3056 - acc: 0.8688 - val_loss: 0.3014 - val_acc: 0.8745\n",
      "Epoch 67/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.3002 - acc: 0.8755 - val_loss: 0.2945 - val_acc: 0.8786\n",
      "Epoch 68/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.2929 - acc: 0.8760 - val_loss: 0.2923 - val_acc: 0.8786\n",
      "Epoch 69/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.2963 - acc: 0.8765 - val_loss: 0.2918 - val_acc: 0.8786\n",
      "Epoch 70/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.2953 - acc: 0.8740 - val_loss: 0.2910 - val_acc: 0.8827\n",
      "Epoch 71/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.2905 - acc: 0.8735 - val_loss: 0.2889 - val_acc: 0.8827\n",
      "Epoch 72/100\n",
      "1944/1944 [==============================] - 1s 337us/step - loss: 0.2886 - acc: 0.8776 - val_loss: 0.2916 - val_acc: 0.8807\n",
      "Epoch 73/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.2919 - acc: 0.8740 - val_loss: 0.2890 - val_acc: 0.8827\n",
      "Epoch 74/100\n",
      "1944/1944 [==============================] - 1s 364us/step - loss: 0.2843 - acc: 0.8781 - val_loss: 0.2863 - val_acc: 0.8889\n",
      "Epoch 75/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.2871 - acc: 0.8812 - val_loss: 0.2922 - val_acc: 0.8827\n",
      "Epoch 76/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.2831 - acc: 0.8755 - val_loss: 0.2839 - val_acc: 0.8909\n",
      "Epoch 77/100\n",
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.2866 - acc: 0.8832 - val_loss: 0.2806 - val_acc: 0.8971\n",
      "Epoch 78/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.2797 - acc: 0.8848 - val_loss: 0.2815 - val_acc: 0.8930\n",
      "Epoch 79/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.2839 - acc: 0.8889 - val_loss: 0.2835 - val_acc: 0.8909\n",
      "Epoch 80/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.2799 - acc: 0.8796 - val_loss: 0.2785 - val_acc: 0.8971\n",
      "Epoch 81/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.2821 - acc: 0.8807 - val_loss: 0.2754 - val_acc: 0.8889\n",
      "Epoch 82/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.2743 - acc: 0.8873 - val_loss: 0.2823 - val_acc: 0.8909\n",
      "Epoch 83/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.2744 - acc: 0.8848 - val_loss: 0.2798 - val_acc: 0.8909\n",
      "Epoch 84/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.2695 - acc: 0.8879 - val_loss: 0.2797 - val_acc: 0.8930\n",
      "Epoch 85/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.2664 - acc: 0.8935 - val_loss: 0.2828 - val_acc: 0.8930\n",
      "Epoch 86/100\n",
      "1944/1944 [==============================] - 1s 359us/step - loss: 0.2705 - acc: 0.8884 - val_loss: 0.2793 - val_acc: 0.8909\n",
      "Epoch 87/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.2681 - acc: 0.8868 - val_loss: 0.2749 - val_acc: 0.9033\n",
      "Epoch 88/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.2684 - acc: 0.8832 - val_loss: 0.2807 - val_acc: 0.8951\n",
      "Epoch 89/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.2613 - acc: 0.8935 - val_loss: 0.2677 - val_acc: 0.9033\n",
      "Epoch 90/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.2642 - acc: 0.8945 - val_loss: 0.2713 - val_acc: 0.9012\n",
      "Epoch 91/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.2607 - acc: 0.8925 - val_loss: 0.2711 - val_acc: 0.9033\n",
      "Epoch 92/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.2668 - acc: 0.8894 - val_loss: 0.2749 - val_acc: 0.9012\n",
      "Epoch 93/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.2622 - acc: 0.8899 - val_loss: 0.2721 - val_acc: 0.8992\n",
      "Epoch 94/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.2668 - acc: 0.8848 - val_loss: 0.2728 - val_acc: 0.9033\n",
      "Epoch 95/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.2651 - acc: 0.8945 - val_loss: 0.2723 - val_acc: 0.9033\n",
      "Epoch 96/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.2559 - acc: 0.8940 - val_loss: 0.2641 - val_acc: 0.9053\n",
      "Epoch 97/100\n",
      "1944/1944 [==============================] - 1s 362us/step - loss: 0.2638 - acc: 0.8920 - val_loss: 0.2704 - val_acc: 0.9033\n",
      "Epoch 98/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.2653 - acc: 0.8930 - val_loss: 0.2643 - val_acc: 0.9074\n",
      "Epoch 99/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.2548 - acc: 0.8945 - val_loss: 0.2651 - val_acc: 0.9095\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 336us/step - loss: 0.2486 - acc: 0.8997 - val_loss: 0.2652 - val_acc: 0.9033\n",
      "Test subject 10, class Replace\n",
      "Train subject 10, class BothReleased\n",
      "Train on 1944 samples, validate on 486 samples\n",
      "Epoch 1/100\n",
      "1944/1944 [==============================] - 2s 836us/step - loss: 0.6915 - acc: 0.5262 - val_loss: 0.6927 - val_acc: 0.5412\n",
      "Epoch 2/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.6925 - acc: 0.5108 - val_loss: 0.6920 - val_acc: 0.5473\n",
      "Epoch 3/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.6924 - acc: 0.5093 - val_loss: 0.6915 - val_acc: 0.5556\n",
      "Epoch 4/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.6920 - acc: 0.5165 - val_loss: 0.6911 - val_acc: 0.5638\n",
      "Epoch 5/100\n",
      "1944/1944 [==============================] - 1s 359us/step - loss: 0.6904 - acc: 0.5303 - val_loss: 0.6906 - val_acc: 0.5617\n",
      "Epoch 6/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.6913 - acc: 0.5201 - val_loss: 0.6902 - val_acc: 0.5535\n",
      "Epoch 7/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.6904 - acc: 0.5442 - val_loss: 0.6897 - val_acc: 0.5658\n",
      "Epoch 8/100\n",
      "1944/1944 [==============================] - 1s 363us/step - loss: 0.6922 - acc: 0.5159 - val_loss: 0.6893 - val_acc: 0.5638\n",
      "Epoch 9/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.6906 - acc: 0.5340 - val_loss: 0.6888 - val_acc: 0.5658\n",
      "Epoch 10/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.6895 - acc: 0.5278 - val_loss: 0.6884 - val_acc: 0.5638\n",
      "Epoch 11/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.6884 - acc: 0.5509 - val_loss: 0.6879 - val_acc: 0.5679\n",
      "Epoch 12/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.6894 - acc: 0.5370 - val_loss: 0.6874 - val_acc: 0.5844\n",
      "Epoch 13/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.6892 - acc: 0.5329 - val_loss: 0.6870 - val_acc: 0.5864\n",
      "Epoch 14/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.6886 - acc: 0.5622 - val_loss: 0.6865 - val_acc: 0.5885\n",
      "Epoch 15/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.6883 - acc: 0.5473 - val_loss: 0.6860 - val_acc: 0.5905\n",
      "Epoch 16/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.6866 - acc: 0.5715 - val_loss: 0.6855 - val_acc: 0.6008\n",
      "Epoch 17/100\n",
      "1944/1944 [==============================] - 1s 337us/step - loss: 0.6881 - acc: 0.5463 - val_loss: 0.6850 - val_acc: 0.6193\n",
      "Epoch 18/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.6862 - acc: 0.5586 - val_loss: 0.6845 - val_acc: 0.6379\n",
      "Epoch 19/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.6843 - acc: 0.5664 - val_loss: 0.6839 - val_acc: 0.6584\n",
      "Epoch 20/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.6866 - acc: 0.5617 - val_loss: 0.6833 - val_acc: 0.6667\n",
      "Epoch 21/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.6838 - acc: 0.5802 - val_loss: 0.6827 - val_acc: 0.6646\n",
      "Epoch 22/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.6846 - acc: 0.5592 - val_loss: 0.6822 - val_acc: 0.6584\n",
      "Epoch 23/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.6850 - acc: 0.5669 - val_loss: 0.6816 - val_acc: 0.6584\n",
      "Epoch 24/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.6849 - acc: 0.5674 - val_loss: 0.6810 - val_acc: 0.6420\n",
      "Epoch 25/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.6820 - acc: 0.5931 - val_loss: 0.6802 - val_acc: 0.6420\n",
      "Epoch 26/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.6821 - acc: 0.5772 - val_loss: 0.6794 - val_acc: 0.6523\n",
      "Epoch 27/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.6801 - acc: 0.6013 - val_loss: 0.6786 - val_acc: 0.6646\n",
      "Epoch 28/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.6803 - acc: 0.5983 - val_loss: 0.6778 - val_acc: 0.6770\n",
      "Epoch 29/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.6766 - acc: 0.6353 - val_loss: 0.6769 - val_acc: 0.6728\n",
      "Epoch 30/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.6773 - acc: 0.6075 - val_loss: 0.6759 - val_acc: 0.6770\n",
      "Epoch 31/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.6779 - acc: 0.6163 - val_loss: 0.6749 - val_acc: 0.6831\n",
      "Epoch 32/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.6756 - acc: 0.6301 - val_loss: 0.6739 - val_acc: 0.6831\n",
      "Epoch 33/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.6753 - acc: 0.6245 - val_loss: 0.6728 - val_acc: 0.6831\n",
      "Epoch 34/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.6721 - acc: 0.6440 - val_loss: 0.6717 - val_acc: 0.6852\n",
      "Epoch 35/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.6706 - acc: 0.6466 - val_loss: 0.6703 - val_acc: 0.6893\n",
      "Epoch 36/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.6710 - acc: 0.6445 - val_loss: 0.6689 - val_acc: 0.6955\n",
      "Epoch 37/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.6718 - acc: 0.6420 - val_loss: 0.6675 - val_acc: 0.6955\n",
      "Epoch 38/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.6671 - acc: 0.6564 - val_loss: 0.6660 - val_acc: 0.7016\n",
      "Epoch 39/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.6665 - acc: 0.6507 - val_loss: 0.6643 - val_acc: 0.6996\n",
      "Epoch 40/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.6632 - acc: 0.6641 - val_loss: 0.6626 - val_acc: 0.7016\n",
      "Epoch 41/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.6634 - acc: 0.6646 - val_loss: 0.6610 - val_acc: 0.6975\n",
      "Epoch 42/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.6629 - acc: 0.6620 - val_loss: 0.6588 - val_acc: 0.6975\n",
      "Epoch 43/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.6581 - acc: 0.6728 - val_loss: 0.6566 - val_acc: 0.6975\n",
      "Epoch 44/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.6564 - acc: 0.6677 - val_loss: 0.6544 - val_acc: 0.6996\n",
      "Epoch 45/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.6523 - acc: 0.6939 - val_loss: 0.6521 - val_acc: 0.6996\n",
      "Epoch 46/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.6485 - acc: 0.7027 - val_loss: 0.6489 - val_acc: 0.7078\n",
      "Epoch 47/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.6440 - acc: 0.7099 - val_loss: 0.6462 - val_acc: 0.7078\n",
      "Epoch 48/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.6418 - acc: 0.7171 - val_loss: 0.6428 - val_acc: 0.7099\n",
      "Epoch 49/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.6387 - acc: 0.7155 - val_loss: 0.6394 - val_acc: 0.7119\n",
      "Epoch 50/100\n",
      "1944/1944 [==============================] - 1s 358us/step - loss: 0.6347 - acc: 0.7217 - val_loss: 0.6362 - val_acc: 0.7119\n",
      "Epoch 51/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.6348 - acc: 0.7037 - val_loss: 0.6321 - val_acc: 0.7099\n",
      "Epoch 52/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.6302 - acc: 0.7088 - val_loss: 0.6279 - val_acc: 0.7099\n",
      "Epoch 53/100\n",
      "1944/1944 [==============================] - 1s 364us/step - loss: 0.6230 - acc: 0.7099 - val_loss: 0.6234 - val_acc: 0.7078\n",
      "Epoch 54/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.6162 - acc: 0.7274 - val_loss: 0.6185 - val_acc: 0.7160\n",
      "Epoch 55/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.6140 - acc: 0.7341 - val_loss: 0.6141 - val_acc: 0.7140\n",
      "Epoch 56/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.6092 - acc: 0.7320 - val_loss: 0.6081 - val_acc: 0.7284\n",
      "Epoch 57/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.6052 - acc: 0.7330 - val_loss: 0.6032 - val_acc: 0.7202\n",
      "Epoch 58/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.5969 - acc: 0.7361 - val_loss: 0.5974 - val_acc: 0.7305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.5918 - acc: 0.7387 - val_loss: 0.5909 - val_acc: 0.7284\n",
      "Epoch 60/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.5876 - acc: 0.7356 - val_loss: 0.5854 - val_acc: 0.7305\n",
      "Epoch 61/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.5809 - acc: 0.7428 - val_loss: 0.5792 - val_acc: 0.7263\n",
      "Epoch 62/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.5709 - acc: 0.7371 - val_loss: 0.5733 - val_acc: 0.7263\n",
      "Epoch 63/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.5653 - acc: 0.7407 - val_loss: 0.5679 - val_acc: 0.7284\n",
      "Epoch 64/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.5576 - acc: 0.7443 - val_loss: 0.5612 - val_acc: 0.7305\n",
      "Epoch 65/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.5497 - acc: 0.7567 - val_loss: 0.5547 - val_acc: 0.7366\n",
      "Epoch 66/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.5414 - acc: 0.7536 - val_loss: 0.5493 - val_acc: 0.7366\n",
      "Epoch 67/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.5393 - acc: 0.7510 - val_loss: 0.5457 - val_acc: 0.7346\n",
      "Epoch 68/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.5249 - acc: 0.7634 - val_loss: 0.5411 - val_acc: 0.7305\n",
      "Epoch 69/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.5243 - acc: 0.7500 - val_loss: 0.5361 - val_acc: 0.7346\n",
      "Epoch 70/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.5147 - acc: 0.7644 - val_loss: 0.5304 - val_acc: 0.7366\n",
      "Epoch 71/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.5075 - acc: 0.7680 - val_loss: 0.5244 - val_acc: 0.7428\n",
      "Epoch 72/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.5060 - acc: 0.7557 - val_loss: 0.5193 - val_acc: 0.7428\n",
      "Epoch 73/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.4908 - acc: 0.7757 - val_loss: 0.5149 - val_acc: 0.7449\n",
      "Epoch 74/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.4956 - acc: 0.7649 - val_loss: 0.5105 - val_acc: 0.7531\n",
      "Epoch 75/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.4886 - acc: 0.7680 - val_loss: 0.5072 - val_acc: 0.7490\n",
      "Epoch 76/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.4847 - acc: 0.7716 - val_loss: 0.5049 - val_acc: 0.7469\n",
      "Epoch 77/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.4759 - acc: 0.7773 - val_loss: 0.4999 - val_acc: 0.7634\n",
      "Epoch 78/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.4797 - acc: 0.7618 - val_loss: 0.4960 - val_acc: 0.7634\n",
      "Epoch 79/100\n",
      "1944/1944 [==============================] - 1s 362us/step - loss: 0.4660 - acc: 0.7834 - val_loss: 0.4923 - val_acc: 0.7654\n",
      "Epoch 80/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.4597 - acc: 0.7850 - val_loss: 0.4888 - val_acc: 0.7634\n",
      "Epoch 81/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.4584 - acc: 0.7912 - val_loss: 0.4856 - val_acc: 0.7654\n",
      "Epoch 82/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.4559 - acc: 0.7922 - val_loss: 0.4829 - val_acc: 0.7695\n",
      "Epoch 83/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.4508 - acc: 0.7881 - val_loss: 0.4803 - val_acc: 0.7695\n",
      "Epoch 84/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.4493 - acc: 0.7855 - val_loss: 0.4765 - val_acc: 0.7675\n",
      "Epoch 85/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.4434 - acc: 0.7886 - val_loss: 0.4736 - val_acc: 0.7716\n",
      "Epoch 86/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.4423 - acc: 0.7912 - val_loss: 0.4708 - val_acc: 0.7716\n",
      "Epoch 87/100\n",
      "1944/1944 [==============================] - 1s 361us/step - loss: 0.4399 - acc: 0.7932 - val_loss: 0.4683 - val_acc: 0.7716\n",
      "Epoch 88/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.4318 - acc: 0.7978 - val_loss: 0.4654 - val_acc: 0.7798\n",
      "Epoch 89/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.4289 - acc: 0.8004 - val_loss: 0.4630 - val_acc: 0.7840\n",
      "Epoch 90/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.4236 - acc: 0.8066 - val_loss: 0.4604 - val_acc: 0.7798\n",
      "Epoch 91/100\n",
      "1944/1944 [==============================] - 1s 356us/step - loss: 0.4254 - acc: 0.8050 - val_loss: 0.4584 - val_acc: 0.7819\n",
      "Epoch 92/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.4226 - acc: 0.8071 - val_loss: 0.4554 - val_acc: 0.7901\n",
      "Epoch 93/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.4145 - acc: 0.8122 - val_loss: 0.4521 - val_acc: 0.7922\n",
      "Epoch 94/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.4188 - acc: 0.8040 - val_loss: 0.4506 - val_acc: 0.8004\n",
      "Epoch 95/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.4025 - acc: 0.8133 - val_loss: 0.4489 - val_acc: 0.8004\n",
      "Epoch 96/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.4118 - acc: 0.8117 - val_loss: 0.4453 - val_acc: 0.7984\n",
      "Epoch 97/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.4054 - acc: 0.8102 - val_loss: 0.4431 - val_acc: 0.8004\n",
      "Epoch 98/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.4018 - acc: 0.8164 - val_loss: 0.4408 - val_acc: 0.7984\n",
      "Epoch 99/100\n",
      "1944/1944 [==============================] - 1s 362us/step - loss: 0.4013 - acc: 0.8153 - val_loss: 0.4387 - val_acc: 0.8004\n",
      "Epoch 100/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.4029 - acc: 0.8210 - val_loss: 0.4369 - val_acc: 0.8066\n",
      "Train on 1944 samples, validate on 486 samples\n",
      "Epoch 1/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.4058 - acc: 0.8117 - val_loss: 0.3568 - val_acc: 0.8539\n",
      "Epoch 2/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.4008 - acc: 0.8148 - val_loss: 0.3494 - val_acc: 0.8580\n",
      "Epoch 3/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.3956 - acc: 0.8205 - val_loss: 0.3503 - val_acc: 0.8580\n",
      "Epoch 4/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.3950 - acc: 0.8215 - val_loss: 0.3471 - val_acc: 0.8621\n",
      "Epoch 5/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.3909 - acc: 0.8164 - val_loss: 0.3434 - val_acc: 0.8642\n",
      "Epoch 6/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.3929 - acc: 0.8236 - val_loss: 0.3433 - val_acc: 0.8663\n",
      "Epoch 7/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.3843 - acc: 0.8302 - val_loss: 0.3384 - val_acc: 0.8663\n",
      "Epoch 8/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.3851 - acc: 0.8225 - val_loss: 0.3360 - val_acc: 0.8683\n",
      "Epoch 9/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.3837 - acc: 0.8282 - val_loss: 0.3354 - val_acc: 0.8704\n",
      "Epoch 10/100\n",
      "1944/1944 [==============================] - 1s 358us/step - loss: 0.3813 - acc: 0.8313 - val_loss: 0.3330 - val_acc: 0.8724\n",
      "Epoch 11/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.3816 - acc: 0.8292 - val_loss: 0.3317 - val_acc: 0.8704\n",
      "Epoch 12/100\n",
      "1944/1944 [==============================] - 1s 337us/step - loss: 0.3731 - acc: 0.8313 - val_loss: 0.3315 - val_acc: 0.8704\n",
      "Epoch 13/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.3771 - acc: 0.8297 - val_loss: 0.3342 - val_acc: 0.8663\n",
      "Epoch 14/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.3690 - acc: 0.8395 - val_loss: 0.3323 - val_acc: 0.8663\n",
      "Epoch 15/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.3610 - acc: 0.8405 - val_loss: 0.3257 - val_acc: 0.8704\n",
      "Epoch 16/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.3616 - acc: 0.8457 - val_loss: 0.3235 - val_acc: 0.8765\n",
      "Epoch 17/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.3621 - acc: 0.8436 - val_loss: 0.3245 - val_acc: 0.8683\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 358us/step - loss: 0.3545 - acc: 0.8436 - val_loss: 0.3211 - val_acc: 0.8724\n",
      "Epoch 19/100\n",
      "1944/1944 [==============================] - 1s 390us/step - loss: 0.3604 - acc: 0.8410 - val_loss: 0.3203 - val_acc: 0.8786\n",
      "Epoch 20/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.3565 - acc: 0.8447 - val_loss: 0.3188 - val_acc: 0.8786\n",
      "Epoch 21/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.3492 - acc: 0.8529 - val_loss: 0.3211 - val_acc: 0.8745\n",
      "Epoch 22/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.3588 - acc: 0.8400 - val_loss: 0.3157 - val_acc: 0.8786\n",
      "Epoch 23/100\n",
      "1944/1944 [==============================] - 1s 360us/step - loss: 0.3450 - acc: 0.8447 - val_loss: 0.3171 - val_acc: 0.8765\n",
      "Epoch 24/100\n",
      "1944/1944 [==============================] - 1s 365us/step - loss: 0.3512 - acc: 0.8508 - val_loss: 0.3112 - val_acc: 0.8786\n",
      "Epoch 25/100\n",
      "1944/1944 [==============================] - 1s 360us/step - loss: 0.3491 - acc: 0.8524 - val_loss: 0.3174 - val_acc: 0.8786\n",
      "Epoch 26/100\n",
      "1944/1944 [==============================] - 1s 374us/step - loss: 0.3497 - acc: 0.8462 - val_loss: 0.3104 - val_acc: 0.8827\n",
      "Epoch 27/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.3481 - acc: 0.8503 - val_loss: 0.3101 - val_acc: 0.8827\n",
      "Epoch 28/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.3529 - acc: 0.8467 - val_loss: 0.3114 - val_acc: 0.8807\n",
      "Epoch 29/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.3453 - acc: 0.8508 - val_loss: 0.3085 - val_acc: 0.8807\n",
      "Epoch 30/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.3431 - acc: 0.8565 - val_loss: 0.3143 - val_acc: 0.8786\n",
      "Epoch 31/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.3406 - acc: 0.8493 - val_loss: 0.3034 - val_acc: 0.8827\n",
      "Epoch 32/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.3403 - acc: 0.8534 - val_loss: 0.3055 - val_acc: 0.8827\n",
      "Epoch 33/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.3390 - acc: 0.8513 - val_loss: 0.3000 - val_acc: 0.8827\n",
      "Epoch 34/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.3385 - acc: 0.8524 - val_loss: 0.3019 - val_acc: 0.8807\n",
      "Epoch 35/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.3334 - acc: 0.8585 - val_loss: 0.3005 - val_acc: 0.8807\n",
      "Epoch 36/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.3352 - acc: 0.8616 - val_loss: 0.2981 - val_acc: 0.8868\n",
      "Epoch 37/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.3323 - acc: 0.8544 - val_loss: 0.3036 - val_acc: 0.8827\n",
      "Epoch 38/100\n",
      "1944/1944 [==============================] - 1s 366us/step - loss: 0.3336 - acc: 0.8591 - val_loss: 0.2979 - val_acc: 0.8848\n",
      "Epoch 39/100\n",
      "1944/1944 [==============================] - 1s 358us/step - loss: 0.3332 - acc: 0.8575 - val_loss: 0.3001 - val_acc: 0.8827\n",
      "Epoch 40/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.3310 - acc: 0.8621 - val_loss: 0.2975 - val_acc: 0.8827\n",
      "Epoch 41/100\n",
      "1944/1944 [==============================] - 1s 374us/step - loss: 0.3264 - acc: 0.8565 - val_loss: 0.2964 - val_acc: 0.8827\n",
      "Epoch 42/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.3272 - acc: 0.8668 - val_loss: 0.2933 - val_acc: 0.8868\n",
      "Epoch 43/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.3170 - acc: 0.8704 - val_loss: 0.2944 - val_acc: 0.8827\n",
      "Epoch 44/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.3139 - acc: 0.8693 - val_loss: 0.2961 - val_acc: 0.8848\n",
      "Epoch 45/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.3200 - acc: 0.8621 - val_loss: 0.2906 - val_acc: 0.8868\n",
      "Epoch 46/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.3172 - acc: 0.8668 - val_loss: 0.3052 - val_acc: 0.8848\n",
      "Epoch 47/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.3208 - acc: 0.8601 - val_loss: 0.2940 - val_acc: 0.8868\n",
      "Epoch 48/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.3181 - acc: 0.8678 - val_loss: 0.2900 - val_acc: 0.8848\n",
      "Epoch 49/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.3126 - acc: 0.8678 - val_loss: 0.2858 - val_acc: 0.8868\n",
      "Epoch 50/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.3179 - acc: 0.8601 - val_loss: 0.2913 - val_acc: 0.8868\n",
      "Epoch 51/100\n",
      "1944/1944 [==============================] - 1s 337us/step - loss: 0.3128 - acc: 0.8632 - val_loss: 0.2864 - val_acc: 0.8889\n",
      "Epoch 52/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.3172 - acc: 0.8668 - val_loss: 0.2916 - val_acc: 0.8889\n",
      "Epoch 53/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.3121 - acc: 0.8699 - val_loss: 0.2950 - val_acc: 0.8868\n",
      "Epoch 54/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.3122 - acc: 0.8699 - val_loss: 0.2875 - val_acc: 0.8868\n",
      "Epoch 55/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.3088 - acc: 0.8719 - val_loss: 0.2929 - val_acc: 0.8889\n",
      "Epoch 56/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.3108 - acc: 0.8750 - val_loss: 0.2882 - val_acc: 0.8868\n",
      "Epoch 57/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.2994 - acc: 0.8781 - val_loss: 0.2909 - val_acc: 0.8889\n",
      "Epoch 58/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.3076 - acc: 0.8709 - val_loss: 0.2897 - val_acc: 0.8889\n",
      "Epoch 59/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.2998 - acc: 0.8771 - val_loss: 0.2918 - val_acc: 0.8889\n",
      "Epoch 60/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.3081 - acc: 0.8688 - val_loss: 0.2831 - val_acc: 0.8909\n",
      "Epoch 61/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.3107 - acc: 0.8652 - val_loss: 0.3016 - val_acc: 0.8848\n",
      "Epoch 62/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.3062 - acc: 0.8719 - val_loss: 0.2830 - val_acc: 0.8889\n",
      "Epoch 63/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.3049 - acc: 0.8750 - val_loss: 0.2859 - val_acc: 0.8889\n",
      "Epoch 64/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.3017 - acc: 0.8781 - val_loss: 0.2862 - val_acc: 0.8868\n",
      "Epoch 65/100\n",
      "1944/1944 [==============================] - 1s 358us/step - loss: 0.3046 - acc: 0.8719 - val_loss: 0.2805 - val_acc: 0.8909\n",
      "Epoch 66/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.2945 - acc: 0.8776 - val_loss: 0.2831 - val_acc: 0.8868\n",
      "Epoch 67/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.2982 - acc: 0.8745 - val_loss: 0.2841 - val_acc: 0.8868\n",
      "Epoch 68/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.2994 - acc: 0.8750 - val_loss: 0.3000 - val_acc: 0.8868\n",
      "Epoch 69/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.2981 - acc: 0.8745 - val_loss: 0.2815 - val_acc: 0.8889\n",
      "Epoch 70/100\n",
      "1944/1944 [==============================] - 1s 367us/step - loss: 0.3000 - acc: 0.8791 - val_loss: 0.2761 - val_acc: 0.8889\n",
      "Epoch 71/100\n",
      "1944/1944 [==============================] - 1s 370us/step - loss: 0.3004 - acc: 0.8750 - val_loss: 0.2744 - val_acc: 0.8889\n",
      "Epoch 72/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.2957 - acc: 0.8786 - val_loss: 0.2799 - val_acc: 0.8889\n",
      "Epoch 73/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.2927 - acc: 0.8791 - val_loss: 0.2806 - val_acc: 0.8868\n",
      "Epoch 74/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.2901 - acc: 0.8776 - val_loss: 0.2721 - val_acc: 0.8909\n",
      "Epoch 75/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.2969 - acc: 0.8822 - val_loss: 0.2803 - val_acc: 0.8889\n",
      "Epoch 76/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.2911 - acc: 0.8817 - val_loss: 0.2795 - val_acc: 0.8889\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.2905 - acc: 0.8873 - val_loss: 0.2717 - val_acc: 0.8930\n",
      "Epoch 78/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.2915 - acc: 0.8848 - val_loss: 0.2728 - val_acc: 0.8930\n",
      "Epoch 79/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.2926 - acc: 0.8822 - val_loss: 0.2757 - val_acc: 0.8930\n",
      "Epoch 80/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.2804 - acc: 0.8879 - val_loss: 0.2802 - val_acc: 0.8889\n",
      "Epoch 81/100\n",
      "1944/1944 [==============================] - 1s 359us/step - loss: 0.2892 - acc: 0.8827 - val_loss: 0.2732 - val_acc: 0.8930\n",
      "Epoch 82/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.2896 - acc: 0.8796 - val_loss: 0.2762 - val_acc: 0.8889\n",
      "Epoch 83/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.2893 - acc: 0.8801 - val_loss: 0.2756 - val_acc: 0.8930\n",
      "Epoch 84/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.2838 - acc: 0.8894 - val_loss: 0.2723 - val_acc: 0.8930\n",
      "Epoch 85/100\n",
      "1944/1944 [==============================] - 1s 361us/step - loss: 0.2869 - acc: 0.8837 - val_loss: 0.2676 - val_acc: 0.8951\n",
      "Epoch 86/100\n",
      "1944/1944 [==============================] - 1s 360us/step - loss: 0.2919 - acc: 0.8760 - val_loss: 0.2785 - val_acc: 0.8889\n",
      "Epoch 87/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.2784 - acc: 0.8879 - val_loss: 0.2773 - val_acc: 0.8909\n",
      "Epoch 88/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.2833 - acc: 0.8889 - val_loss: 0.2711 - val_acc: 0.8930\n",
      "Epoch 89/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.2818 - acc: 0.8868 - val_loss: 0.2635 - val_acc: 0.8951\n",
      "Epoch 90/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.2916 - acc: 0.8776 - val_loss: 0.2718 - val_acc: 0.8930\n",
      "Epoch 91/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.2803 - acc: 0.8920 - val_loss: 0.2728 - val_acc: 0.8930\n",
      "Epoch 92/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.2787 - acc: 0.8863 - val_loss: 0.2727 - val_acc: 0.8930\n",
      "Epoch 93/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.2794 - acc: 0.8848 - val_loss: 0.2749 - val_acc: 0.8930\n",
      "Epoch 94/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.2791 - acc: 0.8848 - val_loss: 0.2668 - val_acc: 0.8951\n",
      "Epoch 95/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.2775 - acc: 0.8858 - val_loss: 0.2717 - val_acc: 0.8951\n",
      "Epoch 96/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.2743 - acc: 0.8894 - val_loss: 0.2693 - val_acc: 0.8951\n",
      "Epoch 97/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.2765 - acc: 0.8904 - val_loss: 0.2763 - val_acc: 0.8951\n",
      "Epoch 98/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.2793 - acc: 0.8889 - val_loss: 0.2576 - val_acc: 0.8992\n",
      "Epoch 99/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.2719 - acc: 0.8879 - val_loss: 0.2772 - val_acc: 0.8889\n",
      "Epoch 100/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.2782 - acc: 0.8935 - val_loss: 0.2641 - val_acc: 0.8951\n",
      "Test subject 10, class BothReleased\n",
      "HandStart AUC score = 0.844\n",
      "FirstDigitTouch AUC score = 0.934\n",
      "BothStartLoadPhase AUC score = 0.948\n",
      "LiftOff AUC score = 0.923\n",
      "Replace AUC score = 0.872\n",
      "BothReleased AUC score = 0.834\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAIABJREFUeJzsnXlYVdX6xz9LUAHFVMQRE0ccmDRw1jDTTMu0TCtzaJ608lY2m/Wzsqw0r3Wrm0Oas2VqmZVezSFUUHEiZ1FBVFBkUAaB9ftjc3YHODPnMK7P85xH9t5r770O6n73eofvK6SUKBQKhUIBUK2sJ6BQKBSK8oMyCgqFQqHQUUZBoVAoFDrKKCgUCoVCRxkFhUKhUOgoo6BQKBQKHWUUFAqFQqGjjIKiwiOEiBNCZAohMoQQF4QQC4QQtYuM6SmE+J8QIl0IkSqEWCeE6FhkTB0hxCwhxNmCa50o2G5g5r5CCPG8EOKQEOKaECJeCLFSCBHkyu+rULgSZRQUlYW7pZS1gVCgM/C64YAQogfwO7AGaAq0BPYDO4QQrQrG1AA2AZ2AQUAdoCdwGehq5p6fAy8AzwP1gXbAT8AQeycvhHC39xyFwiVIKdVHfSr0B4gDbjfa/hj4xWh7G/ClifN+BRYW/Pw4cBGobeM92wJ5QFcLY7YAjxttjwe2G21L4DngOHAa+Ar4pMg11gD/Kvi5KfADkFQw/nmjcV2BaCCt4Ht8VtZ/L+pTMT9qpaCoVAgh/IA7gRMF215ob/wrTQxfAQwo+Pl2YIOUMsPGW/UH4qWUu0s2Y4YB3YCOwBJglBBCAAgh6gEDgWVCiGrAOrQVTrOC+78ohLij4DqfA59LKesArQu+m0JhN8ooKCoLPwkh0oFzwCXgnYL99dH+nSeaOCcRMMQLfMyMMYe9483xoZTyipQyE21FI4E+BcdGAJFSyvNAOOArpXxPSpkjpTwF/Bd4oGDsDaCNEKKBlDJDSrnTCXNTVEGUUVBUFoZJKb2BCKA9/zzsU4B8oImJc5oAyQU/XzYzxhz2jjfHOcMPUkoJLAMeLNj1ELC44OcWQFMhxFXDB3gDaFRw/DG0mMYRIUSUEOIuJ8xNUQVRRkFRqZBS/gksAD4p2L4GRAL3mxg+Ei24DLARuEMIUcvGW20C/IQQYRbGXAO8jLYbm5pyke2lwAghRAs0t9IPBfvPAaellHWNPt5SysEAUsrjUsoHgYbAR8AqO76LQqGjjIKiMjILGCCECC3Yfg0YV5A+6i2EqCeEmAb0AN4tGLMI7cH7gxCivRCimhDCRwjxhhBicNEbSCmPA18CS4UQEUKIGkIIDyHEA0KI1wqGxQD3CiG8hBBt0N7mLSKl3IcWSP4W+E1KebXg0G4gTQjxqhDCUwjhJoQIFEKEAwghHhZC+Eop8wHDOXn2/NIUClBGQVEJkVImAQuBtwu2twN3APeixQHOoKWt9i54uCOlzEYLNh8B/kDL4tmN5obaZeZWzwNzgC/QHsQngeFoAWGAmUAOWjbQd/zjCrLG0oK5LDH6TnnA3Wgpt6fR3F7fAjcVDBkEHBZCZKAFnR+QUmbZeD+FQkdobkyFQqFQKNRKQaFQKBRGKKOgUCgUCh1lFBQKhUKho4yCQqFQKHQqnAhXgwYNpL+/f1lPQ6FQKCoUe/bsSZZS+lobV+GMgr+/P9HR0WU9DYVCoahQCCHO2DJOuY8UCoVCoaOMgkKhUCh0lFFQKBQKhY4yCgqFQqHQUUZBoVAoFDouMwpCiHlCiEtCiENmjgshxOyC5ugHhBBdXDUXhUKhUNiGK1cKC9CUG81xJ1qf27bAk8B/XDgXhUKhUNiAy+oUpJRbhRD+Fobcg9Y0XQI7hRB1hRBNpJTOaHGoUDjMyt8nsf78trKehkOExNygw+Hcsp6Gw6R69yTd21LfIueTnXuGnLyEUr2no7i7uTNh8VyX3qMsYwrNMGpFCMQX7CuGEOJJIUS0ECI6KSmpVCanqLqsP7+NoxW0FUGHw7k0vJRf1tNwmHTvMHJqmHwMFO9R5yRy8hLIk6muuXgFpCwrmoWJfSb/2qWU3wDfAISFhakGEIpCrDy2kvWn1pfsIukX4Jr2wnFUZhEgPJg/vnQr51OWryDt559LdI2sq0fwCG5P50UL7T53ya6zrIkp+Rtz4+RcGqY41vStdmY+GZ7VONA2uND+2MQ0Ojapw/KnepR4fgYObNzA3zu2kBmXRRP/9ox6Z7rTrl2RKUujEA80N9r2A86X0VwU9hI9n5UHF7BeXCvrmRAtsgEIkzWLHbPZnZJf8BCr5gaAT80anNk01mlztIXrUVEAeIWHO3T+xfRsLt/UlIN1OrDn60i7z991+goA3VrWd+j+BmNQN0NbqVytbb8jIsOzGpfquRXb37FJHe4JbaY/yJ1BfKyWA+PXMZAOvSKccs3KQFkahbXABCHEMrQG5akqnuBcSvwGbfT2XIysVKI9PQDTD+PSJEzWZLCsxe0x+aTFZhQ6dv1cDgBezT0sX6QaUMsXvBu7aJbW8QoPp85dd1Fv1EiHzp/8daT+Ru0I3VrW557QZjzU7WaHzl/96V6S8zJo0LYO7bo2olMfM24gGzD58N8Afxg9yEuKwRgE324pH6bq4TKjIIRYCkQADYQQ8cA7QHUAKeVXwHpgMHACuA484qq5VFXWn1rP0StHCagf4NgFriVBzjWoUav4MY+bCPPyZXDIo9zf7v6STdRJnBkzVnOftG+v7/NqTIketNZwlstF5yrgwFs+uMbFYguHtyVwbPdFkuMzaOBXm+EvlTy7/O8dW0iKO42vf8tC+9WD3PW4MvvoQSvHJfCcq+5f1Vl5bCXRF6MJaxTG/EHzLQ+Ong8HVxXff+ESNA6C8b+4ZpJ2Ys3nnnVEMwgtHPCn24OxISipy8WZGFwstmB4kDuDs4e2kpdzhJqe7qTE12D5uytKfE2DQVB+/tKnwklnK0xT1FUUfVELkg5uNdj8SQZjcGa7tt2id+HjjYMgaISzp2oWaw99az53j/btqXPXXS6ZmzFrYhL0t3JbXS7OfAhbZHsyq7cnWx12/vhVAJq2rVui26Vdiib3+kYAGjQvuUvHgK9/S+XnLyOUUaiAmIoVGIxAWKMw/c/BrQabd+1Ez4efX9R+btFbe/iH2ebBc0aWjCmsPfRL6nM3h70uIEfcNMbulfJA07Z1S+z3B/RVwYAnJiiXTiVBGYUKiKlYgVUjUBSDu+iuWTYbAwNpP/+su2qciase+kUpagTsdQHZ4qYpujJwpr+9rDAV/E2KO41fx0BlECoRyihUMOyKFRhTNG5w4aC2QrDDIBhWCKXlu3cVxu4fKHnWTVEOb0tgy+KjwD/umQZ+tWnXtZFTru8s7E3vjDeR+aPcPJUPZRTKGdbSSG2KFUBxI1A0bmBnvCBl+QouvPMO8M8bfUXDsEJwdZaOYYUQMTqgxO4ZV2Iuw8ccKvOnaqCMQhljLkBsiA0UxWY30cFV2mqgcZC2bRQ30GMC/9sMbLZpngZ/f+N333W5e8fZGIyBsZvIXvePPSTHZ9C0bd1ybRAMqAwfRVGUUShjisYH7I4NmCJ6vrYyaNEbHimeTupITKC0/P2uwLA6KOomsvTgL0l2Tlm7imx1C9mzSlBUHZRRKGWKrgwMBsGu+IAxRm6ilJg0raI3KxXwAZ8b8L/iUg0VLSZga3aQOc2dNtm5BNesSceMmoVSNi09+J2VnWMJZ0o2GGPK928KFQ9QmEIZhVJk5bGVvBf5HvCPeyigfoD1+IApTNQYpMVmkHUpB4+GN1mUbCitfH5HMGUAbM0OapiSpwuqGeNV050GtWsUG18aD35L2OvTtxXl+1eUBGUUSgljgzClx5SSS0MYYgYFsYKUk7W4fu4dvMLDK8wKAGxLD7WWHaTLLOTdoEGrOhUq7VP59BXlDWUUSgmDy8gpBsFA4yA9ZpD2ueYmKq8rAHM4Iz3UuDCsvKV9GjCX4698+oryhjIKpYBxbUGJDYLBbWSUWZSyfAXXo6LwCg+vUIHgJbvOsuv0Fbq1rF/i9NDyVhhW1AioHH9FRUEZhVLAsEpwKHZgjClpCtAlJyriKgGwWcTNGOPMofIkH2GgaLxA+fkVFQVlFEoJp6wSjKQpUk7WIu3zn4HNZB05UuFWCQa6taxvl6vIYAyMM4fK0m1kLoNIqXwqKirKKFQEjF1GBdIUaZ+P1VNLy3M2UVGMA8uONIQxxA/KMnPI2BCYS/9UriFFRUUZBRdjHE9wGOMYgpE0RUWsNTDOLqpownIGY2BsCJRbSFHZUEbBxTgrnpByoQVpsT66NIUrVEpdibmqYmNMVRgXLTArS1eRIU6gDIGiMqOMQilQonhC9HxSNu3lQnRdIFnvNVDeXEbWqo4tidCZihMYKG03kaUqYxUnUFQFlFFwISV2HRVkG6Wd8QHKpxidKbeQKSy5ispTnMCSRISKEyiqAsoouJCSuI5SPn6BtHXrAB+yrtXBKzy43BmEw9sSOL3mVIG2UC0a1K5Bw4ya5k8w0yqyPDSgUa4hhUJDGQUXUZKCtZTlK7gw73egJl7tm+Ph37hMXUXm1ETPH79KXYDa7nZnERnjqjiBPYJzyjWkUGgoo+AiHFolFKSepi05D0DjOxpQ7/PfXTE9uzDXX7hp27psybrGhQbuvPlU+akmBs0g/PHfOYB1tVBQriGFwoAyCi7AoVWCcbUyrfBq7kG9MY+6bI62oAvNWXDvLPs6sgxmZhljg6AayisU9qGMgguweZVg3DKzQAI7xWs818/9rmUZ2dE/2dkU7TNc1L1TtLVlecLgMlIGQaGwH2UUnIxdqwTjorQCLaO0z7X2mGWdbmqtz7CxQXBEu8gZWJKY8OsYqAyCQuEAyig4GbtjCUby1xqby1THyNhlZK3PsLm6g9LAUsxAxQcUCsdRRsEF2LRKMO6jXICxBHZZYa03QVm5jcxJUSsXkULhXJRRKCsMsYQCLaOU5Su48M47QOm7jkzJUBcNKpsqUitNt5GSolYoSgdlFMqQlJTgghjCZq5HRQFlU7VsvDowt0KwRbvIEWytJVB1BApF6aCMQhmSFptB1lVN2M4rPJw6d93lUoNgrgjN1opiR2II1h76lmQljFFxAoWidFBGwYnYpHUUPZ+URfNIi7lI1tXqeAQHuUT+2hbFUQPWKoqN22baS1G3T1GUG0ihKF+41CgIIQYBnwNuwLdSyulFjt8MfAfULRjzmpRyvSvn5EpsyTxKWTSPC78lA254tW/msviBqSpkRwXnHG2beWDjBuJjD+HXMVC5fRSKCoLLjIIQwg34AhgAxANRQoi1UspYo2FvASuklP8RQnQE1gP+rppTaWAp8yjl4xcKDELpxA6cITJnvEqwJY5gqiuZcvsoFBUHV64UugInpJSnAIQQy4B7AGOjIAFDXuNNwHkXzqfMSftjKwCNHx1Y7hRPTbFk11neWH0QsG2VULR2QLmGFIqKhyuNQjPgnNF2PNCtyJipwO9CiIlALeB2UxcSQjwJPAlw883OyXpxJiuPrWT9qfUcvXKUgPoBxQcY5CxyruHVvBb1Jn/u9DmYa1tZEgxuow+GB9m0SlDyEgpFxceVRkGY2CeLbD8ILJBSfiqE6AEsEkIESinzC50k5TfANwBhYWFFr1GmrDy2kvci3wM015HJeIJBzqKGD9Tydck8isYQHJWjNu6gZkhBtWYQDC4jJS+hUFR8XGkU4oHmRtt+FHcPPQYMApBSRgohPIAGwCUXzsupGILLU3pMMRlL0Jrl/A0ePlq2UePGLptLSWIIporTrOkamepWpuIHCkXFxpVGIQpoK4RoCSQADwAPFRlzFugPLBBCdAA8gCQXzsklmA0uR88nbd06zRi09sWjsfOb5RSVt3YUQ3HaXTXiCLh2goYXCjqobYDlG0yfU9QYqBWCQlHxcZlRkFLmCiEmAL+hpZvOk1IeFkK8B0RLKdcCLwH/FUJMQnMtjZdSliv3UElIWTSP60la97QWP7mmWY41rSJ76NikDn0unCPpynmoY7quwBhlDBSKyodL6xQKag7WF9k3xejnWKCXK+fgKqwFl43TT+s8+LhL5nB4WwLnj1+ladu6JUo9LVqcpuQkFIqqi6podhBjg1AouGxoqbnub6CmS9JPDS4jQ4VySVcIhsDygGqn9WIzhUJRNVFGoQQE1A9g/qD5hXcaMo08fPBq7+uS9FPjfgeOVCibolvL+nif30YqqthMoajKKKPgChoHQWMfp1/Wlp7J9mJwHd1VI474o4dUSqlCUcVRRsEBrAnfpcSkcT3qlFOa5RgXpRkL2pXUZWTgr1/WMTxxP35ZWrawWiUoFFUbZRQcwKzwXUE3tbTYVoBjzXKKViYbGwJH3EXWpKtbHlVppQqF4h+UUbAT41VCsdoEQze1Wr54hTd2KMBctOagpHEDc9LVl9KySc7I5rpXMzKbB/PSO885dH2FQlG5UEbBTqzJY6ekBHP9yDm8wh2vXHZGvMBYesJUiumoryP1Psul2VZToVCUb5RRsAOLqwS0WIJem2Cn68hZlclQXK3UXJzAkU5qCoWicqOMgh1YWyWkxWYAjvVKcGZlsjW10pJ0UlMoFJUbm4yCEKIGcLOU8oSL51PusdREB8CruYfdBsFZlcnGmEsttbdHgkKhqFpUszZACDEEOAj8UbAdKoRY7eqJVTRSPn6B6+eyHDrXkG3krDRTS9jbI0GhUFQtbFkpvIfWHGczgJQyRgjRxqWzKodYqk1IWb6CC/M0wbs6A/o6dP2mbes6lGFkKuXUVLaRMba21lQoFFUPW4zCDSnlVSEK9cypNEqmtmIunpCyfAUX3nkHgMZ3NLBb1sLYdeQIplJOff1b0qFXRKGGOQYMGUcKhUJhCluMwt9CiJFAtYLeCC8AO107rfKJqXhC2s8/AwUGIdT+h62jriNrKacA7xulnRpQKagKhcISthiFCcAUIB/4Ea0/wuuunFR5w5qshVd4OPVCL9t9XeNVgr1VyraknIJKO1UoFPZhi1G4Q0r5KvCqYYcQ4l40A1ElsJaKSvoFOLMLWvS267qOrBKMDYKllFNDJzXlKlIoFPZgNfsIeMvEvjedPZHyjsVU1GsFHUSDRth8PUdXCdZqEIBCBkG5ihQKhT2YXSkIIe4ABgHNhBCfGR2qg+ZKUhjTojeEPWLT0MPbEtiy+CjgWBqqLfLWym2kUCgcwZL76BJwCMgCDhvtTwdec+WkKgopy1dwPSoKL99soKnN5xncRhGjA5zSIEehUCichVmjIKXcB+wTQiyWUjpWlVXJSVv6LQB1WmTa7Dpy1G2kUCgUpYEtgeZmQoj3gY6Ah2GnlLKdy2ZVUbiWhJdvNvVe/MAm11FJ3EZFU1CLYlyToALMCoXCUWwxCguAacAnwJ3AI6iYwj943GRzLKEkbiNjg2CcgmowBrtOXwG0amUVYFYoFI5ii1HwklL+JoT4REp5EnhLCLHN1RMr76QsX8H1c1l4NfewPhjnuI1MFakZMo26tazPPaHNlHyFQqEoEbYYhWyhaVycFEI8DSQADV07rfKPoZK5Tkfbeh+4QvTOWAJbZRopFApnYItRmATUBp4H3gduAh515aQqCl7NPWyStihJ5bKhLsFULMEQQ1CuIoVC4SysGgUp5a6CH9OBMQBCCD9XTqo8YUriQk9FtdF1ZOsqoajiaXzsIUCrSygaSzCgFE8VCoUzsWgUhBDhQDNgu5QyWQjRCU3u4jagShgGUxIXuuuo0QVsrU+wZZVQNLvIoGukuqcpFIrSwlJF84fAfcB+tODyajSF1I+Ap0tneuWDYhIX6Re0VNQ21+2StjCFKReRKcXToijXkUKhcAWWVgr3ACFSykwhRH3gfMH20dKZWjnGoHV01yyb01HNYbw6MOciModyHSkUCmdjyShkSSkzAaSUV4QQR5RBMMLG+gRzTXRs6YegUCgUpY0lldRWQogfCz6rAX+jbZtks4UQg4QQR4UQJ4QQJvWShBAjhRCxQojDQogljnyJ0sRQn2ALliqYzRWjKRQKRVliaaVwX5HtOfZcWAjhBnwBDADigSghxFopZazRmLZoDXt6SSlThBDlvv5B1zuyUp9gbBDMVTDbu0JQUhYKhcLVWBLE21TCa3cFTkgpTwEIIZahxSlijcY8AXwhpUwpuOelEt7TqZjsuGbQOxpjuVTDFUqoxn0SlJSFQqFwBbYUrzlKM+Cc0XY80K3ImHYAQogdgBswVUq5oeiFhBBPAk8C3Hxz6QVWzXZcszGeYC4N9cDGDcTHHsKvY6Ddc1J9EhQKhSuxpfOaowgT+2SRbXegLRABPAh8K4SoW+wkKb+RUoZJKcN8fX2dPlFLFEpHjZ4PWaklvqYhBdWeWIKhLkGhUChcic0rBSFETSllth3XjgeaG237oaW1Fh2zU0p5AzgthDiKZiSi7LhP6XFwlfZnLfsMU9FK5aS40zZ1TzNG1SUoFIrSwKpREEJ0BeaiaR7dLIQIAR6XUk60cmoU0FYI0RJNRO8B4KEiY35CWyEsEEI0QHMnnbLvK5QyHjeBd2OLQwxpqLVvOsHyd1cUkqsA7Mo4MgSXDUqoqi5BoVC4EltWCrOBu9Ae4Egp9wsh+lk7SUqZK4SYAPyGFi+YJ6U8LIR4D4iWUq4tODZQCBEL5AGvSCkvO/hdXEv0fDizHWhldaghyJyXc4SkSwkW5SossWTXWd5YfRBAl8ZWKBQKV2KLUagmpTyjqWfr5NlycSnlemB9kX1TjH6WwL8KPuUbO11HTdvWJSejBrXqOl6YZnAZfTA8SK0QFApFqWCLUThX4EKSBbUHE4Fjrp1W+SQlJZjrR87hFW7ZfZR2KZqMyweQeUkmW2daQ7mMFApFWWGLUXgGzYV0M3AR2Fiwr8qRFpsBQJ277jI7ZsN/lpIctxb4R+XUEsYFaQaMW2sql5FCoShNbDEKuVLKB1w+k3JGocI1o3iCV3g49UaNNHnO4W0JxG7/E4BOEaMZ9MyDVu9jXJBmQLXWVCgUZYUtRiGqIFV0OfCjlDLdxXMqFxQqXNuxQNtpJZ5gCDDXa9rOJoNgQBWkKRSK8oLV4jUpZWtgGnALcFAI8ZMQokqsHAoVrrXobTUVNe1SNDI3nlp1a5TC7BQKhcL52FTRLKX8S0r5PNAFSAMWu3RWFZDD2xK4HL8XsK9SWaFQKMoTVo2CEKK2EGK0EGIdsBtIAnq6fGYVDGPXka31CEq6QqFQlDdsiSkcAtYBH0spt7l4PuWWlJg0rkedwis83OyYmp7udrmOlHSFQqEob9hiFFpJKfNdPpNyjrV01LRL0WSlxwH2KZ+qOgSFQlGeMGsUhBCfSilfAn4QQhRVN0VKea9LZ1ZesDEdNePyAUDFExQKRcXG0kphecGfdnVcq3TYIG+x4T9LyUqPw8Pb3+54QreW9Z0xS4VCoXAKljqv7S74sYOUspBhKBC6K2lntopDi95w0sfs4ZN7dgDQ+pZeNl9SxRMUCkV5xJaUVFN9Jx9z9kTKM1qQ2XSLh8PbEsjOzMXD29+ugjVQ8QSFQlH+sBRTGIXWA6GlEOJHo0PewFVXT6xckH4BzvxFWqwml20qyGxIRfX0VgVrCoWi4mMpprAbuIzWMe0Lo/3pwD5XTqqs0XWPZE1tRy1fvMIbFwsyG5rp2JuKqlAoFOUVSzGF08BpNFXUKoWueyRrmY0nHN6WwJbFRwH7VwkqyKxQKMorZmMKQog/C/5MEUJcMfqkCCEqfRluWKMw7qe22eMGt1HE6AC7VwkqyKxQKMorlgLNhpabDQBfo49hu3KTfqGgPsE8TdvWJS/7oN6D2R5UkFmhUJRHzBoFoyrm5oCblDIP6AE8BdQqhbmVCYZ4AteSAEhJamM28wjg7x1bANuL1pTekUKhKM/YkpL6E1orztbAQqADsMSlsypDisYT0g6mAJa7rfl1DLS5aE25jhQKRXnGFqOQL6W8AdwLzJJSTgQq9ROtaDzBkryFIyjXkUKhKK/YYhRyhRD3A2OAnwv2VXfdlMo/hlRUhUKhqGzYWtHcD006+5QQoiWw1LXTKt/oBWteR20OMi/ZdZZRX0cSm5jmyqkpFApFibAqnS2lPCSEeB5oI4RoD5yQUr7v+qmVPw5s3MDfO7aQfE6T0T68JQ6wLci8JiaB2MQ0Ojapo+IJCoWi3GLVKAgh+gCLgARAAI2FEGOklDtcPbnSRq9kbhRm8vjfO7Zw4cRJ8vJ9qOnpjl/HQDr0irA5yNyxSR2WP9XDmVNWKBQKp2JLk52ZwGApZSyAEKIDmpEw/eSswOiZR9XqwpkftWrmAg5s3EB87CE8vP1xd7+XiNEBdOpj2xu/qmA2z40bN4iPjycrK6usp6JQVAo8PDzw8/OjenXHQr+2GIUaBoMAIKX8WwhRaYV+whqFcX/CMcBQo/A7F7oEsfe/mnp4bZ9g6jSsa5dBeGP1QUCloZoiPj4eb29v/P39EUKU9XQUigqNlJLLly8THx9Py5YtHbqGLYHmvUKIr4UQvQs+/6GSC+IBhWoUztfzBqBTxGgyUtvYdRlDXcIHw4NUGqoJsrKy8PHxUQZBoXACQgh8fHxKtPK2ZaXwNPA8MBktprAV+LfDd6xgeIWH497QF7+GvmReDwCu0q5rI4vnLNl1VjcGsYlpqi7BCsogKBTOo6T/nywaBSFEENAaWC2l/LhEd6rgXLuaQ3LiVZq2te46Ms40UtlGCoWiImFJJfUNNImL0cAfQghTHdgqLUW7rWWm5wBYXSUYMGQaLX+qh1ollHNq1y6shrtgwQImTJjglGtPnTqVTz75BICdO3fSrVs3QkND6dChA1OnTgVgy5Yt/PXXX3ZfOyYmhvXr15s9vm/fPh5//HGH5l1afPjhh7Rp04aAgAB+++03k2M2bdpEly5dCA0NpXfv3pw4caLQ8VWrViGEIDo6utD+s2fPUrt2bf33n5OTQ9++fcnNzXXNl6kkWIopjAaCpZT3A+HAM/ZeXAgxSAhxVAhxQgjxmoVxI4QQUghRZhlNuhBeAWmxWi2CseaRLasEJXinMMe4ceP45ptviImJ4dChQ4wcqUmnOGIUcnNzrRqFDz74gIkTJ9p1zdIkNjaWZcuWcfjwYTbSOuqkAAAgAElEQVRs2MCzzz5LXl5esXHPPPMMixcvJiYmhoceeohp06bpx9LT05k9ezbdunUrdt6kSZO488479e0aNWrQv39/li9f7povVEmw5D7KllJeA5BSJgkhbAlK6wgh3NA6tg0A4oEoIcRa40ymgnHeaDGLXXbN3MkUS0elFV7h4ZzzqaOnolpDZRqVjHfXHSb2vHMrvjs2rcM7d3dy+Px169Yxbdo0cnJy8PHxYfHixTRq1IipU6dy9uxZTp06xdmzZ3nxxRd5/vnnAXj//fdZuHAhzZs3x9fXl1tuuQWAS5cu0aRJEwDc3Nzo2LEjcXFxfPXVV7i5ufH999/z73//m6tXr5q95/nz54mLi6NBgwZs376dzMxMtm/fzuuvv86oUaP0eaenp3PgwAFCQkIA2L17Ny+++CKZmZl4enoyf/58AgICWLBgAb/88gtZWVlcu3aN//3vf8yYMYMVK1aQnZ3N8OHDeffddwEYNmwY586dIysrixdeeIEnn3zS4d8rwJo1a3jggQeoWbMmLVu2pE2bNuzevZsePQrX8gghSEvT/l2kpqbStGlT/djbb7/N5MmT9dWAgZ9++olWrVpRq1ZhQedhw4bx+uuvM3r06BLNvTJjySi0MurNLIDWxr2apZT3Wrl2V7Tq51MAQohlwD1AbJFx/wd8DLxsz8RdgXE6KrW0lhEGaezaPsFWz1eZRhWTzMxMQkND9e0rV64wdOhQAHr37s3OnTsRQvDtt9/y8ccf8+mnnwJw5MgRNm/eTHp6OgEBATzzzDMcOHCAZcuWsW/fPnJzc+nSpYtuFCZNmkRAQAAREREMGjSIcePG4e/vz9NPP03t2rV5+WXtv0BKSorZe+7Zs4ft27fj6enJggULiI6OZs6cOcW+U3R0NIGBgfp2+/bt2bp1K+7u7mzcuJE33niDH374AYDIyEgOHDhA/fr1+f333zl+/Di7d+9GSsnQoUPZunUrffv2Zd68edSvX5/MzEzCw8O577778PEp3JVw0qRJbN68udh8HnjgAV57rbCzICEhge7du+vbfn5+JCQkFDv322+/ZfDgwXh6elKnTh127twJaO6xc+fOcddddxUyCteuXeOjjz7ijz/+KGYsAgMDibIgha+wbBTuK7Jd/F+eZZoB54y244FCazwhRGeguZTyZyGEWaMghHgSeBLg5ptL4WFbpAVnvabtyEhtQ52G1k9VmUaOU5I3+pLg6elJTEyMvm142IJWRzFq1CgSExPJyckplPs9ZMgQatasSc2aNWnYsCEXL15k27ZtDB8+HC8vLwDduABMmTKF0aNH8/vvv7NkyRKWLl3Kli1bis3H0j2HDh2Kp6en1e+UmJiIr+8/vbBSU1MZN24cx48fRwjBjRs39GMDBgygfn2tsPL333/n999/p3PnzgBkZGRw/Phx+vbty+zZs1m9ejUA586d4/jx48WMwsyZM63OzYCUstg+U5kzM2fOZP369XTr1o0ZM2bwr3/9i2+++YZJkyaxYMGCYuPfeecdJk2aVCxWBNoKrUaNGqSnp+Pt7W3zXKsSlno0byrhtU3lRen/CgrcUTOB8dYuJKX8BvgGICwsrPi/JCejBZlP4RUezrWrOVy9dJ2a3rYHmRWVh4kTJ/Kvf/2LoUOHsmXLFj04DFCzZk39Zzc3N90nbyklsHXr1jzzzDM88cQT+Pr6cvnyZbvuWdQdYg5PT89Cuepvv/02/fr1Y/Xq1cTFxREREWHymlJKXn/9dZ566qlC19uyZQsbN24kMjISLy8vIiIiTObC27NS8PPz49y5f94b4+PjC7mGAJKSkti/f78eMxg1ahSDBg0iPT2dQ4cO6d/jwoULDB06lLVr17Jr1y5WrVrF5MmTuXr1KtWqVcPDw0NPHsjOzsbDw8PSr69KY1ecwE7i0bq2GfADzhttewOBwBYhRBzQHVhbFsFmS0FmQ9aRPbIWispDamoqzZppf+/fffed1fF9+/Zl9erVZGZmkp6ezrp16/Rjv/zyi/52fPz4cdzc3Khbty7e3t6kp6fbfc+i5xnToUOHQlk6xtc09XZt4I477mDevHlkZGj/BxISErh06RKpqanUq1cPLy8vjhw5ortwijJz5kxiYmKKfYoaBNBWPcuWLSM7O5vTp09z/PhxunbtWmhMvXr1SE1N5dgxza37xx9/0KFDB2666SaSk5OJi4sjLi6O7t27s3btWsLCwti2bZu+/8UXX+SNN97QDcLly5fx9fV1WAKiKuBKoxAFtBVCtCyQxXgAWGs4KKVMlVI2kFL6Syn9gZ3AUClltOnLuQ49yNxqsL7PuLFOTU93ZRCqKFOnTuX++++nT58+NGjQwOr4Ll26MGrUKEJDQ7nvvvvo06ePfmzRokUEBAQQGhrKmDFjWLx4MW5ubtx9992sXr2a0NBQtm3bZvM9+/XrR2xsLKGhocUyatq3b09qaqpuNCZPnszrr79Or169TGb4GBg4cCAPPfQQPXr0ICgoiBEjRpCens6gQYPIzc0lODiYt99+u1AswFE6derEyJEj6dixI4MGDeKLL77Azc0NgMGDB3P+/Hnc3d3573//y3333UdISAiLFi1ixowZDt9z8+bNDB482PrAKoww5dczOVCImlLKbLsuLsRgYBbgBsyTUr4vhHgPiJZSri0ydgvwsjWjEBYWJovmI5eURzY8AsD8Bn3h5xc5s6MVNA6ixaKFfPG49obx3LfWQyqjvo4EUEqodvD333/ToUOHsp5GpWTmzJl4e3uX+1qF0uTee+/lww8/JCAgoKyn4lJM/b8SQuyRUlr1xFhdKQghugohDgLHC7ZDhBA2yVxIKddLKdtJKVsbejBIKacUNQgF+yPKYpVQiIOrtD8LMo82/GcpWelxZTcfhaIEPPPMM4XiHlWdnJwchg0bVukNQkmxxX00G7gLuAwgpdyP1omtctKiN3g3BuDkHq1lROtbelk9TRWtKcobHh4ejBkzpqynUW6oUaMGY8eOLetplHtsEcSrJqU8UySjwrxTshJwKi+Ls/k55ORdx8Pbn0HPPGj1HEONgipaUygUFRlbVgrnhBBdASmEcBNCvAgcc/G8yoyUmDTiUi+TIiVSNLCpaM2AqlFQKBQVHVuMwjPAv4CbgYtoqaN26yCVe9IvwJntxJzM50ptT9w9GlPTeyRhdw2xeqpyHSkUisqCVfeRlPISWjpp5eZaEgBnPW8CIK9aB262QQAPlOtIoVBUHmzJPvqvEOKbop/SmFxpc9jzGdKqN0a4++FeM9iuCmblOqq4uLm5ERoaqn/i4uKIjo7WBe5s4erVq3z55Zf6dlxcHJ6ennTu3JkOHTrQtWvXQoVoa9euZfr06Ravef78eUaMGAEUlsmeP3++PtcaNWoQFBREaGioyQIxR3n44Yf56aefrI67du0aERER5OfnO+3ezmb9+vUEBATQpk0bszUOcXFx3HbbbQQHB9OvXz/On9fqbE+fPq3LdgcGBvLf//632LmDBw8upJ314osvsnXrVtd8mdJASmnxA4wy+oxD67Hwb2vnuepzyy23SGcz/tfx8uXpz8o5T22Snz70lJz94CPy0NZ4m88f+dVfcuRXfzl9XlWB2NjYsp6CrFWrls1jb9y4YXL/6dOnZadOncxunzx5UoaEhMh58+Y5NMf58+fL5557rtj+Fi1ayKSkJIeuaYnRo0fL1atXWx03a9YsOWfOHJuvm5+fL/Py8koyNbvIycmRLVu2lHFxcTIrK0sGBgbKo0ePFhs3bNgw+f3330sppfztt9/k+PHjpZRSZmVlyaysLCmllKmpqbJ58+by4sWL+nnLly+XDz74oAwJCdH3nThxQg4aNMiVX8sqpv5fodWHWX3GWl0pSCmXG32+A+4FOrrOTJUuBokLn0uB5GYfQObGUyf/is0VzCqe4ER+fQ3mD3Hu51fH3p63bNnCXQW9NKZOncqTTz7JwIEDGTt2LIcPH6Zr166EhoYSHBzM8ePHee211zh58iShoaG88sorxa7XqlUrPvvsM2bPng0UbuRz8uRJunfvTnh4OFOmTNGF3OLi4ggMDCQnJ4cpU6awfPlyk9XLxiQnJzN06FCCg4Pp2bMnhw4dAuCtt95i1qxZ+rj27dsTHx8PaCuP4OBgQkJCeOSRR/QxmzdvpmfPnrRq1UoXwivK4sWLueeeewBIS0vjtttuo0uXLgQHB/Pzzz8DcOLECQIDA3n66afp0qULiYmJ/Prrr/To0UOvAL927RqgidmFh4fr46WNxbXm2LlzJx06dKBFixbUrFmTkSNHsmbNmmLjYmNj6d+/PwD9+/fnxx81QWiD4CFomkn5+fn6nNLS0pg9ezavv/56oWu1bt2axMREkpKSSjT3ssIRmYuWQAtnT6SsMEhc1M/Px71A1fvmajVsPl/FEyo+Buns0NBQhg8fbnLMnj17WLNmDUuWLOGrr77ihRdeICYmhujoaPz8/Jg+fTqtW7cmJibGrIuiS5cuHDlypNj+F154gRdeeIGoqKhignCg5de/9957jBo1ipiYmEJ9E4ry9ttv061bNw4cOMDUqVMZP368xe++f/9+PvroI7Zs2cL+/ft1iW7Q+j/s2LGDn376qdiDDyArK4v4+Hj8/PwATYRvzZo17N27l40bNzJp0iR9bGxsLI899hj79u2jevXqTJ8+nU2bNrF3716Cg4P5/PPP9d9FVFQUBw8eJDU1lQ0bNhS778KFCwu5+wwfU7+XhIQEmjf/R4LNnDx3SEiILiX+ww8/kJaWRmpqKqAZ5+DgYFq0aMFbb71Fo0aaW/nNN9/k1VdfNala27lzZ4e66ZUHrAaahRAp/KNuWg24AjjPeVkOGHShLzcyOyDzD1A/I5NWBTLCtqLiCU7iTss+dldRVDrbFMaS1T169OD9998nPj6ee++9l7Zt29p0H3NvvZGRkbr//qGHHtL7KjjC9u3b+eWXXwBNx2j8+PH6W7gp/ve//zFq1ChdOru+0b/9YcOGIYQgODjY5IP00qVLhcZLKXn11VfZvn071apV49y5cyQnJwPa23N4eDgAf/31F7GxsfTs2RPQKo179+4NaK03Z8yYQVZWFsnJydxyyy2FuqcBjB071uYiNFO/c3Py3BMmTGDu3LnceuutNG7cGHd37fHo7+/PgQMHSEhIYNiwYYwYMYIzZ84QHx/P3XffXaw9KEDDhg31uERFw6JRENpvLwQw/IvIlyVdz5VDfJK1IJF72iWgcAtOSxhcR91a2mdEFBUPY3nphx56iG7duvHLL79wxx138O2339KqVSur19i3b5/LdZ6K/vc0bLu7uxcKBhtkr6WUZqW+jSUyTP23LyrPvXDhQlJTU9m7dy/u7u74+fnpx4vKcw8aNIhFixYVut7169eZMGECe/fupVmzZrz11lsm5bkXLlzIZ599Vmx/QEBAMdeaLfLcAM2aNdNdZGlpafzwww/FZMqbNWtG+/bt2b59O/Hx8ezatQt/f39yc3O5dOkS/fv3Z9MmreNAVlaWTX0vyiMW3UcFBmC1lDKv4FPpDEKDuLZ4p7emZvpGrtW4QQ1/f10d1RKq9WbV5dSpU7Rq1Yrnn3+eoUOHcuDAAYsy1qC5IF5++WWTPZO7d++uuy6WLVtm8nxr1zfQt29fFi9eDMDGjRvx8/OjVq1a+Pv7s2fPHkBrzWl4UN5+++0sW7aMK1e0uJjhT1vw9fUlKyuLnBxNXj41NZWGDRvi7u7OH3/8YXJ1AdCzZ0/+/PNPTp06BWgZTMePHyczM5Nq1arRoEED0tPT9d9JUcaOHWtSnttUrKV79+7ExsZy5swZsrOzWbFiRaHGRwaSk5N1w/fBBx/oIoLx8fG6Ybp8+TKRkZG0a9eOCRMm6K1Rt2zZQseOHXWDAHDs2LFCne8qErbEFHYLIbq4fCZlhM85fwDyc44CEDT8fpvOU603qy7Lly8nMDCQ0NBQjhw5wtixY/Hx8aFXr14EBgbqgeaTJ0/qKakjR45k4sSJhQK5BmbNmsVnn31G165dSUxM5Kabbio2xpJMtjHvvfcef/31F8HBwUyZMoX58+cDcP/993Px4kU6d+7M3Llz9ZVNcHAwkydPpm/fvmaD5Jbo37+/7jsfM2YMf/31F2FhYaxcudKsW61Ro0bMnTuXUaNGERISQs+ePTl27Bg+Pj6MGzeOwMBAhg8frjfWKQnVq1dn9uzZDBgwgI4dO/Lwww/rgnhvvvmmnua7adMm2rVrR7t27bhy5Yqe3nvo0CHCw8MJCQmhX79+vP7663TsaDnPJjs7m7i4OL17XUXDrHS2EMJdSplboJDaATgJXEPrqCallGViKJwtnT39zSWQc40mJ1dAjVqMW2Y9N9uwSujWsr6SyS4hSjpbc5t4enoihGDZsmUsXbrUZIZMeSQqKoovv/xSNz4KWLlyJbGxsbzzzjtlNoeSSGdbiinsBroAw0o2vXJOXg610vPIz87H1qQjlXGkcCZ79uxhwoQJSCmpW7cu8+bNK+sp2Ux4eDi9e/cmPz+fatVc2bOr4iClLJR5VdGwZBQEgJTyZCnNpdQ5vC0B76s343Fd0/dzL9KE3BIq40jhLPr06cP+/fvLehoO89hjj5X1FMoVI0daj0mWZywZBV8hxL/MHZRSFg//VzCO7b4IgHfGHjK9vXFv6Gv1HJVxpFAoKjOW1ntuQG3A28ynUpAvTnDThf0ky1ybxivXkUKhqMxYWikkSinfK7WZlAFJmUnUvJ7P+XqajevQK8Km85TrSKFQVFYsrRRMV7RUIq5kXgYgr6bAr2MgwbcPKuMZKRQKRdliySj0L7VZlCFuCKrbYP+W7DrLqK8jiU1MK4VZKUoTg3R2SEgIXbp0sapZExcXx5IlS/RtY3G7osybN4+goCCCg4MJDAzUU00XLFjgkAzCTz/9RGxsrL49fvx4Vq1aZfd1LDF16lQ++eQT/fotW7YkNDSULl26EBkZCUBERATOTA23RnmXo75y5QoDBgygbdu2DBgwgJSUFJPjXn31VQIDAwkMDDRZbzJx4kRdEBHg7Nmz9OvXj86dOxMcHKzXVRw8eNCqrpWjmDUKUsrKL/2ZlwM2FmmviUkgNjGNjk3qqHhCJcOgfbR//34+/PBDk+JvxhQ1CuaIj4/n/fffZ/v27Rw4cICdO3cSHKy1d3XEKOTm5hYzCqXBjBkziImJYfr06Tz11FOlem/QHrg7d+6kb9++Np+Tm2tbjNBZTJ8+nf79+3P8+HH69+9vslfGL7/8wt69e4mJiWHXrl3MmDGDtLR/XjKjo6O5evVqoXOmTZvGyJEj2bdvH8uWLePZZ58FICgoiPj4eM6ePev072JVEK+yYkhHzc77g6vVa+Jnwzkdm9RRxWou5KPdH3HkSnEV0ZLQvn57Xu36qs3j09LSqFevHqDlm0+ePJlff/0VIQRvvfUWo0aN4rXXXuPvv/8mNDSUcePGUa9ePc6fP8+gQYM4efIkw4cP5+OPP+bSpUt4e3vrb361a9emdu3arFq1iujoaEaPHo2npyeRkZHMmDGDdevWkZmZSc+ePfn6668RQhAREUHPnj3ZsWMHAwcOZO3atfz5559MmzbNrAyEuXlnZGRwzz33kJKSwo0bN5g2bZoue/3++++zcOFCmjdvjq+vL7fcckux6/bt27eQ+NvKlSt59tlnuXr1KnPnzqVPnz7ExcUxZswYXYRvzpw59OzZk8TEREaNGkVaWhq5ubn85z//oU+fPvz++++88847ZGdn07p1a+bPn1/oTRlg1apVDBr0j2v3vffes/q7Gjp0KGPHjuXpp5/WH5yzZs2iV69e7N69mxdffJHMzEw8PT2ZP3++XuXsKGvWrGHLli0AjBs3joiICD766KNCY2JjY7n11ltxd3fH3d2dkJAQNmzYwMiRI8nLy+OVV15hyZIlhWTKhRC64UhNTS2k23T33XezbNkyJk+eXKK5F6XKVpsY0lEN8ha2BpkVlQ+DdHb79u15/PHHefvttwH48ccf9RXExo0beeWVV0hMTGT69On06dOHmJgYvUjJoL1z8OBBli9fzrlz5wgJCaFRo0a0bNmSRx55hHXr1gEwYsQIwsLCWLx4MTExMXh6ejJhwgSioqI4dOgQmZmZei8C0Lq6/fnnn7z55psMHTpUf3Nv3bq1ye9jbt4eHh6sXr2avXv3snnzZl566SWklOzZs4dly5axb98+fvzxR6Kiokxed926dQQFBenbubm57N69m1mzZvHuu+8CmjroH3/8wd69e1m+fLnevW7JkiXccccd+rxCQ0NJTk5m2rRpbNy4kb179xIWFmZS6G7Hjh2FjJQtv6uXXnqJF154gUmTJhEVFcUPP/yg6xm1b9+erVu3sm/fPt577z3eeOONYvdMT083Kc8dGhpqcqV28eJFmjRpAkCTJk24dOlSsTEhISH8+uuvXL9+neTkZDZv3qxrUM2ZM4ehQ4fq1zAwdepUvv/+e/z8/Bg8eDD//ve/9WNhYWFs27at2H1KSpVdKQCke5/kpkupNHDzVkHmcoA9b/TOxFg6OzIykrFjx3Lo0CG2b9/Ogw8+iJubG40aNeLWW28lKiqKOnXqFLtG//79dc2ijh07cubMGZo3b86GDRuIiopi06ZNTJo0iT179jB16tRi52/evJmPP/6Y69evc+XKFTp16sTdd98NYLF/ginMzfvOO+/kjTfeYOvWrVSrVo2EhAQuXrzItm3bGD58OF5eXgDFBONeeeUVpk2bhq+vL3PnztX333vvvQDccsstxMXFAXDjxg0mTJhATEwMbm5uHDumFYaGh4fz6KOPcuPGDYYNG0ZoaCh//vknsbGx9OrVC9AktHv0KL4ST0xMxNf3nxoiW39XGzduLPQAT0tLIz09ndTUVMaNG8fx48cRQnDjxo1i9/T29rYqp24vAwcOJCoqip49e+Lr60uPHj1wd3fn/PnzrFy5Ul9pGLN06VLGjx/PSy+9RGRkJGPGjOHQoUNUq1bNZfLcVdcopF+A/NL1OyrKPz169CA5OZmkpCS7un4Zy0y7ubnpPm0hBF27dqVr164MGDCARx55pJhRyMrK4tlnnyU6OprmzZszderUQpLRRSWcrWFu3osXLyYpKYk9e/ZQvXp1/P399fuYk88GLaZg6BVtjOE7G3/fmTNn0qhRI/bv309+fj4eHh6A5nraunUrv/zyC2PGjOGVV16hXr16DBgwgKVLl1r8PsYS3fb8rvLz84mMjCwmYT1x4kT69evH6tWriYuLIyIiotg909PT6dOnj8n5LFmypJgoXqNGjUhMTKRJkyYkJibSsGFDk+e++eabvPnmm4Amwd62bVv27dvHiRMnaNOmDaBpYbVp04YTJ04wd+5cvdFQjx499D4TDRs2dJk8d5V1H3EtiVrXBB7ZZT0RRXniyJEj5OXl4ePjQ9++fVm+fDl5eXkkJSWxdetWunbtarOM9fnz59m7d6++HRMTQ4sWWtNC42sYHmoNGjQgIyPDYjaRLfc2N2+DtHX16tXZvHkzZ86c0cevXr2azMxM0tPTdTeXI6SmptKkSROqVavGokWLyMvLA+DMmTM0bNiQJ554gscee4y9e/fSvXt3duzYoccprl+/rq8sjOnQoYM+xp7f1cCBA5kzZ46+bXjzT01NpVkzLVlkwYIFJs81rBRMfUyppA4dOpTvvvsOgO+++06P1RiTl5fH5ctaGvyBAwc4cOAAAwcOZMiQIVy4cIG4uDji4uLw8vLSv+/NN9+sS3L//fffZGVl6asmV8lzV82VQvR8yErHK1N707FH80hR+TDEFEB7y/7uu+9wc3Nj+PDhREZGEhISghCCjz/+mMaNG+Pj46MHCsePH68Hpoty48YNXn75Zc6fP4+Hhwe+vr589dVXgJbq+fTTT+uB5ieeeIKgoCD8/f31DmWmeOCBB3jiiSeYPXu2/kB86qmnePHFFwFo3rw5f/31l8l5jx49mrvvvpuwsDA9hgLofZJDQ0Np0aKF2TdkW3j22We57777WLlyJf369dPf3Lds2cKMGTOoXr06tWvXZuHChfj6+rJgwQIefPBBsrO1t7Np06bRrl27QtccMmQIX3/9NY8//jh169a1+Xc1e/ZsnnvuOYKDg8nNzaVv37589dVXTJ48mXHjxvHZZ59x2223OfxdjXnttdcYOXIkc+fO5eabb2blypWAllH01Vdf8e2333Ljxg39d1unTh2+//57vbubOT799FOeeOIJZs6ciRCCBQsW6Ku6zZs3M2TIEKfM3xiz0tnlFadIZ88fwuq9d3Al3YOcjFXUD+rCqHfMt4JUUtmuQ0lnK2yhd+/e/Pzzz9StW7esp1IuyM7O5tZbb2X79u0mDUtJpLOrrvvI4yZs+fqqw5pCUfZ8+umnLsnJr6icPXuW6dOnW11pOIJL3UdCiEHA52jiet9KKacXOf4v4HEgF0gCHpVSnnHlnOxFdVhTKMoeZ3Rhq0y0bdvWbGe7kuKylYIQwg34ArgT6Ag8KIQoGqHZB4RJKYOBVcDHrppPUZLII89GZVQlgKdQKKoKrnQfdQVOSClPSSlzgGVAoZC8lHKzlPJ6weZOsKmw2ClcQcuKqF6tutkxht4JCoVCUVVwpVFoBpwz2o4v2GeOx4BfTR0QQjwphIgWQkQnJSU5bYK5efGkWsjPVr0TFApFVcOVRsHU09ZkqpMQ4mEgDJhh6riU8hspZZiUMsy4srGk5ORpNsuSxIVyHSkUiqqEK41CPNDcaNsPKFaTLYS4HXgTGCqlLJVSssOXgvBO13RjGgh3kxIXynVUdSgqwAbw1VdfsXDhQkAraAsNDaVz587s2bOHL7/8stDYw4cPc9ttt9GuXTvatm3L//3f/+lVxdnZ2dx+++2EhoayfPlytm3bRqdOnQgNDSUzM7PQdTIzM7n11lv1gq/yyIYNGwgICKBNmzYmlUBBK1Tr378/wXXz164AAB6wSURBVMHBREREEB8fD2jFYz169KBTp04EBwcXko5+7LHHCAkJITg4mBEjRpCRkQFomkDz5893/RdT/IOU0iUftMymU0BLoAawH+hUZExn4CTQ1tbr3nLLLbJERM2TP074XM55apP8z7BhcsGoe0wOG/nVX7LFqz/LxTvPlOx+CovExsaW9RRkrVq1LB7/8MMP5ZQpU6SUUp4+fVp26tRJP3b9+nXZqlUr+dtvv0kppbx27ZocNGiQnDNnjpRSysjISNm3b199/FNPPSXnzZtn8j5z5syRs2bNsnne+fn5Mi8vz+bxJSU3N1e2atVKnjx5UmZnZ8vg4GB5+PDhYuNGjBghFyxYIKWUctOmTfLhhx+WUkp59OhReezYMSmllAkJCbJx48YyJSVFSillamqqfv6kSZPkhx9+KKXUfp+hoaEu/V6VEVP/r4BoacMz1mUpqVLKXCHEBOA3tJTUeVLKw0KI9womtxbNXVQbWFlQpXdWSjnU7EWdwcFVwB2IjI1cq3EDb59GZocq11HpcuGDD8j+27nS2TU7tKexCRVMa0ydOpXatWvTsWNHZs2ahZubG1u3bqVRo0acPHmS0NBQBgwYQPv27enVqxcDBw4EwMvLizlz5hAREcH999/Pww8/TFJSEqGhoTzzzDOsWLGC3377jY0bN7J48eJC91y8eLHep8GczHVcXBx33nkn/fr1IzIykp9++omjR4+alJ82JzHtKLt376ZNmza0atUK0Kqr16xZU0z2ITY2lpkzZwLQr18/hg0bBlCoUrlp06Y0bNiQpKQk6tatq4sMSinJzMzU5+nl5YW/vz+7d++ma9euDs9dYTsuLV6TUq6XUraTUraWUr5fsG9KgUFASnm7lLKRlDK04ONag2DA4yZy8rQgctDw+wsdUh3WFMYMHjyYp59+mkmTJrF582amT59O69atiYmJYcaMGRw+fLhY74HWrVuTkZGBh4cH3377rS6z/dRTT+nS10UNQk5ODqdOncLf3x/ArMw1wNGjRxk7diz79u2jVq1aZuWnLUlMG1i8eLFJeWhTAngJCQk0b/6PR9jPz4+EhIRi40JCQvReD6tXryY9PV3X/DGwe/ducnJyCsl/P/LIIzRu3JgjR44wceJEfb+rJKIVpqma2kcFeOXlFIsnqA5rZYcjb/RljZTS7Nu3PW/lycnJhSQcpJQmZa4BWrRoQffu3QHYuXOnWflpSxLTBkaPHs3o0aNt/q62fMdPPvmECRMmsGDBAvr27UuzZs0KVd4mJiYyZswYvvvuO6pV++e9dP78+eTl5TFx4kSWL1/OI488Amg9Go4cce4KUmGeKm0UzKE6rClspVOnTsV6B586dYratWvj7e1t83WM5aHBssy1sTy0lNKk/LQ1iWnj+8yYUTzpr02bNsUUSP38/PSmMKC1GzXuBGagadOm/Pjjj4DmBvvhhx/0XhNpaWkMGTKEadOm6YbNGDc3N0aNGsWMGTN0o+AqiWiFaaqu9pFC4QBFpatHjx7N9u3b2bhxI6BlED3//PN2t0isV68eeXl5+oPbnMx1UczJT9sqMT169GiT8tCmxoeHh3P8+HFOnz5NTk4Oy5YtK9aQB7RVT35+PgAffvghjz76KKCtYoYPH87YsWO5//5/3LZSSn3+UkrWrVunK7iC6ySiFaapkkYhLeMUefmXi+1XaahVk+vXr+Pn56d/TLWENODj40OvXr0IDAzklVdewdPTkzVr1jBt2jQCAgIICgoiPDycCRMm2D2PgQMHsn37dkB7WEdHR+ttO40fksYYy08HBwfTvXt3jhw5UkhietiwYRYlpm3F3d2dOXPmcMcdd9ChQwdGjhxJp06dAJgyZQpr164FNJnsgIAA2rVrx8WLF/WmMitWrGDr1q0sWLBAj13ExMQgpWTcuHEEBQURFBREYmIiU6ZM0e+7Y8cObr/99hLPX2EbVU86e/4QvtjckKzsJJpmpfHgmn+W/qO+jmTX6StK/K4UUdLZ/7Bv3z4+++wzFi1aVNZTKTeo34ljKOlsB3Cr5kP93OI+VpWGqigrOnfuTL9+/cp18Vppk5yczP/93/+V9TSqFFXSKNxAQpEVknIdKcoDjz76KG5ubmU9jXLDgAED9DRdRelQtYxC9Hw27K5OXnYyAD6e/7ThVOJ3CoVCUdWMwsFVnEzX0gTr5At8PTVxPcMqQbmOFApFVadqGQWAau6I6r70OLAbUO02FQqFwpgqZRQOXwoiO68m1fK0HOo6d92l2m0qFAqFEVXKKBxL1lK03PMyONvam3qjRgIq46iq4+bmRmhoKIGBgdx9991cvXrV4WtFRERQopRpK1QWee2zZ8/Sr18/OnfuTHBwMOvXrweKazFVq1aNmJgYrl+/zpAhQ2jfvj2dOnXitdde06+l5LWdS5UyCgA13bJxy9cqUlXGkQI0iYmYmBgOHTpE/fr1+eKLL8p6SmaZN28e9957r80ZSlJKvbq4NMjLy+O5557j119/JTY2lqVLlxIbG1ts3LRp0xg5ciT79u1j2bJlPPvss0DhCutFixbh7+9PaGgoAC+//DJHjhxh37597Nixg19/1Ro1Pvroo8yePbvUvmNlp0prH6mMo/LFthXHSD6X4dRrNmhemz4j21kfWECPHj04cOCAvj1jxgxWrPj/9s49rKoy3+Ofn6AiqRzTsfCgoo9pgbARO5pdvOR4Ny+NkzFTyjRmcvKuzdiTzuRUT2aaSlIOpoNWo5SjHWdO5gUhy1CRIyCaDl6oSEYRFMRAubznj7VYw2UjG+W+38/z7OfZa613vev32xv2b72/913f3yfcuHGDiRMnsnTpUlJTUxk5ciT9+/fn2LFj9OzZk82bN+Pu7l6mr5CQEOLi4sjLy2PSpEksXboUgLi4OObMmcP169dp2bIlUVFRuLu7s2jRImJiYrhx4wYvvvgiL7zwQgX7moq8toiQk2MoEWdnZ9vVUNqyZQtBQUGAIaE9ZMgQAFq0aEFgYKBVvEfLa9csTjdSKI9OHWlKKCoqIioqytLz2bNnDykpKRw5coSEhATi4+Mt8bvTp08zffp0kpKSaNu2bYVqbABvvPEGR48eJSkpiS+//JKkpCRu3rzJ5MmTWbNmDYmJiezbt49WrVqxYcMGPDw8iIuLIy4ujvXr13P+/Pky/TUlee1XX32Vjz76CC8vL0aPHs27775boU1kZKQVFEpz9epV/v73vzN06FBrn5bXrjmceqSgaVhU546+JsnLyyMgIIDU1FT69u3LsGHDACMo7Nmzhz59+gDGnXlKSgpdunShc+fOllz1M888Q2hoKAsXLizT7yeffEJ4eDiFhYWkp6dz8uRJRARPT09Li6ikuMyePXtISkqyhOiys7NJSUmhW7duVn9NSV57y5YtBAcHs2DBAmJjY3n22WdJTk62pLQPHz6Mu7t7BSG8wsJCgoKCmD17tjUaAS2vXZM4VVDIyT1H/o0M3KtuqnEiSuYUsrOzGTt2LGFhYcyePRulFC+//HKFNE5qamqFH7ry2+fPn2fFihXExcXRrl07goODyc/Pr7T+glKKd999lxEjRtzSzqYir71hwwa++OILwEjZ5efnc/nyZTp27AjA1q1b7Y4Spk+fzn333cfcuXMr+KLltWsGp0of5V7/HgC3/NtfXaJpunh4eBAaGsqKFSsoKChgxIgRbNy40Soi/+OPP3Lp0iXAWD0TGxsLGHe9jz76aJm+cnJyuOuuu/Dw8ODixYvWpOj999/PhQsXiIuLA+DatWsUFhYyYsQI3n//fQoKCgBDLvr69etl+mxK8tpdunQhKioKMMTb8vPz+dnPjIdJi4uL+fTTT3n66afLnLN48WKys7NZvXp1hf60vHbN4VRBAaC4ZXva3LxGc2mrVx5pKtCnTx9sNhtbt25l+PDh/OpXv2LAgAH4+fkxadIkq5bCAw88wKZNm/D39ycrK4uQkJAy/dhsNvr06YOvry/PPfeclbpp0aIFkZGRzJo1C5vNxrBhw8jPz2fatGn4+PgQGBhI7969eeGFFygsLKxgX1OR1165ciXr16/HZrMRFBRERESENYI6cOAAXl5eZdJDaWlpvPHGG5w8eZLAwEACAgL44IMPrONaXrvmcCrp7LApv+FGUTGj4o+Q6tWLkAef1w+t1TONUTo7NTWVsWPHkpycXOfX1lLSFdGfSUW0dHY1aGY+83O8V3+98kjT6NDy2hXR8to1i1NNNJdw1rs177Xxp399G6JplHh7e9fLKKGEkvKWGoOS1WKamsHpRgoABab2kX5oTaPRaMrilEEB9ENrGo1GYw+nCgqqSNGskU2sazQaTV3idEEBINbHo54t0Wg0moaJUwUFgGIRvgxoV99maBoQJdLZNpuNwMBAvvnmm1u2T01NtUTpACIiIpg5c6bdtt7e3vj5+eHv78+gQYMqfcCs/DmXL1+unhM1QGXXVUrx+OOPWwJ2DZH4+Hj8/Pzo0aOH9TR6ebKzs3niiSew2Wz4+vpactvfffcdffv2JSAgAF9fX9atW1fh3HHjxpV5OG7hwoXs37+/9hyqR5wuKADk5BXUtwmaBkSJzEViYiJvvvkmL7/88i3blw8KVREdHU1SUhKDBw/m9ddfv1Nz65zPP/8cm81m6TQ5Ql0vmQ0JCSE8PJyUlBRSUlIsCY3ShIWF4ePjQ2JiIjExMSxYsICbN2/i6enJN998Q0JCAocPH2bZsmVcuHDBOm/79u20bt26TF+zZs2qtFZEY8dplqReifzEuHswZWf0yqOGR3REOJe+O1ejfXbs2p0hwdMdbp+Tk0O7dsZIUinF7373O3bt2oWIsHjxYiZPnsyiRYv49ttvCQgIYOrUqbRr144LFy4wcuRIzp49y8SJE1m+fHmFvgcMGFBG9/+jjz4iNDSUmzdv0r9/f957770KdRIqa1OZLPeiRYvYuXMnrq6uDB8+nBUrVpCRkcGMGTP4/ntD5mX16tU88sgjZGZmEhQUREZGBv369bN7dw2G9tH06f/+DCdMmMAPP/xAfn4+c+bMsY61bt2a+fPns3v3blauXEmrVq2YP38+ubm5dOjQgYiICDw9PVm/fj3h4eHcvHmTHj168OGHH1aQHa8O6enp5OTkWCJ/U6ZM4bPPPmPUqFFl2okI165dQylFbm4ud999N66urpYIH8CNGzfK1J/Izc3lnXfeITw8nKeeesra37VrVzIzM/nXv/7Fvffee9u2N0ScZqRw/It/UujqTqGL0LnFI3rlkcaiRCX1/vvvZ9q0aSxZsgQw7hBLRhD79u3jpZdeIj09nWXLlvHYY4+RkJDAvHnzAEhISCAyMpLjx48TGRlZRhSuhC+++IIJEyYAxhOnkZGRHDx4kISEBFxcXPj444/LtL9VG3uy3FlZWezYsYMTJ06QlJTE4sWLAZgzZw7z5s0jLi6Ov/3tb0ybNg2ApUuX8uijj3Ls2DHGjRtnBY3yHDx4kL59+1rbGzduJD4+nqNHjxIaGkpmZiYA169fp3fv3hw+fJj+/fsza9Ystm3bRnx8PM899xyvvPIKAE8++SRxcXEkJibywAMPsGHDhgrXjI6OtivX/fDDD1do++OPP+Ll5WVtVybXPXPmTL799ls6deqEn58fa9assQLCDz/8gL+/P507d+b3v/+9JeK3ZMkSFixYYDdoBQYGcvDgQbufWWPGaUYKP4oXkMaNltdoVzSwvs3R2KE6d/Q1SUn6CCA2NpYpU6aQnJzM119/TVBQEC4uLtxzzz0MGjSIuLg4u2mUoUOH4uFhLGDw8fHhu+++s+oKDBkyhIsXL9KxY0crfRQVFUV8fLylN5SXl2cphJZwqzb2ZLl9fHxwc3Nj2rRpjBkzhrFjxwKwb9++MtXPcnJyuHbtGgcOHGD79u0AjBkzxhohlScrK4s2bdpY26GhoezYsQMwfkxTUlJo3749Li4u/OIXvwCMeg7JycnWg2VFRUV4enoCkJyczOLFi7l69Sq5ubl2lWGHDBlifSdV4ahc9+7duwkICGD//v2cPXuWYcOG8dhjj9G2bVs6d+5MUlISFy5cYMKECUyaNIn09HTOnDnDqlWrSE1NrdBfx44dy6SZmgq1GhREZCSwBnABPlBKLSt3vCWwGegLZAKTlVKptWJM0U2aFf1ErutPOnWkqZQBAwZw+fJlMjIyKk2n2KNly5bWexcXlzJidtHR0dx1110EBwfzhz/8gXfeeQelFFOnTuXNN9+stM/K2lQmy+3q6sqRI0eIiopi69atrF27lv3791NcXExsbKxdaWlHqqy5urpSXFxMs2bNiImJYd++fcTGxuLu7s7gwYMttVU3Nzcr/aWUwtfX11KSLU1wcDCfffYZNpuNiIgIYmJiKrSJjo62RmGlcXd3r7AQwMvLy6rCBpXLdf/lL39h0aJFiAg9evSgW7dunDp1qky1tk6dOuHr68tXX31lyZJ7e3tTWFjIpUuXGDx4sGVvU5XrrrX0kYi4AGHAKMAHCBIRn3LNfgtcUUr1AFYBb9WWPcX5iRSpLIqbNdepI02lnDp1iqKiItq3b8/AgQOJjIykqKiIjIwMDhw4QL9+/WjTpo2lluoorVq1YvXq1WzevJmsrCyGDh3Ktm3bLCnurKysCiuTKmtTmSx3bm4u2dnZjB49mtWrV1t32sOHD2ft2rVWvyX7Bw4caKWjdu3axZUrV+za3qtXL86dM+Z6srOzadeuHe7u7pw6dYpDhw5Vek5GRoYVFAoKCjhx4gRgyIV7enpSUFBQIWVWQslIofzL3sowT09P2rRpw6FDh1BKsXnzZsaPH1+hXWm57osXL3L69Gm6d+9OWloaeXl5AFy5coWDBw/Sq1cvQkJCuHDhAqmpqXz99df07NmzTABrqnLdtTlS6AecUUqdAxCRrcB4oHQV7/HAq+b7bcBaERFVC9KtVzkNuPF9J8cKnmuch5I5BTDucDdt2oSLiwsTJ04kNjYWm82GiLB8+XLuvfde2rdvj6urKzabjeDg4ErTLuXx9PQkKCiIsLAwlixZwuuvv87w4cMpLi6mefPmhIWF0bVrV6u9j4+P3TYPPfSQJcvdvXt3S5b72rVrjB8/3irms2rVKsBI97z44ov4+/tTWFjIwIEDWbduHX/84x8JCgoiMDCQQYMG0aWL/ZulMWPGEBMTQ48ePRg5ciTr1q3D39+fXr16WdXdytOiRQu2bdvG7Nmzyc7OprCwkLlz5+Lr68trr71G//796dq1K35+ftUOsPZ4//33CQ4OJi8vj1GjRlmTzCXLS2fMmMGSJUsIDg7Gz88PpRRvvfUWHTp0YO/evSxYsAARQSnFwoUL8fPzu+X1CgoKOHPmDA8+WKXoaKOj1qSzRWQSMFIpNc3cfhbor5SaWapNstkmzdw+a7a5XK6v6cB0gC5duvR1ZK13eV59aSTZqgDXYU/x9oiKBdE19UNjlM52NtLT05kyZQp79+6tb1MaDCW1sRuqOuudSGfX5kjBXrKyfARypA1KqXAgHIx6CrdjzKtvV1y3rNFoqsbT05Pnn3+enJycaj2r0JQpLCxkwYIF9W1GrVCbQSEN6Fxq2wsoP1Vf0iZNRFwBD0CXQ9NoGhil1+hr4Je//GV9m1Br1OZzCnHAfSLSTURaAE8DO8u12QlMNd9PAvbXxnyCpmGjv3KNpua40/+nWgsKSqlCYCawG/gW+EQpdUJE/iQiJZW8NwDtReQMMB9YVFv2aBombm5uZGZm6sCg0dQASikyMzNxc3O77T6cqkazpuFRUFBAWlqatdZdo9HcGW5ubnh5edG8efMy+xvCRLNGUyXNmzenW7du9W2GRqMxcRrtI41Go9FUjQ4KGo1Go7HQQUGj0Wg0Fo1uollEMoDqP9Js0AGo+5JW9Yv22TnQPjsHd+JzV6XUz6pq1OiCwp0gIkcdmX1vSmifnQPts3NQFz7r9JFGo9FoLHRQ0Gg0Go2FswWF8Po2oB7QPjsH2mfnoNZ9dqo5BY1Go9HcGmcbKWg0Go3mFuigoNFoNBqLJhkURGSkiJwWkTMiUkF5VURaikikefywiHjXvZU1iwM+zxeRkyKSJCJRItLVXj+Niap8LtVukogoEWn0yxcd8VlEnjK/6xMi8te6trGmceBvu4uIRIvIMfPve3R92FlTiMhGEblkVqa0d1xEJNT8PJJEJLBGDVBKNakX4AKcBboDLYBEwKdcm/8G1pnvnwYi69vuOvB5COBuvg9xBp/Ndm2AA8Ah4MH6trsOvuf7gGNAO3O7Y33bXQc+hwMh5nsfILW+7b5DnwcCgUByJcdHA7swKlc+BByuyes3xZFCP+CMUuqcUuomsBUYX67NeGCT+X4bMFRE7JUGbSxU6bNSKlop9ZO5eQijEl5jxpHvGeA1YDnQFLS5HfH5eSBMKXUFQCl1qY5trGkc8VkBJXVCPahY4bFRoZQ6wK0rUI4HNiuDQ8B/iIhnTV2/KQaF/wR+KLWdZu6z20YZxYCygfZ1Yl3t4IjPpfktxp1GY6ZKn0WkD9BZKfWPujSsFnHke+4J9BSRgyJySERG1pl1tYMjPr8KPCMiacDnwKy6Ma3eqO7/e7VoivUU7N3xl19360ibxoTD/ojIM8CDwKBataj2uaXPItIMWAUE15VBdYAj37MrRgppMMZo8CsR6a2UulrLttUWjvgcBEQopVaKyADgQ9Pn4to3r16o1d+vpjhSSAM6l9r2ouJw0mojIq4YQ85bDdcaOo74jIj8HHgFGKeUulFHttUWVfncBugNxIhIKkbudWcjn2x29G/7f5RSBUqp88BpjCDRWHHE598CnwAopWIBNwzhuKaKQ//vt0tTDApxwH0i0k1EWmBMJO8s12YnMNV8PwnYr8wZnEZKlT6bqZQ/YwSExp5nhip8VkplK6U6KKW8lVLeGPMo45RSjbmWqyN/259hLCpARDpgpJPO1amVNYsjPn8PDAUQkQcwgkJGnVpZt+wEppirkB4CspVS6TXVeZNLHymlCkVkJrAbY+XCRqXUCRH5E3BUKbUT2IAxxDyDMUJ4uv4svnMc9PltoDXwqTmn/r1Saly9GX2HOOhzk8JBn3cDw0XkJFAEvKSUyqw/q+8MB31eAKwXkXkYaZTgxnyTJyJbMNJ/Hcx5kj8CzQGUUusw5k1GA2eAn4Df1Oj1G/Fnp9FoNJoapimmjzQajUZzm+igoNFoNBoLHRQ0Go1GY6GDgkaj0WgsdFDQaDQajYUOCpoGh4gUiUhCqZf3Ldp6V6YmWc1rxphKnImmRESv2+hjhohMMd8Hi0inUsc+EBGfGrYzTkQCHDhnroi43+m1Nc6BDgqahkieUiqg1Cu1jq77a6WUDUMs8e3qnqyUWqeU2mxuBgOdSh2bppQ6WSNW/tvO93DMzrmADgoah9BBQdMoMEcEX4nI/5mvh+208RWRI+boIklE7jP3P1Nq/59FxKWKyx0AepjnDjV1+o+bOvctzf3L5N/1KVaY+14VkYUiMglDX+pj85qtzDv8B0UkRESWl7I5WETevU07YyklhCYi74vIUTHqKCw1983GCE7RIhJt7hsuIrHm5/ipiLSu4joaJ0IHBU1DpFWp1NEOc98lYJhSKhCYDITaOW8GsEYpFYDxo5xmyh5MBh4x9xcBv67i+k8Ax0XEDYgAJiul/DAUAEJE5G5gIuCrlPIHXi99slJqG3AU444+QCmVV+rwNuDJUtuTgcjbtHMkhqxFCa8opR4E/IFBIuKvlArF0MUZopQaYkpfLAZ+bn6WR4H5VVxH40Q0OZkLTZMgz/xhLE1zYK2ZQy/C0PQpTyzwioh4AduVUikiMhToC8SZ8h6tMAKMPT4WkTwgFUN+uRdwXin1T/P4JuBFYC1GfYYPROR/AYeluZVSGSJyztSsSTGvcdDstzp23oUh+1C66tZTIjId4//aE6PgTFK5cx8y9x80r9MC43PTaAAdFDSNh3nARcCGMcKtUDRHKfVXETkMjAF2i8g0DJnhTUqplx24xq9LC+aJiN0aG6YeTz8MEbangZnA49XwJRJ4CjgF7FBKKTF+oR22E6MC2TIgDHhSRLoBC4H/UkpdEZEIDGG48giwVykVVA17NU6ETh9pGgseQLqpkf8sxl1yGUSkO3DOTJnsxEijRAGTRKSj2eZucbw+9SnAW0R6mNvPAl+aOXgPpdTnGJO49lYAXcOQ77bHdmACRh2ASHNftexUShVgpIEeMlNPbYHrQLaI3AOMqsSWQ8AjJT6JiLuI2Bt1aZwUHRQ0jYX3gKkicggjdXTdTpvJQLKIJAD3Y5QsPInx47lHRJKAvRiplSpRSuVjKFB+KiLHgWJgHcYP7D/M/r7EGMWUJwJYVzLRXK7fK8BJoKtS6oi5r9p2mnMVK4GFSqlEjNrMJ4CNGCmpEsKBXSISrZTKwFgZtcW8ziGMz0qjAbRKqkaj0WhKoUcKGo1Go7HQQUGj0Wg0FjooaDQajcZCBwWNRqPRWOigoNFoNBoLHRQ0Go1GY6GDgkaj0Wgs/h9pWjYeHh8c6gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50195 50195\n",
      "Train subject 11, class HandStart\n",
      "Train on 1956 samples, validate on 489 samples\n",
      "Epoch 1/100\n",
      "1956/1956 [==============================] - 2s 960us/step - loss: 0.6956 - acc: 0.5072 - val_loss: 0.6918 - val_acc: 0.5194\n",
      "Epoch 2/100\n",
      "1956/1956 [==============================] - 1s 338us/step - loss: 0.6948 - acc: 0.4934 - val_loss: 0.6917 - val_acc: 0.5440\n",
      "Epoch 3/100\n",
      "1956/1956 [==============================] - 1s 345us/step - loss: 0.6946 - acc: 0.5056 - val_loss: 0.6916 - val_acc: 0.5583\n",
      "Epoch 4/100\n",
      "1956/1956 [==============================] - 1s 342us/step - loss: 0.6959 - acc: 0.5026 - val_loss: 0.6916 - val_acc: 0.5215\n",
      "Epoch 5/100\n",
      "1956/1956 [==============================] - 1s 344us/step - loss: 0.6936 - acc: 0.5143 - val_loss: 0.6914 - val_acc: 0.5256\n",
      "Epoch 6/100\n",
      "1956/1956 [==============================] - 1s 343us/step - loss: 0.6956 - acc: 0.5123 - val_loss: 0.6914 - val_acc: 0.5215\n",
      "Epoch 7/100\n",
      "1956/1956 [==============================] - 1s 347us/step - loss: 0.6914 - acc: 0.5148 - val_loss: 0.6913 - val_acc: 0.5337\n",
      "Epoch 8/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.6923 - acc: 0.5112 - val_loss: 0.6911 - val_acc: 0.5358\n",
      "Epoch 9/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.6943 - acc: 0.5066 - val_loss: 0.6909 - val_acc: 0.5317\n",
      "Epoch 10/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.6898 - acc: 0.5271 - val_loss: 0.6908 - val_acc: 0.5317\n",
      "Epoch 11/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.6908 - acc: 0.5133 - val_loss: 0.6906 - val_acc: 0.5337\n",
      "Epoch 12/100\n",
      "1956/1956 [==============================] - 1s 343us/step - loss: 0.6919 - acc: 0.5245 - val_loss: 0.6904 - val_acc: 0.5297\n",
      "Epoch 13/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.6908 - acc: 0.5286 - val_loss: 0.6901 - val_acc: 0.5419\n",
      "Epoch 14/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.6909 - acc: 0.5353 - val_loss: 0.6901 - val_acc: 0.5358\n",
      "Epoch 15/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.6917 - acc: 0.5123 - val_loss: 0.6898 - val_acc: 0.5419\n",
      "Epoch 16/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.6900 - acc: 0.5327 - val_loss: 0.6897 - val_acc: 0.5419\n",
      "Epoch 17/100\n",
      "1956/1956 [==============================] - 1s 341us/step - loss: 0.6924 - acc: 0.5143 - val_loss: 0.6892 - val_acc: 0.5583\n",
      "Epoch 18/100\n",
      "1956/1956 [==============================] - 1s 345us/step - loss: 0.6926 - acc: 0.5276 - val_loss: 0.6893 - val_acc: 0.5603\n",
      "Epoch 19/100\n",
      "1956/1956 [==============================] - 1s 343us/step - loss: 0.6886 - acc: 0.5429 - val_loss: 0.6891 - val_acc: 0.5562\n",
      "Epoch 20/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.6895 - acc: 0.5276 - val_loss: 0.6890 - val_acc: 0.5562\n",
      "Epoch 21/100\n",
      "1956/1956 [==============================] - 1s 347us/step - loss: 0.6908 - acc: 0.5399 - val_loss: 0.6889 - val_acc: 0.5460\n",
      "Epoch 22/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.6884 - acc: 0.5322 - val_loss: 0.6885 - val_acc: 0.5603\n",
      "Epoch 23/100\n",
      "1956/1956 [==============================] - 1s 348us/step - loss: 0.6919 - acc: 0.5281 - val_loss: 0.6882 - val_acc: 0.5562\n",
      "Epoch 24/100\n",
      "1956/1956 [==============================] - 1s 341us/step - loss: 0.6914 - acc: 0.5286 - val_loss: 0.6881 - val_acc: 0.5603\n",
      "Epoch 25/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.6884 - acc: 0.5475 - val_loss: 0.6876 - val_acc: 0.5685\n",
      "Epoch 26/100\n",
      "1956/1956 [==============================] - 1s 346us/step - loss: 0.6887 - acc: 0.5404 - val_loss: 0.6874 - val_acc: 0.5685\n",
      "Epoch 27/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.6879 - acc: 0.5450 - val_loss: 0.6870 - val_acc: 0.5644\n",
      "Epoch 28/100\n",
      "1956/1956 [==============================] - 1s 347us/step - loss: 0.6886 - acc: 0.5327 - val_loss: 0.6869 - val_acc: 0.5665\n",
      "Epoch 29/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.6865 - acc: 0.5470 - val_loss: 0.6865 - val_acc: 0.5685\n",
      "Epoch 30/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.6870 - acc: 0.5496 - val_loss: 0.6863 - val_acc: 0.5706\n",
      "Epoch 31/100\n",
      "1956/1956 [==============================] - 1s 347us/step - loss: 0.6889 - acc: 0.5475 - val_loss: 0.6861 - val_acc: 0.5644\n",
      "Epoch 32/100\n",
      "1956/1956 [==============================] - 1s 347us/step - loss: 0.6894 - acc: 0.5322 - val_loss: 0.6856 - val_acc: 0.5726\n",
      "Epoch 33/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.6870 - acc: 0.5465 - val_loss: 0.6856 - val_acc: 0.5706\n",
      "Epoch 34/100\n",
      "1956/1956 [==============================] - 1s 342us/step - loss: 0.6886 - acc: 0.5465 - val_loss: 0.6852 - val_acc: 0.5706\n",
      "Epoch 35/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.6876 - acc: 0.5424 - val_loss: 0.6849 - val_acc: 0.5746\n",
      "Epoch 36/100\n",
      "1956/1956 [==============================] - 1s 347us/step - loss: 0.6873 - acc: 0.5455 - val_loss: 0.6846 - val_acc: 0.5726\n",
      "Epoch 37/100\n",
      "1956/1956 [==============================] - 1s 345us/step - loss: 0.6869 - acc: 0.5429 - val_loss: 0.6842 - val_acc: 0.5665\n",
      "Epoch 38/100\n",
      "1956/1956 [==============================] - 1s 346us/step - loss: 0.6868 - acc: 0.5445 - val_loss: 0.6840 - val_acc: 0.5726\n",
      "Epoch 39/100\n",
      "1956/1956 [==============================] - 1s 347us/step - loss: 0.6867 - acc: 0.5373 - val_loss: 0.6838 - val_acc: 0.5685\n",
      "Epoch 40/100\n",
      "1956/1956 [==============================] - 1s 346us/step - loss: 0.6876 - acc: 0.5343 - val_loss: 0.6836 - val_acc: 0.5706\n",
      "Epoch 41/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.6867 - acc: 0.5450 - val_loss: 0.6832 - val_acc: 0.5726\n",
      "Epoch 42/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.6876 - acc: 0.5465 - val_loss: 0.6831 - val_acc: 0.5706\n",
      "Epoch 43/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.6877 - acc: 0.5516 - val_loss: 0.6826 - val_acc: 0.5644\n",
      "Epoch 44/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.6866 - acc: 0.5521 - val_loss: 0.6821 - val_acc: 0.5685\n",
      "Epoch 45/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.6848 - acc: 0.5654 - val_loss: 0.6821 - val_acc: 0.5644\n",
      "Epoch 46/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.6837 - acc: 0.5777 - val_loss: 0.6817 - val_acc: 0.5644\n",
      "Epoch 47/100\n",
      "1956/1956 [==============================] - 1s 348us/step - loss: 0.6878 - acc: 0.5491 - val_loss: 0.6816 - val_acc: 0.5624\n",
      "Epoch 48/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.6845 - acc: 0.5516 - val_loss: 0.6813 - val_acc: 0.5583\n",
      "Epoch 49/100\n",
      "1956/1956 [==============================] - 1s 345us/step - loss: 0.6831 - acc: 0.5660 - val_loss: 0.6811 - val_acc: 0.5603\n",
      "Epoch 50/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.6832 - acc: 0.5731 - val_loss: 0.6811 - val_acc: 0.5644\n",
      "Epoch 51/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.6816 - acc: 0.5716 - val_loss: 0.6803 - val_acc: 0.5644\n",
      "Epoch 52/100\n",
      "1956/1956 [==============================] - 1s 345us/step - loss: 0.6819 - acc: 0.5787 - val_loss: 0.6794 - val_acc: 0.5869\n",
      "Epoch 53/100\n",
      "1956/1956 [==============================] - 1s 347us/step - loss: 0.6806 - acc: 0.5762 - val_loss: 0.6793 - val_acc: 0.5746\n",
      "Epoch 54/100\n",
      "1956/1956 [==============================] - 1s 348us/step - loss: 0.6826 - acc: 0.5741 - val_loss: 0.6788 - val_acc: 0.5808\n",
      "Epoch 55/100\n",
      "1956/1956 [==============================] - 1s 345us/step - loss: 0.6830 - acc: 0.5639 - val_loss: 0.6786 - val_acc: 0.5787\n",
      "Epoch 56/100\n",
      "1956/1956 [==============================] - 1s 345us/step - loss: 0.6812 - acc: 0.5629 - val_loss: 0.6784 - val_acc: 0.5787\n",
      "Epoch 57/100\n",
      "1956/1956 [==============================] - 1s 345us/step - loss: 0.6795 - acc: 0.5762 - val_loss: 0.6779 - val_acc: 0.5828\n",
      "Epoch 58/100\n",
      "1956/1956 [==============================] - 1s 348us/step - loss: 0.6801 - acc: 0.5685 - val_loss: 0.6779 - val_acc: 0.5787\n",
      "Epoch 59/100\n",
      "1956/1956 [==============================] - 1s 347us/step - loss: 0.6785 - acc: 0.5828 - val_loss: 0.6779 - val_acc: 0.5746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "1956/1956 [==============================] - 1s 343us/step - loss: 0.6814 - acc: 0.5741 - val_loss: 0.6777 - val_acc: 0.5706\n",
      "Epoch 61/100\n",
      "1956/1956 [==============================] - 1s 341us/step - loss: 0.6785 - acc: 0.5833 - val_loss: 0.6772 - val_acc: 0.5746\n",
      "Epoch 62/100\n",
      "1956/1956 [==============================] - 1s 344us/step - loss: 0.6805 - acc: 0.5670 - val_loss: 0.6767 - val_acc: 0.5787\n",
      "Epoch 63/100\n",
      "1956/1956 [==============================] - 1s 346us/step - loss: 0.6816 - acc: 0.5721 - val_loss: 0.6760 - val_acc: 0.5808\n",
      "Epoch 64/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.6789 - acc: 0.5844 - val_loss: 0.6753 - val_acc: 0.5849\n",
      "Epoch 65/100\n",
      "1956/1956 [==============================] - ETA: 0s - loss: 0.6782 - acc: 0.576 - 1s 353us/step - loss: 0.6781 - acc: 0.5746 - val_loss: 0.6744 - val_acc: 0.5910\n",
      "Epoch 66/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.6761 - acc: 0.5890 - val_loss: 0.6743 - val_acc: 0.5869\n",
      "Epoch 67/100\n",
      "1956/1956 [==============================] - 1s 344us/step - loss: 0.6748 - acc: 0.5859 - val_loss: 0.6738 - val_acc: 0.5910\n",
      "Epoch 68/100\n",
      "1956/1956 [==============================] - 1s 344us/step - loss: 0.6774 - acc: 0.5849 - val_loss: 0.6734 - val_acc: 0.5869\n",
      "Epoch 69/100\n",
      "1956/1956 [==============================] - 1s 347us/step - loss: 0.6755 - acc: 0.5838 - val_loss: 0.6736 - val_acc: 0.5869\n",
      "Epoch 70/100\n",
      "1956/1956 [==============================] - 1s 344us/step - loss: 0.6768 - acc: 0.5813 - val_loss: 0.6727 - val_acc: 0.5910\n",
      "Epoch 71/100\n",
      "1956/1956 [==============================] - 1s 347us/step - loss: 0.6757 - acc: 0.5941 - val_loss: 0.6718 - val_acc: 0.5930\n",
      "Epoch 72/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.6739 - acc: 0.5925 - val_loss: 0.6715 - val_acc: 0.5910\n",
      "Epoch 73/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.6759 - acc: 0.5813 - val_loss: 0.6714 - val_acc: 0.5951\n",
      "Epoch 74/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.6751 - acc: 0.5849 - val_loss: 0.6711 - val_acc: 0.5930\n",
      "Epoch 75/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.6738 - acc: 0.5782 - val_loss: 0.6707 - val_acc: 0.5930\n",
      "Epoch 76/100\n",
      "1956/1956 [==============================] - 1s 347us/step - loss: 0.6719 - acc: 0.5803 - val_loss: 0.6705 - val_acc: 0.5890\n",
      "Epoch 77/100\n",
      "1956/1956 [==============================] - 1s 348us/step - loss: 0.6716 - acc: 0.5966 - val_loss: 0.6698 - val_acc: 0.5992\n",
      "Epoch 78/100\n",
      "1956/1956 [==============================] - 1s 345us/step - loss: 0.6753 - acc: 0.5905 - val_loss: 0.6697 - val_acc: 0.5910\n",
      "Epoch 79/100\n",
      "1956/1956 [==============================] - 1s 343us/step - loss: 0.6703 - acc: 0.5951 - val_loss: 0.6698 - val_acc: 0.5910\n",
      "Epoch 80/100\n",
      "1956/1956 [==============================] - 1s 344us/step - loss: 0.6728 - acc: 0.5920 - val_loss: 0.6687 - val_acc: 0.5971\n",
      "Epoch 81/100\n",
      "1956/1956 [==============================] - 1s 344us/step - loss: 0.6649 - acc: 0.6053 - val_loss: 0.6683 - val_acc: 0.6033\n",
      "Epoch 82/100\n",
      "1956/1956 [==============================] - 1s 341us/step - loss: 0.6690 - acc: 0.6028 - val_loss: 0.6681 - val_acc: 0.5951\n",
      "Epoch 83/100\n",
      "1956/1956 [==============================] - 1s 342us/step - loss: 0.6680 - acc: 0.5951 - val_loss: 0.6668 - val_acc: 0.5992\n",
      "Epoch 84/100\n",
      "1956/1956 [==============================] - 1s 341us/step - loss: 0.6658 - acc: 0.6012 - val_loss: 0.6664 - val_acc: 0.6012\n",
      "Epoch 85/100\n",
      "1956/1956 [==============================] - 1s 344us/step - loss: 0.6675 - acc: 0.5997 - val_loss: 0.6666 - val_acc: 0.6012\n",
      "Epoch 86/100\n",
      "1956/1956 [==============================] - 1s 347us/step - loss: 0.6653 - acc: 0.6012 - val_loss: 0.6662 - val_acc: 0.6012\n",
      "Epoch 87/100\n",
      "1956/1956 [==============================] - 1s 344us/step - loss: 0.6627 - acc: 0.6125 - val_loss: 0.6660 - val_acc: 0.6012\n",
      "Epoch 88/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.6624 - acc: 0.6089 - val_loss: 0.6658 - val_acc: 0.6033\n",
      "Epoch 89/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.6643 - acc: 0.5951 - val_loss: 0.6645 - val_acc: 0.6053\n",
      "Epoch 90/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.6643 - acc: 0.6017 - val_loss: 0.6635 - val_acc: 0.6033\n",
      "Epoch 91/100\n",
      "1956/1956 [==============================] - 1s 369us/step - loss: 0.6634 - acc: 0.6007 - val_loss: 0.6643 - val_acc: 0.6012\n",
      "Epoch 92/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.6606 - acc: 0.6038 - val_loss: 0.6638 - val_acc: 0.6012\n",
      "Epoch 93/100\n",
      "1956/1956 [==============================] - 1s 342us/step - loss: 0.6626 - acc: 0.5946 - val_loss: 0.6619 - val_acc: 0.5992\n",
      "Epoch 94/100\n",
      "1956/1956 [==============================] - 1s 348us/step - loss: 0.6616 - acc: 0.5992 - val_loss: 0.6628 - val_acc: 0.6033\n",
      "Epoch 95/100\n",
      "1956/1956 [==============================] - 1s 343us/step - loss: 0.6618 - acc: 0.5982 - val_loss: 0.6626 - val_acc: 0.6033\n",
      "Epoch 96/100\n",
      "1956/1956 [==============================] - 1s 376us/step - loss: 0.6583 - acc: 0.6048 - val_loss: 0.6611 - val_acc: 0.6074\n",
      "Epoch 97/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.6603 - acc: 0.5997 - val_loss: 0.6607 - val_acc: 0.6074\n",
      "Epoch 98/100\n",
      "1956/1956 [==============================] - 1s 344us/step - loss: 0.6610 - acc: 0.6022 - val_loss: 0.6610 - val_acc: 0.6094\n",
      "Epoch 99/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.6587 - acc: 0.5997 - val_loss: 0.6603 - val_acc: 0.6094\n",
      "Epoch 100/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.6585 - acc: 0.6053 - val_loss: 0.6597 - val_acc: 0.6094\n",
      "Train on 1956 samples, validate on 489 samples\n",
      "Epoch 1/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.6707 - acc: 0.5782 - val_loss: 0.6770 - val_acc: 0.5930\n",
      "Epoch 2/100\n",
      "1956/1956 [==============================] - 1s 387us/step - loss: 0.6706 - acc: 0.5752 - val_loss: 0.6787 - val_acc: 0.5951\n",
      "Epoch 3/100\n",
      "1956/1956 [==============================] - 1s 386us/step - loss: 0.6744 - acc: 0.5665 - val_loss: 0.6770 - val_acc: 0.6012\n",
      "Epoch 4/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.6700 - acc: 0.5752 - val_loss: 0.6756 - val_acc: 0.6053\n",
      "Epoch 5/100\n",
      "1956/1956 [==============================] - 1s 341us/step - loss: 0.6687 - acc: 0.5879 - val_loss: 0.6751 - val_acc: 0.6033\n",
      "Epoch 6/100\n",
      "1956/1956 [==============================] - 1s 344us/step - loss: 0.6685 - acc: 0.5900 - val_loss: 0.6754 - val_acc: 0.6074\n",
      "Epoch 7/100\n",
      "1956/1956 [==============================] - 1s 371us/step - loss: 0.6659 - acc: 0.5915 - val_loss: 0.6774 - val_acc: 0.6053\n",
      "Epoch 8/100\n",
      "1956/1956 [==============================] - 1s 346us/step - loss: 0.6686 - acc: 0.5813 - val_loss: 0.6736 - val_acc: 0.6115\n",
      "Epoch 9/100\n",
      "1956/1956 [==============================] - 1s 374us/step - loss: 0.6719 - acc: 0.5731 - val_loss: 0.6741 - val_acc: 0.6176\n",
      "Epoch 10/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.6689 - acc: 0.5813 - val_loss: 0.6745 - val_acc: 0.6135\n",
      "Epoch 11/100\n",
      "1956/1956 [==============================] - 1s 370us/step - loss: 0.6688 - acc: 0.5818 - val_loss: 0.6741 - val_acc: 0.6135\n",
      "Epoch 12/100\n",
      "1956/1956 [==============================] - 1s 375us/step - loss: 0.6694 - acc: 0.5833 - val_loss: 0.6753 - val_acc: 0.6115\n",
      "Epoch 13/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.6675 - acc: 0.5823 - val_loss: 0.6766 - val_acc: 0.6155\n",
      "Epoch 14/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.6691 - acc: 0.5838 - val_loss: 0.6739 - val_acc: 0.6115\n",
      "Epoch 15/100\n",
      "1956/1956 [==============================] - 1s 346us/step - loss: 0.6611 - acc: 0.5920 - val_loss: 0.6741 - val_acc: 0.6176\n",
      "Epoch 16/100\n",
      "1956/1956 [==============================] - 1s 344us/step - loss: 0.6671 - acc: 0.5884 - val_loss: 0.6724 - val_acc: 0.6196\n",
      "Epoch 17/100\n",
      "1956/1956 [==============================] - 1s 347us/step - loss: 0.6647 - acc: 0.5910 - val_loss: 0.6734 - val_acc: 0.6196\n",
      "Epoch 18/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.6629 - acc: 0.5890 - val_loss: 0.6735 - val_acc: 0.6237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.6641 - acc: 0.5930 - val_loss: 0.6712 - val_acc: 0.6176\n",
      "Epoch 20/100\n",
      "1956/1956 [==============================] - 1s 347us/step - loss: 0.6619 - acc: 0.5915 - val_loss: 0.6706 - val_acc: 0.6217\n",
      "Epoch 21/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.6625 - acc: 0.5849 - val_loss: 0.6712 - val_acc: 0.6217\n",
      "Epoch 22/100\n",
      "1956/1956 [==============================] - 1s 346us/step - loss: 0.6581 - acc: 0.6017 - val_loss: 0.6700 - val_acc: 0.6237\n",
      "Epoch 23/100\n",
      "1956/1956 [==============================] - 1s 348us/step - loss: 0.6629 - acc: 0.5828 - val_loss: 0.6681 - val_acc: 0.6258\n",
      "Epoch 24/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.6624 - acc: 0.5961 - val_loss: 0.6700 - val_acc: 0.6217\n",
      "Epoch 25/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.6612 - acc: 0.5997 - val_loss: 0.6675 - val_acc: 0.6299\n",
      "Epoch 26/100\n",
      "1956/1956 [==============================] - 1s 345us/step - loss: 0.6578 - acc: 0.6033 - val_loss: 0.6665 - val_acc: 0.6217\n",
      "Epoch 27/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.6607 - acc: 0.5936 - val_loss: 0.6665 - val_acc: 0.6278\n",
      "Epoch 28/100\n",
      "1956/1956 [==============================] - 1s 340us/step - loss: 0.6577 - acc: 0.6022 - val_loss: 0.6664 - val_acc: 0.6278\n",
      "Epoch 29/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.6553 - acc: 0.6028 - val_loss: 0.6704 - val_acc: 0.6278\n",
      "Epoch 30/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.6587 - acc: 0.5976 - val_loss: 0.6687 - val_acc: 0.6258\n",
      "Epoch 31/100\n",
      "1956/1956 [==============================] - 1s 348us/step - loss: 0.6522 - acc: 0.6063 - val_loss: 0.6653 - val_acc: 0.6258\n",
      "Epoch 32/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.6581 - acc: 0.5920 - val_loss: 0.6653 - val_acc: 0.6278\n",
      "Epoch 33/100\n",
      "1956/1956 [==============================] - 1s 401us/step - loss: 0.6563 - acc: 0.6115 - val_loss: 0.6682 - val_acc: 0.6278\n",
      "Epoch 34/100\n",
      "1956/1956 [==============================] - 1s 383us/step - loss: 0.6533 - acc: 0.6084 - val_loss: 0.6687 - val_acc: 0.6299\n",
      "Epoch 35/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.6597 - acc: 0.5997 - val_loss: 0.6639 - val_acc: 0.6299\n",
      "Epoch 36/100\n",
      "1956/1956 [==============================] - 1s 345us/step - loss: 0.6549 - acc: 0.6028 - val_loss: 0.6639 - val_acc: 0.6237\n",
      "Epoch 37/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.6547 - acc: 0.6094 - val_loss: 0.6609 - val_acc: 0.6339\n",
      "Epoch 38/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.6529 - acc: 0.5920 - val_loss: 0.6631 - val_acc: 0.6258\n",
      "Epoch 39/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.6536 - acc: 0.6012 - val_loss: 0.6620 - val_acc: 0.6278\n",
      "Epoch 40/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6512 - acc: 0.6115 - val_loss: 0.6629 - val_acc: 0.6237\n",
      "Epoch 41/100\n",
      "1956/1956 [==============================] - 1s 345us/step - loss: 0.6536 - acc: 0.6099 - val_loss: 0.6601 - val_acc: 0.6360\n",
      "Epoch 42/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.6490 - acc: 0.6166 - val_loss: 0.6597 - val_acc: 0.6339\n",
      "Epoch 43/100\n",
      "1956/1956 [==============================] - 1s 343us/step - loss: 0.6507 - acc: 0.6140 - val_loss: 0.6595 - val_acc: 0.6339\n",
      "Epoch 44/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.6564 - acc: 0.6002 - val_loss: 0.6608 - val_acc: 0.6217\n",
      "Epoch 45/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.6484 - acc: 0.6099 - val_loss: 0.6625 - val_acc: 0.6217\n",
      "Epoch 46/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.6504 - acc: 0.6099 - val_loss: 0.6587 - val_acc: 0.6299\n",
      "Epoch 47/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.6522 - acc: 0.6099 - val_loss: 0.6600 - val_acc: 0.6217\n",
      "Epoch 48/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.6500 - acc: 0.6125 - val_loss: 0.6573 - val_acc: 0.6299\n",
      "Epoch 49/100\n",
      "1956/1956 [==============================] - 1s 339us/step - loss: 0.6437 - acc: 0.6299 - val_loss: 0.6559 - val_acc: 0.6360\n",
      "Epoch 50/100\n",
      "1956/1956 [==============================] - 1s 342us/step - loss: 0.6476 - acc: 0.6207 - val_loss: 0.6563 - val_acc: 0.6299\n",
      "Epoch 51/100\n",
      "1956/1956 [==============================] - 1s 340us/step - loss: 0.6463 - acc: 0.6201 - val_loss: 0.6606 - val_acc: 0.6196\n",
      "Epoch 52/100\n",
      "1956/1956 [==============================] - 1s 345us/step - loss: 0.6443 - acc: 0.6268 - val_loss: 0.6586 - val_acc: 0.6237\n",
      "Epoch 53/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.6466 - acc: 0.6319 - val_loss: 0.6588 - val_acc: 0.6237\n",
      "Epoch 54/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.6442 - acc: 0.6196 - val_loss: 0.6592 - val_acc: 0.6237\n",
      "Epoch 55/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.6429 - acc: 0.6283 - val_loss: 0.6562 - val_acc: 0.6299\n",
      "Epoch 56/100\n",
      "1956/1956 [==============================] - 1s 343us/step - loss: 0.6435 - acc: 0.6217 - val_loss: 0.6569 - val_acc: 0.6299\n",
      "Epoch 57/100\n",
      "1956/1956 [==============================] - 1s 346us/step - loss: 0.6448 - acc: 0.6155 - val_loss: 0.6533 - val_acc: 0.6339\n",
      "Epoch 58/100\n",
      "1956/1956 [==============================] - 1s 347us/step - loss: 0.6426 - acc: 0.6217 - val_loss: 0.6547 - val_acc: 0.6278\n",
      "Epoch 59/100\n",
      "1956/1956 [==============================] - 1s 345us/step - loss: 0.6423 - acc: 0.6181 - val_loss: 0.6522 - val_acc: 0.6380\n",
      "Epoch 60/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.6463 - acc: 0.6227 - val_loss: 0.6557 - val_acc: 0.6258\n",
      "Epoch 61/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.6445 - acc: 0.6161 - val_loss: 0.6538 - val_acc: 0.6299\n",
      "Epoch 62/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.6428 - acc: 0.6222 - val_loss: 0.6547 - val_acc: 0.6278\n",
      "Epoch 63/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.6337 - acc: 0.6472 - val_loss: 0.6562 - val_acc: 0.6237\n",
      "Epoch 64/100\n",
      "1956/1956 [==============================] - 1s 347us/step - loss: 0.6393 - acc: 0.6334 - val_loss: 0.6515 - val_acc: 0.6360\n",
      "Epoch 65/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.6402 - acc: 0.6253 - val_loss: 0.6538 - val_acc: 0.6319\n",
      "Epoch 66/100\n",
      "1956/1956 [==============================] - 1s 345us/step - loss: 0.6383 - acc: 0.6324 - val_loss: 0.6502 - val_acc: 0.6380\n",
      "Epoch 67/100\n",
      "1956/1956 [==============================] - 1s 346us/step - loss: 0.6416 - acc: 0.6283 - val_loss: 0.6518 - val_acc: 0.6319\n",
      "Epoch 68/100\n",
      "1956/1956 [==============================] - 1s 347us/step - loss: 0.6375 - acc: 0.6217 - val_loss: 0.6527 - val_acc: 0.6319\n",
      "Epoch 69/100\n",
      "1956/1956 [==============================] - 1s 345us/step - loss: 0.6341 - acc: 0.6442 - val_loss: 0.6459 - val_acc: 0.6442\n",
      "Epoch 70/100\n",
      "1956/1956 [==============================] - 1s 340us/step - loss: 0.6340 - acc: 0.6431 - val_loss: 0.6520 - val_acc: 0.6319\n",
      "Epoch 71/100\n",
      "1956/1956 [==============================] - 1s 344us/step - loss: 0.6329 - acc: 0.6385 - val_loss: 0.6483 - val_acc: 0.6360\n",
      "Epoch 72/100\n",
      "1956/1956 [==============================] - 1s 348us/step - loss: 0.6365 - acc: 0.6365 - val_loss: 0.6505 - val_acc: 0.6319\n",
      "Epoch 73/100\n",
      "1956/1956 [==============================] - 1s 344us/step - loss: 0.6361 - acc: 0.6283 - val_loss: 0.6530 - val_acc: 0.6278\n",
      "Epoch 74/100\n",
      "1956/1956 [==============================] - 1s 347us/step - loss: 0.6297 - acc: 0.6483 - val_loss: 0.6511 - val_acc: 0.6299\n",
      "Epoch 75/100\n",
      "1956/1956 [==============================] - 1s 343us/step - loss: 0.6282 - acc: 0.6493 - val_loss: 0.6461 - val_acc: 0.6380\n",
      "Epoch 76/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.6298 - acc: 0.6411 - val_loss: 0.6445 - val_acc: 0.6339\n",
      "Epoch 77/100\n",
      "1956/1956 [==============================] - 1s 343us/step - loss: 0.6310 - acc: 0.6421 - val_loss: 0.6455 - val_acc: 0.6380\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.6308 - acc: 0.6488 - val_loss: 0.6425 - val_acc: 0.6360\n",
      "Epoch 79/100\n",
      "1956/1956 [==============================] - 1s 346us/step - loss: 0.6275 - acc: 0.6380 - val_loss: 0.6403 - val_acc: 0.6503\n",
      "Epoch 80/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.6223 - acc: 0.6524 - val_loss: 0.6407 - val_acc: 0.6462\n",
      "Epoch 81/100\n",
      "1956/1956 [==============================] - 1s 344us/step - loss: 0.6235 - acc: 0.6431 - val_loss: 0.6408 - val_acc: 0.6462\n",
      "Epoch 82/100\n",
      "1956/1956 [==============================] - 1s 344us/step - loss: 0.6290 - acc: 0.6375 - val_loss: 0.6427 - val_acc: 0.6401\n",
      "Epoch 83/100\n",
      "1956/1956 [==============================] - 1s 341us/step - loss: 0.6257 - acc: 0.6421 - val_loss: 0.6426 - val_acc: 0.6401\n",
      "Epoch 84/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.6259 - acc: 0.6442 - val_loss: 0.6438 - val_acc: 0.6380\n",
      "Epoch 85/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.6205 - acc: 0.6488 - val_loss: 0.6414 - val_acc: 0.6421\n",
      "Epoch 86/100\n",
      "1956/1956 [==============================] - 1s 348us/step - loss: 0.6242 - acc: 0.6539 - val_loss: 0.6442 - val_acc: 0.6380\n",
      "Epoch 87/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.6189 - acc: 0.6626 - val_loss: 0.6412 - val_acc: 0.6421\n",
      "Epoch 88/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.6221 - acc: 0.6462 - val_loss: 0.6424 - val_acc: 0.6401\n",
      "Epoch 89/100\n",
      "1956/1956 [==============================] - 1s 346us/step - loss: 0.6256 - acc: 0.6411 - val_loss: 0.6433 - val_acc: 0.6319\n",
      "Epoch 90/100\n",
      "1956/1956 [==============================] - 1s 348us/step - loss: 0.6181 - acc: 0.6488 - val_loss: 0.6432 - val_acc: 0.6299\n",
      "Epoch 91/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.6130 - acc: 0.6616 - val_loss: 0.6402 - val_acc: 0.6421\n",
      "Epoch 92/100\n",
      "1956/1956 [==============================] - 1s 345us/step - loss: 0.6182 - acc: 0.6559 - val_loss: 0.6385 - val_acc: 0.6421\n",
      "Epoch 93/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.6128 - acc: 0.6564 - val_loss: 0.6423 - val_acc: 0.6319\n",
      "Epoch 94/100\n",
      "1956/1956 [==============================] - 1s 345us/step - loss: 0.6143 - acc: 0.6656 - val_loss: 0.6383 - val_acc: 0.6401\n",
      "Epoch 95/100\n",
      "1956/1956 [==============================] - 1s 344us/step - loss: 0.6186 - acc: 0.6457 - val_loss: 0.6354 - val_acc: 0.6462\n",
      "Epoch 96/100\n",
      "1956/1956 [==============================] - 1s 348us/step - loss: 0.6140 - acc: 0.6503 - val_loss: 0.6376 - val_acc: 0.6380\n",
      "Epoch 97/100\n",
      "1956/1956 [==============================] - 1s 347us/step - loss: 0.6147 - acc: 0.6544 - val_loss: 0.6355 - val_acc: 0.6442\n",
      "Epoch 98/100\n",
      "1956/1956 [==============================] - 1s 348us/step - loss: 0.6131 - acc: 0.6595 - val_loss: 0.6357 - val_acc: 0.6401\n",
      "Epoch 99/100\n",
      "1956/1956 [==============================] - 1s 347us/step - loss: 0.6119 - acc: 0.6718 - val_loss: 0.6340 - val_acc: 0.6483\n",
      "Epoch 100/100\n",
      "1956/1956 [==============================] - 1s 345us/step - loss: 0.6095 - acc: 0.6646 - val_loss: 0.6378 - val_acc: 0.6442\n",
      "Test subject 11, class HandStart\n",
      "Train subject 11, class FirstDigitTouch\n",
      "Train on 1956 samples, validate on 489 samples\n",
      "Epoch 1/100\n",
      "1956/1956 [==============================] - 2s 878us/step - loss: 0.6982 - acc: 0.5066 - val_loss: 0.6957 - val_acc: 0.4417\n",
      "Epoch 2/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.6972 - acc: 0.5051 - val_loss: 0.6942 - val_acc: 0.5256\n",
      "Epoch 3/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.7015 - acc: 0.4939 - val_loss: 0.6927 - val_acc: 0.5337\n",
      "Epoch 4/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.6981 - acc: 0.4949 - val_loss: 0.6915 - val_acc: 0.5481\n",
      "Epoch 5/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.6934 - acc: 0.5220 - val_loss: 0.6902 - val_acc: 0.5542\n",
      "Epoch 6/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.6963 - acc: 0.5031 - val_loss: 0.6893 - val_acc: 0.5644\n",
      "Epoch 7/100\n",
      "1956/1956 [==============================] - 1s 346us/step - loss: 0.6954 - acc: 0.5245 - val_loss: 0.6882 - val_acc: 0.5481\n",
      "Epoch 8/100\n",
      "1956/1956 [==============================] - 1s 345us/step - loss: 0.6921 - acc: 0.5327 - val_loss: 0.6868 - val_acc: 0.6074\n",
      "Epoch 9/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.6895 - acc: 0.5317 - val_loss: 0.6856 - val_acc: 0.6115\n",
      "Epoch 10/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.6934 - acc: 0.5184 - val_loss: 0.6844 - val_acc: 0.6135\n",
      "Epoch 11/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.6892 - acc: 0.5251 - val_loss: 0.6832 - val_acc: 0.6380\n",
      "Epoch 12/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.6889 - acc: 0.5378 - val_loss: 0.6820 - val_acc: 0.6442\n",
      "Epoch 13/100\n",
      "1956/1956 [==============================] - 1s 348us/step - loss: 0.6899 - acc: 0.5261 - val_loss: 0.6807 - val_acc: 0.6360\n",
      "Epoch 14/100\n",
      "1956/1956 [==============================] - 1s 348us/step - loss: 0.6888 - acc: 0.5307 - val_loss: 0.6792 - val_acc: 0.6442\n",
      "Epoch 15/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.6861 - acc: 0.5542 - val_loss: 0.6780 - val_acc: 0.6319\n",
      "Epoch 16/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.6840 - acc: 0.5690 - val_loss: 0.6766 - val_acc: 0.6442\n",
      "Epoch 17/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.6865 - acc: 0.5317 - val_loss: 0.6752 - val_acc: 0.6442\n",
      "Epoch 18/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.6860 - acc: 0.5424 - val_loss: 0.6736 - val_acc: 0.6503\n",
      "Epoch 19/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.6846 - acc: 0.5435 - val_loss: 0.6718 - val_acc: 0.6585\n",
      "Epoch 20/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.6780 - acc: 0.5920 - val_loss: 0.6702 - val_acc: 0.6605\n",
      "Epoch 21/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.6753 - acc: 0.5884 - val_loss: 0.6682 - val_acc: 0.6830\n",
      "Epoch 22/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.6771 - acc: 0.5920 - val_loss: 0.6662 - val_acc: 0.6830\n",
      "Epoch 23/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.6737 - acc: 0.6028 - val_loss: 0.6640 - val_acc: 0.6871\n",
      "Epoch 24/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.6758 - acc: 0.5910 - val_loss: 0.6618 - val_acc: 0.6871\n",
      "Epoch 25/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.6727 - acc: 0.5920 - val_loss: 0.6593 - val_acc: 0.6892\n",
      "Epoch 26/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.6696 - acc: 0.5956 - val_loss: 0.6567 - val_acc: 0.6933\n",
      "Epoch 27/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.6707 - acc: 0.6099 - val_loss: 0.6540 - val_acc: 0.6892\n",
      "Epoch 28/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6647 - acc: 0.6191 - val_loss: 0.6516 - val_acc: 0.6953\n",
      "Epoch 29/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.6644 - acc: 0.6237 - val_loss: 0.6488 - val_acc: 0.6973\n",
      "Epoch 30/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.6620 - acc: 0.6309 - val_loss: 0.6455 - val_acc: 0.6973\n",
      "Epoch 31/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.6570 - acc: 0.6339 - val_loss: 0.6418 - val_acc: 0.7117\n",
      "Epoch 32/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.6533 - acc: 0.6524 - val_loss: 0.6380 - val_acc: 0.7076\n",
      "Epoch 33/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.6513 - acc: 0.6431 - val_loss: 0.6342 - val_acc: 0.7157\n",
      "Epoch 34/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.6475 - acc: 0.6656 - val_loss: 0.6298 - val_acc: 0.7157\n",
      "Epoch 35/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.6437 - acc: 0.6549 - val_loss: 0.6253 - val_acc: 0.7137\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.6387 - acc: 0.6713 - val_loss: 0.6209 - val_acc: 0.7157\n",
      "Epoch 37/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.6353 - acc: 0.6672 - val_loss: 0.6151 - val_acc: 0.7280\n",
      "Epoch 38/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.6277 - acc: 0.6876 - val_loss: 0.6096 - val_acc: 0.7301\n",
      "Epoch 39/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.6335 - acc: 0.6851 - val_loss: 0.6032 - val_acc: 0.7464\n",
      "Epoch 40/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.6227 - acc: 0.6892 - val_loss: 0.5975 - val_acc: 0.7301\n",
      "Epoch 41/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.6185 - acc: 0.6999 - val_loss: 0.5927 - val_acc: 0.7198\n",
      "Epoch 42/100\n",
      "1956/1956 [==============================] - 1s 347us/step - loss: 0.6121 - acc: 0.7091 - val_loss: 0.5847 - val_acc: 0.7239\n",
      "Epoch 43/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.6088 - acc: 0.7009 - val_loss: 0.5776 - val_acc: 0.7321\n",
      "Epoch 44/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.5973 - acc: 0.7183 - val_loss: 0.5691 - val_acc: 0.7505\n",
      "Epoch 45/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.5903 - acc: 0.7203 - val_loss: 0.5610 - val_acc: 0.7526\n",
      "Epoch 46/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.5833 - acc: 0.7219 - val_loss: 0.5521 - val_acc: 0.7587\n",
      "Epoch 47/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.5729 - acc: 0.7382 - val_loss: 0.5455 - val_acc: 0.7526\n",
      "Epoch 48/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.5727 - acc: 0.7326 - val_loss: 0.5384 - val_acc: 0.7464\n",
      "Epoch 49/100\n",
      "1956/1956 [==============================] - 1s 347us/step - loss: 0.5592 - acc: 0.7326 - val_loss: 0.5318 - val_acc: 0.7485\n",
      "Epoch 50/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.5489 - acc: 0.7418 - val_loss: 0.5187 - val_acc: 0.7751\n",
      "Epoch 51/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.5491 - acc: 0.7444 - val_loss: 0.5104 - val_acc: 0.7812\n",
      "Epoch 52/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.5404 - acc: 0.7546 - val_loss: 0.5021 - val_acc: 0.7873\n",
      "Epoch 53/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.5307 - acc: 0.7526 - val_loss: 0.4955 - val_acc: 0.7853\n",
      "Epoch 54/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.5251 - acc: 0.7669 - val_loss: 0.4874 - val_acc: 0.7935\n",
      "Epoch 55/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.5213 - acc: 0.7720 - val_loss: 0.4853 - val_acc: 0.7812\n",
      "Epoch 56/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.5167 - acc: 0.7648 - val_loss: 0.4774 - val_acc: 0.7873\n",
      "Epoch 57/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.4990 - acc: 0.7720 - val_loss: 0.4674 - val_acc: 0.7996\n",
      "Epoch 58/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.5045 - acc: 0.7730 - val_loss: 0.4616 - val_acc: 0.8037\n",
      "Epoch 59/100\n",
      "1956/1956 [==============================] - 1s 347us/step - loss: 0.4924 - acc: 0.7827 - val_loss: 0.4600 - val_acc: 0.7975\n",
      "Epoch 60/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.4956 - acc: 0.7812 - val_loss: 0.4510 - val_acc: 0.8098\n",
      "Epoch 61/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.4826 - acc: 0.7766 - val_loss: 0.4496 - val_acc: 0.8098\n",
      "Epoch 62/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.4751 - acc: 0.7868 - val_loss: 0.4425 - val_acc: 0.8057\n",
      "Epoch 63/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.4779 - acc: 0.7735 - val_loss: 0.4433 - val_acc: 0.8078\n",
      "Epoch 64/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.4713 - acc: 0.7832 - val_loss: 0.4400 - val_acc: 0.8119\n",
      "Epoch 65/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.4654 - acc: 0.7940 - val_loss: 0.4379 - val_acc: 0.8160\n",
      "Epoch 66/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.4522 - acc: 0.8032 - val_loss: 0.4256 - val_acc: 0.8098\n",
      "Epoch 67/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.4577 - acc: 0.7986 - val_loss: 0.4215 - val_acc: 0.8160\n",
      "Epoch 68/100\n",
      "1956/1956 [==============================] - 1s 344us/step - loss: 0.4491 - acc: 0.8016 - val_loss: 0.4224 - val_acc: 0.8139\n",
      "Epoch 69/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.4500 - acc: 0.8021 - val_loss: 0.4215 - val_acc: 0.8119\n",
      "Epoch 70/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.4456 - acc: 0.7981 - val_loss: 0.4172 - val_acc: 0.8139\n",
      "Epoch 71/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.4524 - acc: 0.7909 - val_loss: 0.4121 - val_acc: 0.8139\n",
      "Epoch 72/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.4463 - acc: 0.7970 - val_loss: 0.4112 - val_acc: 0.8160\n",
      "Epoch 73/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.4391 - acc: 0.8047 - val_loss: 0.4135 - val_acc: 0.8180\n",
      "Epoch 74/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.4422 - acc: 0.8057 - val_loss: 0.4081 - val_acc: 0.8160\n",
      "Epoch 75/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.4391 - acc: 0.8139 - val_loss: 0.4114 - val_acc: 0.8200\n",
      "Epoch 76/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.4287 - acc: 0.8144 - val_loss: 0.3993 - val_acc: 0.8221\n",
      "Epoch 77/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.4366 - acc: 0.8032 - val_loss: 0.4036 - val_acc: 0.8200\n",
      "Epoch 78/100\n",
      "1956/1956 [==============================] - 1s 368us/step - loss: 0.4250 - acc: 0.8154 - val_loss: 0.4013 - val_acc: 0.8200\n",
      "Epoch 79/100\n",
      "1956/1956 [==============================] - 1s 346us/step - loss: 0.4279 - acc: 0.8062 - val_loss: 0.4003 - val_acc: 0.8221\n",
      "Epoch 80/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.4162 - acc: 0.8246 - val_loss: 0.3978 - val_acc: 0.8200\n",
      "Epoch 81/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.4179 - acc: 0.8185 - val_loss: 0.4040 - val_acc: 0.8262\n",
      "Epoch 82/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.4203 - acc: 0.8170 - val_loss: 0.3986 - val_acc: 0.8241\n",
      "Epoch 83/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.4159 - acc: 0.8231 - val_loss: 0.4029 - val_acc: 0.8241\n",
      "Epoch 84/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.4091 - acc: 0.8175 - val_loss: 0.3998 - val_acc: 0.8303\n",
      "Epoch 85/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.4137 - acc: 0.8206 - val_loss: 0.3954 - val_acc: 0.8221\n",
      "Epoch 86/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.4052 - acc: 0.8318 - val_loss: 0.3918 - val_acc: 0.8180\n",
      "Epoch 87/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.4035 - acc: 0.8160 - val_loss: 0.3946 - val_acc: 0.8180\n",
      "Epoch 88/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.4094 - acc: 0.8190 - val_loss: 0.3924 - val_acc: 0.8241\n",
      "Epoch 89/100\n",
      "1956/1956 [==============================] - 1s 348us/step - loss: 0.3985 - acc: 0.8257 - val_loss: 0.3896 - val_acc: 0.8221\n",
      "Epoch 90/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.4118 - acc: 0.8195 - val_loss: 0.3924 - val_acc: 0.8241\n",
      "Epoch 91/100\n",
      "1956/1956 [==============================] - 1s 344us/step - loss: 0.4026 - acc: 0.8226 - val_loss: 0.3846 - val_acc: 0.8303\n",
      "Epoch 92/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.3964 - acc: 0.8308 - val_loss: 0.3875 - val_acc: 0.8221\n",
      "Epoch 93/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.3993 - acc: 0.8277 - val_loss: 0.3859 - val_acc: 0.8241\n",
      "Epoch 94/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.3985 - acc: 0.8303 - val_loss: 0.3833 - val_acc: 0.8303\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.3991 - acc: 0.8241 - val_loss: 0.3881 - val_acc: 0.8282\n",
      "Epoch 96/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.3962 - acc: 0.8287 - val_loss: 0.3868 - val_acc: 0.8241\n",
      "Epoch 97/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.3966 - acc: 0.8298 - val_loss: 0.3873 - val_acc: 0.8262\n",
      "Epoch 98/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.3903 - acc: 0.8287 - val_loss: 0.3847 - val_acc: 0.8241\n",
      "Epoch 99/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.3926 - acc: 0.8267 - val_loss: 0.3859 - val_acc: 0.8241\n",
      "Epoch 100/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.3918 - acc: 0.8308 - val_loss: 0.3829 - val_acc: 0.8241\n",
      "Train on 1956 samples, validate on 489 samples\n",
      "Epoch 1/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.4322 - acc: 0.8027 - val_loss: 0.4335 - val_acc: 0.8016\n",
      "Epoch 2/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.4270 - acc: 0.8078 - val_loss: 0.4292 - val_acc: 0.8119\n",
      "Epoch 3/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.4220 - acc: 0.8078 - val_loss: 0.4296 - val_acc: 0.8057\n",
      "Epoch 4/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.4297 - acc: 0.8139 - val_loss: 0.4311 - val_acc: 0.8037\n",
      "Epoch 5/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.4181 - acc: 0.8134 - val_loss: 0.4241 - val_acc: 0.8078\n",
      "Epoch 6/100\n",
      "1956/1956 [==============================] - 1s 347us/step - loss: 0.4232 - acc: 0.8093 - val_loss: 0.4228 - val_acc: 0.8098\n",
      "Epoch 7/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.4188 - acc: 0.8144 - val_loss: 0.4253 - val_acc: 0.8078\n",
      "Epoch 8/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.4074 - acc: 0.8149 - val_loss: 0.4223 - val_acc: 0.8098\n",
      "Epoch 9/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.4126 - acc: 0.8134 - val_loss: 0.4194 - val_acc: 0.8139\n",
      "Epoch 10/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.4220 - acc: 0.8037 - val_loss: 0.4228 - val_acc: 0.8098\n",
      "Epoch 11/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.4097 - acc: 0.8185 - val_loss: 0.4207 - val_acc: 0.8078\n",
      "Epoch 12/100\n",
      "1956/1956 [==============================] - 1s 348us/step - loss: 0.4095 - acc: 0.8134 - val_loss: 0.4186 - val_acc: 0.8119\n",
      "Epoch 13/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.4154 - acc: 0.8149 - val_loss: 0.4216 - val_acc: 0.8078\n",
      "Epoch 14/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.4106 - acc: 0.8206 - val_loss: 0.4178 - val_acc: 0.8119\n",
      "Epoch 15/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.4158 - acc: 0.8185 - val_loss: 0.4162 - val_acc: 0.8119\n",
      "Epoch 16/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.4108 - acc: 0.8134 - val_loss: 0.4153 - val_acc: 0.8139\n",
      "Epoch 17/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.4021 - acc: 0.8246 - val_loss: 0.4147 - val_acc: 0.8160\n",
      "Epoch 18/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.4126 - acc: 0.8124 - val_loss: 0.4150 - val_acc: 0.8119\n",
      "Epoch 19/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.3963 - acc: 0.8333 - val_loss: 0.4129 - val_acc: 0.8180\n",
      "Epoch 20/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.4105 - acc: 0.8154 - val_loss: 0.4154 - val_acc: 0.8057\n",
      "Epoch 21/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.4020 - acc: 0.8277 - val_loss: 0.4156 - val_acc: 0.8037\n",
      "Epoch 22/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.4009 - acc: 0.8144 - val_loss: 0.4133 - val_acc: 0.8139\n",
      "Epoch 23/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.4001 - acc: 0.8252 - val_loss: 0.4117 - val_acc: 0.8139\n",
      "Epoch 24/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.4053 - acc: 0.8216 - val_loss: 0.4115 - val_acc: 0.8139\n",
      "Epoch 25/100\n",
      "1956/1956 [==============================] - 1s 348us/step - loss: 0.3984 - acc: 0.8185 - val_loss: 0.4127 - val_acc: 0.8119\n",
      "Epoch 26/100\n",
      "1956/1956 [==============================] - 1s 348us/step - loss: 0.4009 - acc: 0.8267 - val_loss: 0.4108 - val_acc: 0.8139\n",
      "Epoch 27/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.3919 - acc: 0.8246 - val_loss: 0.4109 - val_acc: 0.8098\n",
      "Epoch 28/100\n",
      "1956/1956 [==============================] - 1s 346us/step - loss: 0.3963 - acc: 0.8287 - val_loss: 0.4084 - val_acc: 0.8139\n",
      "Epoch 29/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.4026 - acc: 0.8231 - val_loss: 0.4053 - val_acc: 0.8262\n",
      "Epoch 30/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.3998 - acc: 0.8323 - val_loss: 0.4089 - val_acc: 0.8139\n",
      "Epoch 31/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.3928 - acc: 0.8272 - val_loss: 0.4094 - val_acc: 0.8119\n",
      "Epoch 32/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.3929 - acc: 0.8267 - val_loss: 0.4055 - val_acc: 0.8180\n",
      "Epoch 33/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.3928 - acc: 0.8287 - val_loss: 0.4048 - val_acc: 0.8180\n",
      "Epoch 34/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.3973 - acc: 0.8165 - val_loss: 0.4059 - val_acc: 0.8139\n",
      "Epoch 35/100\n",
      "1956/1956 [==============================] - 1s 346us/step - loss: 0.3855 - acc: 0.8267 - val_loss: 0.4030 - val_acc: 0.8200\n",
      "Epoch 36/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.3966 - acc: 0.8333 - val_loss: 0.4016 - val_acc: 0.8262\n",
      "Epoch 37/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.3918 - acc: 0.8303 - val_loss: 0.3994 - val_acc: 0.8303\n",
      "Epoch 38/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.3917 - acc: 0.8241 - val_loss: 0.4005 - val_acc: 0.8282\n",
      "Epoch 39/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.3804 - acc: 0.8400 - val_loss: 0.4030 - val_acc: 0.8139\n",
      "Epoch 40/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.3842 - acc: 0.8287 - val_loss: 0.4022 - val_acc: 0.8119\n",
      "Epoch 41/100\n",
      "1956/1956 [==============================] - 1s 348us/step - loss: 0.3930 - acc: 0.8200 - val_loss: 0.3982 - val_acc: 0.8282\n",
      "Epoch 42/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.3869 - acc: 0.8236 - val_loss: 0.3985 - val_acc: 0.8241\n",
      "Epoch 43/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.3833 - acc: 0.8292 - val_loss: 0.4028 - val_acc: 0.8078\n",
      "Epoch 44/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.3818 - acc: 0.8313 - val_loss: 0.4020 - val_acc: 0.8078\n",
      "Epoch 45/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.3870 - acc: 0.8303 - val_loss: 0.3999 - val_acc: 0.8180\n",
      "Epoch 46/100\n",
      "1956/1956 [==============================] - 1s 348us/step - loss: 0.3899 - acc: 0.8282 - val_loss: 0.4012 - val_acc: 0.8098\n",
      "Epoch 47/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.3815 - acc: 0.8303 - val_loss: 0.4001 - val_acc: 0.8119\n",
      "Epoch 48/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.3798 - acc: 0.8354 - val_loss: 0.3991 - val_acc: 0.8139\n",
      "Epoch 49/100\n",
      "1956/1956 [==============================] - 1s 346us/step - loss: 0.3761 - acc: 0.8420 - val_loss: 0.3942 - val_acc: 0.8262\n",
      "Epoch 50/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.3778 - acc: 0.8303 - val_loss: 0.3966 - val_acc: 0.8160\n",
      "Epoch 51/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.3759 - acc: 0.8384 - val_loss: 0.3942 - val_acc: 0.8160\n",
      "Epoch 52/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.3709 - acc: 0.8410 - val_loss: 0.3934 - val_acc: 0.8160\n",
      "Epoch 53/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.3765 - acc: 0.8359 - val_loss: 0.3956 - val_acc: 0.8139\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.3736 - acc: 0.8364 - val_loss: 0.3938 - val_acc: 0.8139\n",
      "Epoch 55/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.3732 - acc: 0.8405 - val_loss: 0.3910 - val_acc: 0.8180\n",
      "Epoch 56/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.3780 - acc: 0.8328 - val_loss: 0.3914 - val_acc: 0.8180\n",
      "Epoch 57/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.3740 - acc: 0.8303 - val_loss: 0.3908 - val_acc: 0.8180\n",
      "Epoch 58/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.3733 - acc: 0.8405 - val_loss: 0.3889 - val_acc: 0.8221\n",
      "Epoch 59/100\n",
      "1956/1956 [==============================] - 1s 371us/step - loss: 0.3811 - acc: 0.8308 - val_loss: 0.3898 - val_acc: 0.8200\n",
      "Epoch 60/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.3762 - acc: 0.8364 - val_loss: 0.3877 - val_acc: 0.8221\n",
      "Epoch 61/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.3789 - acc: 0.8374 - val_loss: 0.3892 - val_acc: 0.8241\n",
      "Epoch 62/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.3730 - acc: 0.8328 - val_loss: 0.3866 - val_acc: 0.8221\n",
      "Epoch 63/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.3697 - acc: 0.8395 - val_loss: 0.3870 - val_acc: 0.8262\n",
      "Epoch 64/100\n",
      "1956/1956 [==============================] - 1s 348us/step - loss: 0.3635 - acc: 0.8420 - val_loss: 0.3872 - val_acc: 0.8241\n",
      "Epoch 65/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.3797 - acc: 0.8390 - val_loss: 0.3855 - val_acc: 0.8262\n",
      "Epoch 66/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.3643 - acc: 0.8425 - val_loss: 0.3833 - val_acc: 0.8282\n",
      "Epoch 67/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.3656 - acc: 0.8338 - val_loss: 0.3863 - val_acc: 0.8262\n",
      "Epoch 68/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.3659 - acc: 0.8410 - val_loss: 0.3906 - val_acc: 0.8180\n",
      "Epoch 69/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.3586 - acc: 0.8476 - val_loss: 0.3826 - val_acc: 0.8323\n",
      "Epoch 70/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.3617 - acc: 0.8425 - val_loss: 0.3902 - val_acc: 0.8200\n",
      "Epoch 71/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.3619 - acc: 0.8405 - val_loss: 0.3798 - val_acc: 0.8262\n",
      "Epoch 72/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.3649 - acc: 0.8425 - val_loss: 0.3804 - val_acc: 0.8303\n",
      "Epoch 73/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.3583 - acc: 0.8446 - val_loss: 0.3827 - val_acc: 0.8262\n",
      "Epoch 74/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.3649 - acc: 0.8471 - val_loss: 0.3784 - val_acc: 0.8303\n",
      "Epoch 75/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.3586 - acc: 0.8425 - val_loss: 0.3793 - val_acc: 0.8282\n",
      "Epoch 76/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.3523 - acc: 0.8466 - val_loss: 0.3814 - val_acc: 0.8303\n",
      "Epoch 77/100\n",
      "1956/1956 [==============================] - 1s 348us/step - loss: 0.3560 - acc: 0.8533 - val_loss: 0.3775 - val_acc: 0.8303\n",
      "Epoch 78/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.3560 - acc: 0.8456 - val_loss: 0.3758 - val_acc: 0.8282\n",
      "Epoch 79/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.3547 - acc: 0.8517 - val_loss: 0.3784 - val_acc: 0.8344\n",
      "Epoch 80/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.3496 - acc: 0.8507 - val_loss: 0.3749 - val_acc: 0.8303\n",
      "Epoch 81/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.3502 - acc: 0.8456 - val_loss: 0.3739 - val_acc: 0.8303\n",
      "Epoch 82/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.3465 - acc: 0.8548 - val_loss: 0.3726 - val_acc: 0.8303\n",
      "Epoch 83/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.3552 - acc: 0.8528 - val_loss: 0.3753 - val_acc: 0.8364\n",
      "Epoch 84/100\n",
      "1956/1956 [==============================] - 1s 345us/step - loss: 0.3550 - acc: 0.8466 - val_loss: 0.3765 - val_acc: 0.8323\n",
      "Epoch 85/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.3532 - acc: 0.8476 - val_loss: 0.3740 - val_acc: 0.8364\n",
      "Epoch 86/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.3497 - acc: 0.8507 - val_loss: 0.3736 - val_acc: 0.8364\n",
      "Epoch 87/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.3477 - acc: 0.8476 - val_loss: 0.3727 - val_acc: 0.8364\n",
      "Epoch 88/100\n",
      "1956/1956 [==============================] - 1s 348us/step - loss: 0.3465 - acc: 0.8507 - val_loss: 0.3766 - val_acc: 0.8323\n",
      "Epoch 89/100\n",
      "1956/1956 [==============================] - 1s 348us/step - loss: 0.3562 - acc: 0.8487 - val_loss: 0.3746 - val_acc: 0.8384\n",
      "Epoch 90/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.3471 - acc: 0.8553 - val_loss: 0.3766 - val_acc: 0.8323\n",
      "Epoch 91/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.3513 - acc: 0.8517 - val_loss: 0.3749 - val_acc: 0.8344\n",
      "Epoch 92/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.3390 - acc: 0.8528 - val_loss: 0.3677 - val_acc: 0.8405\n",
      "Epoch 93/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.3455 - acc: 0.8589 - val_loss: 0.3689 - val_acc: 0.8364\n",
      "Epoch 94/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.3427 - acc: 0.8563 - val_loss: 0.3699 - val_acc: 0.8384\n",
      "Epoch 95/100\n",
      "1956/1956 [==============================] - ETA: 0s - loss: 0.3379 - acc: 0.856 - 1s 348us/step - loss: 0.3449 - acc: 0.8512 - val_loss: 0.3683 - val_acc: 0.8364\n",
      "Epoch 96/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.3425 - acc: 0.8517 - val_loss: 0.3706 - val_acc: 0.8384\n",
      "Epoch 97/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.3373 - acc: 0.8487 - val_loss: 0.3719 - val_acc: 0.8384\n",
      "Epoch 98/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.3436 - acc: 0.8543 - val_loss: 0.3663 - val_acc: 0.8384\n",
      "Epoch 99/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.3414 - acc: 0.8543 - val_loss: 0.3642 - val_acc: 0.8466\n",
      "Epoch 100/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.3361 - acc: 0.8594 - val_loss: 0.3632 - val_acc: 0.8466\n",
      "Test subject 11, class FirstDigitTouch\n",
      "Train subject 11, class BothStartLoadPhase\n",
      "Train on 1955 samples, validate on 489 samples\n",
      "Epoch 1/100\n",
      "1955/1955 [==============================] - 2s 973us/step - loss: 0.6947 - acc: 0.4895 - val_loss: 0.6930 - val_acc: 0.5153\n",
      "Epoch 2/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.6945 - acc: 0.5074 - val_loss: 0.6928 - val_acc: 0.5133\n",
      "Epoch 3/100\n",
      "1955/1955 [==============================] - 1s 339us/step - loss: 0.6946 - acc: 0.4818 - val_loss: 0.6922 - val_acc: 0.5031\n",
      "Epoch 4/100\n",
      "1955/1955 [==============================] - 1s 351us/step - loss: 0.6939 - acc: 0.4992 - val_loss: 0.6917 - val_acc: 0.5174\n",
      "Epoch 5/100\n",
      "1955/1955 [==============================] - 1s 349us/step - loss: 0.6947 - acc: 0.4818 - val_loss: 0.6913 - val_acc: 0.5378\n",
      "Epoch 6/100\n",
      "1955/1955 [==============================] - 1s 357us/step - loss: 0.6919 - acc: 0.5197 - val_loss: 0.6908 - val_acc: 0.5624\n",
      "Epoch 7/100\n",
      "1955/1955 [==============================] - 1s 368us/step - loss: 0.6926 - acc: 0.5115 - val_loss: 0.6907 - val_acc: 0.5562\n",
      "Epoch 8/100\n",
      "1955/1955 [==============================] - 1s 355us/step - loss: 0.6909 - acc: 0.5335 - val_loss: 0.6903 - val_acc: 0.5828\n",
      "Epoch 9/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.6927 - acc: 0.5166 - val_loss: 0.6899 - val_acc: 0.5706\n",
      "Epoch 10/100\n",
      "1955/1955 [==============================] - 1s 352us/step - loss: 0.6917 - acc: 0.5059 - val_loss: 0.6896 - val_acc: 0.5787\n",
      "Epoch 11/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.6913 - acc: 0.5156 - val_loss: 0.6893 - val_acc: 0.5910\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1955/1955 [==============================] - 1s 355us/step - loss: 0.6894 - acc: 0.5371 - val_loss: 0.6891 - val_acc: 0.5910\n",
      "Epoch 13/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.6927 - acc: 0.5217 - val_loss: 0.6887 - val_acc: 0.5849\n",
      "Epoch 14/100\n",
      "1955/1955 [==============================] - 1s 352us/step - loss: 0.6904 - acc: 0.5320 - val_loss: 0.6885 - val_acc: 0.5992\n",
      "Epoch 15/100\n",
      "1955/1955 [==============================] - 1s 351us/step - loss: 0.6912 - acc: 0.5212 - val_loss: 0.6882 - val_acc: 0.5849\n",
      "Epoch 16/100\n",
      "1955/1955 [==============================] - 1s 360us/step - loss: 0.6915 - acc: 0.5304 - val_loss: 0.6880 - val_acc: 0.5787\n",
      "Epoch 17/100\n",
      "1955/1955 [==============================] - 1s 352us/step - loss: 0.6897 - acc: 0.5361 - val_loss: 0.6878 - val_acc: 0.5869\n",
      "Epoch 18/100\n",
      "1955/1955 [==============================] - 1s 354us/step - loss: 0.6883 - acc: 0.5529 - val_loss: 0.6877 - val_acc: 0.5951\n",
      "Epoch 19/100\n",
      "1955/1955 [==============================] - 1s 356us/step - loss: 0.6897 - acc: 0.5320 - val_loss: 0.6873 - val_acc: 0.5849\n",
      "Epoch 20/100\n",
      "1955/1955 [==============================] - 1s 354us/step - loss: 0.6888 - acc: 0.5494 - val_loss: 0.6869 - val_acc: 0.5971\n",
      "Epoch 21/100\n",
      "1955/1955 [==============================] - 1s 373us/step - loss: 0.6878 - acc: 0.5376 - val_loss: 0.6867 - val_acc: 0.5890\n",
      "Epoch 22/100\n",
      "1955/1955 [==============================] - 1s 357us/step - loss: 0.6864 - acc: 0.5591 - val_loss: 0.6864 - val_acc: 0.5910\n",
      "Epoch 23/100\n",
      "1955/1955 [==============================] - 1s 352us/step - loss: 0.6872 - acc: 0.5488 - val_loss: 0.6861 - val_acc: 0.6033\n",
      "Epoch 24/100\n",
      "1955/1955 [==============================] - 1s 356us/step - loss: 0.6871 - acc: 0.5545 - val_loss: 0.6859 - val_acc: 0.6053\n",
      "Epoch 25/100\n",
      "1955/1955 [==============================] - 1s 358us/step - loss: 0.6874 - acc: 0.5432 - val_loss: 0.6855 - val_acc: 0.6053\n",
      "Epoch 26/100\n",
      "1955/1955 [==============================] - 1s 352us/step - loss: 0.6875 - acc: 0.5504 - val_loss: 0.6851 - val_acc: 0.6074\n",
      "Epoch 27/100\n",
      "1955/1955 [==============================] - 1s 353us/step - loss: 0.6864 - acc: 0.5570 - val_loss: 0.6849 - val_acc: 0.6155\n",
      "Epoch 28/100\n",
      "1955/1955 [==============================] - 1s 367us/step - loss: 0.6852 - acc: 0.5831 - val_loss: 0.6846 - val_acc: 0.6196\n",
      "Epoch 29/100\n",
      "1955/1955 [==============================] - 1s 353us/step - loss: 0.6858 - acc: 0.5734 - val_loss: 0.6843 - val_acc: 0.6258\n",
      "Epoch 30/100\n",
      "1955/1955 [==============================] - 1s 352us/step - loss: 0.6839 - acc: 0.5714 - val_loss: 0.6842 - val_acc: 0.6176\n",
      "Epoch 31/100\n",
      "1955/1955 [==============================] - 1s 355us/step - loss: 0.6842 - acc: 0.5657 - val_loss: 0.6837 - val_acc: 0.6196\n",
      "Epoch 32/100\n",
      "1955/1955 [==============================] - 1s 350us/step - loss: 0.6846 - acc: 0.5601 - val_loss: 0.6833 - val_acc: 0.6196\n",
      "Epoch 33/100\n",
      "1955/1955 [==============================] - 1s 358us/step - loss: 0.6827 - acc: 0.5765 - val_loss: 0.6830 - val_acc: 0.6196\n",
      "Epoch 34/100\n",
      "1955/1955 [==============================] - 1s 357us/step - loss: 0.6825 - acc: 0.5688 - val_loss: 0.6823 - val_acc: 0.6319\n",
      "Epoch 35/100\n",
      "1955/1955 [==============================] - 1s 351us/step - loss: 0.6810 - acc: 0.5887 - val_loss: 0.6821 - val_acc: 0.6237\n",
      "Epoch 36/100\n",
      "1955/1955 [==============================] - 1s 349us/step - loss: 0.6824 - acc: 0.5903 - val_loss: 0.6817 - val_acc: 0.6196\n",
      "Epoch 37/100\n",
      "1955/1955 [==============================] - 1s 355us/step - loss: 0.6796 - acc: 0.5954 - val_loss: 0.6811 - val_acc: 0.6217\n",
      "Epoch 38/100\n",
      "1955/1955 [==============================] - 1s 345us/step - loss: 0.6826 - acc: 0.5775 - val_loss: 0.6805 - val_acc: 0.6258\n",
      "Epoch 39/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.6795 - acc: 0.5995 - val_loss: 0.6800 - val_acc: 0.6258\n",
      "Epoch 40/100\n",
      "1955/1955 [==============================] - 1s 351us/step - loss: 0.6768 - acc: 0.6107 - val_loss: 0.6793 - val_acc: 0.6319\n",
      "Epoch 41/100\n",
      "1955/1955 [==============================] - 1s 353us/step - loss: 0.6760 - acc: 0.6256 - val_loss: 0.6786 - val_acc: 0.6299\n",
      "Epoch 42/100\n",
      "1955/1955 [==============================] - 1s 351us/step - loss: 0.6797 - acc: 0.5985 - val_loss: 0.6781 - val_acc: 0.6258\n",
      "Epoch 43/100\n",
      "1955/1955 [==============================] - 1s 354us/step - loss: 0.6763 - acc: 0.6102 - val_loss: 0.6776 - val_acc: 0.6258\n",
      "Epoch 44/100\n",
      "1955/1955 [==============================] - 1s 358us/step - loss: 0.6765 - acc: 0.6118 - val_loss: 0.6769 - val_acc: 0.6258\n",
      "Epoch 45/100\n",
      "1955/1955 [==============================] - 1s 350us/step - loss: 0.6746 - acc: 0.6133 - val_loss: 0.6759 - val_acc: 0.6258\n",
      "Epoch 46/100\n",
      "1955/1955 [==============================] - 1s 352us/step - loss: 0.6739 - acc: 0.6189 - val_loss: 0.6754 - val_acc: 0.6319\n",
      "Epoch 47/100\n",
      "1955/1955 [==============================] - 1s 353us/step - loss: 0.6721 - acc: 0.6210 - val_loss: 0.6746 - val_acc: 0.6360\n",
      "Epoch 48/100\n",
      "1955/1955 [==============================] - 1s 354us/step - loss: 0.6730 - acc: 0.6297 - val_loss: 0.6741 - val_acc: 0.6421\n",
      "Epoch 49/100\n",
      "1955/1955 [==============================] - 1s 353us/step - loss: 0.6705 - acc: 0.6327 - val_loss: 0.6733 - val_acc: 0.6483\n",
      "Epoch 50/100\n",
      "1955/1955 [==============================] - 1s 350us/step - loss: 0.6706 - acc: 0.6312 - val_loss: 0.6721 - val_acc: 0.6421\n",
      "Epoch 51/100\n",
      "1955/1955 [==============================] - 1s 360us/step - loss: 0.6674 - acc: 0.6425 - val_loss: 0.6715 - val_acc: 0.6462\n",
      "Epoch 52/100\n",
      "1955/1955 [==============================] - 1s 349us/step - loss: 0.6679 - acc: 0.6455 - val_loss: 0.6701 - val_acc: 0.6462\n",
      "Epoch 53/100\n",
      "1955/1955 [==============================] - 1s 354us/step - loss: 0.6645 - acc: 0.6547 - val_loss: 0.6690 - val_acc: 0.6503\n",
      "Epoch 54/100\n",
      "1955/1955 [==============================] - 1s 356us/step - loss: 0.6661 - acc: 0.6506 - val_loss: 0.6678 - val_acc: 0.6462\n",
      "Epoch 55/100\n",
      "1955/1955 [==============================] - 1s 356us/step - loss: 0.6660 - acc: 0.6435 - val_loss: 0.6662 - val_acc: 0.6483\n",
      "Epoch 56/100\n",
      "1955/1955 [==============================] - 1s 359us/step - loss: 0.6600 - acc: 0.6685 - val_loss: 0.6649 - val_acc: 0.6483\n",
      "Epoch 57/100\n",
      "1955/1955 [==============================] - 1s 363us/step - loss: 0.6602 - acc: 0.6558 - val_loss: 0.6635 - val_acc: 0.6483\n",
      "Epoch 58/100\n",
      "1955/1955 [==============================] - 1s 350us/step - loss: 0.6569 - acc: 0.6629 - val_loss: 0.6619 - val_acc: 0.6544\n",
      "Epoch 59/100\n",
      "1955/1955 [==============================] - 1s 354us/step - loss: 0.6573 - acc: 0.6568 - val_loss: 0.6605 - val_acc: 0.6544\n",
      "Epoch 60/100\n",
      "1955/1955 [==============================] - 1s 353us/step - loss: 0.6528 - acc: 0.6680 - val_loss: 0.6589 - val_acc: 0.6524\n",
      "Epoch 61/100\n",
      "1955/1955 [==============================] - 1s 362us/step - loss: 0.6560 - acc: 0.6598 - val_loss: 0.6570 - val_acc: 0.6585\n",
      "Epoch 62/100\n",
      "1955/1955 [==============================] - 1s 358us/step - loss: 0.6528 - acc: 0.6593 - val_loss: 0.6558 - val_acc: 0.6585\n",
      "Epoch 63/100\n",
      "1955/1955 [==============================] - 1s 351us/step - loss: 0.6460 - acc: 0.6762 - val_loss: 0.6540 - val_acc: 0.6585\n",
      "Epoch 64/100\n",
      "1955/1955 [==============================] - 1s 357us/step - loss: 0.6453 - acc: 0.6813 - val_loss: 0.6517 - val_acc: 0.6585\n",
      "Epoch 65/100\n",
      "1955/1955 [==============================] - 1s 355us/step - loss: 0.6432 - acc: 0.6824 - val_loss: 0.6494 - val_acc: 0.6564\n",
      "Epoch 66/100\n",
      "1955/1955 [==============================] - 1s 359us/step - loss: 0.6436 - acc: 0.6737 - val_loss: 0.6473 - val_acc: 0.6585\n",
      "Epoch 67/100\n",
      "1955/1955 [==============================] - 1s 353us/step - loss: 0.6379 - acc: 0.6916 - val_loss: 0.6445 - val_acc: 0.6585\n",
      "Epoch 68/100\n",
      "1955/1955 [==============================] - 1s 352us/step - loss: 0.6362 - acc: 0.6992 - val_loss: 0.6421 - val_acc: 0.6667\n",
      "Epoch 69/100\n",
      "1955/1955 [==============================] - 1s 353us/step - loss: 0.6346 - acc: 0.6839 - val_loss: 0.6395 - val_acc: 0.6585\n",
      "Epoch 70/100\n",
      "1955/1955 [==============================] - 1s 359us/step - loss: 0.6323 - acc: 0.6926 - val_loss: 0.6369 - val_acc: 0.6605\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1955/1955 [==============================] - 1s 353us/step - loss: 0.6238 - acc: 0.7023 - val_loss: 0.6345 - val_acc: 0.6667\n",
      "Epoch 72/100\n",
      "1955/1955 [==============================] - 1s 351us/step - loss: 0.6221 - acc: 0.7038 - val_loss: 0.6314 - val_acc: 0.6626\n",
      "Epoch 73/100\n",
      "1955/1955 [==============================] - 1s 365us/step - loss: 0.6178 - acc: 0.7090 - val_loss: 0.6284 - val_acc: 0.6646\n",
      "Epoch 74/100\n",
      "1955/1955 [==============================] - 1s 356us/step - loss: 0.6162 - acc: 0.7125 - val_loss: 0.6256 - val_acc: 0.6667\n",
      "Epoch 75/100\n",
      "1955/1955 [==============================] - 1s 360us/step - loss: 0.6118 - acc: 0.7095 - val_loss: 0.6224 - val_acc: 0.6646\n",
      "Epoch 76/100\n",
      "1955/1955 [==============================] - 1s 353us/step - loss: 0.6069 - acc: 0.7269 - val_loss: 0.6189 - val_acc: 0.6646\n",
      "Epoch 77/100\n",
      "1955/1955 [==============================] - 1s 358us/step - loss: 0.6070 - acc: 0.7166 - val_loss: 0.6155 - val_acc: 0.6667\n",
      "Epoch 78/100\n",
      "1955/1955 [==============================] - 1s 352us/step - loss: 0.6012 - acc: 0.7156 - val_loss: 0.6121 - val_acc: 0.6646\n",
      "Epoch 79/100\n",
      "1955/1955 [==============================] - 1s 354us/step - loss: 0.5980 - acc: 0.7156 - val_loss: 0.6089 - val_acc: 0.6687\n",
      "Epoch 80/100\n",
      "1955/1955 [==============================] - 1s 360us/step - loss: 0.5898 - acc: 0.7269 - val_loss: 0.6054 - val_acc: 0.6728\n",
      "Epoch 81/100\n",
      "1955/1955 [==============================] - 1s 351us/step - loss: 0.5870 - acc: 0.7289 - val_loss: 0.6018 - val_acc: 0.6708\n",
      "Epoch 82/100\n",
      "1955/1955 [==============================] - 1s 363us/step - loss: 0.5802 - acc: 0.7361 - val_loss: 0.5981 - val_acc: 0.6769\n",
      "Epoch 83/100\n",
      "1955/1955 [==============================] - 1s 353us/step - loss: 0.5826 - acc: 0.7253 - val_loss: 0.5945 - val_acc: 0.6769\n",
      "Epoch 84/100\n",
      "1955/1955 [==============================] - 1s 358us/step - loss: 0.5748 - acc: 0.7437 - val_loss: 0.5908 - val_acc: 0.6830\n",
      "Epoch 85/100\n",
      "1955/1955 [==============================] - 1s 356us/step - loss: 0.5721 - acc: 0.7355 - val_loss: 0.5878 - val_acc: 0.6810\n",
      "Epoch 86/100\n",
      "1955/1955 [==============================] - 1s 356us/step - loss: 0.5633 - acc: 0.7437 - val_loss: 0.5841 - val_acc: 0.6830\n",
      "Epoch 87/100\n",
      "1955/1955 [==============================] - 1s 364us/step - loss: 0.5570 - acc: 0.7550 - val_loss: 0.5804 - val_acc: 0.6851\n",
      "Epoch 88/100\n",
      "1955/1955 [==============================] - 1s 356us/step - loss: 0.5535 - acc: 0.7514 - val_loss: 0.5760 - val_acc: 0.6994\n",
      "Epoch 89/100\n",
      "1955/1955 [==============================] - 1s 361us/step - loss: 0.5530 - acc: 0.7545 - val_loss: 0.5725 - val_acc: 0.6953\n",
      "Epoch 90/100\n",
      "1955/1955 [==============================] - 1s 367us/step - loss: 0.5485 - acc: 0.7478 - val_loss: 0.5690 - val_acc: 0.7014\n",
      "Epoch 91/100\n",
      "1955/1955 [==============================] - 1s 355us/step - loss: 0.5423 - acc: 0.7540 - val_loss: 0.5659 - val_acc: 0.7055\n",
      "Epoch 92/100\n",
      "1955/1955 [==============================] - 1s 364us/step - loss: 0.5380 - acc: 0.7586 - val_loss: 0.5624 - val_acc: 0.7055\n",
      "Epoch 93/100\n",
      "1955/1955 [==============================] - 1s 364us/step - loss: 0.5340 - acc: 0.7662 - val_loss: 0.5591 - val_acc: 0.7076\n",
      "Epoch 94/100\n",
      "1955/1955 [==============================] - 1s 403us/step - loss: 0.5259 - acc: 0.7734 - val_loss: 0.5561 - val_acc: 0.7117\n",
      "Epoch 95/100\n",
      "1955/1955 [==============================] - 1s 381us/step - loss: 0.5306 - acc: 0.7611 - val_loss: 0.5528 - val_acc: 0.7137\n",
      "Epoch 96/100\n",
      "1955/1955 [==============================] - 1s 400us/step - loss: 0.5207 - acc: 0.7678 - val_loss: 0.5494 - val_acc: 0.7117\n",
      "Epoch 97/100\n",
      "1955/1955 [==============================] - 1s 364us/step - loss: 0.5128 - acc: 0.7739 - val_loss: 0.5473 - val_acc: 0.7301\n",
      "Epoch 98/100\n",
      "1955/1955 [==============================] - 1s 364us/step - loss: 0.5191 - acc: 0.7775 - val_loss: 0.5434 - val_acc: 0.7219\n",
      "Epoch 99/100\n",
      "1955/1955 [==============================] - 1s 359us/step - loss: 0.5162 - acc: 0.7657 - val_loss: 0.5406 - val_acc: 0.7239\n",
      "Epoch 100/100\n",
      "1955/1955 [==============================] - 1s 369us/step - loss: 0.5081 - acc: 0.7801 - val_loss: 0.5375 - val_acc: 0.7280\n",
      "Train on 1955 samples, validate on 489 samples\n",
      "Epoch 1/100\n",
      "1955/1955 [==============================] - 1s 359us/step - loss: 0.5167 - acc: 0.7729 - val_loss: 0.4936 - val_acc: 0.7771\n",
      "Epoch 2/100\n",
      "1955/1955 [==============================] - 1s 363us/step - loss: 0.5131 - acc: 0.7683 - val_loss: 0.4897 - val_acc: 0.7791\n",
      "Epoch 3/100\n",
      "1955/1955 [==============================] - 1s 364us/step - loss: 0.5111 - acc: 0.7693 - val_loss: 0.4867 - val_acc: 0.7710\n",
      "Epoch 4/100\n",
      "1955/1955 [==============================] - 1s 386us/step - loss: 0.5058 - acc: 0.7698 - val_loss: 0.4849 - val_acc: 0.7730\n",
      "Epoch 5/100\n",
      "1955/1955 [==============================] - 1s 388us/step - loss: 0.5041 - acc: 0.7734 - val_loss: 0.4800 - val_acc: 0.7751\n",
      "Epoch 6/100\n",
      "1955/1955 [==============================] - 1s 366us/step - loss: 0.5031 - acc: 0.7734 - val_loss: 0.4774 - val_acc: 0.7771\n",
      "Epoch 7/100\n",
      "1955/1955 [==============================] - 1s 367us/step - loss: 0.4969 - acc: 0.7847 - val_loss: 0.4744 - val_acc: 0.7771\n",
      "Epoch 8/100\n",
      "1955/1955 [==============================] - 1s 351us/step - loss: 0.4876 - acc: 0.7847 - val_loss: 0.4721 - val_acc: 0.7751\n",
      "Epoch 9/100\n",
      "1955/1955 [==============================] - 1s 360us/step - loss: 0.4891 - acc: 0.7903 - val_loss: 0.4707 - val_acc: 0.7771\n",
      "Epoch 10/100\n",
      "1955/1955 [==============================] - 1s 357us/step - loss: 0.4897 - acc: 0.7847 - val_loss: 0.4676 - val_acc: 0.7771\n",
      "Epoch 11/100\n",
      "1955/1955 [==============================] - 1s 359us/step - loss: 0.4920 - acc: 0.7744 - val_loss: 0.4655 - val_acc: 0.7791\n",
      "Epoch 12/100\n",
      "1955/1955 [==============================] - 1s 363us/step - loss: 0.4800 - acc: 0.7811 - val_loss: 0.4662 - val_acc: 0.7771\n",
      "Epoch 13/100\n",
      "1955/1955 [==============================] - 1s 361us/step - loss: 0.4775 - acc: 0.7893 - val_loss: 0.4621 - val_acc: 0.7771\n",
      "Epoch 14/100\n",
      "1955/1955 [==============================] - 1s 356us/step - loss: 0.4780 - acc: 0.7821 - val_loss: 0.4603 - val_acc: 0.7771\n",
      "Epoch 15/100\n",
      "1955/1955 [==============================] - 1s 357us/step - loss: 0.4769 - acc: 0.7841 - val_loss: 0.4576 - val_acc: 0.7832\n",
      "Epoch 16/100\n",
      "1955/1955 [==============================] - 1s 361us/step - loss: 0.4834 - acc: 0.7821 - val_loss: 0.4568 - val_acc: 0.7812\n",
      "Epoch 17/100\n",
      "1955/1955 [==============================] - 1s 357us/step - loss: 0.4738 - acc: 0.7913 - val_loss: 0.4550 - val_acc: 0.7832\n",
      "Epoch 18/100\n",
      "1955/1955 [==============================] - 1s 357us/step - loss: 0.4758 - acc: 0.7816 - val_loss: 0.4534 - val_acc: 0.7873\n",
      "Epoch 19/100\n",
      "1955/1955 [==============================] - 1s 351us/step - loss: 0.4735 - acc: 0.7801 - val_loss: 0.4547 - val_acc: 0.7873\n",
      "Epoch 20/100\n",
      "1955/1955 [==============================] - 1s 357us/step - loss: 0.4788 - acc: 0.7852 - val_loss: 0.4514 - val_acc: 0.7873\n",
      "Epoch 21/100\n",
      "1955/1955 [==============================] - 1s 367us/step - loss: 0.4704 - acc: 0.7831 - val_loss: 0.4503 - val_acc: 0.7894\n",
      "Epoch 22/100\n",
      "1955/1955 [==============================] - 1s 363us/step - loss: 0.4713 - acc: 0.7821 - val_loss: 0.4485 - val_acc: 0.7873\n",
      "Epoch 23/100\n",
      "1955/1955 [==============================] - 1s 355us/step - loss: 0.4702 - acc: 0.7990 - val_loss: 0.4479 - val_acc: 0.7894\n",
      "Epoch 24/100\n",
      "1955/1955 [==============================] - 1s 365us/step - loss: 0.4625 - acc: 0.7882 - val_loss: 0.4474 - val_acc: 0.7894\n",
      "Epoch 25/100\n",
      "1955/1955 [==============================] - 1s 374us/step - loss: 0.4600 - acc: 0.7913 - val_loss: 0.4474 - val_acc: 0.7935\n",
      "Epoch 26/100\n",
      "1955/1955 [==============================] - 1s 356us/step - loss: 0.4532 - acc: 0.7934 - val_loss: 0.4468 - val_acc: 0.7935\n",
      "Epoch 27/100\n",
      "1955/1955 [==============================] - 1s 351us/step - loss: 0.4691 - acc: 0.7872 - val_loss: 0.4447 - val_acc: 0.7935\n",
      "Epoch 28/100\n",
      "1955/1955 [==============================] - 1s 360us/step - loss: 0.4563 - acc: 0.7974 - val_loss: 0.4426 - val_acc: 0.7955\n",
      "Epoch 29/100\n",
      "1955/1955 [==============================] - 1s 358us/step - loss: 0.4625 - acc: 0.7974 - val_loss: 0.4435 - val_acc: 0.8016\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1955/1955 [==============================] - 1s 350us/step - loss: 0.4595 - acc: 0.7934 - val_loss: 0.4410 - val_acc: 0.7955\n",
      "Epoch 31/100\n",
      "1955/1955 [==============================] - 1s 359us/step - loss: 0.4592 - acc: 0.7872 - val_loss: 0.4420 - val_acc: 0.8016\n",
      "Epoch 32/100\n",
      "1955/1955 [==============================] - 1s 353us/step - loss: 0.4574 - acc: 0.7980 - val_loss: 0.4399 - val_acc: 0.7996\n",
      "Epoch 33/100\n",
      "1955/1955 [==============================] - 1s 374us/step - loss: 0.4511 - acc: 0.8010 - val_loss: 0.4389 - val_acc: 0.7996\n",
      "Epoch 34/100\n",
      "1955/1955 [==============================] - 1s 349us/step - loss: 0.4409 - acc: 0.8015 - val_loss: 0.4374 - val_acc: 0.7975\n",
      "Epoch 35/100\n",
      "1955/1955 [==============================] - 1s 350us/step - loss: 0.4540 - acc: 0.7980 - val_loss: 0.4370 - val_acc: 0.8016\n",
      "Epoch 36/100\n",
      "1955/1955 [==============================] - 1s 351us/step - loss: 0.4467 - acc: 0.7995 - val_loss: 0.4364 - val_acc: 0.8016\n",
      "Epoch 37/100\n",
      "1955/1955 [==============================] - 1s 355us/step - loss: 0.4355 - acc: 0.8066 - val_loss: 0.4342 - val_acc: 0.7996\n",
      "Epoch 38/100\n",
      "1955/1955 [==============================] - 1s 363us/step - loss: 0.4435 - acc: 0.8010 - val_loss: 0.4343 - val_acc: 0.8016\n",
      "Epoch 39/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.4462 - acc: 0.8046 - val_loss: 0.4328 - val_acc: 0.8037\n",
      "Epoch 40/100\n",
      "1955/1955 [==============================] - 1s 359us/step - loss: 0.4424 - acc: 0.7954 - val_loss: 0.4330 - val_acc: 0.8057\n",
      "Epoch 41/100\n",
      "1955/1955 [==============================] - 1s 352us/step - loss: 0.4384 - acc: 0.8082 - val_loss: 0.4310 - val_acc: 0.7996\n",
      "Epoch 42/100\n",
      "1955/1955 [==============================] - 1s 352us/step - loss: 0.4442 - acc: 0.8082 - val_loss: 0.4305 - val_acc: 0.8037\n",
      "Epoch 43/100\n",
      "1955/1955 [==============================] - 1s 357us/step - loss: 0.4326 - acc: 0.8061 - val_loss: 0.4294 - val_acc: 0.8016\n",
      "Epoch 44/100\n",
      "1955/1955 [==============================] - 1s 356us/step - loss: 0.4395 - acc: 0.8077 - val_loss: 0.4291 - val_acc: 0.8037\n",
      "Epoch 45/100\n",
      "1955/1955 [==============================] - 1s 349us/step - loss: 0.4371 - acc: 0.8051 - val_loss: 0.4279 - val_acc: 0.8016\n",
      "Epoch 46/100\n",
      "1955/1955 [==============================] - 1s 358us/step - loss: 0.4357 - acc: 0.8102 - val_loss: 0.4271 - val_acc: 0.8037\n",
      "Epoch 47/100\n",
      "1955/1955 [==============================] - 1s 360us/step - loss: 0.4394 - acc: 0.7990 - val_loss: 0.4263 - val_acc: 0.8057\n",
      "Epoch 48/100\n",
      "1955/1955 [==============================] - 1s 353us/step - loss: 0.4360 - acc: 0.8077 - val_loss: 0.4257 - val_acc: 0.8078\n",
      "Epoch 49/100\n",
      "1955/1955 [==============================] - 1s 352us/step - loss: 0.4316 - acc: 0.8169 - val_loss: 0.4271 - val_acc: 0.8037\n",
      "Epoch 50/100\n",
      "1955/1955 [==============================] - 1s 369us/step - loss: 0.4255 - acc: 0.8133 - val_loss: 0.4239 - val_acc: 0.8078\n",
      "Epoch 51/100\n",
      "1955/1955 [==============================] - 1s 356us/step - loss: 0.4380 - acc: 0.8020 - val_loss: 0.4244 - val_acc: 0.8057\n",
      "Epoch 52/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.4336 - acc: 0.8066 - val_loss: 0.4238 - val_acc: 0.8057\n",
      "Epoch 53/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.4306 - acc: 0.8056 - val_loss: 0.4214 - val_acc: 0.8078\n",
      "Epoch 54/100\n",
      "1955/1955 [==============================] - 1s 353us/step - loss: 0.4303 - acc: 0.8143 - val_loss: 0.4221 - val_acc: 0.8057\n",
      "Epoch 55/100\n",
      "1955/1955 [==============================] - 1s 354us/step - loss: 0.4248 - acc: 0.8118 - val_loss: 0.4221 - val_acc: 0.8119\n",
      "Epoch 56/100\n",
      "1955/1955 [==============================] - 1s 357us/step - loss: 0.4298 - acc: 0.8174 - val_loss: 0.4206 - val_acc: 0.8057\n",
      "Epoch 57/100\n",
      "1955/1955 [==============================] - 1s 350us/step - loss: 0.4233 - acc: 0.8153 - val_loss: 0.4193 - val_acc: 0.8078\n",
      "Epoch 58/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.4231 - acc: 0.8179 - val_loss: 0.4211 - val_acc: 0.8221\n",
      "Epoch 59/100\n",
      "1955/1955 [==============================] - 1s 353us/step - loss: 0.4252 - acc: 0.8133 - val_loss: 0.4162 - val_acc: 0.8098\n",
      "Epoch 60/100\n",
      "1955/1955 [==============================] - 1s 353us/step - loss: 0.4306 - acc: 0.8164 - val_loss: 0.4159 - val_acc: 0.8119\n",
      "Epoch 61/100\n",
      "1955/1955 [==============================] - 1s 356us/step - loss: 0.4230 - acc: 0.8123 - val_loss: 0.4157 - val_acc: 0.8160\n",
      "Epoch 62/100\n",
      "1955/1955 [==============================] - 1s 357us/step - loss: 0.4248 - acc: 0.8102 - val_loss: 0.4144 - val_acc: 0.8139\n",
      "Epoch 63/100\n",
      "1955/1955 [==============================] - 1s 354us/step - loss: 0.4298 - acc: 0.8056 - val_loss: 0.4144 - val_acc: 0.8160\n",
      "Epoch 64/100\n",
      "1955/1955 [==============================] - 1s 356us/step - loss: 0.4248 - acc: 0.8153 - val_loss: 0.4138 - val_acc: 0.8160\n",
      "Epoch 65/100\n",
      "1955/1955 [==============================] - 1s 353us/step - loss: 0.4206 - acc: 0.8138 - val_loss: 0.4136 - val_acc: 0.8160\n",
      "Epoch 66/100\n",
      "1955/1955 [==============================] - 1s 353us/step - loss: 0.4124 - acc: 0.8256 - val_loss: 0.4129 - val_acc: 0.8160\n",
      "Epoch 67/100\n",
      "1955/1955 [==============================] - 1s 363us/step - loss: 0.4171 - acc: 0.8148 - val_loss: 0.4116 - val_acc: 0.8200\n",
      "Epoch 68/100\n",
      "1955/1955 [==============================] - 1s 350us/step - loss: 0.4154 - acc: 0.8148 - val_loss: 0.4103 - val_acc: 0.8200\n",
      "Epoch 69/100\n",
      "1955/1955 [==============================] - 1s 350us/step - loss: 0.4196 - acc: 0.8174 - val_loss: 0.4099 - val_acc: 0.8221\n",
      "Epoch 70/100\n",
      "1955/1955 [==============================] - 1s 349us/step - loss: 0.4177 - acc: 0.8194 - val_loss: 0.4094 - val_acc: 0.8221\n",
      "Epoch 71/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.4123 - acc: 0.8215 - val_loss: 0.4109 - val_acc: 0.8262\n",
      "Epoch 72/100\n",
      "1955/1955 [==============================] - 1s 357us/step - loss: 0.4078 - acc: 0.8246 - val_loss: 0.4080 - val_acc: 0.8221\n",
      "Epoch 73/100\n",
      "1955/1955 [==============================] - 1s 372us/step - loss: 0.4149 - acc: 0.8199 - val_loss: 0.4065 - val_acc: 0.8180\n",
      "Epoch 74/100\n",
      "1955/1955 [==============================] - 1s 355us/step - loss: 0.4089 - acc: 0.8205 - val_loss: 0.4058 - val_acc: 0.8221\n",
      "Epoch 75/100\n",
      "1955/1955 [==============================] - 1s 352us/step - loss: 0.4106 - acc: 0.8235 - val_loss: 0.4059 - val_acc: 0.8241\n",
      "Epoch 76/100\n",
      "1955/1955 [==============================] - 1s 353us/step - loss: 0.4069 - acc: 0.8266 - val_loss: 0.4045 - val_acc: 0.8200\n",
      "Epoch 77/100\n",
      "1955/1955 [==============================] - 1s 347us/step - loss: 0.4013 - acc: 0.8266 - val_loss: 0.4039 - val_acc: 0.8139\n",
      "Epoch 78/100\n",
      "1955/1955 [==============================] - 1s 356us/step - loss: 0.4009 - acc: 0.8276 - val_loss: 0.4043 - val_acc: 0.8262\n",
      "Epoch 79/100\n",
      "1955/1955 [==============================] - 1s 350us/step - loss: 0.4044 - acc: 0.8246 - val_loss: 0.4024 - val_acc: 0.8303\n",
      "Epoch 80/100\n",
      "1955/1955 [==============================] - 1s 356us/step - loss: 0.4094 - acc: 0.8261 - val_loss: 0.4035 - val_acc: 0.8282\n",
      "Epoch 81/100\n",
      "1955/1955 [==============================] - 1s 364us/step - loss: 0.4046 - acc: 0.8317 - val_loss: 0.4019 - val_acc: 0.8282\n",
      "Epoch 82/100\n",
      "1955/1955 [==============================] - 1s 359us/step - loss: 0.3982 - acc: 0.8271 - val_loss: 0.4027 - val_acc: 0.8344\n",
      "Epoch 83/100\n",
      "1955/1955 [==============================] - 1s 353us/step - loss: 0.4019 - acc: 0.8281 - val_loss: 0.4002 - val_acc: 0.8303\n",
      "Epoch 84/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.4029 - acc: 0.8210 - val_loss: 0.3980 - val_acc: 0.8282\n",
      "Epoch 85/100\n",
      "1955/1955 [==============================] - 1s 359us/step - loss: 0.4092 - acc: 0.8230 - val_loss: 0.3983 - val_acc: 0.8303\n",
      "Epoch 86/100\n",
      "1955/1955 [==============================] - 1s 356us/step - loss: 0.3954 - acc: 0.8297 - val_loss: 0.3983 - val_acc: 0.8323\n",
      "Epoch 87/100\n",
      "1955/1955 [==============================] - 1s 349us/step - loss: 0.3978 - acc: 0.8261 - val_loss: 0.3969 - val_acc: 0.8323\n",
      "Epoch 88/100\n",
      "1955/1955 [==============================] - 1s 349us/step - loss: 0.3989 - acc: 0.8189 - val_loss: 0.3953 - val_acc: 0.8282\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1955/1955 [==============================] - 1s 352us/step - loss: 0.3974 - acc: 0.8302 - val_loss: 0.3970 - val_acc: 0.8364\n",
      "Epoch 90/100\n",
      "1955/1955 [==============================] - 1s 358us/step - loss: 0.4001 - acc: 0.8297 - val_loss: 0.3964 - val_acc: 0.8384\n",
      "Epoch 91/100\n",
      "1955/1955 [==============================] - 1s 365us/step - loss: 0.3901 - acc: 0.8281 - val_loss: 0.3942 - val_acc: 0.8344\n",
      "Epoch 92/100\n",
      "1955/1955 [==============================] - 1s 359us/step - loss: 0.3921 - acc: 0.8317 - val_loss: 0.3937 - val_acc: 0.8344\n",
      "Epoch 93/100\n",
      "1955/1955 [==============================] - 1s 350us/step - loss: 0.3895 - acc: 0.8317 - val_loss: 0.3924 - val_acc: 0.8303\n",
      "Epoch 94/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.3885 - acc: 0.8348 - val_loss: 0.3917 - val_acc: 0.8323\n",
      "Epoch 95/100\n",
      "1955/1955 [==============================] - 1s 355us/step - loss: 0.3946 - acc: 0.8343 - val_loss: 0.3922 - val_acc: 0.8364\n",
      "Epoch 96/100\n",
      "1955/1955 [==============================] - 1s 347us/step - loss: 0.3911 - acc: 0.8312 - val_loss: 0.3912 - val_acc: 0.8344\n",
      "Epoch 97/100\n",
      "1955/1955 [==============================] - 1s 347us/step - loss: 0.3953 - acc: 0.8240 - val_loss: 0.3925 - val_acc: 0.8384\n",
      "Epoch 98/100\n",
      "1955/1955 [==============================] - 1s 354us/step - loss: 0.3868 - acc: 0.8348 - val_loss: 0.3935 - val_acc: 0.8364\n",
      "Epoch 99/100\n",
      "1955/1955 [==============================] - ETA: 0s - loss: 0.4012 - acc: 0.825 - 1s 352us/step - loss: 0.3942 - acc: 0.8297 - val_loss: 0.3896 - val_acc: 0.8344\n",
      "Epoch 100/100\n",
      "1955/1955 [==============================] - 1s 350us/step - loss: 0.3910 - acc: 0.8338 - val_loss: 0.3910 - val_acc: 0.8364\n",
      "Test subject 11, class BothStartLoadPhase\n",
      "Train subject 11, class LiftOff\n",
      "Train on 1955 samples, validate on 489 samples\n",
      "Epoch 1/100\n",
      "1955/1955 [==============================] - 2s 937us/step - loss: 0.6923 - acc: 0.5120 - val_loss: 0.6915 - val_acc: 0.5337\n",
      "Epoch 2/100\n",
      "1955/1955 [==============================] - 1s 346us/step - loss: 0.6929 - acc: 0.5018 - val_loss: 0.6915 - val_acc: 0.5746\n",
      "Epoch 3/100\n",
      "1955/1955 [==============================] - 1s 347us/step - loss: 0.6942 - acc: 0.5038 - val_loss: 0.6915 - val_acc: 0.5828\n",
      "Epoch 4/100\n",
      "1955/1955 [==============================] - 1s 346us/step - loss: 0.6939 - acc: 0.5038 - val_loss: 0.6914 - val_acc: 0.5726\n",
      "Epoch 5/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.6932 - acc: 0.5033 - val_loss: 0.6914 - val_acc: 0.5542\n",
      "Epoch 6/100\n",
      "1955/1955 [==============================] - 1s 360us/step - loss: 0.6913 - acc: 0.5176 - val_loss: 0.6914 - val_acc: 0.5378\n",
      "Epoch 7/100\n",
      "1955/1955 [==============================] - 1s 349us/step - loss: 0.6945 - acc: 0.4946 - val_loss: 0.6914 - val_acc: 0.5297\n",
      "Epoch 8/100\n",
      "1955/1955 [==============================] - 1s 344us/step - loss: 0.6945 - acc: 0.4967 - val_loss: 0.6914 - val_acc: 0.5092\n",
      "Epoch 9/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.6915 - acc: 0.5161 - val_loss: 0.6914 - val_acc: 0.5112\n",
      "Epoch 10/100\n",
      "1955/1955 [==============================] - 1s 349us/step - loss: 0.6917 - acc: 0.5110 - val_loss: 0.6912 - val_acc: 0.5112\n",
      "Epoch 11/100\n",
      "1955/1955 [==============================] - 1s 346us/step - loss: 0.6927 - acc: 0.5258 - val_loss: 0.6912 - val_acc: 0.5031\n",
      "Epoch 12/100\n",
      "1955/1955 [==============================] - 1s 347us/step - loss: 0.6907 - acc: 0.5350 - val_loss: 0.6911 - val_acc: 0.4969\n",
      "Epoch 13/100\n",
      "1955/1955 [==============================] - 1s 346us/step - loss: 0.6928 - acc: 0.5079 - val_loss: 0.6907 - val_acc: 0.5133\n",
      "Epoch 14/100\n",
      "1955/1955 [==============================] - 1s 343us/step - loss: 0.6914 - acc: 0.5279 - val_loss: 0.6905 - val_acc: 0.5112\n",
      "Epoch 15/100\n",
      "1955/1955 [==============================] - 1s 349us/step - loss: 0.6920 - acc: 0.5105 - val_loss: 0.6905 - val_acc: 0.5092\n",
      "Epoch 16/100\n",
      "1955/1955 [==============================] - 1s 342us/step - loss: 0.6915 - acc: 0.5345 - val_loss: 0.6902 - val_acc: 0.5092\n",
      "Epoch 17/100\n",
      "1955/1955 [==============================] - 1s 343us/step - loss: 0.6916 - acc: 0.5294 - val_loss: 0.6900 - val_acc: 0.5133\n",
      "Epoch 18/100\n",
      "1955/1955 [==============================] - 1s 349us/step - loss: 0.6909 - acc: 0.5281 - val_loss: 0.6898 - val_acc: 0.5153\n",
      "Epoch 19/100\n",
      "1955/1955 [==============================] - 1s 349us/step - loss: 0.6915 - acc: 0.5258 - val_loss: 0.6894 - val_acc: 0.5276\n",
      "Epoch 20/100\n",
      "1955/1955 [==============================] - 1s 350us/step - loss: 0.6912 - acc: 0.5243 - val_loss: 0.6893 - val_acc: 0.5235\n",
      "Epoch 21/100\n",
      "1955/1955 [==============================] - 1s 351us/step - loss: 0.6892 - acc: 0.5453 - val_loss: 0.6890 - val_acc: 0.5358\n",
      "Epoch 22/100\n",
      "1955/1955 [==============================] - 1s 351us/step - loss: 0.6910 - acc: 0.5315 - val_loss: 0.6888 - val_acc: 0.5297\n",
      "Epoch 23/100\n",
      "1955/1955 [==============================] - 1s 355us/step - loss: 0.6915 - acc: 0.5253 - val_loss: 0.6884 - val_acc: 0.5399\n",
      "Epoch 24/100\n",
      "1955/1955 [==============================] - 1s 354us/step - loss: 0.6907 - acc: 0.5381 - val_loss: 0.6882 - val_acc: 0.5399\n",
      "Epoch 25/100\n",
      "1955/1955 [==============================] - 1s 357us/step - loss: 0.6883 - acc: 0.5499 - val_loss: 0.6880 - val_acc: 0.5419\n",
      "Epoch 26/100\n",
      "1955/1955 [==============================] - 1s 350us/step - loss: 0.6890 - acc: 0.5381 - val_loss: 0.6879 - val_acc: 0.5460\n",
      "Epoch 27/100\n",
      "1955/1955 [==============================] - 1s 346us/step - loss: 0.6884 - acc: 0.5560 - val_loss: 0.6875 - val_acc: 0.5501\n",
      "Epoch 28/100\n",
      "1955/1955 [==============================] - 1s 343us/step - loss: 0.6898 - acc: 0.5355 - val_loss: 0.6873 - val_acc: 0.5481\n",
      "Epoch 29/100\n",
      "1955/1955 [==============================] - 1s 352us/step - loss: 0.6876 - acc: 0.5504 - val_loss: 0.6868 - val_acc: 0.5665\n",
      "Epoch 30/100\n",
      "1955/1955 [==============================] - 1s 342us/step - loss: 0.6871 - acc: 0.5621 - val_loss: 0.6865 - val_acc: 0.5767\n",
      "Epoch 31/100\n",
      "1955/1955 [==============================] - 1s 350us/step - loss: 0.6891 - acc: 0.5545 - val_loss: 0.6860 - val_acc: 0.5992\n",
      "Epoch 32/100\n",
      "1955/1955 [==============================] - 1s 353us/step - loss: 0.6877 - acc: 0.5524 - val_loss: 0.6859 - val_acc: 0.5746\n",
      "Epoch 33/100\n",
      "1955/1955 [==============================] - 1s 356us/step - loss: 0.6888 - acc: 0.5616 - val_loss: 0.6856 - val_acc: 0.5787\n",
      "Epoch 34/100\n",
      "1955/1955 [==============================] - 1s 354us/step - loss: 0.6899 - acc: 0.5402 - val_loss: 0.6854 - val_acc: 0.5767\n",
      "Epoch 35/100\n",
      "1955/1955 [==============================] - 1s 347us/step - loss: 0.6846 - acc: 0.5683 - val_loss: 0.6851 - val_acc: 0.5767\n",
      "Epoch 36/100\n",
      "1955/1955 [==============================] - 1s 350us/step - loss: 0.6879 - acc: 0.5570 - val_loss: 0.6847 - val_acc: 0.5971\n",
      "Epoch 37/100\n",
      "1955/1955 [==============================] - 1s 345us/step - loss: 0.6884 - acc: 0.5514 - val_loss: 0.6843 - val_acc: 0.6074\n",
      "Epoch 38/100\n",
      "1955/1955 [==============================] - 1s 347us/step - loss: 0.6863 - acc: 0.5775 - val_loss: 0.6839 - val_acc: 0.6196\n",
      "Epoch 39/100\n",
      "1955/1955 [==============================] - 1s 352us/step - loss: 0.6863 - acc: 0.5765 - val_loss: 0.6836 - val_acc: 0.6074\n",
      "Epoch 40/100\n",
      "1955/1955 [==============================] - 1s 359us/step - loss: 0.6867 - acc: 0.5591 - val_loss: 0.6832 - val_acc: 0.6135\n",
      "Epoch 41/100\n",
      "1955/1955 [==============================] - 1s 351us/step - loss: 0.6840 - acc: 0.5877 - val_loss: 0.6827 - val_acc: 0.6380\n",
      "Epoch 42/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.6876 - acc: 0.5611 - val_loss: 0.6823 - val_acc: 0.6401\n",
      "Epoch 43/100\n",
      "1955/1955 [==============================] - 1s 351us/step - loss: 0.6855 - acc: 0.5765 - val_loss: 0.6817 - val_acc: 0.6524\n",
      "Epoch 44/100\n",
      "1955/1955 [==============================] - 1s 342us/step - loss: 0.6855 - acc: 0.5606 - val_loss: 0.6817 - val_acc: 0.6237\n",
      "Epoch 45/100\n",
      "1955/1955 [==============================] - 1s 347us/step - loss: 0.6854 - acc: 0.5724 - val_loss: 0.6811 - val_acc: 0.6380\n",
      "Epoch 46/100\n",
      "1955/1955 [==============================] - 1s 342us/step - loss: 0.6844 - acc: 0.5826 - val_loss: 0.6807 - val_acc: 0.6421\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1955/1955 [==============================] - 1s 344us/step - loss: 0.6839 - acc: 0.5765 - val_loss: 0.6802 - val_acc: 0.6442\n",
      "Epoch 48/100\n",
      "1955/1955 [==============================] - 1s 347us/step - loss: 0.6833 - acc: 0.5821 - val_loss: 0.6799 - val_acc: 0.6401\n",
      "Epoch 49/100\n",
      "1955/1955 [==============================] - 1s 347us/step - loss: 0.6824 - acc: 0.5959 - val_loss: 0.6792 - val_acc: 0.6462\n",
      "Epoch 50/100\n",
      "1955/1955 [==============================] - 1s 356us/step - loss: 0.6834 - acc: 0.5893 - val_loss: 0.6786 - val_acc: 0.6585\n",
      "Epoch 51/100\n",
      "1955/1955 [==============================] - 1s 358us/step - loss: 0.6828 - acc: 0.5985 - val_loss: 0.6783 - val_acc: 0.6421\n",
      "Epoch 52/100\n",
      "1955/1955 [==============================] - 1s 343us/step - loss: 0.6810 - acc: 0.6026 - val_loss: 0.6774 - val_acc: 0.6708\n",
      "Epoch 53/100\n",
      "1955/1955 [==============================] - 1s 349us/step - loss: 0.6785 - acc: 0.6148 - val_loss: 0.6767 - val_acc: 0.6789\n",
      "Epoch 54/100\n",
      "1955/1955 [==============================] - 1s 345us/step - loss: 0.6808 - acc: 0.5872 - val_loss: 0.6762 - val_acc: 0.6728\n",
      "Epoch 55/100\n",
      "1955/1955 [==============================] - 1s 350us/step - loss: 0.6800 - acc: 0.6036 - val_loss: 0.6754 - val_acc: 0.6748\n",
      "Epoch 56/100\n",
      "1955/1955 [==============================] - 1s 350us/step - loss: 0.6809 - acc: 0.6000 - val_loss: 0.6748 - val_acc: 0.6748\n",
      "Epoch 57/100\n",
      "1955/1955 [==============================] - 1s 344us/step - loss: 0.6801 - acc: 0.6123 - val_loss: 0.6739 - val_acc: 0.6933\n",
      "Epoch 58/100\n",
      "1955/1955 [==============================] - 1s 343us/step - loss: 0.6771 - acc: 0.6184 - val_loss: 0.6734 - val_acc: 0.6789\n",
      "Epoch 59/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.6754 - acc: 0.6302 - val_loss: 0.6726 - val_acc: 0.6789\n",
      "Epoch 60/100\n",
      "1955/1955 [==============================] - 1s 349us/step - loss: 0.6758 - acc: 0.6194 - val_loss: 0.6720 - val_acc: 0.6748\n",
      "Epoch 61/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.6779 - acc: 0.6051 - val_loss: 0.6711 - val_acc: 0.6789\n",
      "Epoch 62/100\n",
      "1955/1955 [==============================] - 1s 349us/step - loss: 0.6763 - acc: 0.6143 - val_loss: 0.6702 - val_acc: 0.6789\n",
      "Epoch 63/100\n",
      "1955/1955 [==============================] - 1s 351us/step - loss: 0.6737 - acc: 0.6276 - val_loss: 0.6690 - val_acc: 0.6953\n",
      "Epoch 64/100\n",
      "1955/1955 [==============================] - 1s 358us/step - loss: 0.6743 - acc: 0.6261 - val_loss: 0.6677 - val_acc: 0.7117\n",
      "Epoch 65/100\n",
      "1955/1955 [==============================] - 1s 361us/step - loss: 0.6761 - acc: 0.6220 - val_loss: 0.6668 - val_acc: 0.7137\n",
      "Epoch 66/100\n",
      "1955/1955 [==============================] - 1s 346us/step - loss: 0.6739 - acc: 0.6276 - val_loss: 0.6659 - val_acc: 0.7096\n",
      "Epoch 67/100\n",
      "1955/1955 [==============================] - 1s 345us/step - loss: 0.6724 - acc: 0.6292 - val_loss: 0.6650 - val_acc: 0.7076\n",
      "Epoch 68/100\n",
      "1955/1955 [==============================] - 1s 349us/step - loss: 0.6723 - acc: 0.6445 - val_loss: 0.6635 - val_acc: 0.7178\n",
      "Epoch 69/100\n",
      "1955/1955 [==============================] - 1s 350us/step - loss: 0.6690 - acc: 0.6394 - val_loss: 0.6624 - val_acc: 0.7178\n",
      "Epoch 70/100\n",
      "1955/1955 [==============================] - 1s 342us/step - loss: 0.6717 - acc: 0.6317 - val_loss: 0.6611 - val_acc: 0.7157\n",
      "Epoch 71/100\n",
      "1955/1955 [==============================] - 1s 343us/step - loss: 0.6692 - acc: 0.6471 - val_loss: 0.6599 - val_acc: 0.7198\n",
      "Epoch 72/100\n",
      "1955/1955 [==============================] - 1s 349us/step - loss: 0.6633 - acc: 0.6685 - val_loss: 0.6584 - val_acc: 0.7219\n",
      "Epoch 73/100\n",
      "1955/1955 [==============================] - 1s 346us/step - loss: 0.6673 - acc: 0.6476 - val_loss: 0.6574 - val_acc: 0.7137\n",
      "Epoch 74/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.6646 - acc: 0.6665 - val_loss: 0.6559 - val_acc: 0.7137\n",
      "Epoch 75/100\n",
      "1955/1955 [==============================] - 1s 349us/step - loss: 0.6628 - acc: 0.6634 - val_loss: 0.6543 - val_acc: 0.7157\n",
      "Epoch 76/100\n",
      "1955/1955 [==============================] - 1s 347us/step - loss: 0.6645 - acc: 0.6563 - val_loss: 0.6531 - val_acc: 0.7117\n",
      "Epoch 77/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.6590 - acc: 0.6742 - val_loss: 0.6510 - val_acc: 0.7137\n",
      "Epoch 78/100\n",
      "1955/1955 [==============================] - 1s 355us/step - loss: 0.6588 - acc: 0.6783 - val_loss: 0.6494 - val_acc: 0.7096\n",
      "Epoch 79/100\n",
      "1955/1955 [==============================] - 1s 358us/step - loss: 0.6559 - acc: 0.6844 - val_loss: 0.6467 - val_acc: 0.7342\n",
      "Epoch 80/100\n",
      "1955/1955 [==============================] - 1s 350us/step - loss: 0.6568 - acc: 0.6706 - val_loss: 0.6448 - val_acc: 0.7260\n",
      "Epoch 81/100\n",
      "1955/1955 [==============================] - 1s 349us/step - loss: 0.6532 - acc: 0.6675 - val_loss: 0.6427 - val_acc: 0.7280\n",
      "Epoch 82/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.6514 - acc: 0.6890 - val_loss: 0.6405 - val_acc: 0.7219\n",
      "Epoch 83/100\n",
      "1955/1955 [==============================] - 1s 349us/step - loss: 0.6494 - acc: 0.6824 - val_loss: 0.6380 - val_acc: 0.7198\n",
      "Epoch 84/100\n",
      "1955/1955 [==============================] - 1s 344us/step - loss: 0.6449 - acc: 0.6951 - val_loss: 0.6347 - val_acc: 0.7362\n",
      "Epoch 85/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.6428 - acc: 0.6905 - val_loss: 0.6323 - val_acc: 0.7301\n",
      "Epoch 86/100\n",
      "1955/1955 [==============================] - 1s 339us/step - loss: 0.6388 - acc: 0.7008 - val_loss: 0.6287 - val_acc: 0.7403\n",
      "Epoch 87/100\n",
      "1955/1955 [==============================] - 1s 350us/step - loss: 0.6363 - acc: 0.7054 - val_loss: 0.6256 - val_acc: 0.7362\n",
      "Epoch 88/100\n",
      "1955/1955 [==============================] - 1s 346us/step - loss: 0.6355 - acc: 0.7038 - val_loss: 0.6226 - val_acc: 0.7342\n",
      "Epoch 89/100\n",
      "1955/1955 [==============================] - 1s 353us/step - loss: 0.6283 - acc: 0.7161 - val_loss: 0.6186 - val_acc: 0.7423\n",
      "Epoch 90/100\n",
      "1955/1955 [==============================] - 1s 349us/step - loss: 0.6297 - acc: 0.7074 - val_loss: 0.6146 - val_acc: 0.7444\n",
      "Epoch 91/100\n",
      "1955/1955 [==============================] - 1s 350us/step - loss: 0.6184 - acc: 0.7263 - val_loss: 0.6105 - val_acc: 0.7485\n",
      "Epoch 92/100\n",
      "1955/1955 [==============================] - 1s 362us/step - loss: 0.6195 - acc: 0.7263 - val_loss: 0.6064 - val_acc: 0.7526\n",
      "Epoch 93/100\n",
      "1955/1955 [==============================] - 1s 351us/step - loss: 0.6182 - acc: 0.7228 - val_loss: 0.6023 - val_acc: 0.7505\n",
      "Epoch 94/100\n",
      "1955/1955 [==============================] - 1s 350us/step - loss: 0.6142 - acc: 0.7146 - val_loss: 0.5989 - val_acc: 0.7423\n",
      "Epoch 95/100\n",
      "1955/1955 [==============================] - 1s 360us/step - loss: 0.6090 - acc: 0.7320 - val_loss: 0.5929 - val_acc: 0.7566\n",
      "Epoch 96/100\n",
      "1955/1955 [==============================] - 1s 349us/step - loss: 0.6025 - acc: 0.7315 - val_loss: 0.5887 - val_acc: 0.7505\n",
      "Epoch 97/100\n",
      "1955/1955 [==============================] - 1s 346us/step - loss: 0.6016 - acc: 0.7330 - val_loss: 0.5830 - val_acc: 0.7607\n",
      "Epoch 98/100\n",
      "1955/1955 [==============================] - 1s 346us/step - loss: 0.5911 - acc: 0.7422 - val_loss: 0.5783 - val_acc: 0.7587\n",
      "Epoch 99/100\n",
      "1955/1955 [==============================] - 1s 343us/step - loss: 0.5934 - acc: 0.7263 - val_loss: 0.5746 - val_acc: 0.7546\n",
      "Epoch 100/100\n",
      "1955/1955 [==============================] - 1s 343us/step - loss: 0.5878 - acc: 0.7407 - val_loss: 0.5689 - val_acc: 0.7607\n",
      "Train on 1955 samples, validate on 489 samples\n",
      "Epoch 1/100\n",
      "1955/1955 [==============================] - 1s 344us/step - loss: 0.5851 - acc: 0.7412 - val_loss: 0.5662 - val_acc: 0.7669\n",
      "Epoch 2/100\n",
      "1955/1955 [==============================] - 1s 349us/step - loss: 0.5753 - acc: 0.7442 - val_loss: 0.5618 - val_acc: 0.7730\n",
      "Epoch 3/100\n",
      "1955/1955 [==============================] - 1s 351us/step - loss: 0.5773 - acc: 0.7279 - val_loss: 0.5575 - val_acc: 0.7771\n",
      "Epoch 4/100\n",
      "1955/1955 [==============================] - 1s 345us/step - loss: 0.5724 - acc: 0.7330 - val_loss: 0.5513 - val_acc: 0.7730\n",
      "Epoch 5/100\n",
      "1955/1955 [==============================] - 1s 343us/step - loss: 0.5620 - acc: 0.7412 - val_loss: 0.5477 - val_acc: 0.7812\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1955/1955 [==============================] - 1s 347us/step - loss: 0.5745 - acc: 0.7325 - val_loss: 0.5457 - val_acc: 0.7771\n",
      "Epoch 7/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.5593 - acc: 0.7417 - val_loss: 0.5418 - val_acc: 0.7771\n",
      "Epoch 8/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.5529 - acc: 0.7509 - val_loss: 0.5362 - val_acc: 0.7832\n",
      "Epoch 9/100\n",
      "1955/1955 [==============================] - 1s 366us/step - loss: 0.5524 - acc: 0.7488 - val_loss: 0.5321 - val_acc: 0.7832\n",
      "Epoch 10/100\n",
      "1955/1955 [==============================] - 1s 345us/step - loss: 0.5465 - acc: 0.7504 - val_loss: 0.5277 - val_acc: 0.7853\n",
      "Epoch 11/100\n",
      "1955/1955 [==============================] - 1s 347us/step - loss: 0.5406 - acc: 0.7529 - val_loss: 0.5265 - val_acc: 0.7853\n",
      "Epoch 12/100\n",
      "1955/1955 [==============================] - 1s 347us/step - loss: 0.5423 - acc: 0.7596 - val_loss: 0.5191 - val_acc: 0.7853\n",
      "Epoch 13/100\n",
      "1955/1955 [==============================] - 1s 347us/step - loss: 0.5380 - acc: 0.7611 - val_loss: 0.5156 - val_acc: 0.7914\n",
      "Epoch 14/100\n",
      "1955/1955 [==============================] - 1s 352us/step - loss: 0.5361 - acc: 0.7637 - val_loss: 0.5140 - val_acc: 0.7914\n",
      "Epoch 15/100\n",
      "1955/1955 [==============================] - 1s 357us/step - loss: 0.5351 - acc: 0.7642 - val_loss: 0.5083 - val_acc: 0.7935\n",
      "Epoch 16/100\n",
      "1955/1955 [==============================] - 1s 344us/step - loss: 0.5294 - acc: 0.7565 - val_loss: 0.5086 - val_acc: 0.7914\n",
      "Epoch 17/100\n",
      "1955/1955 [==============================] - 1s 351us/step - loss: 0.5316 - acc: 0.7529 - val_loss: 0.5042 - val_acc: 0.7975\n",
      "Epoch 18/100\n",
      "1955/1955 [==============================] - 1s 354us/step - loss: 0.5342 - acc: 0.7596 - val_loss: 0.4999 - val_acc: 0.7955\n",
      "Epoch 19/100\n",
      "1955/1955 [==============================] - 1s 351us/step - loss: 0.5159 - acc: 0.7739 - val_loss: 0.4970 - val_acc: 0.7975\n",
      "Epoch 20/100\n",
      "1955/1955 [==============================] - 1s 347us/step - loss: 0.5240 - acc: 0.7647 - val_loss: 0.4966 - val_acc: 0.8016\n",
      "Epoch 21/100\n",
      "1955/1955 [==============================] - 1s 345us/step - loss: 0.5186 - acc: 0.7724 - val_loss: 0.4969 - val_acc: 0.8119\n",
      "Epoch 22/100\n",
      "1955/1955 [==============================] - 1s 341us/step - loss: 0.5053 - acc: 0.7790 - val_loss: 0.4929 - val_acc: 0.8078\n",
      "Epoch 23/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.5234 - acc: 0.7668 - val_loss: 0.4902 - val_acc: 0.8057\n",
      "Epoch 24/100\n",
      "1955/1955 [==============================] - 1s 365us/step - loss: 0.5065 - acc: 0.7816 - val_loss: 0.4867 - val_acc: 0.8098\n",
      "Epoch 25/100\n",
      "1955/1955 [==============================] - 1s 350us/step - loss: 0.5188 - acc: 0.7749 - val_loss: 0.4864 - val_acc: 0.8139\n",
      "Epoch 26/100\n",
      "1955/1955 [==============================] - 1s 349us/step - loss: 0.5129 - acc: 0.7703 - val_loss: 0.4866 - val_acc: 0.8160\n",
      "Epoch 27/100\n",
      "1955/1955 [==============================] - 1s 346us/step - loss: 0.5106 - acc: 0.7770 - val_loss: 0.4850 - val_acc: 0.8180\n",
      "Epoch 28/100\n",
      "1955/1955 [==============================] - 1s 346us/step - loss: 0.5005 - acc: 0.7816 - val_loss: 0.4818 - val_acc: 0.8160\n",
      "Epoch 29/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.5076 - acc: 0.7903 - val_loss: 0.4792 - val_acc: 0.8139\n",
      "Epoch 30/100\n",
      "1955/1955 [==============================] - 1s 356us/step - loss: 0.5077 - acc: 0.7852 - val_loss: 0.4792 - val_acc: 0.8262\n",
      "Epoch 31/100\n",
      "1955/1955 [==============================] - 1s 354us/step - loss: 0.4981 - acc: 0.7857 - val_loss: 0.4762 - val_acc: 0.8180\n",
      "Epoch 32/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.5084 - acc: 0.7934 - val_loss: 0.4763 - val_acc: 0.8241\n",
      "Epoch 33/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.5157 - acc: 0.7760 - val_loss: 0.4760 - val_acc: 0.8262\n",
      "Epoch 34/100\n",
      "1955/1955 [==============================] - 1s 355us/step - loss: 0.4960 - acc: 0.7928 - val_loss: 0.4720 - val_acc: 0.8139\n",
      "Epoch 35/100\n",
      "1955/1955 [==============================] - 1s 353us/step - loss: 0.4991 - acc: 0.7785 - val_loss: 0.4712 - val_acc: 0.8241\n",
      "Epoch 36/100\n",
      "1955/1955 [==============================] - 1s 345us/step - loss: 0.5011 - acc: 0.7928 - val_loss: 0.4705 - val_acc: 0.8262\n",
      "Epoch 37/100\n",
      "1955/1955 [==============================] - 1s 342us/step - loss: 0.4997 - acc: 0.7893 - val_loss: 0.4687 - val_acc: 0.8262\n",
      "Epoch 38/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.5015 - acc: 0.7867 - val_loss: 0.4693 - val_acc: 0.8364\n",
      "Epoch 39/100\n",
      "1955/1955 [==============================] - 1s 349us/step - loss: 0.4949 - acc: 0.7816 - val_loss: 0.4681 - val_acc: 0.8323\n",
      "Epoch 40/100\n",
      "1955/1955 [==============================] - 1s 349us/step - loss: 0.4879 - acc: 0.7964 - val_loss: 0.4658 - val_acc: 0.8344\n",
      "Epoch 41/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.4892 - acc: 0.7882 - val_loss: 0.4642 - val_acc: 0.8323\n",
      "Epoch 42/100\n",
      "1955/1955 [==============================] - 1s 355us/step - loss: 0.4941 - acc: 0.7898 - val_loss: 0.4620 - val_acc: 0.8180\n",
      "Epoch 43/100\n",
      "1955/1955 [==============================] - 1s 351us/step - loss: 0.4931 - acc: 0.7862 - val_loss: 0.4631 - val_acc: 0.8303\n",
      "Epoch 44/100\n",
      "1955/1955 [==============================] - 1s 345us/step - loss: 0.4912 - acc: 0.7893 - val_loss: 0.4609 - val_acc: 0.8364\n",
      "Epoch 45/100\n",
      "1955/1955 [==============================] - 1s 345us/step - loss: 0.4859 - acc: 0.7913 - val_loss: 0.4594 - val_acc: 0.8282\n",
      "Epoch 46/100\n",
      "1955/1955 [==============================] - 1s 344us/step - loss: 0.4883 - acc: 0.7872 - val_loss: 0.4596 - val_acc: 0.8323\n",
      "Epoch 47/100\n",
      "1955/1955 [==============================] - 1s 361us/step - loss: 0.5051 - acc: 0.7795 - val_loss: 0.4582 - val_acc: 0.8344\n",
      "Epoch 48/100\n",
      "1955/1955 [==============================] - 1s 347us/step - loss: 0.4911 - acc: 0.7949 - val_loss: 0.4573 - val_acc: 0.8303\n",
      "Epoch 49/100\n",
      "1955/1955 [==============================] - 1s 350us/step - loss: 0.4911 - acc: 0.7882 - val_loss: 0.4582 - val_acc: 0.8323\n",
      "Epoch 50/100\n",
      "1955/1955 [==============================] - 1s 366us/step - loss: 0.4923 - acc: 0.7939 - val_loss: 0.4564 - val_acc: 0.8323\n",
      "Epoch 51/100\n",
      "1955/1955 [==============================] - 1s 361us/step - loss: 0.4939 - acc: 0.7939 - val_loss: 0.4559 - val_acc: 0.8364\n",
      "Epoch 52/100\n",
      "1955/1955 [==============================] - 1s 390us/step - loss: 0.4790 - acc: 0.7882 - val_loss: 0.4549 - val_acc: 0.8364\n",
      "Epoch 53/100\n",
      "1955/1955 [==============================] - 1s 347us/step - loss: 0.4918 - acc: 0.7934 - val_loss: 0.4534 - val_acc: 0.8364\n",
      "Epoch 54/100\n",
      "1955/1955 [==============================] - 1s 359us/step - loss: 0.5001 - acc: 0.7857 - val_loss: 0.4531 - val_acc: 0.8384\n",
      "Epoch 55/100\n",
      "1955/1955 [==============================] - 1s 367us/step - loss: 0.4846 - acc: 0.7974 - val_loss: 0.4519 - val_acc: 0.8405\n",
      "Epoch 56/100\n",
      "1955/1955 [==============================] - 1s 369us/step - loss: 0.4773 - acc: 0.8020 - val_loss: 0.4521 - val_acc: 0.8344\n",
      "Epoch 57/100\n",
      "1955/1955 [==============================] - 1s 359us/step - loss: 0.4910 - acc: 0.7928 - val_loss: 0.4503 - val_acc: 0.8425\n",
      "Epoch 58/100\n",
      "1955/1955 [==============================] - 1s 370us/step - loss: 0.4779 - acc: 0.8066 - val_loss: 0.4518 - val_acc: 0.8344\n",
      "Epoch 59/100\n",
      "1955/1955 [==============================] - 1s 357us/step - loss: 0.4698 - acc: 0.8031 - val_loss: 0.4484 - val_acc: 0.8364\n",
      "Epoch 60/100\n",
      "1955/1955 [==============================] - 1s 362us/step - loss: 0.4823 - acc: 0.7934 - val_loss: 0.4489 - val_acc: 0.8384\n",
      "Epoch 61/100\n",
      "1955/1955 [==============================] - 1s 365us/step - loss: 0.4877 - acc: 0.7980 - val_loss: 0.4481 - val_acc: 0.8405\n",
      "Epoch 62/100\n",
      "1955/1955 [==============================] - 1s 355us/step - loss: 0.4791 - acc: 0.7969 - val_loss: 0.4468 - val_acc: 0.8425\n",
      "Epoch 63/100\n",
      "1955/1955 [==============================] - 1s 361us/step - loss: 0.4827 - acc: 0.7939 - val_loss: 0.4465 - val_acc: 0.8425\n",
      "Epoch 64/100\n",
      "1955/1955 [==============================] - 1s 345us/step - loss: 0.4793 - acc: 0.8010 - val_loss: 0.4457 - val_acc: 0.8405\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1955/1955 [==============================] - 1s 341us/step - loss: 0.4716 - acc: 0.8041 - val_loss: 0.4447 - val_acc: 0.8425\n",
      "Epoch 66/100\n",
      "1955/1955 [==============================] - 1s 345us/step - loss: 0.4858 - acc: 0.7969 - val_loss: 0.4445 - val_acc: 0.8425\n",
      "Epoch 67/100\n",
      "1955/1955 [==============================] - 1s 344us/step - loss: 0.4724 - acc: 0.7980 - val_loss: 0.4450 - val_acc: 0.8344\n",
      "Epoch 68/100\n",
      "1955/1955 [==============================] - 1s 362us/step - loss: 0.4761 - acc: 0.8031 - val_loss: 0.4435 - val_acc: 0.8425\n",
      "Epoch 69/100\n",
      "1955/1955 [==============================] - 1s 366us/step - loss: 0.4647 - acc: 0.8026 - val_loss: 0.4427 - val_acc: 0.8425\n",
      "Epoch 70/100\n",
      "1955/1955 [==============================] - 1s 368us/step - loss: 0.4682 - acc: 0.8010 - val_loss: 0.4418 - val_acc: 0.8425\n",
      "Epoch 71/100\n",
      "1955/1955 [==============================] - 1s 352us/step - loss: 0.4658 - acc: 0.8026 - val_loss: 0.4408 - val_acc: 0.8446\n",
      "Epoch 72/100\n",
      "1955/1955 [==============================] - 1s 355us/step - loss: 0.4751 - acc: 0.8000 - val_loss: 0.4409 - val_acc: 0.8405\n",
      "Epoch 73/100\n",
      "1955/1955 [==============================] - 1s 367us/step - loss: 0.4722 - acc: 0.8026 - val_loss: 0.4395 - val_acc: 0.8446\n",
      "Epoch 74/100\n",
      "1955/1955 [==============================] - 1s 356us/step - loss: 0.4668 - acc: 0.8123 - val_loss: 0.4389 - val_acc: 0.8446\n",
      "Epoch 75/100\n",
      "1955/1955 [==============================] - 1s 346us/step - loss: 0.4708 - acc: 0.8061 - val_loss: 0.4385 - val_acc: 0.8425\n",
      "Epoch 76/100\n",
      "1955/1955 [==============================] - 1s 345us/step - loss: 0.4621 - acc: 0.8082 - val_loss: 0.4380 - val_acc: 0.8446\n",
      "Epoch 77/100\n",
      "1955/1955 [==============================] - 1s 342us/step - loss: 0.4625 - acc: 0.8046 - val_loss: 0.4372 - val_acc: 0.8425\n",
      "Epoch 78/100\n",
      "1955/1955 [==============================] - 1s 355us/step - loss: 0.4614 - acc: 0.8061 - val_loss: 0.4358 - val_acc: 0.8446\n",
      "Epoch 79/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.4655 - acc: 0.7980 - val_loss: 0.4352 - val_acc: 0.8446\n",
      "Epoch 80/100\n",
      "1955/1955 [==============================] - 1s 350us/step - loss: 0.4661 - acc: 0.8179 - val_loss: 0.4344 - val_acc: 0.8466\n",
      "Epoch 81/100\n",
      "1955/1955 [==============================] - 1s 353us/step - loss: 0.4568 - acc: 0.8133 - val_loss: 0.4345 - val_acc: 0.8405\n",
      "Epoch 82/100\n",
      "1955/1955 [==============================] - 1s 346us/step - loss: 0.4644 - acc: 0.7954 - val_loss: 0.4335 - val_acc: 0.8466\n",
      "Epoch 83/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.4674 - acc: 0.8041 - val_loss: 0.4333 - val_acc: 0.8446\n",
      "Epoch 84/100\n",
      "1955/1955 [==============================] - 1s 351us/step - loss: 0.4652 - acc: 0.8041 - val_loss: 0.4324 - val_acc: 0.8487\n",
      "Epoch 85/100\n",
      "1955/1955 [==============================] - 1s 358us/step - loss: 0.4654 - acc: 0.8087 - val_loss: 0.4327 - val_acc: 0.8425\n",
      "Epoch 86/100\n",
      "1955/1955 [==============================] - 1s 343us/step - loss: 0.4558 - acc: 0.8056 - val_loss: 0.4344 - val_acc: 0.8344\n",
      "Epoch 87/100\n",
      "1955/1955 [==============================] - 1s 343us/step - loss: 0.4635 - acc: 0.8097 - val_loss: 0.4312 - val_acc: 0.8487\n",
      "Epoch 88/100\n",
      "1955/1955 [==============================] - 1s 355us/step - loss: 0.4613 - acc: 0.8164 - val_loss: 0.4306 - val_acc: 0.8446\n",
      "Epoch 89/100\n",
      "1955/1955 [==============================] - 1s 346us/step - loss: 0.4567 - acc: 0.8082 - val_loss: 0.4303 - val_acc: 0.8466\n",
      "Epoch 90/100\n",
      "1955/1955 [==============================] - 1s 341us/step - loss: 0.4529 - acc: 0.8184 - val_loss: 0.4288 - val_acc: 0.8446\n",
      "Epoch 91/100\n",
      "1955/1955 [==============================] - 1s 353us/step - loss: 0.4522 - acc: 0.8107 - val_loss: 0.4282 - val_acc: 0.8446\n",
      "Epoch 92/100\n",
      "1955/1955 [==============================] - 1s 344us/step - loss: 0.4566 - acc: 0.8041 - val_loss: 0.4294 - val_acc: 0.8364\n",
      "Epoch 93/100\n",
      "1955/1955 [==============================] - 1s 347us/step - loss: 0.4569 - acc: 0.8102 - val_loss: 0.4288 - val_acc: 0.8466\n",
      "Epoch 94/100\n",
      "1955/1955 [==============================] - 1s 346us/step - loss: 0.4464 - acc: 0.8184 - val_loss: 0.4261 - val_acc: 0.8487\n",
      "Epoch 95/100\n",
      "1955/1955 [==============================] - 1s 354us/step - loss: 0.4507 - acc: 0.8107 - val_loss: 0.4257 - val_acc: 0.8466\n",
      "Epoch 96/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.4587 - acc: 0.8097 - val_loss: 0.4247 - val_acc: 0.8446\n",
      "Epoch 97/100\n",
      "1955/1955 [==============================] - 1s 345us/step - loss: 0.4586 - acc: 0.8102 - val_loss: 0.4246 - val_acc: 0.8446\n",
      "Epoch 98/100\n",
      "1955/1955 [==============================] - 1s 349us/step - loss: 0.4519 - acc: 0.8128 - val_loss: 0.4246 - val_acc: 0.8507\n",
      "Epoch 99/100\n",
      "1955/1955 [==============================] - 1s 345us/step - loss: 0.4530 - acc: 0.8133 - val_loss: 0.4247 - val_acc: 0.8528\n",
      "Epoch 100/100\n",
      "1955/1955 [==============================] - 1s 343us/step - loss: 0.4551 - acc: 0.8046 - val_loss: 0.4223 - val_acc: 0.8466\n",
      "Test subject 11, class LiftOff\n",
      "Train subject 11, class Replace\n",
      "Train on 1944 samples, validate on 486 samples\n",
      "Epoch 1/100\n",
      "1944/1944 [==============================] - 2s 969us/step - loss: 0.6969 - acc: 0.4851 - val_loss: 0.6939 - val_acc: 0.5082\n",
      "Epoch 2/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.6958 - acc: 0.4887 - val_loss: 0.6923 - val_acc: 0.5021\n",
      "Epoch 3/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.6931 - acc: 0.5134 - val_loss: 0.6907 - val_acc: 0.5062\n",
      "Epoch 4/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.6920 - acc: 0.5180 - val_loss: 0.6893 - val_acc: 0.5082\n",
      "Epoch 5/100\n",
      "1944/1944 [==============================] - 1s 362us/step - loss: 0.6912 - acc: 0.5340 - val_loss: 0.6878 - val_acc: 0.5103\n",
      "Epoch 6/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.6895 - acc: 0.5283 - val_loss: 0.6864 - val_acc: 0.5123\n",
      "Epoch 7/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.6861 - acc: 0.5484 - val_loss: 0.6848 - val_acc: 0.5267\n",
      "Epoch 8/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.6848 - acc: 0.5586 - val_loss: 0.6834 - val_acc: 0.5309\n",
      "Epoch 9/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.6852 - acc: 0.5504 - val_loss: 0.6818 - val_acc: 0.5391\n",
      "Epoch 10/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.6819 - acc: 0.5782 - val_loss: 0.6801 - val_acc: 0.5494\n",
      "Epoch 11/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.6823 - acc: 0.5638 - val_loss: 0.6783 - val_acc: 0.5679\n",
      "Epoch 12/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.6817 - acc: 0.5802 - val_loss: 0.6764 - val_acc: 0.5844\n",
      "Epoch 13/100\n",
      "1944/1944 [==============================] - 1s 367us/step - loss: 0.6768 - acc: 0.5844 - val_loss: 0.6744 - val_acc: 0.5905\n",
      "Epoch 14/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.6751 - acc: 0.6116 - val_loss: 0.6724 - val_acc: 0.6049\n",
      "Epoch 15/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.6721 - acc: 0.6204 - val_loss: 0.6701 - val_acc: 0.6091\n",
      "Epoch 16/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.6708 - acc: 0.6091 - val_loss: 0.6677 - val_acc: 0.6091\n",
      "Epoch 17/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.6670 - acc: 0.6456 - val_loss: 0.6650 - val_acc: 0.6091\n",
      "Epoch 18/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.6676 - acc: 0.6296 - val_loss: 0.6622 - val_acc: 0.6111\n",
      "Epoch 19/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.6650 - acc: 0.6466 - val_loss: 0.6592 - val_acc: 0.6152\n",
      "Epoch 20/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.6585 - acc: 0.6615 - val_loss: 0.6559 - val_acc: 0.6173\n",
      "Epoch 21/100\n",
      "1944/1944 [==============================] - 1s 360us/step - loss: 0.6577 - acc: 0.6528 - val_loss: 0.6523 - val_acc: 0.6296\n",
      "Epoch 22/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.6528 - acc: 0.6564 - val_loss: 0.6484 - val_acc: 0.6358\n",
      "Epoch 23/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.6519 - acc: 0.6723 - val_loss: 0.6443 - val_acc: 0.6379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.6431 - acc: 0.6785 - val_loss: 0.6397 - val_acc: 0.6481\n",
      "Epoch 25/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.6380 - acc: 0.6867 - val_loss: 0.6346 - val_acc: 0.6770\n",
      "Epoch 26/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.6341 - acc: 0.7047 - val_loss: 0.6292 - val_acc: 0.6914\n",
      "Epoch 27/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.6306 - acc: 0.6914 - val_loss: 0.6233 - val_acc: 0.6975\n",
      "Epoch 28/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.6267 - acc: 0.7073 - val_loss: 0.6170 - val_acc: 0.7016\n",
      "Epoch 29/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.6198 - acc: 0.7094 - val_loss: 0.6101 - val_acc: 0.7058\n",
      "Epoch 30/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.6109 - acc: 0.7207 - val_loss: 0.6025 - val_acc: 0.7099\n",
      "Epoch 31/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.5989 - acc: 0.7269 - val_loss: 0.5941 - val_acc: 0.7119\n",
      "Epoch 32/100\n",
      "1944/1944 [==============================] - 1s 356us/step - loss: 0.5957 - acc: 0.7248 - val_loss: 0.5852 - val_acc: 0.7243\n",
      "Epoch 33/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.5876 - acc: 0.7320 - val_loss: 0.5764 - val_acc: 0.7284\n",
      "Epoch 34/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.5797 - acc: 0.7351 - val_loss: 0.5674 - val_acc: 0.7387\n",
      "Epoch 35/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.5675 - acc: 0.7464 - val_loss: 0.5569 - val_acc: 0.7531\n",
      "Epoch 36/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.5579 - acc: 0.7438 - val_loss: 0.5473 - val_acc: 0.7613\n",
      "Epoch 37/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.5465 - acc: 0.7593 - val_loss: 0.5367 - val_acc: 0.7613\n",
      "Epoch 38/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.5359 - acc: 0.7546 - val_loss: 0.5261 - val_acc: 0.7613\n",
      "Epoch 39/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.5239 - acc: 0.7649 - val_loss: 0.5160 - val_acc: 0.7695\n",
      "Epoch 40/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.5183 - acc: 0.7716 - val_loss: 0.5057 - val_acc: 0.7778\n",
      "Epoch 41/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.5083 - acc: 0.7685 - val_loss: 0.4971 - val_acc: 0.7881\n",
      "Epoch 42/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.5108 - acc: 0.7587 - val_loss: 0.4881 - val_acc: 0.7922\n",
      "Epoch 43/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.4884 - acc: 0.7767 - val_loss: 0.4798 - val_acc: 0.7942\n",
      "Epoch 44/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.4813 - acc: 0.7829 - val_loss: 0.4710 - val_acc: 0.7963\n",
      "Epoch 45/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.4788 - acc: 0.7778 - val_loss: 0.4629 - val_acc: 0.8086\n",
      "Epoch 46/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.4723 - acc: 0.7840 - val_loss: 0.4556 - val_acc: 0.8128\n",
      "Epoch 47/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.4619 - acc: 0.7870 - val_loss: 0.4493 - val_acc: 0.8169\n",
      "Epoch 48/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.4487 - acc: 0.8040 - val_loss: 0.4426 - val_acc: 0.8210\n",
      "Epoch 49/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.4534 - acc: 0.7906 - val_loss: 0.4369 - val_acc: 0.8189\n",
      "Epoch 50/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.4413 - acc: 0.8009 - val_loss: 0.4321 - val_acc: 0.8210\n",
      "Epoch 51/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.4294 - acc: 0.8040 - val_loss: 0.4264 - val_acc: 0.8230\n",
      "Epoch 52/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.4294 - acc: 0.8040 - val_loss: 0.4214 - val_acc: 0.8251\n",
      "Epoch 53/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.4255 - acc: 0.8045 - val_loss: 0.4171 - val_acc: 0.8292\n",
      "Epoch 54/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.4277 - acc: 0.8020 - val_loss: 0.4130 - val_acc: 0.8292\n",
      "Epoch 55/100\n",
      "1944/1944 [==============================] - 1s 363us/step - loss: 0.4171 - acc: 0.8097 - val_loss: 0.4093 - val_acc: 0.8272\n",
      "Epoch 56/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.4198 - acc: 0.8122 - val_loss: 0.4055 - val_acc: 0.8313\n",
      "Epoch 57/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.4059 - acc: 0.8086 - val_loss: 0.4020 - val_acc: 0.8333\n",
      "Epoch 58/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.4177 - acc: 0.8092 - val_loss: 0.3989 - val_acc: 0.8416\n",
      "Epoch 59/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.3994 - acc: 0.8169 - val_loss: 0.3956 - val_acc: 0.8416\n",
      "Epoch 60/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.3912 - acc: 0.8261 - val_loss: 0.3924 - val_acc: 0.8457\n",
      "Epoch 61/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.3934 - acc: 0.8169 - val_loss: 0.3895 - val_acc: 0.8477\n",
      "Epoch 62/100\n",
      "1944/1944 [==============================] - 1s 363us/step - loss: 0.3829 - acc: 0.8308 - val_loss: 0.3866 - val_acc: 0.8477\n",
      "Epoch 63/100\n",
      "1944/1944 [==============================] - 1s 379us/step - loss: 0.3883 - acc: 0.8256 - val_loss: 0.3842 - val_acc: 0.8477\n",
      "Epoch 64/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.3812 - acc: 0.8282 - val_loss: 0.3812 - val_acc: 0.8457\n",
      "Epoch 65/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.3836 - acc: 0.8297 - val_loss: 0.3797 - val_acc: 0.8519\n",
      "Epoch 66/100\n",
      "1944/1944 [==============================] - 1s 358us/step - loss: 0.3662 - acc: 0.8416 - val_loss: 0.3765 - val_acc: 0.8560\n",
      "Epoch 67/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.3777 - acc: 0.8308 - val_loss: 0.3752 - val_acc: 0.8539\n",
      "Epoch 68/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.3749 - acc: 0.8374 - val_loss: 0.3739 - val_acc: 0.8519\n",
      "Epoch 69/100\n",
      "1944/1944 [==============================] - 1s 356us/step - loss: 0.3638 - acc: 0.8431 - val_loss: 0.3710 - val_acc: 0.8580\n",
      "Epoch 70/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.3698 - acc: 0.8385 - val_loss: 0.3698 - val_acc: 0.8560\n",
      "Epoch 71/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.3652 - acc: 0.8369 - val_loss: 0.3689 - val_acc: 0.8560\n",
      "Epoch 72/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.3660 - acc: 0.8467 - val_loss: 0.3676 - val_acc: 0.8580\n",
      "Epoch 73/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.3611 - acc: 0.8467 - val_loss: 0.3647 - val_acc: 0.8642\n",
      "Epoch 74/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.3452 - acc: 0.8508 - val_loss: 0.3612 - val_acc: 0.8601\n",
      "Epoch 75/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.3543 - acc: 0.8519 - val_loss: 0.3610 - val_acc: 0.8642\n",
      "Epoch 76/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.3564 - acc: 0.8457 - val_loss: 0.3600 - val_acc: 0.8642\n",
      "Epoch 77/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.3487 - acc: 0.8493 - val_loss: 0.3571 - val_acc: 0.8663\n",
      "Epoch 78/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.3506 - acc: 0.8493 - val_loss: 0.3568 - val_acc: 0.8621\n",
      "Epoch 79/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.3400 - acc: 0.8555 - val_loss: 0.3555 - val_acc: 0.8642\n",
      "Epoch 80/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.3450 - acc: 0.8565 - val_loss: 0.3543 - val_acc: 0.8663\n",
      "Epoch 81/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.3433 - acc: 0.8544 - val_loss: 0.3542 - val_acc: 0.8683\n",
      "Epoch 82/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.3381 - acc: 0.8632 - val_loss: 0.3535 - val_acc: 0.8663\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.3346 - acc: 0.8678 - val_loss: 0.3512 - val_acc: 0.8704\n",
      "Epoch 84/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.3355 - acc: 0.8642 - val_loss: 0.3504 - val_acc: 0.8704\n",
      "Epoch 85/100\n",
      "1944/1944 [==============================] - 1s 359us/step - loss: 0.3285 - acc: 0.8565 - val_loss: 0.3499 - val_acc: 0.8683\n",
      "Epoch 86/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.3310 - acc: 0.8657 - val_loss: 0.3478 - val_acc: 0.8642\n",
      "Epoch 87/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.3281 - acc: 0.8611 - val_loss: 0.3490 - val_acc: 0.8663\n",
      "Epoch 88/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.3182 - acc: 0.8663 - val_loss: 0.3484 - val_acc: 0.8663\n",
      "Epoch 89/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.3282 - acc: 0.8642 - val_loss: 0.3458 - val_acc: 0.8683\n",
      "Epoch 90/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.3252 - acc: 0.8688 - val_loss: 0.3446 - val_acc: 0.8663\n",
      "Epoch 91/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.3180 - acc: 0.8673 - val_loss: 0.3441 - val_acc: 0.8663\n",
      "Epoch 92/100\n",
      "1944/1944 [==============================] - 1s 362us/step - loss: 0.3211 - acc: 0.8591 - val_loss: 0.3449 - val_acc: 0.8663\n",
      "Epoch 93/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.3144 - acc: 0.8688 - val_loss: 0.3435 - val_acc: 0.8663\n",
      "Epoch 94/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.3129 - acc: 0.8673 - val_loss: 0.3424 - val_acc: 0.8663\n",
      "Epoch 95/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.3162 - acc: 0.8663 - val_loss: 0.3403 - val_acc: 0.8683\n",
      "Epoch 96/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.3117 - acc: 0.8704 - val_loss: 0.3402 - val_acc: 0.8683\n",
      "Epoch 97/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.3145 - acc: 0.8673 - val_loss: 0.3394 - val_acc: 0.8683\n",
      "Epoch 98/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.3081 - acc: 0.8740 - val_loss: 0.3378 - val_acc: 0.8683\n",
      "Epoch 99/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.3119 - acc: 0.8740 - val_loss: 0.3384 - val_acc: 0.8704\n",
      "Epoch 100/100\n",
      "1944/1944 [==============================] - 1s 361us/step - loss: 0.3155 - acc: 0.8704 - val_loss: 0.3386 - val_acc: 0.8642\n",
      "Train on 1944 samples, validate on 486 samples\n",
      "Epoch 1/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.3153 - acc: 0.8791 - val_loss: 0.3051 - val_acc: 0.8868\n",
      "Epoch 2/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.3117 - acc: 0.8771 - val_loss: 0.3028 - val_acc: 0.8827\n",
      "Epoch 3/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.3125 - acc: 0.8776 - val_loss: 0.3013 - val_acc: 0.8827\n",
      "Epoch 4/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.3153 - acc: 0.8801 - val_loss: 0.3000 - val_acc: 0.8889\n",
      "Epoch 5/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.3057 - acc: 0.8781 - val_loss: 0.3002 - val_acc: 0.8889\n",
      "Epoch 6/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.3071 - acc: 0.8801 - val_loss: 0.2998 - val_acc: 0.8889\n",
      "Epoch 7/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.3023 - acc: 0.8853 - val_loss: 0.2986 - val_acc: 0.8889\n",
      "Epoch 8/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.2967 - acc: 0.8843 - val_loss: 0.2983 - val_acc: 0.8889\n",
      "Epoch 9/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.2990 - acc: 0.8786 - val_loss: 0.2962 - val_acc: 0.8889\n",
      "Epoch 10/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.3013 - acc: 0.8807 - val_loss: 0.2970 - val_acc: 0.8909\n",
      "Epoch 11/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.3002 - acc: 0.8843 - val_loss: 0.2958 - val_acc: 0.8889\n",
      "Epoch 12/100\n",
      "1944/1944 [==============================] - 1s 360us/step - loss: 0.3013 - acc: 0.8863 - val_loss: 0.2940 - val_acc: 0.8889\n",
      "Epoch 13/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.3005 - acc: 0.8848 - val_loss: 0.2960 - val_acc: 0.8930\n",
      "Epoch 14/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.3051 - acc: 0.8843 - val_loss: 0.2928 - val_acc: 0.8909\n",
      "Epoch 15/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.2971 - acc: 0.8827 - val_loss: 0.2924 - val_acc: 0.8868\n",
      "Epoch 16/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.2946 - acc: 0.8868 - val_loss: 0.2917 - val_acc: 0.8868\n",
      "Epoch 17/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.2989 - acc: 0.8807 - val_loss: 0.2910 - val_acc: 0.8889\n",
      "Epoch 18/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.2855 - acc: 0.8863 - val_loss: 0.2898 - val_acc: 0.8889\n",
      "Epoch 19/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.2863 - acc: 0.8935 - val_loss: 0.2894 - val_acc: 0.8909\n",
      "Epoch 20/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.2926 - acc: 0.8771 - val_loss: 0.2884 - val_acc: 0.8909\n",
      "Epoch 21/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.2841 - acc: 0.8827 - val_loss: 0.2868 - val_acc: 0.8889\n",
      "Epoch 22/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.2821 - acc: 0.8915 - val_loss: 0.2853 - val_acc: 0.8868\n",
      "Epoch 23/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.2800 - acc: 0.8904 - val_loss: 0.2843 - val_acc: 0.8889\n",
      "Epoch 24/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.2762 - acc: 0.8899 - val_loss: 0.2848 - val_acc: 0.8930\n",
      "Epoch 25/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.2844 - acc: 0.8930 - val_loss: 0.2848 - val_acc: 0.8951\n",
      "Epoch 26/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.2823 - acc: 0.8920 - val_loss: 0.2830 - val_acc: 0.8909\n",
      "Epoch 27/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.2823 - acc: 0.8863 - val_loss: 0.2826 - val_acc: 0.8930\n",
      "Epoch 28/100\n",
      "1944/1944 [==============================] - 1s 360us/step - loss: 0.2799 - acc: 0.8884 - val_loss: 0.2824 - val_acc: 0.8930\n",
      "Epoch 29/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.2759 - acc: 0.8945 - val_loss: 0.2813 - val_acc: 0.8930\n",
      "Epoch 30/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.2741 - acc: 0.8889 - val_loss: 0.2815 - val_acc: 0.8930\n",
      "Epoch 31/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.2734 - acc: 0.8899 - val_loss: 0.2812 - val_acc: 0.8930\n",
      "Epoch 32/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.2740 - acc: 0.8863 - val_loss: 0.2809 - val_acc: 0.8951\n",
      "Epoch 33/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.2798 - acc: 0.8925 - val_loss: 0.2790 - val_acc: 0.8930\n",
      "Epoch 34/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.2737 - acc: 0.8940 - val_loss: 0.2785 - val_acc: 0.8930\n",
      "Epoch 35/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.2700 - acc: 0.8889 - val_loss: 0.2779 - val_acc: 0.8930\n",
      "Epoch 36/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.2709 - acc: 0.8930 - val_loss: 0.2768 - val_acc: 0.8930\n",
      "Epoch 37/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.2764 - acc: 0.8925 - val_loss: 0.2763 - val_acc: 0.8930\n",
      "Epoch 38/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.2643 - acc: 0.8940 - val_loss: 0.2752 - val_acc: 0.8951\n",
      "Epoch 39/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.2673 - acc: 0.8920 - val_loss: 0.2736 - val_acc: 0.8951\n",
      "Epoch 40/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.2588 - acc: 0.8981 - val_loss: 0.2738 - val_acc: 0.8930\n",
      "Epoch 41/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.2596 - acc: 0.8945 - val_loss: 0.2723 - val_acc: 0.8951\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.2665 - acc: 0.8940 - val_loss: 0.2711 - val_acc: 0.8930\n",
      "Epoch 43/100\n",
      "1944/1944 [==============================] - 1s 356us/step - loss: 0.2608 - acc: 0.8971 - val_loss: 0.2725 - val_acc: 0.8930\n",
      "Epoch 44/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.2604 - acc: 0.8935 - val_loss: 0.2715 - val_acc: 0.8951\n",
      "Epoch 45/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.2619 - acc: 0.8971 - val_loss: 0.2717 - val_acc: 0.8951\n",
      "Epoch 46/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.2620 - acc: 0.8961 - val_loss: 0.2695 - val_acc: 0.8930\n",
      "Epoch 47/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.2531 - acc: 0.9012 - val_loss: 0.2688 - val_acc: 0.8930\n",
      "Epoch 48/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.2554 - acc: 0.9002 - val_loss: 0.2681 - val_acc: 0.8930\n",
      "Epoch 49/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.2488 - acc: 0.8992 - val_loss: 0.2680 - val_acc: 0.8930\n",
      "Epoch 50/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.2525 - acc: 0.8997 - val_loss: 0.2680 - val_acc: 0.8951\n",
      "Epoch 51/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.2535 - acc: 0.9012 - val_loss: 0.2675 - val_acc: 0.8971\n",
      "Epoch 52/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.2542 - acc: 0.9017 - val_loss: 0.2665 - val_acc: 0.8971\n",
      "Epoch 53/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.2526 - acc: 0.8981 - val_loss: 0.2654 - val_acc: 0.8971\n",
      "Epoch 54/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.2505 - acc: 0.9043 - val_loss: 0.2643 - val_acc: 0.8951\n",
      "Epoch 55/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.2447 - acc: 0.9007 - val_loss: 0.2645 - val_acc: 0.8971\n",
      "Epoch 56/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.2500 - acc: 0.9069 - val_loss: 0.2641 - val_acc: 0.8971\n",
      "Epoch 57/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.2458 - acc: 0.9028 - val_loss: 0.2627 - val_acc: 0.8971\n",
      "Epoch 58/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.2484 - acc: 0.9028 - val_loss: 0.2613 - val_acc: 0.8951\n",
      "Epoch 59/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.2463 - acc: 0.9038 - val_loss: 0.2609 - val_acc: 0.8951\n",
      "Epoch 60/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.2436 - acc: 0.9033 - val_loss: 0.2605 - val_acc: 0.8951\n",
      "Epoch 61/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.2426 - acc: 0.9069 - val_loss: 0.2613 - val_acc: 0.8971\n",
      "Epoch 62/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.2396 - acc: 0.9043 - val_loss: 0.2597 - val_acc: 0.8951\n",
      "Epoch 63/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.2475 - acc: 0.8981 - val_loss: 0.2606 - val_acc: 0.8951\n",
      "Epoch 64/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.2378 - acc: 0.9017 - val_loss: 0.2587 - val_acc: 0.8951\n",
      "Epoch 65/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.2381 - acc: 0.9028 - val_loss: 0.2584 - val_acc: 0.8951\n",
      "Epoch 66/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.2363 - acc: 0.9002 - val_loss: 0.2592 - val_acc: 0.8930\n",
      "Epoch 67/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.2334 - acc: 0.9064 - val_loss: 0.2577 - val_acc: 0.8930\n",
      "Epoch 68/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.2397 - acc: 0.9033 - val_loss: 0.2573 - val_acc: 0.8930\n",
      "Epoch 69/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.2407 - acc: 0.9059 - val_loss: 0.2581 - val_acc: 0.8930\n",
      "Epoch 70/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.2390 - acc: 0.9090 - val_loss: 0.2565 - val_acc: 0.8930\n",
      "Epoch 71/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.2315 - acc: 0.9090 - val_loss: 0.2553 - val_acc: 0.8909\n",
      "Epoch 72/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.2315 - acc: 0.9105 - val_loss: 0.2544 - val_acc: 0.8889\n",
      "Epoch 73/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.2375 - acc: 0.9043 - val_loss: 0.2555 - val_acc: 0.8930\n",
      "Epoch 74/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.2326 - acc: 0.9105 - val_loss: 0.2543 - val_acc: 0.8909\n",
      "Epoch 75/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.2276 - acc: 0.9053 - val_loss: 0.2545 - val_acc: 0.8930\n",
      "Epoch 76/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.2398 - acc: 0.9038 - val_loss: 0.2537 - val_acc: 0.8930\n",
      "Epoch 77/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.2347 - acc: 0.9048 - val_loss: 0.2528 - val_acc: 0.8930\n",
      "Epoch 78/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.2328 - acc: 0.9079 - val_loss: 0.2520 - val_acc: 0.8889\n",
      "Epoch 79/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.2286 - acc: 0.9059 - val_loss: 0.2518 - val_acc: 0.8889\n",
      "Epoch 80/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.2333 - acc: 0.9064 - val_loss: 0.2505 - val_acc: 0.8889\n",
      "Epoch 81/100\n",
      "1944/1944 [==============================] - 1s 356us/step - loss: 0.2300 - acc: 0.9064 - val_loss: 0.2506 - val_acc: 0.8889\n",
      "Epoch 82/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.2313 - acc: 0.9043 - val_loss: 0.2507 - val_acc: 0.8889\n",
      "Epoch 83/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.2292 - acc: 0.9059 - val_loss: 0.2500 - val_acc: 0.8889\n",
      "Epoch 84/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.2273 - acc: 0.9115 - val_loss: 0.2505 - val_acc: 0.8951\n",
      "Epoch 85/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.2338 - acc: 0.9053 - val_loss: 0.2494 - val_acc: 0.8951\n",
      "Epoch 86/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.2328 - acc: 0.9059 - val_loss: 0.2479 - val_acc: 0.8889\n",
      "Epoch 87/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.2225 - acc: 0.9059 - val_loss: 0.2489 - val_acc: 0.8951\n",
      "Epoch 88/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.2264 - acc: 0.9043 - val_loss: 0.2493 - val_acc: 0.8951\n",
      "Epoch 89/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.2208 - acc: 0.9136 - val_loss: 0.2501 - val_acc: 0.8930\n",
      "Epoch 90/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.2218 - acc: 0.9110 - val_loss: 0.2483 - val_acc: 0.8951\n",
      "Epoch 91/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.2192 - acc: 0.9162 - val_loss: 0.2478 - val_acc: 0.8951\n",
      "Epoch 92/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.2237 - acc: 0.9053 - val_loss: 0.2475 - val_acc: 0.8951\n",
      "Epoch 93/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.2190 - acc: 0.9074 - val_loss: 0.2467 - val_acc: 0.8951\n",
      "Epoch 94/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.2156 - acc: 0.9136 - val_loss: 0.2469 - val_acc: 0.8930\n",
      "Epoch 95/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.2199 - acc: 0.9141 - val_loss: 0.2458 - val_acc: 0.8951\n",
      "Epoch 96/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.2225 - acc: 0.9079 - val_loss: 0.2461 - val_acc: 0.8930\n",
      "Epoch 97/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.2168 - acc: 0.9141 - val_loss: 0.2471 - val_acc: 0.8930\n",
      "Epoch 98/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.2284 - acc: 0.9048 - val_loss: 0.2457 - val_acc: 0.8930\n",
      "Epoch 99/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.2134 - acc: 0.9074 - val_loss: 0.2452 - val_acc: 0.8930\n",
      "Epoch 100/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.2240 - acc: 0.9090 - val_loss: 0.2459 - val_acc: 0.8930\n",
      "Test subject 11, class Replace\n",
      "Train subject 11, class BothReleased\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1944 samples, validate on 486 samples\n",
      "Epoch 1/100\n",
      "1944/1944 [==============================] - 2s 1ms/step - loss: 0.6945 - acc: 0.5051 - val_loss: 0.6916 - val_acc: 0.5658\n",
      "Epoch 2/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.6952 - acc: 0.4974 - val_loss: 0.6910 - val_acc: 0.5658\n",
      "Epoch 3/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.6902 - acc: 0.5329 - val_loss: 0.6903 - val_acc: 0.5761\n",
      "Epoch 4/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.6928 - acc: 0.5036 - val_loss: 0.6897 - val_acc: 0.5802\n",
      "Epoch 5/100\n",
      "1944/1944 [==============================] - 1s 361us/step - loss: 0.6915 - acc: 0.5082 - val_loss: 0.6890 - val_acc: 0.5844\n",
      "Epoch 6/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.6922 - acc: 0.5149 - val_loss: 0.6883 - val_acc: 0.5844\n",
      "Epoch 7/100\n",
      "1944/1944 [==============================] - 1s 356us/step - loss: 0.6891 - acc: 0.5417 - val_loss: 0.6877 - val_acc: 0.5947\n",
      "Epoch 8/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.6900 - acc: 0.5391 - val_loss: 0.6870 - val_acc: 0.6029\n",
      "Epoch 9/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.6909 - acc: 0.5201 - val_loss: 0.6863 - val_acc: 0.5967\n",
      "Epoch 10/100\n",
      "1944/1944 [==============================] - 1s 356us/step - loss: 0.6872 - acc: 0.5507 - val_loss: 0.6856 - val_acc: 0.6029\n",
      "Epoch 11/100\n",
      "1944/1944 [==============================] - 1s 366us/step - loss: 0.6879 - acc: 0.5592 - val_loss: 0.6848 - val_acc: 0.6029\n",
      "Epoch 12/100\n",
      "1944/1944 [==============================] - 1s 367us/step - loss: 0.6852 - acc: 0.5556 - val_loss: 0.6840 - val_acc: 0.6029\n",
      "Epoch 13/100\n",
      "1944/1944 [==============================] - 1s 369us/step - loss: 0.6884 - acc: 0.5545 - val_loss: 0.6832 - val_acc: 0.6070\n",
      "Epoch 14/100\n",
      "1944/1944 [==============================] - 1s 366us/step - loss: 0.6881 - acc: 0.5432 - val_loss: 0.6824 - val_acc: 0.6029\n",
      "Epoch 15/100\n",
      "1944/1944 [==============================] - 1s 367us/step - loss: 0.6858 - acc: 0.5592 - val_loss: 0.6815 - val_acc: 0.6152\n",
      "Epoch 16/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.6873 - acc: 0.5540 - val_loss: 0.6806 - val_acc: 0.6214\n",
      "Epoch 17/100\n",
      "1944/1944 [==============================] - 1s 358us/step - loss: 0.6832 - acc: 0.5864 - val_loss: 0.6796 - val_acc: 0.6193\n",
      "Epoch 18/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.6837 - acc: 0.5751 - val_loss: 0.6787 - val_acc: 0.6214\n",
      "Epoch 19/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.6849 - acc: 0.5715 - val_loss: 0.6776 - val_acc: 0.6235\n",
      "Epoch 20/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.6842 - acc: 0.5658 - val_loss: 0.6766 - val_acc: 0.6276\n",
      "Epoch 21/100\n",
      "1944/1944 [==============================] - 1s 378us/step - loss: 0.6791 - acc: 0.5900 - val_loss: 0.6755 - val_acc: 0.6358\n",
      "Epoch 22/100\n",
      "1944/1944 [==============================] - 1s 368us/step - loss: 0.6809 - acc: 0.5818 - val_loss: 0.6743 - val_acc: 0.6379\n",
      "Epoch 23/100\n",
      "1944/1944 [==============================] - 1s 370us/step - loss: 0.6791 - acc: 0.6008 - val_loss: 0.6731 - val_acc: 0.6420\n",
      "Epoch 24/100\n",
      "1944/1944 [==============================] - 1s 402us/step - loss: 0.6775 - acc: 0.5854 - val_loss: 0.6718 - val_acc: 0.6461\n",
      "Epoch 25/100\n",
      "1944/1944 [==============================] - 1s 363us/step - loss: 0.6761 - acc: 0.6065 - val_loss: 0.6704 - val_acc: 0.6440\n",
      "Epoch 26/100\n",
      "1944/1944 [==============================] - 1s 376us/step - loss: 0.6768 - acc: 0.6019 - val_loss: 0.6690 - val_acc: 0.6481\n",
      "Epoch 27/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.6736 - acc: 0.6127 - val_loss: 0.6675 - val_acc: 0.6502\n",
      "Epoch 28/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.6767 - acc: 0.5947 - val_loss: 0.6659 - val_acc: 0.6523\n",
      "Epoch 29/100\n",
      "1944/1944 [==============================] - 1s 356us/step - loss: 0.6735 - acc: 0.6065 - val_loss: 0.6644 - val_acc: 0.6523\n",
      "Epoch 30/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.6729 - acc: 0.6080 - val_loss: 0.6627 - val_acc: 0.6523\n",
      "Epoch 31/100\n",
      "1944/1944 [==============================] - 1s 362us/step - loss: 0.6707 - acc: 0.6245 - val_loss: 0.6609 - val_acc: 0.6502\n",
      "Epoch 32/100\n",
      "1944/1944 [==============================] - 1s 356us/step - loss: 0.6693 - acc: 0.6163 - val_loss: 0.6589 - val_acc: 0.6543\n",
      "Epoch 33/100\n",
      "1944/1944 [==============================] - 1s 365us/step - loss: 0.6693 - acc: 0.6142 - val_loss: 0.6569 - val_acc: 0.6502\n",
      "Epoch 34/100\n",
      "1944/1944 [==============================] - 1s 360us/step - loss: 0.6675 - acc: 0.6343 - val_loss: 0.6547 - val_acc: 0.6564\n",
      "Epoch 35/100\n",
      "1944/1944 [==============================] - 1s 359us/step - loss: 0.6636 - acc: 0.6281 - val_loss: 0.6524 - val_acc: 0.6584\n",
      "Epoch 36/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.6629 - acc: 0.6291 - val_loss: 0.6500 - val_acc: 0.6605\n",
      "Epoch 37/100\n",
      "1944/1944 [==============================] - 1s 377us/step - loss: 0.6623 - acc: 0.6379 - val_loss: 0.6476 - val_acc: 0.6605\n",
      "Epoch 38/100\n",
      "1944/1944 [==============================] - 1s 396us/step - loss: 0.6576 - acc: 0.6445 - val_loss: 0.6451 - val_acc: 0.6605\n",
      "Epoch 39/100\n",
      "1944/1944 [==============================] - 1s 377us/step - loss: 0.6552 - acc: 0.6517 - val_loss: 0.6423 - val_acc: 0.6667\n",
      "Epoch 40/100\n",
      "1944/1944 [==============================] - 1s 377us/step - loss: 0.6544 - acc: 0.6574 - val_loss: 0.6394 - val_acc: 0.6667\n",
      "Epoch 41/100\n",
      "1944/1944 [==============================] - 1s 375us/step - loss: 0.6502 - acc: 0.6553 - val_loss: 0.6364 - val_acc: 0.6646\n",
      "Epoch 42/100\n",
      "1944/1944 [==============================] - 1s 369us/step - loss: 0.6484 - acc: 0.6569 - val_loss: 0.6333 - val_acc: 0.6687\n",
      "Epoch 43/100\n",
      "1944/1944 [==============================] - 1s 368us/step - loss: 0.6457 - acc: 0.6656 - val_loss: 0.6300 - val_acc: 0.6728\n",
      "Epoch 44/100\n",
      "1944/1944 [==============================] - 1s 368us/step - loss: 0.6476 - acc: 0.6533 - val_loss: 0.6267 - val_acc: 0.6790\n",
      "Epoch 45/100\n",
      "1944/1944 [==============================] - 1s 363us/step - loss: 0.6424 - acc: 0.6497 - val_loss: 0.6230 - val_acc: 0.6790\n",
      "Epoch 46/100\n",
      "1944/1944 [==============================] - 1s 383us/step - loss: 0.6408 - acc: 0.6698 - val_loss: 0.6191 - val_acc: 0.6790\n",
      "Epoch 47/100\n",
      "1944/1944 [==============================] - 1s 371us/step - loss: 0.6314 - acc: 0.6770 - val_loss: 0.6151 - val_acc: 0.6852\n",
      "Epoch 48/100\n",
      "1944/1944 [==============================] - 1s 372us/step - loss: 0.6304 - acc: 0.6775 - val_loss: 0.6107 - val_acc: 0.6872\n",
      "Epoch 49/100\n",
      "1944/1944 [==============================] - 1s 365us/step - loss: 0.6270 - acc: 0.6780 - val_loss: 0.6060 - val_acc: 0.6893\n",
      "Epoch 50/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.6242 - acc: 0.6795 - val_loss: 0.6015 - val_acc: 0.6893\n",
      "Epoch 51/100\n",
      "1944/1944 [==============================] - 1s 358us/step - loss: 0.6191 - acc: 0.6872 - val_loss: 0.5965 - val_acc: 0.6934\n",
      "Epoch 52/100\n",
      "1944/1944 [==============================] - 1s 398us/step - loss: 0.6132 - acc: 0.6903 - val_loss: 0.5912 - val_acc: 0.6955\n",
      "Epoch 53/100\n",
      "1944/1944 [==============================] - 1s 370us/step - loss: 0.6131 - acc: 0.6955 - val_loss: 0.5859 - val_acc: 0.6955\n",
      "Epoch 54/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.6084 - acc: 0.6867 - val_loss: 0.5801 - val_acc: 0.6955\n",
      "Epoch 55/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.6042 - acc: 0.6950 - val_loss: 0.5744 - val_acc: 0.6996\n",
      "Epoch 56/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.5923 - acc: 0.6991 - val_loss: 0.5680 - val_acc: 0.7119\n",
      "Epoch 57/100\n",
      "1944/1944 [==============================] - 1s 356us/step - loss: 0.5896 - acc: 0.7109 - val_loss: 0.5614 - val_acc: 0.7202\n",
      "Epoch 58/100\n",
      "1944/1944 [==============================] - 1s 360us/step - loss: 0.5852 - acc: 0.7073 - val_loss: 0.5546 - val_acc: 0.7305\n",
      "Epoch 59/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.5774 - acc: 0.7140 - val_loss: 0.5474 - val_acc: 0.7284\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.5733 - acc: 0.7181 - val_loss: 0.5399 - val_acc: 0.7325\n",
      "Epoch 61/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.5666 - acc: 0.7269 - val_loss: 0.5322 - val_acc: 0.7407\n",
      "Epoch 62/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.5571 - acc: 0.7217 - val_loss: 0.5242 - val_acc: 0.7387\n",
      "Epoch 63/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.5488 - acc: 0.7341 - val_loss: 0.5160 - val_acc: 0.7510\n",
      "Epoch 64/100\n",
      "1944/1944 [==============================] - 1s 358us/step - loss: 0.5459 - acc: 0.7356 - val_loss: 0.5077 - val_acc: 0.7572\n",
      "Epoch 65/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.5329 - acc: 0.7438 - val_loss: 0.4988 - val_acc: 0.7593\n",
      "Epoch 66/100\n",
      "1944/1944 [==============================] - 1s 356us/step - loss: 0.5253 - acc: 0.7397 - val_loss: 0.4900 - val_acc: 0.7634\n",
      "Epoch 67/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.5183 - acc: 0.7536 - val_loss: 0.4808 - val_acc: 0.7613\n",
      "Epoch 68/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.5159 - acc: 0.7572 - val_loss: 0.4716 - val_acc: 0.7716\n",
      "Epoch 69/100\n",
      "1944/1944 [==============================] - 1s 356us/step - loss: 0.5011 - acc: 0.7629 - val_loss: 0.4624 - val_acc: 0.7798\n",
      "Epoch 70/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.4944 - acc: 0.7644 - val_loss: 0.4533 - val_acc: 0.7840\n",
      "Epoch 71/100\n",
      "1944/1944 [==============================] - 1s 365us/step - loss: 0.4898 - acc: 0.7711 - val_loss: 0.4444 - val_acc: 0.7840\n",
      "Epoch 72/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.4750 - acc: 0.7788 - val_loss: 0.4353 - val_acc: 0.7922\n",
      "Epoch 73/100\n",
      "1944/1944 [==============================] - 1s 362us/step - loss: 0.4671 - acc: 0.7860 - val_loss: 0.4264 - val_acc: 0.7984\n",
      "Epoch 74/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.4640 - acc: 0.7840 - val_loss: 0.4180 - val_acc: 0.8025\n",
      "Epoch 75/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.4571 - acc: 0.7927 - val_loss: 0.4098 - val_acc: 0.8107\n",
      "Epoch 76/100\n",
      "1944/1944 [==============================] - 1s 358us/step - loss: 0.4472 - acc: 0.7953 - val_loss: 0.4023 - val_acc: 0.8086\n",
      "Epoch 77/100\n",
      "1944/1944 [==============================] - 1s 361us/step - loss: 0.4463 - acc: 0.7942 - val_loss: 0.3950 - val_acc: 0.8107\n",
      "Epoch 78/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.4317 - acc: 0.8076 - val_loss: 0.3881 - val_acc: 0.8128\n",
      "Epoch 79/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.4245 - acc: 0.8086 - val_loss: 0.3814 - val_acc: 0.8272\n",
      "Epoch 80/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.4234 - acc: 0.8081 - val_loss: 0.3755 - val_acc: 0.8374\n",
      "Epoch 81/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.4092 - acc: 0.8236 - val_loss: 0.3701 - val_acc: 0.8416\n",
      "Epoch 82/100\n",
      "1944/1944 [==============================] - 1s 364us/step - loss: 0.4101 - acc: 0.8076 - val_loss: 0.3647 - val_acc: 0.8436\n",
      "Epoch 83/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.4033 - acc: 0.8189 - val_loss: 0.3598 - val_acc: 0.8477\n",
      "Epoch 84/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.3959 - acc: 0.8349 - val_loss: 0.3558 - val_acc: 0.8519\n",
      "Epoch 85/100\n",
      "1944/1944 [==============================] - 1s 365us/step - loss: 0.4051 - acc: 0.8302 - val_loss: 0.3522 - val_acc: 0.8621\n",
      "Epoch 86/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.3879 - acc: 0.8292 - val_loss: 0.3480 - val_acc: 0.8663\n",
      "Epoch 87/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.3848 - acc: 0.8354 - val_loss: 0.3440 - val_acc: 0.8745\n",
      "Epoch 88/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.3880 - acc: 0.8256 - val_loss: 0.3409 - val_acc: 0.8786\n",
      "Epoch 89/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.3800 - acc: 0.8364 - val_loss: 0.3385 - val_acc: 0.8765\n",
      "Epoch 90/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.3788 - acc: 0.8436 - val_loss: 0.3357 - val_acc: 0.8807\n",
      "Epoch 91/100\n",
      "1944/1944 [==============================] - 1s 359us/step - loss: 0.3722 - acc: 0.8385 - val_loss: 0.3335 - val_acc: 0.8827\n",
      "Epoch 92/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.3670 - acc: 0.8385 - val_loss: 0.3308 - val_acc: 0.8848\n",
      "Epoch 93/100\n",
      "1944/1944 [==============================] - 1s 378us/step - loss: 0.3631 - acc: 0.8447 - val_loss: 0.3282 - val_acc: 0.8868\n",
      "Epoch 94/100\n",
      "1944/1944 [==============================] - 1s 360us/step - loss: 0.3592 - acc: 0.8539 - val_loss: 0.3254 - val_acc: 0.8848\n",
      "Epoch 95/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.3646 - acc: 0.8503 - val_loss: 0.3238 - val_acc: 0.8889\n",
      "Epoch 96/100\n",
      "1944/1944 [==============================] - 1s 360us/step - loss: 0.3594 - acc: 0.8488 - val_loss: 0.3210 - val_acc: 0.8868\n",
      "Epoch 97/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.3511 - acc: 0.8611 - val_loss: 0.3195 - val_acc: 0.8868\n",
      "Epoch 98/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.3508 - acc: 0.8585 - val_loss: 0.3182 - val_acc: 0.8909\n",
      "Epoch 99/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.3575 - acc: 0.8544 - val_loss: 0.3174 - val_acc: 0.8909\n",
      "Epoch 100/100\n",
      "1944/1944 [==============================] - 1s 373us/step - loss: 0.3488 - acc: 0.8570 - val_loss: 0.3152 - val_acc: 0.8889\n",
      "Train on 1944 samples, validate on 486 samples\n",
      "Epoch 1/100\n",
      "1944/1944 [==============================] - 1s 358us/step - loss: 0.3383 - acc: 0.8601 - val_loss: 0.3377 - val_acc: 0.8724\n",
      "Epoch 2/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.3467 - acc: 0.8580 - val_loss: 0.3360 - val_acc: 0.8724\n",
      "Epoch 3/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.3449 - acc: 0.8627 - val_loss: 0.3347 - val_acc: 0.8704\n",
      "Epoch 4/100\n",
      "1944/1944 [==============================] - 1s 360us/step - loss: 0.3374 - acc: 0.8560 - val_loss: 0.3341 - val_acc: 0.8683\n",
      "Epoch 5/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.3370 - acc: 0.8621 - val_loss: 0.3318 - val_acc: 0.8704\n",
      "Epoch 6/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.3355 - acc: 0.8580 - val_loss: 0.3302 - val_acc: 0.8642\n",
      "Epoch 7/100\n",
      "1944/1944 [==============================] - 1s 356us/step - loss: 0.3428 - acc: 0.8575 - val_loss: 0.3293 - val_acc: 0.8642\n",
      "Epoch 8/100\n",
      "1944/1944 [==============================] - 1s 361us/step - loss: 0.3384 - acc: 0.8606 - val_loss: 0.3279 - val_acc: 0.8663\n",
      "Epoch 9/100\n",
      "1944/1944 [==============================] - 1s 362us/step - loss: 0.3349 - acc: 0.8560 - val_loss: 0.3270 - val_acc: 0.8663\n",
      "Epoch 10/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.3268 - acc: 0.8663 - val_loss: 0.3255 - val_acc: 0.8663\n",
      "Epoch 11/100\n",
      "1944/1944 [==============================] - 1s 376us/step - loss: 0.3272 - acc: 0.8611 - val_loss: 0.3241 - val_acc: 0.8704\n",
      "Epoch 12/100\n",
      "1944/1944 [==============================] - 1s 364us/step - loss: 0.3189 - acc: 0.8657 - val_loss: 0.3237 - val_acc: 0.8704\n",
      "Epoch 13/100\n",
      "1944/1944 [==============================] - 1s 359us/step - loss: 0.3176 - acc: 0.8709 - val_loss: 0.3230 - val_acc: 0.8704\n",
      "Epoch 14/100\n",
      "1944/1944 [==============================] - 1s 359us/step - loss: 0.3252 - acc: 0.8627 - val_loss: 0.3214 - val_acc: 0.8704\n",
      "Epoch 15/100\n",
      "1944/1944 [==============================] - 1s 373us/step - loss: 0.3113 - acc: 0.8637 - val_loss: 0.3202 - val_acc: 0.8724\n",
      "Epoch 16/100\n",
      "1944/1944 [==============================] - 1s 358us/step - loss: 0.3225 - acc: 0.8678 - val_loss: 0.3191 - val_acc: 0.8724\n",
      "Epoch 17/100\n",
      "1944/1944 [==============================] - 1s 358us/step - loss: 0.3126 - acc: 0.8668 - val_loss: 0.3185 - val_acc: 0.8724\n",
      "Epoch 18/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.3118 - acc: 0.8771 - val_loss: 0.3171 - val_acc: 0.8724\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 358us/step - loss: 0.3096 - acc: 0.8673 - val_loss: 0.3168 - val_acc: 0.8745\n",
      "Epoch 20/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.3145 - acc: 0.8729 - val_loss: 0.3163 - val_acc: 0.8745\n",
      "Epoch 21/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.3041 - acc: 0.8729 - val_loss: 0.3153 - val_acc: 0.8745\n",
      "Epoch 22/100\n",
      "1944/1944 [==============================] - 1s 363us/step - loss: 0.3074 - acc: 0.8771 - val_loss: 0.3140 - val_acc: 0.8724\n",
      "Epoch 23/100\n",
      "1944/1944 [==============================] - 1s 364us/step - loss: 0.3062 - acc: 0.8735 - val_loss: 0.3140 - val_acc: 0.8745\n",
      "Epoch 24/100\n",
      "1944/1944 [==============================] - 1s 395us/step - loss: 0.3028 - acc: 0.8755 - val_loss: 0.3126 - val_acc: 0.8724\n",
      "Epoch 25/100\n",
      "1944/1944 [==============================] - 1s 364us/step - loss: 0.3023 - acc: 0.8678 - val_loss: 0.3119 - val_acc: 0.8724\n",
      "Epoch 26/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.3037 - acc: 0.8724 - val_loss: 0.3107 - val_acc: 0.8745\n",
      "Epoch 27/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.3071 - acc: 0.8765 - val_loss: 0.3108 - val_acc: 0.8765\n",
      "Epoch 28/100\n",
      "1944/1944 [==============================] - 1s 367us/step - loss: 0.3010 - acc: 0.8776 - val_loss: 0.3098 - val_acc: 0.8765\n",
      "Epoch 29/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.2935 - acc: 0.8796 - val_loss: 0.3092 - val_acc: 0.8765\n",
      "Epoch 30/100\n",
      "1944/1944 [==============================] - 1s 393us/step - loss: 0.2988 - acc: 0.8822 - val_loss: 0.3097 - val_acc: 0.8765\n",
      "Epoch 31/100\n",
      "1944/1944 [==============================] - 1s 388us/step - loss: 0.2971 - acc: 0.8817 - val_loss: 0.3081 - val_acc: 0.8786\n",
      "Epoch 32/100\n",
      "1944/1944 [==============================] - 1s 356us/step - loss: 0.2891 - acc: 0.8832 - val_loss: 0.3068 - val_acc: 0.8765\n",
      "Epoch 33/100\n",
      "1944/1944 [==============================] - 1s 359us/step - loss: 0.2972 - acc: 0.8735 - val_loss: 0.3058 - val_acc: 0.8765\n",
      "Epoch 34/100\n",
      "1944/1944 [==============================] - 1s 363us/step - loss: 0.2953 - acc: 0.8822 - val_loss: 0.3061 - val_acc: 0.8765\n",
      "Epoch 35/100\n",
      "1944/1944 [==============================] - 1s 368us/step - loss: 0.2911 - acc: 0.8719 - val_loss: 0.3059 - val_acc: 0.8807\n",
      "Epoch 36/100\n",
      "1944/1944 [==============================] - 1s 358us/step - loss: 0.2909 - acc: 0.8817 - val_loss: 0.3048 - val_acc: 0.8765\n",
      "Epoch 37/100\n",
      "1944/1944 [==============================] - 1s 375us/step - loss: 0.2844 - acc: 0.8873 - val_loss: 0.3047 - val_acc: 0.8786\n",
      "Epoch 38/100\n",
      "1944/1944 [==============================] - 1s 361us/step - loss: 0.2891 - acc: 0.8750 - val_loss: 0.3041 - val_acc: 0.8807\n",
      "Epoch 39/100\n",
      "1944/1944 [==============================] - 1s 360us/step - loss: 0.2851 - acc: 0.8837 - val_loss: 0.3041 - val_acc: 0.8807\n",
      "Epoch 40/100\n",
      "1944/1944 [==============================] - 1s 359us/step - loss: 0.2936 - acc: 0.8822 - val_loss: 0.3023 - val_acc: 0.8786\n",
      "Epoch 41/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.2817 - acc: 0.8858 - val_loss: 0.3020 - val_acc: 0.8807\n",
      "Epoch 42/100\n",
      "1944/1944 [==============================] - 1s 360us/step - loss: 0.2903 - acc: 0.8853 - val_loss: 0.3009 - val_acc: 0.8807\n",
      "Epoch 43/100\n",
      "1944/1944 [==============================] - 1s 375us/step - loss: 0.2890 - acc: 0.8786 - val_loss: 0.3003 - val_acc: 0.8827\n",
      "Epoch 44/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.2833 - acc: 0.8832 - val_loss: 0.3006 - val_acc: 0.8889\n",
      "Epoch 45/100\n",
      "1944/1944 [==============================] - 1s 358us/step - loss: 0.2847 - acc: 0.8801 - val_loss: 0.2997 - val_acc: 0.8868\n",
      "Epoch 46/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.2848 - acc: 0.8843 - val_loss: 0.2984 - val_acc: 0.8848\n",
      "Epoch 47/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.2813 - acc: 0.8873 - val_loss: 0.2981 - val_acc: 0.8848\n",
      "Epoch 48/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.2817 - acc: 0.8873 - val_loss: 0.2977 - val_acc: 0.8848\n",
      "Epoch 49/100\n",
      "1944/1944 [==============================] - 1s 360us/step - loss: 0.2787 - acc: 0.8904 - val_loss: 0.2968 - val_acc: 0.8868\n",
      "Epoch 50/100\n",
      "1944/1944 [==============================] - 1s 359us/step - loss: 0.2764 - acc: 0.8884 - val_loss: 0.2969 - val_acc: 0.8868\n",
      "Epoch 51/100\n",
      "1944/1944 [==============================] - 1s 358us/step - loss: 0.2790 - acc: 0.8843 - val_loss: 0.2968 - val_acc: 0.8868\n",
      "Epoch 52/100\n",
      "1944/1944 [==============================] - 1s 361us/step - loss: 0.2821 - acc: 0.8812 - val_loss: 0.2958 - val_acc: 0.8868\n",
      "Epoch 53/100\n",
      "1944/1944 [==============================] - 1s 363us/step - loss: 0.2750 - acc: 0.8832 - val_loss: 0.2955 - val_acc: 0.8868\n",
      "Epoch 54/100\n",
      "1944/1944 [==============================] - 1s 358us/step - loss: 0.2783 - acc: 0.8801 - val_loss: 0.2940 - val_acc: 0.8889\n",
      "Epoch 55/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.2748 - acc: 0.8873 - val_loss: 0.2941 - val_acc: 0.8868\n",
      "Epoch 56/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.2710 - acc: 0.8858 - val_loss: 0.2932 - val_acc: 0.8868\n",
      "Epoch 57/100\n",
      "1944/1944 [==============================] - 1s 358us/step - loss: 0.2701 - acc: 0.8812 - val_loss: 0.2917 - val_acc: 0.8889\n",
      "Epoch 58/100\n",
      "1944/1944 [==============================] - 1s 373us/step - loss: 0.2713 - acc: 0.8863 - val_loss: 0.2922 - val_acc: 0.8889\n",
      "Epoch 59/100\n",
      "1944/1944 [==============================] - 1s 361us/step - loss: 0.2622 - acc: 0.8884 - val_loss: 0.2932 - val_acc: 0.8889\n",
      "Epoch 60/100\n",
      "1944/1944 [==============================] - 1s 356us/step - loss: 0.2777 - acc: 0.8884 - val_loss: 0.2918 - val_acc: 0.8889\n",
      "Epoch 61/100\n",
      "1944/1944 [==============================] - 1s 360us/step - loss: 0.2716 - acc: 0.8904 - val_loss: 0.2911 - val_acc: 0.8868\n",
      "Epoch 62/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.2706 - acc: 0.8920 - val_loss: 0.2917 - val_acc: 0.8889\n",
      "Epoch 63/100\n",
      "1944/1944 [==============================] - 1s 359us/step - loss: 0.2721 - acc: 0.8832 - val_loss: 0.2898 - val_acc: 0.8868\n",
      "Epoch 64/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.2717 - acc: 0.8863 - val_loss: 0.2905 - val_acc: 0.8909\n",
      "Epoch 65/100\n",
      "1944/1944 [==============================] - 1s 356us/step - loss: 0.2769 - acc: 0.8904 - val_loss: 0.2891 - val_acc: 0.8889\n",
      "Epoch 66/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.2659 - acc: 0.8961 - val_loss: 0.2892 - val_acc: 0.8909\n",
      "Epoch 67/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.2673 - acc: 0.8920 - val_loss: 0.2879 - val_acc: 0.8889\n",
      "Epoch 68/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.2668 - acc: 0.8909 - val_loss: 0.2876 - val_acc: 0.8889\n",
      "Epoch 69/100\n",
      "1944/1944 [==============================] - 1s 360us/step - loss: 0.2700 - acc: 0.8879 - val_loss: 0.2875 - val_acc: 0.8889\n",
      "Epoch 70/100\n",
      "1944/1944 [==============================] - 1s 367us/step - loss: 0.2634 - acc: 0.8889 - val_loss: 0.2862 - val_acc: 0.8889\n",
      "Epoch 71/100\n",
      "1944/1944 [==============================] - 1s 362us/step - loss: 0.2585 - acc: 0.8961 - val_loss: 0.2861 - val_acc: 0.8889\n",
      "Epoch 72/100\n",
      "1944/1944 [==============================] - 1s 359us/step - loss: 0.2596 - acc: 0.8945 - val_loss: 0.2862 - val_acc: 0.8889\n",
      "Epoch 73/100\n",
      "1944/1944 [==============================] - 1s 358us/step - loss: 0.2636 - acc: 0.8909 - val_loss: 0.2862 - val_acc: 0.8868\n",
      "Epoch 74/100\n",
      "1944/1944 [==============================] - 1s 359us/step - loss: 0.2647 - acc: 0.8971 - val_loss: 0.2838 - val_acc: 0.8868\n",
      "Epoch 75/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.2637 - acc: 0.8951 - val_loss: 0.2834 - val_acc: 0.8889\n",
      "Epoch 76/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.2542 - acc: 0.8966 - val_loss: 0.2832 - val_acc: 0.8868\n",
      "Epoch 77/100\n",
      "1944/1944 [==============================] - 1s 400us/step - loss: 0.2639 - acc: 0.8987 - val_loss: 0.2833 - val_acc: 0.8868\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 379us/step - loss: 0.2576 - acc: 0.8935 - val_loss: 0.2831 - val_acc: 0.8868\n",
      "Epoch 79/100\n",
      "1944/1944 [==============================] - 1s 367us/step - loss: 0.2611 - acc: 0.8904 - val_loss: 0.2812 - val_acc: 0.8868\n",
      "Epoch 80/100\n",
      "1944/1944 [==============================] - 1s 387us/step - loss: 0.2579 - acc: 0.8971 - val_loss: 0.2818 - val_acc: 0.8848\n",
      "Epoch 81/100\n",
      "1944/1944 [==============================] - 1s 364us/step - loss: 0.2497 - acc: 0.9028 - val_loss: 0.2820 - val_acc: 0.8848\n",
      "Epoch 82/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.2585 - acc: 0.8961 - val_loss: 0.2809 - val_acc: 0.8848\n",
      "Epoch 83/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.2535 - acc: 0.8987 - val_loss: 0.2794 - val_acc: 0.8848\n",
      "Epoch 84/100\n",
      "1944/1944 [==============================] - 1s 356us/step - loss: 0.2512 - acc: 0.9002 - val_loss: 0.2799 - val_acc: 0.8868\n",
      "Epoch 85/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.2523 - acc: 0.8992 - val_loss: 0.2794 - val_acc: 0.8868\n",
      "Epoch 86/100\n",
      "1944/1944 [==============================] - 1s 374us/step - loss: 0.2514 - acc: 0.8935 - val_loss: 0.2804 - val_acc: 0.8909\n",
      "Epoch 87/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.2527 - acc: 0.9007 - val_loss: 0.2798 - val_acc: 0.8909\n",
      "Epoch 88/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.2485 - acc: 0.9012 - val_loss: 0.2791 - val_acc: 0.8889\n",
      "Epoch 89/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.2551 - acc: 0.9007 - val_loss: 0.2780 - val_acc: 0.8889\n",
      "Epoch 90/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.2516 - acc: 0.8956 - val_loss: 0.2783 - val_acc: 0.8909\n",
      "Epoch 91/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.2472 - acc: 0.9028 - val_loss: 0.2775 - val_acc: 0.8909\n",
      "Epoch 92/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.2494 - acc: 0.9023 - val_loss: 0.2763 - val_acc: 0.8889\n",
      "Epoch 93/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.2447 - acc: 0.9059 - val_loss: 0.2784 - val_acc: 0.8909\n",
      "Epoch 94/100\n",
      "1944/1944 [==============================] - 1s 366us/step - loss: 0.2490 - acc: 0.8956 - val_loss: 0.2757 - val_acc: 0.8889\n",
      "Epoch 95/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.2539 - acc: 0.8997 - val_loss: 0.2765 - val_acc: 0.8909\n",
      "Epoch 96/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.2557 - acc: 0.8945 - val_loss: 0.2737 - val_acc: 0.8889\n",
      "Epoch 97/100\n",
      "1944/1944 [==============================] - 1s 361us/step - loss: 0.2490 - acc: 0.8966 - val_loss: 0.2735 - val_acc: 0.8930\n",
      "Epoch 98/100\n",
      "1944/1944 [==============================] - 1s 371us/step - loss: 0.2450 - acc: 0.8987 - val_loss: 0.2724 - val_acc: 0.8909\n",
      "Epoch 99/100\n",
      "1944/1944 [==============================] - 1s 356us/step - loss: 0.2458 - acc: 0.9069 - val_loss: 0.2720 - val_acc: 0.8909\n",
      "Epoch 100/100\n",
      "1944/1944 [==============================] - 1s 364us/step - loss: 0.2486 - acc: 0.8976 - val_loss: 0.2742 - val_acc: 0.8951\n",
      "Test subject 11, class BothReleased\n",
      "HandStart AUC score = 0.631\n",
      "FirstDigitTouch AUC score = 0.897\n",
      "BothStartLoadPhase AUC score = 0.850\n",
      "LiftOff AUC score = 0.869\n",
      "Replace AUC score = 0.906\n",
      "BothReleased AUC score = 0.918\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53062 53062\n",
      "Train subject 12, class HandStart\n",
      "Train on 1956 samples, validate on 489 samples\n",
      "Epoch 1/100\n",
      "1956/1956 [==============================] - 2s 1ms/step - loss: 0.6936 - acc: 0.5015 - val_loss: 0.6941 - val_acc: 0.4581\n",
      "Epoch 2/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.6948 - acc: 0.4872 - val_loss: 0.6938 - val_acc: 0.4703\n",
      "Epoch 3/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.6935 - acc: 0.4985 - val_loss: 0.6935 - val_acc: 0.4908\n",
      "Epoch 4/100\n",
      "1956/1956 [==============================] - 1s 372us/step - loss: 0.6958 - acc: 0.4806 - val_loss: 0.6934 - val_acc: 0.4969\n",
      "Epoch 5/100\n",
      "1956/1956 [==============================] - 1s 372us/step - loss: 0.6952 - acc: 0.4959 - val_loss: 0.6932 - val_acc: 0.5092\n",
      "Epoch 6/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.6933 - acc: 0.5015 - val_loss: 0.6931 - val_acc: 0.5133\n",
      "Epoch 7/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.6937 - acc: 0.4934 - val_loss: 0.6929 - val_acc: 0.5153\n",
      "Epoch 8/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6933 - acc: 0.5133 - val_loss: 0.6928 - val_acc: 0.5133\n",
      "Epoch 9/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.6949 - acc: 0.4934 - val_loss: 0.6927 - val_acc: 0.5276\n",
      "Epoch 10/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.6940 - acc: 0.4857 - val_loss: 0.6925 - val_acc: 0.5501\n",
      "Epoch 11/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.6930 - acc: 0.5097 - val_loss: 0.6924 - val_acc: 0.5562\n",
      "Epoch 12/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6943 - acc: 0.5015 - val_loss: 0.6923 - val_acc: 0.5583\n",
      "Epoch 13/100\n",
      "1956/1956 [==============================] - 1s 367us/step - loss: 0.6936 - acc: 0.5072 - val_loss: 0.6922 - val_acc: 0.5644\n",
      "Epoch 14/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.6940 - acc: 0.4959 - val_loss: 0.6920 - val_acc: 0.5644\n",
      "Epoch 15/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.6935 - acc: 0.4939 - val_loss: 0.6920 - val_acc: 0.5603\n",
      "Epoch 16/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.6938 - acc: 0.5041 - val_loss: 0.6919 - val_acc: 0.5665\n",
      "Epoch 17/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.6920 - acc: 0.5199 - val_loss: 0.6917 - val_acc: 0.5665\n",
      "Epoch 18/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.6926 - acc: 0.5138 - val_loss: 0.6917 - val_acc: 0.5562\n",
      "Epoch 19/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.6946 - acc: 0.4857 - val_loss: 0.6916 - val_acc: 0.5603\n",
      "Epoch 20/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6928 - acc: 0.5189 - val_loss: 0.6915 - val_acc: 0.5521\n",
      "Epoch 21/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.6916 - acc: 0.5215 - val_loss: 0.6914 - val_acc: 0.5603\n",
      "Epoch 22/100\n",
      "1956/1956 [==============================] - 1s 367us/step - loss: 0.6919 - acc: 0.5291 - val_loss: 0.6913 - val_acc: 0.5665\n",
      "Epoch 23/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.6920 - acc: 0.5184 - val_loss: 0.6912 - val_acc: 0.5603\n",
      "Epoch 24/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.6923 - acc: 0.5128 - val_loss: 0.6911 - val_acc: 0.5624\n",
      "Epoch 25/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.6917 - acc: 0.5220 - val_loss: 0.6911 - val_acc: 0.5624\n",
      "Epoch 26/100\n",
      "1956/1956 [==============================] - 1s 368us/step - loss: 0.6926 - acc: 0.5112 - val_loss: 0.6911 - val_acc: 0.5685\n",
      "Epoch 27/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6927 - acc: 0.5118 - val_loss: 0.6911 - val_acc: 0.5665\n",
      "Epoch 28/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.6928 - acc: 0.5046 - val_loss: 0.6909 - val_acc: 0.5787\n",
      "Epoch 29/100\n",
      "1956/1956 [==============================] - 1s 380us/step - loss: 0.6925 - acc: 0.5286 - val_loss: 0.6908 - val_acc: 0.5624\n",
      "Epoch 30/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.6908 - acc: 0.5373 - val_loss: 0.6907 - val_acc: 0.5624\n",
      "Epoch 31/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.6911 - acc: 0.5429 - val_loss: 0.6906 - val_acc: 0.5521\n",
      "Epoch 32/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.6911 - acc: 0.5271 - val_loss: 0.6906 - val_acc: 0.5521\n",
      "Epoch 33/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.6930 - acc: 0.5133 - val_loss: 0.6906 - val_acc: 0.5706\n",
      "Epoch 34/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.6911 - acc: 0.5245 - val_loss: 0.6904 - val_acc: 0.5644\n",
      "Epoch 35/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.6917 - acc: 0.5251 - val_loss: 0.6903 - val_acc: 0.5603\n",
      "Epoch 36/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.6907 - acc: 0.5291 - val_loss: 0.6903 - val_acc: 0.5624\n",
      "Epoch 37/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.6900 - acc: 0.5337 - val_loss: 0.6901 - val_acc: 0.5624\n",
      "Epoch 38/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.6930 - acc: 0.5138 - val_loss: 0.6901 - val_acc: 0.5644\n",
      "Epoch 39/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.6909 - acc: 0.5353 - val_loss: 0.6900 - val_acc: 0.5583\n",
      "Epoch 40/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.6919 - acc: 0.5245 - val_loss: 0.6899 - val_acc: 0.5665\n",
      "Epoch 41/100\n",
      "1956/1956 [==============================] - 1s 367us/step - loss: 0.6924 - acc: 0.5046 - val_loss: 0.6898 - val_acc: 0.5665\n",
      "Epoch 42/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.6903 - acc: 0.5383 - val_loss: 0.6897 - val_acc: 0.5644\n",
      "Epoch 43/100\n",
      "1956/1956 [==============================] - 1s 367us/step - loss: 0.6911 - acc: 0.5174 - val_loss: 0.6895 - val_acc: 0.5481\n",
      "Epoch 44/100\n",
      "1956/1956 [==============================] - 1s 367us/step - loss: 0.6906 - acc: 0.5404 - val_loss: 0.6894 - val_acc: 0.5460\n",
      "Epoch 45/100\n",
      "1956/1956 [==============================] - 1s 372us/step - loss: 0.6908 - acc: 0.5261 - val_loss: 0.6893 - val_acc: 0.5481\n",
      "Epoch 46/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6910 - acc: 0.5245 - val_loss: 0.6893 - val_acc: 0.5562\n",
      "Epoch 47/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.6901 - acc: 0.5373 - val_loss: 0.6892 - val_acc: 0.5603\n",
      "Epoch 48/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6904 - acc: 0.5343 - val_loss: 0.6891 - val_acc: 0.5624\n",
      "Epoch 49/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.6898 - acc: 0.5394 - val_loss: 0.6890 - val_acc: 0.5746\n",
      "Epoch 50/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.6908 - acc: 0.5256 - val_loss: 0.6890 - val_acc: 0.5726\n",
      "Epoch 51/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6893 - acc: 0.5491 - val_loss: 0.6889 - val_acc: 0.5828\n",
      "Epoch 52/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.6894 - acc: 0.5399 - val_loss: 0.6890 - val_acc: 0.5869\n",
      "Epoch 53/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6902 - acc: 0.5368 - val_loss: 0.6889 - val_acc: 0.5890\n",
      "Epoch 54/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.6887 - acc: 0.5445 - val_loss: 0.6888 - val_acc: 0.5890\n",
      "Epoch 55/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.6901 - acc: 0.5435 - val_loss: 0.6888 - val_acc: 0.5828\n",
      "Epoch 56/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.6874 - acc: 0.5542 - val_loss: 0.6886 - val_acc: 0.5890\n",
      "Epoch 57/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.6894 - acc: 0.5470 - val_loss: 0.6884 - val_acc: 0.5849\n",
      "Epoch 58/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.6883 - acc: 0.5521 - val_loss: 0.6883 - val_acc: 0.5869\n",
      "Epoch 59/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.6895 - acc: 0.5465 - val_loss: 0.6881 - val_acc: 0.5951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.6892 - acc: 0.5475 - val_loss: 0.6881 - val_acc: 0.5869\n",
      "Epoch 61/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.6893 - acc: 0.5547 - val_loss: 0.6880 - val_acc: 0.5890\n",
      "Epoch 62/100\n",
      "1956/1956 [==============================] - 1s 368us/step - loss: 0.6881 - acc: 0.5496 - val_loss: 0.6879 - val_acc: 0.5910\n",
      "Epoch 63/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.6892 - acc: 0.5378 - val_loss: 0.6877 - val_acc: 0.5951\n",
      "Epoch 64/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.6914 - acc: 0.5348 - val_loss: 0.6874 - val_acc: 0.5890\n",
      "Epoch 65/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6893 - acc: 0.5532 - val_loss: 0.6874 - val_acc: 0.6012\n",
      "Epoch 66/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.6872 - acc: 0.5644 - val_loss: 0.6873 - val_acc: 0.6012\n",
      "Epoch 67/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.6887 - acc: 0.5532 - val_loss: 0.6871 - val_acc: 0.5951\n",
      "Epoch 68/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6885 - acc: 0.5475 - val_loss: 0.6870 - val_acc: 0.5890\n",
      "Epoch 69/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.6868 - acc: 0.5741 - val_loss: 0.6868 - val_acc: 0.5890\n",
      "Epoch 70/100\n",
      "1956/1956 [==============================] - 1s 367us/step - loss: 0.6882 - acc: 0.5475 - val_loss: 0.6867 - val_acc: 0.5869\n",
      "Epoch 71/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.6888 - acc: 0.5470 - val_loss: 0.6864 - val_acc: 0.5869\n",
      "Epoch 72/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.6863 - acc: 0.5695 - val_loss: 0.6863 - val_acc: 0.5890\n",
      "Epoch 73/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.6869 - acc: 0.5752 - val_loss: 0.6861 - val_acc: 0.5869\n",
      "Epoch 74/100\n",
      "1956/1956 [==============================] - 1s 372us/step - loss: 0.6876 - acc: 0.5501 - val_loss: 0.6859 - val_acc: 0.5869\n",
      "Epoch 75/100\n",
      "1956/1956 [==============================] - 1s 368us/step - loss: 0.6870 - acc: 0.5624 - val_loss: 0.6859 - val_acc: 0.5951\n",
      "Epoch 76/100\n",
      "1956/1956 [==============================] - 1s 368us/step - loss: 0.6868 - acc: 0.5598 - val_loss: 0.6858 - val_acc: 0.5971\n",
      "Epoch 77/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.6881 - acc: 0.5440 - val_loss: 0.6857 - val_acc: 0.6012\n",
      "Epoch 78/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.6865 - acc: 0.5578 - val_loss: 0.6856 - val_acc: 0.6053\n",
      "Epoch 79/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.6873 - acc: 0.5613 - val_loss: 0.6855 - val_acc: 0.6074\n",
      "Epoch 80/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.6879 - acc: 0.5634 - val_loss: 0.6852 - val_acc: 0.5971\n",
      "Epoch 81/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.6865 - acc: 0.5726 - val_loss: 0.6851 - val_acc: 0.6074\n",
      "Epoch 82/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.6882 - acc: 0.5496 - val_loss: 0.6849 - val_acc: 0.5992\n",
      "Epoch 83/100\n",
      "1956/1956 [==============================] - 1s 377us/step - loss: 0.6868 - acc: 0.5690 - val_loss: 0.6848 - val_acc: 0.6074\n",
      "Epoch 84/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.6856 - acc: 0.5782 - val_loss: 0.6846 - val_acc: 0.6074\n",
      "Epoch 85/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.6838 - acc: 0.5925 - val_loss: 0.6844 - val_acc: 0.6033\n",
      "Epoch 86/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.6852 - acc: 0.5808 - val_loss: 0.6841 - val_acc: 0.5951\n",
      "Epoch 87/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.6847 - acc: 0.5890 - val_loss: 0.6839 - val_acc: 0.5951\n",
      "Epoch 88/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.6851 - acc: 0.5803 - val_loss: 0.6837 - val_acc: 0.5951\n",
      "Epoch 89/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.6848 - acc: 0.5792 - val_loss: 0.6834 - val_acc: 0.5992\n",
      "Epoch 90/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.6858 - acc: 0.5700 - val_loss: 0.6832 - val_acc: 0.5992\n",
      "Epoch 91/100\n",
      "1956/1956 [==============================] - 1s 374us/step - loss: 0.6847 - acc: 0.5767 - val_loss: 0.6830 - val_acc: 0.5992\n",
      "Epoch 92/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.6863 - acc: 0.5634 - val_loss: 0.6829 - val_acc: 0.5992\n",
      "Epoch 93/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.6821 - acc: 0.5884 - val_loss: 0.6825 - val_acc: 0.5971\n",
      "Epoch 94/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.6841 - acc: 0.5772 - val_loss: 0.6824 - val_acc: 0.5971\n",
      "Epoch 95/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.6855 - acc: 0.5665 - val_loss: 0.6820 - val_acc: 0.5992\n",
      "Epoch 96/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.6823 - acc: 0.5854 - val_loss: 0.6818 - val_acc: 0.5992\n",
      "Epoch 97/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.6828 - acc: 0.5808 - val_loss: 0.6816 - val_acc: 0.6012\n",
      "Epoch 98/100\n",
      "1956/1956 [==============================] - 1s 372us/step - loss: 0.6826 - acc: 0.5849 - val_loss: 0.6815 - val_acc: 0.5971\n",
      "Epoch 99/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.6816 - acc: 0.5997 - val_loss: 0.6811 - val_acc: 0.5992\n",
      "Epoch 100/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.6819 - acc: 0.5828 - val_loss: 0.6810 - val_acc: 0.6012\n",
      "Train on 1956 samples, validate on 489 samples\n",
      "Epoch 1/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.6816 - acc: 0.5936 - val_loss: 0.6808 - val_acc: 0.6217\n",
      "Epoch 2/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.6838 - acc: 0.5711 - val_loss: 0.6806 - val_acc: 0.6135\n",
      "Epoch 3/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.6824 - acc: 0.5828 - val_loss: 0.6805 - val_acc: 0.5971\n",
      "Epoch 4/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.6809 - acc: 0.5946 - val_loss: 0.6805 - val_acc: 0.5828\n",
      "Epoch 5/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6831 - acc: 0.5838 - val_loss: 0.6803 - val_acc: 0.5746\n",
      "Epoch 6/100\n",
      "1956/1956 [==============================] - 1s 371us/step - loss: 0.6828 - acc: 0.5828 - val_loss: 0.6802 - val_acc: 0.5808\n",
      "Epoch 7/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.6808 - acc: 0.5956 - val_loss: 0.6800 - val_acc: 0.5787\n",
      "Epoch 8/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.6818 - acc: 0.5854 - val_loss: 0.6795 - val_acc: 0.5828\n",
      "Epoch 9/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.6810 - acc: 0.5787 - val_loss: 0.6793 - val_acc: 0.5808\n",
      "Epoch 10/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.6803 - acc: 0.5818 - val_loss: 0.6791 - val_acc: 0.5808\n",
      "Epoch 11/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.6806 - acc: 0.5808 - val_loss: 0.6789 - val_acc: 0.5808\n",
      "Epoch 12/100\n",
      "1956/1956 [==============================] - 1s 376us/step - loss: 0.6814 - acc: 0.5905 - val_loss: 0.6788 - val_acc: 0.5767\n",
      "Epoch 13/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.6798 - acc: 0.5833 - val_loss: 0.6785 - val_acc: 0.5787\n",
      "Epoch 14/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.6795 - acc: 0.5854 - val_loss: 0.6778 - val_acc: 0.5787\n",
      "Epoch 15/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.6807 - acc: 0.5905 - val_loss: 0.6775 - val_acc: 0.5828\n",
      "Epoch 16/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.6808 - acc: 0.5803 - val_loss: 0.6770 - val_acc: 0.5910\n",
      "Epoch 17/100\n",
      "1956/1956 [==============================] - 1s 367us/step - loss: 0.6801 - acc: 0.5828 - val_loss: 0.6764 - val_acc: 0.6012\n",
      "Epoch 18/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.6814 - acc: 0.5792 - val_loss: 0.6760 - val_acc: 0.6012\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956/1956 [==============================] - 1s 370us/step - loss: 0.6807 - acc: 0.5767 - val_loss: 0.6755 - val_acc: 0.6115\n",
      "Epoch 20/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.6787 - acc: 0.5920 - val_loss: 0.6755 - val_acc: 0.6053\n",
      "Epoch 21/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6760 - acc: 0.5966 - val_loss: 0.6748 - val_acc: 0.6115\n",
      "Epoch 22/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.6782 - acc: 0.5951 - val_loss: 0.6747 - val_acc: 0.6012\n",
      "Epoch 23/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.6769 - acc: 0.6053 - val_loss: 0.6743 - val_acc: 0.6053\n",
      "Epoch 24/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.6753 - acc: 0.5920 - val_loss: 0.6739 - val_acc: 0.6053\n",
      "Epoch 25/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.6755 - acc: 0.5971 - val_loss: 0.6733 - val_acc: 0.6012\n",
      "Epoch 26/100\n",
      "1956/1956 [==============================] - 1s 376us/step - loss: 0.6754 - acc: 0.6007 - val_loss: 0.6728 - val_acc: 0.6094\n",
      "Epoch 27/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.6740 - acc: 0.6079 - val_loss: 0.6725 - val_acc: 0.5971\n",
      "Epoch 28/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.6746 - acc: 0.5971 - val_loss: 0.6718 - val_acc: 0.6094\n",
      "Epoch 29/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.6738 - acc: 0.6161 - val_loss: 0.6714 - val_acc: 0.6135\n",
      "Epoch 30/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.6702 - acc: 0.6191 - val_loss: 0.6710 - val_acc: 0.6135\n",
      "Epoch 31/100\n",
      "1956/1956 [==============================] - 1s 374us/step - loss: 0.6712 - acc: 0.6150 - val_loss: 0.6705 - val_acc: 0.6135\n",
      "Epoch 32/100\n",
      "1956/1956 [==============================] - 1s 376us/step - loss: 0.6734 - acc: 0.6115 - val_loss: 0.6699 - val_acc: 0.6135\n",
      "Epoch 33/100\n",
      "1956/1956 [==============================] - 1s 369us/step - loss: 0.6740 - acc: 0.5987 - val_loss: 0.6694 - val_acc: 0.6135\n",
      "Epoch 34/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.6707 - acc: 0.6099 - val_loss: 0.6689 - val_acc: 0.6155\n",
      "Epoch 35/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.6702 - acc: 0.6104 - val_loss: 0.6685 - val_acc: 0.6135\n",
      "Epoch 36/100\n",
      "1956/1956 [==============================] - 1s 377us/step - loss: 0.6707 - acc: 0.6115 - val_loss: 0.6679 - val_acc: 0.6135\n",
      "Epoch 37/100\n",
      "1956/1956 [==============================] - 1s 392us/step - loss: 0.6707 - acc: 0.6217 - val_loss: 0.6671 - val_acc: 0.6196\n",
      "Epoch 38/100\n",
      "1956/1956 [==============================] - 1s 386us/step - loss: 0.6683 - acc: 0.6166 - val_loss: 0.6662 - val_acc: 0.6155\n",
      "Epoch 39/100\n",
      "1956/1956 [==============================] - 1s 367us/step - loss: 0.6692 - acc: 0.6171 - val_loss: 0.6660 - val_acc: 0.6237\n",
      "Epoch 40/100\n",
      "1956/1956 [==============================] - 1s 370us/step - loss: 0.6686 - acc: 0.6196 - val_loss: 0.6653 - val_acc: 0.6237\n",
      "Epoch 41/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.6680 - acc: 0.6181 - val_loss: 0.6649 - val_acc: 0.6217\n",
      "Epoch 42/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.6646 - acc: 0.6212 - val_loss: 0.6638 - val_acc: 0.6217\n",
      "Epoch 43/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6685 - acc: 0.5982 - val_loss: 0.6636 - val_acc: 0.6258\n",
      "Epoch 44/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.6617 - acc: 0.6278 - val_loss: 0.6629 - val_acc: 0.6258\n",
      "Epoch 45/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6628 - acc: 0.6196 - val_loss: 0.6624 - val_acc: 0.6339\n",
      "Epoch 46/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.6637 - acc: 0.6217 - val_loss: 0.6617 - val_acc: 0.6339\n",
      "Epoch 47/100\n",
      "1956/1956 [==============================] - 1s 367us/step - loss: 0.6650 - acc: 0.6130 - val_loss: 0.6608 - val_acc: 0.6237\n",
      "Epoch 48/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6619 - acc: 0.6396 - val_loss: 0.6598 - val_acc: 0.6237\n",
      "Epoch 49/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.6629 - acc: 0.6227 - val_loss: 0.6595 - val_acc: 0.6278\n",
      "Epoch 50/100\n",
      "1956/1956 [==============================] - 1s 368us/step - loss: 0.6603 - acc: 0.6212 - val_loss: 0.6586 - val_acc: 0.6278\n",
      "Epoch 51/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.6591 - acc: 0.6355 - val_loss: 0.6577 - val_acc: 0.6299\n",
      "Epoch 52/100\n",
      "1956/1956 [==============================] - 1s 367us/step - loss: 0.6609 - acc: 0.6273 - val_loss: 0.6569 - val_acc: 0.6319\n",
      "Epoch 53/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.6581 - acc: 0.6288 - val_loss: 0.6562 - val_acc: 0.6339\n",
      "Epoch 54/100\n",
      "1956/1956 [==============================] - 1s 375us/step - loss: 0.6567 - acc: 0.6273 - val_loss: 0.6557 - val_acc: 0.6278\n",
      "Epoch 55/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.6560 - acc: 0.6278 - val_loss: 0.6549 - val_acc: 0.6299\n",
      "Epoch 56/100\n",
      "1956/1956 [==============================] - 1s 378us/step - loss: 0.6552 - acc: 0.6304 - val_loss: 0.6543 - val_acc: 0.6380\n",
      "Epoch 57/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.6571 - acc: 0.6196 - val_loss: 0.6535 - val_acc: 0.6442\n",
      "Epoch 58/100\n",
      "1956/1956 [==============================] - 1s 370us/step - loss: 0.6535 - acc: 0.6339 - val_loss: 0.6525 - val_acc: 0.6319\n",
      "Epoch 59/100\n",
      "1956/1956 [==============================] - 1s 370us/step - loss: 0.6546 - acc: 0.6339 - val_loss: 0.6518 - val_acc: 0.6339\n",
      "Epoch 60/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.6536 - acc: 0.6227 - val_loss: 0.6509 - val_acc: 0.6360\n",
      "Epoch 61/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.6562 - acc: 0.6288 - val_loss: 0.6500 - val_acc: 0.6319\n",
      "Epoch 62/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.6475 - acc: 0.6457 - val_loss: 0.6491 - val_acc: 0.6299\n",
      "Epoch 63/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.6507 - acc: 0.6242 - val_loss: 0.6484 - val_acc: 0.6299\n",
      "Epoch 64/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.6500 - acc: 0.6273 - val_loss: 0.6477 - val_acc: 0.6360\n",
      "Epoch 65/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.6525 - acc: 0.6247 - val_loss: 0.6467 - val_acc: 0.6258\n",
      "Epoch 66/100\n",
      "1956/1956 [==============================] - 1s 382us/step - loss: 0.6444 - acc: 0.6411 - val_loss: 0.6458 - val_acc: 0.6299\n",
      "Epoch 67/100\n",
      "1956/1956 [==============================] - 1s 369us/step - loss: 0.6486 - acc: 0.6309 - val_loss: 0.6450 - val_acc: 0.6299\n",
      "Epoch 68/100\n",
      "1956/1956 [==============================] - 1s 368us/step - loss: 0.6464 - acc: 0.6396 - val_loss: 0.6442 - val_acc: 0.6360\n",
      "Epoch 69/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.6412 - acc: 0.6457 - val_loss: 0.6434 - val_acc: 0.6319\n",
      "Epoch 70/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.6430 - acc: 0.6478 - val_loss: 0.6428 - val_acc: 0.6401\n",
      "Epoch 71/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.6411 - acc: 0.6421 - val_loss: 0.6419 - val_acc: 0.6380\n",
      "Epoch 72/100\n",
      "1956/1956 [==============================] - 1s 380us/step - loss: 0.6383 - acc: 0.6493 - val_loss: 0.6409 - val_acc: 0.6380\n",
      "Epoch 73/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.6394 - acc: 0.6396 - val_loss: 0.6402 - val_acc: 0.6380\n",
      "Epoch 74/100\n",
      "1956/1956 [==============================] - 1s 368us/step - loss: 0.6402 - acc: 0.6339 - val_loss: 0.6398 - val_acc: 0.6483\n",
      "Epoch 75/100\n",
      "1956/1956 [==============================] - 1s 372us/step - loss: 0.6399 - acc: 0.6472 - val_loss: 0.6386 - val_acc: 0.6442\n",
      "Epoch 76/100\n",
      "1956/1956 [==============================] - 1s 367us/step - loss: 0.6379 - acc: 0.6416 - val_loss: 0.6385 - val_acc: 0.6544\n",
      "Epoch 77/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.6390 - acc: 0.6462 - val_loss: 0.6374 - val_acc: 0.6585\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.6360 - acc: 0.6452 - val_loss: 0.6361 - val_acc: 0.6462\n",
      "Epoch 79/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.6321 - acc: 0.6493 - val_loss: 0.6353 - val_acc: 0.6339\n",
      "Epoch 80/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6340 - acc: 0.6498 - val_loss: 0.6345 - val_acc: 0.6421\n",
      "Epoch 81/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.6301 - acc: 0.6621 - val_loss: 0.6342 - val_acc: 0.6544\n",
      "Epoch 82/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6274 - acc: 0.6636 - val_loss: 0.6331 - val_acc: 0.6503\n",
      "Epoch 83/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6327 - acc: 0.6503 - val_loss: 0.6323 - val_acc: 0.6483\n",
      "Epoch 84/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.6303 - acc: 0.6493 - val_loss: 0.6319 - val_acc: 0.6503\n",
      "Epoch 85/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.6238 - acc: 0.6626 - val_loss: 0.6310 - val_acc: 0.6503\n",
      "Epoch 86/100\n",
      "1956/1956 [==============================] - 1s 369us/step - loss: 0.6276 - acc: 0.6605 - val_loss: 0.6302 - val_acc: 0.6503\n",
      "Epoch 87/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.6275 - acc: 0.6483 - val_loss: 0.6296 - val_acc: 0.6442\n",
      "Epoch 88/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.6271 - acc: 0.6580 - val_loss: 0.6290 - val_acc: 0.6524\n",
      "Epoch 89/100\n",
      "1956/1956 [==============================] - 1s 375us/step - loss: 0.6256 - acc: 0.6616 - val_loss: 0.6282 - val_acc: 0.6524\n",
      "Epoch 90/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.6218 - acc: 0.6616 - val_loss: 0.6275 - val_acc: 0.6442\n",
      "Epoch 91/100\n",
      "1956/1956 [==============================] - 1s 367us/step - loss: 0.6247 - acc: 0.6472 - val_loss: 0.6276 - val_acc: 0.6626\n",
      "Epoch 92/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.6221 - acc: 0.6580 - val_loss: 0.6262 - val_acc: 0.6544\n",
      "Epoch 93/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.6165 - acc: 0.6733 - val_loss: 0.6254 - val_acc: 0.6544\n",
      "Epoch 94/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.6207 - acc: 0.6769 - val_loss: 0.6248 - val_acc: 0.6544\n",
      "Epoch 95/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.6207 - acc: 0.6631 - val_loss: 0.6245 - val_acc: 0.6605\n",
      "Epoch 96/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.6158 - acc: 0.6636 - val_loss: 0.6237 - val_acc: 0.6564\n",
      "Epoch 97/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.6180 - acc: 0.6544 - val_loss: 0.6228 - val_acc: 0.6503\n",
      "Epoch 98/100\n",
      "1956/1956 [==============================] - 1s 372us/step - loss: 0.6190 - acc: 0.6442 - val_loss: 0.6224 - val_acc: 0.6585\n",
      "Epoch 99/100\n",
      "1956/1956 [==============================] - 1s 370us/step - loss: 0.6151 - acc: 0.6728 - val_loss: 0.6221 - val_acc: 0.6646\n",
      "Epoch 100/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.6158 - acc: 0.6636 - val_loss: 0.6212 - val_acc: 0.6462\n",
      "Test subject 12, class HandStart\n",
      "Train subject 12, class FirstDigitTouch\n",
      "Train on 1956 samples, validate on 489 samples\n",
      "Epoch 1/100\n",
      "1956/1956 [==============================] - 2s 1ms/step - loss: 0.6944 - acc: 0.5000 - val_loss: 0.6926 - val_acc: 0.5153\n",
      "Epoch 2/100\n",
      "1956/1956 [==============================] - 1s 379us/step - loss: 0.6926 - acc: 0.5138 - val_loss: 0.6925 - val_acc: 0.5031\n",
      "Epoch 3/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.6933 - acc: 0.5179 - val_loss: 0.6922 - val_acc: 0.5133\n",
      "Epoch 4/100\n",
      "1956/1956 [==============================] - 1s 367us/step - loss: 0.6906 - acc: 0.5322 - val_loss: 0.6919 - val_acc: 0.5133\n",
      "Epoch 5/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.6939 - acc: 0.5056 - val_loss: 0.6914 - val_acc: 0.5256\n",
      "Epoch 6/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.6920 - acc: 0.5210 - val_loss: 0.6910 - val_acc: 0.5256\n",
      "Epoch 7/100\n",
      "1956/1956 [==============================] - 1s 379us/step - loss: 0.6918 - acc: 0.5256 - val_loss: 0.6906 - val_acc: 0.5399\n",
      "Epoch 8/100\n",
      "1956/1956 [==============================] - 1s 368us/step - loss: 0.6916 - acc: 0.5312 - val_loss: 0.6903 - val_acc: 0.5337\n",
      "Epoch 9/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.6912 - acc: 0.5251 - val_loss: 0.6901 - val_acc: 0.5235\n",
      "Epoch 10/100\n",
      "1956/1956 [==============================] - 1s 372us/step - loss: 0.6941 - acc: 0.5092 - val_loss: 0.6896 - val_acc: 0.5337\n",
      "Epoch 11/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.6918 - acc: 0.5215 - val_loss: 0.6894 - val_acc: 0.5276\n",
      "Epoch 12/100\n",
      "1956/1956 [==============================] - 1s 371us/step - loss: 0.6905 - acc: 0.5235 - val_loss: 0.6889 - val_acc: 0.5337\n",
      "Epoch 13/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.6877 - acc: 0.5481 - val_loss: 0.6880 - val_acc: 0.5746\n",
      "Epoch 14/100\n",
      "1956/1956 [==============================] - 1s 371us/step - loss: 0.6923 - acc: 0.5148 - val_loss: 0.6876 - val_acc: 0.5869\n",
      "Epoch 15/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.6920 - acc: 0.5199 - val_loss: 0.6871 - val_acc: 0.6033\n",
      "Epoch 16/100\n",
      "1956/1956 [==============================] - 1s 381us/step - loss: 0.6886 - acc: 0.5343 - val_loss: 0.6868 - val_acc: 0.5951\n",
      "Epoch 17/100\n",
      "1956/1956 [==============================] - 1s 377us/step - loss: 0.6898 - acc: 0.5424 - val_loss: 0.6863 - val_acc: 0.6074\n",
      "Epoch 18/100\n",
      "1956/1956 [==============================] - 1s 373us/step - loss: 0.6880 - acc: 0.5440 - val_loss: 0.6861 - val_acc: 0.5849\n",
      "Epoch 19/100\n",
      "1956/1956 [==============================] - 1s 367us/step - loss: 0.6873 - acc: 0.5491 - val_loss: 0.6855 - val_acc: 0.6135\n",
      "Epoch 20/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.6871 - acc: 0.5573 - val_loss: 0.6846 - val_acc: 0.6401\n",
      "Epoch 21/100\n",
      "1956/1956 [==============================] - 1s 369us/step - loss: 0.6884 - acc: 0.5409 - val_loss: 0.6840 - val_acc: 0.6401\n",
      "Epoch 22/100\n",
      "1956/1956 [==============================] - 1s 377us/step - loss: 0.6863 - acc: 0.5578 - val_loss: 0.6836 - val_acc: 0.6442\n",
      "Epoch 23/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.6892 - acc: 0.5435 - val_loss: 0.6831 - val_acc: 0.6421\n",
      "Epoch 24/100\n",
      "1956/1956 [==============================] - 1s 367us/step - loss: 0.6863 - acc: 0.5557 - val_loss: 0.6823 - val_acc: 0.6442\n",
      "Epoch 25/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.6865 - acc: 0.5573 - val_loss: 0.6817 - val_acc: 0.6401\n",
      "Epoch 26/100\n",
      "1956/1956 [==============================] - 1s 370us/step - loss: 0.6854 - acc: 0.5588 - val_loss: 0.6811 - val_acc: 0.6360\n",
      "Epoch 27/100\n",
      "1956/1956 [==============================] - 1s 367us/step - loss: 0.6845 - acc: 0.5675 - val_loss: 0.6805 - val_acc: 0.6401\n",
      "Epoch 28/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.6862 - acc: 0.5460 - val_loss: 0.6802 - val_acc: 0.6483\n",
      "Epoch 29/100\n",
      "1956/1956 [==============================] - 1s 373us/step - loss: 0.6827 - acc: 0.5695 - val_loss: 0.6795 - val_acc: 0.6483\n",
      "Epoch 30/100\n",
      "1956/1956 [==============================] - 1s 383us/step - loss: 0.6821 - acc: 0.5782 - val_loss: 0.6788 - val_acc: 0.6421\n",
      "Epoch 31/100\n",
      "1956/1956 [==============================] - 1s 383us/step - loss: 0.6861 - acc: 0.5670 - val_loss: 0.6784 - val_acc: 0.6524\n",
      "Epoch 32/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.6813 - acc: 0.5782 - val_loss: 0.6780 - val_acc: 0.6483\n",
      "Epoch 33/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.6817 - acc: 0.5787 - val_loss: 0.6770 - val_acc: 0.6585\n",
      "Epoch 34/100\n",
      "1956/1956 [==============================] - 1s 367us/step - loss: 0.6858 - acc: 0.5450 - val_loss: 0.6763 - val_acc: 0.6544\n",
      "Epoch 35/100\n",
      "1956/1956 [==============================] - 1s 368us/step - loss: 0.6825 - acc: 0.5567 - val_loss: 0.6759 - val_acc: 0.6503\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956/1956 [==============================] - 1s 379us/step - loss: 0.6806 - acc: 0.5813 - val_loss: 0.6752 - val_acc: 0.6503\n",
      "Epoch 37/100\n",
      "1956/1956 [==============================] - 1s 381us/step - loss: 0.6797 - acc: 0.5828 - val_loss: 0.6741 - val_acc: 0.6564\n",
      "Epoch 38/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.6816 - acc: 0.5649 - val_loss: 0.6732 - val_acc: 0.6544\n",
      "Epoch 39/100\n",
      "1956/1956 [==============================] - 1s 378us/step - loss: 0.6776 - acc: 0.6109 - val_loss: 0.6725 - val_acc: 0.6524\n",
      "Epoch 40/100\n",
      "1956/1956 [==============================] - 1s 391us/step - loss: 0.6782 - acc: 0.5859 - val_loss: 0.6719 - val_acc: 0.6564\n",
      "Epoch 41/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.6746 - acc: 0.6155 - val_loss: 0.6710 - val_acc: 0.6605\n",
      "Epoch 42/100\n",
      "1956/1956 [==============================] - 1s 368us/step - loss: 0.6789 - acc: 0.5828 - val_loss: 0.6700 - val_acc: 0.6483\n",
      "Epoch 43/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6756 - acc: 0.6053 - val_loss: 0.6689 - val_acc: 0.6626\n",
      "Epoch 44/100\n",
      "1956/1956 [==============================] - 1s 372us/step - loss: 0.6749 - acc: 0.6043 - val_loss: 0.6680 - val_acc: 0.6544\n",
      "Epoch 45/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.6780 - acc: 0.5895 - val_loss: 0.6669 - val_acc: 0.6667\n",
      "Epoch 46/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.6726 - acc: 0.6099 - val_loss: 0.6656 - val_acc: 0.6687\n",
      "Epoch 47/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.6748 - acc: 0.5930 - val_loss: 0.6645 - val_acc: 0.6667\n",
      "Epoch 48/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.6724 - acc: 0.6155 - val_loss: 0.6636 - val_acc: 0.6687\n",
      "Epoch 49/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.6724 - acc: 0.6074 - val_loss: 0.6624 - val_acc: 0.6708\n",
      "Epoch 50/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.6708 - acc: 0.6140 - val_loss: 0.6611 - val_acc: 0.6748\n",
      "Epoch 51/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.6717 - acc: 0.6069 - val_loss: 0.6600 - val_acc: 0.6789\n",
      "Epoch 52/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.6709 - acc: 0.6007 - val_loss: 0.6584 - val_acc: 0.6708\n",
      "Epoch 53/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.6686 - acc: 0.6186 - val_loss: 0.6570 - val_acc: 0.6728\n",
      "Epoch 54/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.6687 - acc: 0.6222 - val_loss: 0.6558 - val_acc: 0.6810\n",
      "Epoch 55/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.6680 - acc: 0.6140 - val_loss: 0.6543 - val_acc: 0.6810\n",
      "Epoch 56/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.6656 - acc: 0.6212 - val_loss: 0.6528 - val_acc: 0.6789\n",
      "Epoch 57/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.6649 - acc: 0.6288 - val_loss: 0.6513 - val_acc: 0.6810\n",
      "Epoch 58/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.6641 - acc: 0.6319 - val_loss: 0.6496 - val_acc: 0.6830\n",
      "Epoch 59/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.6602 - acc: 0.6212 - val_loss: 0.6478 - val_acc: 0.6789\n",
      "Epoch 60/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.6630 - acc: 0.6304 - val_loss: 0.6461 - val_acc: 0.6728\n",
      "Epoch 61/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.6573 - acc: 0.6431 - val_loss: 0.6444 - val_acc: 0.6830\n",
      "Epoch 62/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.6622 - acc: 0.6268 - val_loss: 0.6428 - val_acc: 0.6810\n",
      "Epoch 63/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.6554 - acc: 0.6339 - val_loss: 0.6409 - val_acc: 0.6810\n",
      "Epoch 64/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.6562 - acc: 0.6370 - val_loss: 0.6391 - val_acc: 0.6851\n",
      "Epoch 65/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.6521 - acc: 0.6544 - val_loss: 0.6371 - val_acc: 0.6851\n",
      "Epoch 66/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.6552 - acc: 0.6309 - val_loss: 0.6351 - val_acc: 0.6830\n",
      "Epoch 67/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6487 - acc: 0.6534 - val_loss: 0.6328 - val_acc: 0.6851\n",
      "Epoch 68/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.6495 - acc: 0.6513 - val_loss: 0.6305 - val_acc: 0.6810\n",
      "Epoch 69/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.6474 - acc: 0.6472 - val_loss: 0.6284 - val_acc: 0.6851\n",
      "Epoch 70/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.6445 - acc: 0.6498 - val_loss: 0.6261 - val_acc: 0.6851\n",
      "Epoch 71/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.6431 - acc: 0.6421 - val_loss: 0.6238 - val_acc: 0.6851\n",
      "Epoch 72/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6437 - acc: 0.6585 - val_loss: 0.6216 - val_acc: 0.6892\n",
      "Epoch 73/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.6374 - acc: 0.6723 - val_loss: 0.6191 - val_acc: 0.6830\n",
      "Epoch 74/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.6375 - acc: 0.6539 - val_loss: 0.6166 - val_acc: 0.6912\n",
      "Epoch 75/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.6329 - acc: 0.6728 - val_loss: 0.6140 - val_acc: 0.6953\n",
      "Epoch 76/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6359 - acc: 0.6575 - val_loss: 0.6112 - val_acc: 0.6871\n",
      "Epoch 77/100\n",
      "1956/1956 [==============================] - 1s 367us/step - loss: 0.6271 - acc: 0.6718 - val_loss: 0.6086 - val_acc: 0.6953\n",
      "Epoch 78/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.6255 - acc: 0.6723 - val_loss: 0.6057 - val_acc: 0.6953\n",
      "Epoch 79/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6220 - acc: 0.6805 - val_loss: 0.6026 - val_acc: 0.6933\n",
      "Epoch 80/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.6149 - acc: 0.6718 - val_loss: 0.5995 - val_acc: 0.7096\n",
      "Epoch 81/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.6218 - acc: 0.6723 - val_loss: 0.5966 - val_acc: 0.7117\n",
      "Epoch 82/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.6138 - acc: 0.6764 - val_loss: 0.5936 - val_acc: 0.7035\n",
      "Epoch 83/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.6064 - acc: 0.6994 - val_loss: 0.5901 - val_acc: 0.7096\n",
      "Epoch 84/100\n",
      "1956/1956 [==============================] - 1s 370us/step - loss: 0.6098 - acc: 0.6938 - val_loss: 0.5874 - val_acc: 0.7178\n",
      "Epoch 85/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6129 - acc: 0.6861 - val_loss: 0.5845 - val_acc: 0.7198\n",
      "Epoch 86/100\n",
      "1956/1956 [==============================] - 1s 370us/step - loss: 0.5999 - acc: 0.6881 - val_loss: 0.5808 - val_acc: 0.7198\n",
      "Epoch 87/100\n",
      "1956/1956 [==============================] - 1s 369us/step - loss: 0.6093 - acc: 0.6794 - val_loss: 0.5784 - val_acc: 0.7157\n",
      "Epoch 88/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.5999 - acc: 0.6938 - val_loss: 0.5766 - val_acc: 0.7239\n",
      "Epoch 89/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.5921 - acc: 0.6984 - val_loss: 0.5725 - val_acc: 0.7321\n",
      "Epoch 90/100\n",
      "1956/1956 [==============================] - 1s 369us/step - loss: 0.5902 - acc: 0.7137 - val_loss: 0.5688 - val_acc: 0.7239\n",
      "Epoch 91/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.5923 - acc: 0.7004 - val_loss: 0.5658 - val_acc: 0.7342\n",
      "Epoch 92/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.5856 - acc: 0.7055 - val_loss: 0.5637 - val_acc: 0.7403\n",
      "Epoch 93/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.5917 - acc: 0.6887 - val_loss: 0.5603 - val_acc: 0.7362\n",
      "Epoch 94/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.5826 - acc: 0.7137 - val_loss: 0.5577 - val_acc: 0.7342\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956/1956 [==============================] - 1s 369us/step - loss: 0.5829 - acc: 0.7137 - val_loss: 0.5545 - val_acc: 0.7444\n",
      "Epoch 96/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.5778 - acc: 0.7137 - val_loss: 0.5525 - val_acc: 0.7403\n",
      "Epoch 97/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.5706 - acc: 0.7101 - val_loss: 0.5493 - val_acc: 0.7382\n",
      "Epoch 98/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.5743 - acc: 0.7127 - val_loss: 0.5459 - val_acc: 0.7526\n",
      "Epoch 99/100\n",
      "1956/1956 [==============================] - 1s 372us/step - loss: 0.5707 - acc: 0.7178 - val_loss: 0.5441 - val_acc: 0.7423\n",
      "Epoch 100/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.5719 - acc: 0.7122 - val_loss: 0.5435 - val_acc: 0.7485\n",
      "Train on 1956 samples, validate on 489 samples\n",
      "Epoch 1/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.5709 - acc: 0.7117 - val_loss: 0.5467 - val_acc: 0.7362\n",
      "Epoch 2/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.5650 - acc: 0.7147 - val_loss: 0.5434 - val_acc: 0.7362\n",
      "Epoch 3/100\n",
      "1956/1956 [==============================] - 1s 371us/step - loss: 0.5643 - acc: 0.7096 - val_loss: 0.5408 - val_acc: 0.7362\n",
      "Epoch 4/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.5584 - acc: 0.7285 - val_loss: 0.5369 - val_acc: 0.7382\n",
      "Epoch 5/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.5571 - acc: 0.7157 - val_loss: 0.5328 - val_acc: 0.7403\n",
      "Epoch 6/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.5498 - acc: 0.7193 - val_loss: 0.5310 - val_acc: 0.7444\n",
      "Epoch 7/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.5495 - acc: 0.7321 - val_loss: 0.5284 - val_acc: 0.7423\n",
      "Epoch 8/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.5474 - acc: 0.7239 - val_loss: 0.5246 - val_acc: 0.7505\n",
      "Epoch 9/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.5478 - acc: 0.7352 - val_loss: 0.5233 - val_acc: 0.7444\n",
      "Epoch 10/100\n",
      "1956/1956 [==============================] - 1s 347us/step - loss: 0.5421 - acc: 0.7321 - val_loss: 0.5206 - val_acc: 0.7505\n",
      "Epoch 11/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.5434 - acc: 0.7311 - val_loss: 0.5171 - val_acc: 0.7382\n",
      "Epoch 12/100\n",
      "1956/1956 [==============================] - 1s 348us/step - loss: 0.5358 - acc: 0.7413 - val_loss: 0.5165 - val_acc: 0.7505\n",
      "Epoch 13/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.5457 - acc: 0.7331 - val_loss: 0.5136 - val_acc: 0.7464\n",
      "Epoch 14/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.5382 - acc: 0.7301 - val_loss: 0.5129 - val_acc: 0.7607\n",
      "Epoch 15/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.5269 - acc: 0.7367 - val_loss: 0.5099 - val_acc: 0.7546\n",
      "Epoch 16/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.5271 - acc: 0.7357 - val_loss: 0.5097 - val_acc: 0.7648\n",
      "Epoch 17/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.5278 - acc: 0.7459 - val_loss: 0.5054 - val_acc: 0.7566\n",
      "Epoch 18/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.5243 - acc: 0.7434 - val_loss: 0.5013 - val_acc: 0.7485\n",
      "Epoch 19/100\n",
      "1956/1956 [==============================] - 1s 369us/step - loss: 0.5197 - acc: 0.7505 - val_loss: 0.5016 - val_acc: 0.7587\n",
      "Epoch 20/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.5197 - acc: 0.7500 - val_loss: 0.4988 - val_acc: 0.7566\n",
      "Epoch 21/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.5111 - acc: 0.7520 - val_loss: 0.5017 - val_acc: 0.7669\n",
      "Epoch 22/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.5158 - acc: 0.7490 - val_loss: 0.4948 - val_acc: 0.7526\n",
      "Epoch 23/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.5172 - acc: 0.7413 - val_loss: 0.4914 - val_acc: 0.7485\n",
      "Epoch 24/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.5159 - acc: 0.7505 - val_loss: 0.4898 - val_acc: 0.7587\n",
      "Epoch 25/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.5081 - acc: 0.7515 - val_loss: 0.4885 - val_acc: 0.7566\n",
      "Epoch 26/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.5170 - acc: 0.7520 - val_loss: 0.4861 - val_acc: 0.7566\n",
      "Epoch 27/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.4971 - acc: 0.7653 - val_loss: 0.4860 - val_acc: 0.7607\n",
      "Epoch 28/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.5031 - acc: 0.7577 - val_loss: 0.4817 - val_acc: 0.7566\n",
      "Epoch 29/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.4996 - acc: 0.7592 - val_loss: 0.4810 - val_acc: 0.7587\n",
      "Epoch 30/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.4974 - acc: 0.7638 - val_loss: 0.4815 - val_acc: 0.7587\n",
      "Epoch 31/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.4904 - acc: 0.7679 - val_loss: 0.4843 - val_acc: 0.7689\n",
      "Epoch 32/100\n",
      "1956/1956 [==============================] - 1s 346us/step - loss: 0.4986 - acc: 0.7602 - val_loss: 0.4760 - val_acc: 0.7607\n",
      "Epoch 33/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.4854 - acc: 0.7638 - val_loss: 0.4816 - val_acc: 0.7710\n",
      "Epoch 34/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.4902 - acc: 0.7715 - val_loss: 0.4737 - val_acc: 0.7587\n",
      "Epoch 35/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.4906 - acc: 0.7674 - val_loss: 0.4706 - val_acc: 0.7628\n",
      "Epoch 36/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.4849 - acc: 0.7633 - val_loss: 0.4705 - val_acc: 0.7648\n",
      "Epoch 37/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.4913 - acc: 0.7653 - val_loss: 0.4665 - val_acc: 0.7689\n",
      "Epoch 38/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.4777 - acc: 0.7689 - val_loss: 0.4675 - val_acc: 0.7648\n",
      "Epoch 39/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.4754 - acc: 0.7766 - val_loss: 0.4643 - val_acc: 0.7710\n",
      "Epoch 40/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.4785 - acc: 0.7781 - val_loss: 0.4662 - val_acc: 0.7710\n",
      "Epoch 41/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.4780 - acc: 0.7853 - val_loss: 0.4586 - val_acc: 0.7710\n",
      "Epoch 42/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.4754 - acc: 0.7807 - val_loss: 0.4604 - val_acc: 0.7751\n",
      "Epoch 43/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.4776 - acc: 0.7843 - val_loss: 0.4578 - val_acc: 0.7751\n",
      "Epoch 44/100\n",
      "1956/1956 [==============================] - 1s 348us/step - loss: 0.4703 - acc: 0.7832 - val_loss: 0.4546 - val_acc: 0.7751\n",
      "Epoch 45/100\n",
      "1956/1956 [==============================] - 1s 348us/step - loss: 0.4685 - acc: 0.7822 - val_loss: 0.4575 - val_acc: 0.7791\n",
      "Epoch 46/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.4694 - acc: 0.7858 - val_loss: 0.4550 - val_acc: 0.7791\n",
      "Epoch 47/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.4642 - acc: 0.7904 - val_loss: 0.4525 - val_acc: 0.7791\n",
      "Epoch 48/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.4590 - acc: 0.8006 - val_loss: 0.4485 - val_acc: 0.7791\n",
      "Epoch 49/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.4635 - acc: 0.7843 - val_loss: 0.4500 - val_acc: 0.7832\n",
      "Epoch 50/100\n",
      "1956/1956 [==============================] - 1s 345us/step - loss: 0.4678 - acc: 0.7837 - val_loss: 0.4482 - val_acc: 0.7812\n",
      "Epoch 51/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.4659 - acc: 0.7791 - val_loss: 0.4479 - val_acc: 0.7853\n",
      "Epoch 52/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.4682 - acc: 0.7802 - val_loss: 0.4459 - val_acc: 0.7873\n",
      "Epoch 53/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.4598 - acc: 0.7837 - val_loss: 0.4463 - val_acc: 0.7832\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.4623 - acc: 0.7802 - val_loss: 0.4458 - val_acc: 0.7873\n",
      "Epoch 55/100\n",
      "1956/1956 [==============================] - 1s 348us/step - loss: 0.4602 - acc: 0.7878 - val_loss: 0.4417 - val_acc: 0.7894\n",
      "Epoch 56/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.4552 - acc: 0.7832 - val_loss: 0.4414 - val_acc: 0.7873\n",
      "Epoch 57/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.4526 - acc: 0.7965 - val_loss: 0.4396 - val_acc: 0.7853\n",
      "Epoch 58/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.4559 - acc: 0.7822 - val_loss: 0.4430 - val_acc: 0.7894\n",
      "Epoch 59/100\n",
      "1956/1956 [==============================] - 1s 347us/step - loss: 0.4592 - acc: 0.7924 - val_loss: 0.4346 - val_acc: 0.7873\n",
      "Epoch 60/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.4543 - acc: 0.7940 - val_loss: 0.4347 - val_acc: 0.7955\n",
      "Epoch 61/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.4495 - acc: 0.7955 - val_loss: 0.4371 - val_acc: 0.7935\n",
      "Epoch 62/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.4528 - acc: 0.7843 - val_loss: 0.4342 - val_acc: 0.7935\n",
      "Epoch 63/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.4540 - acc: 0.7960 - val_loss: 0.4320 - val_acc: 0.7935\n",
      "Epoch 64/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.4356 - acc: 0.8134 - val_loss: 0.4303 - val_acc: 0.7975\n",
      "Epoch 65/100\n",
      "1956/1956 [==============================] - 1s 369us/step - loss: 0.4390 - acc: 0.8052 - val_loss: 0.4308 - val_acc: 0.7996\n",
      "Epoch 66/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.4369 - acc: 0.8011 - val_loss: 0.4264 - val_acc: 0.7914\n",
      "Epoch 67/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.4420 - acc: 0.8088 - val_loss: 0.4249 - val_acc: 0.7914\n",
      "Epoch 68/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.4379 - acc: 0.8093 - val_loss: 0.4252 - val_acc: 0.7996\n",
      "Epoch 69/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.4350 - acc: 0.7996 - val_loss: 0.4312 - val_acc: 0.7975\n",
      "Epoch 70/100\n",
      "1956/1956 [==============================] - 1s 345us/step - loss: 0.4350 - acc: 0.8057 - val_loss: 0.4212 - val_acc: 0.7955\n",
      "Epoch 71/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.4358 - acc: 0.8011 - val_loss: 0.4200 - val_acc: 0.7955\n",
      "Epoch 72/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.4295 - acc: 0.8052 - val_loss: 0.4201 - val_acc: 0.8037\n",
      "Epoch 73/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.4422 - acc: 0.8062 - val_loss: 0.4218 - val_acc: 0.8057\n",
      "Epoch 74/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.4358 - acc: 0.7996 - val_loss: 0.4158 - val_acc: 0.8016\n",
      "Epoch 75/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.4317 - acc: 0.8021 - val_loss: 0.4157 - val_acc: 0.7996\n",
      "Epoch 76/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.4250 - acc: 0.8027 - val_loss: 0.4185 - val_acc: 0.8057\n",
      "Epoch 77/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.4247 - acc: 0.8083 - val_loss: 0.4145 - val_acc: 0.8078\n",
      "Epoch 78/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.4265 - acc: 0.8073 - val_loss: 0.4117 - val_acc: 0.8057\n",
      "Epoch 79/100\n",
      "1956/1956 [==============================] - 1s 346us/step - loss: 0.4291 - acc: 0.8073 - val_loss: 0.4178 - val_acc: 0.8078\n",
      "Epoch 80/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.4310 - acc: 0.7965 - val_loss: 0.4172 - val_acc: 0.8098\n",
      "Epoch 81/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.4255 - acc: 0.8113 - val_loss: 0.4111 - val_acc: 0.8119\n",
      "Epoch 82/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.4211 - acc: 0.8062 - val_loss: 0.4122 - val_acc: 0.8119\n",
      "Epoch 83/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.4230 - acc: 0.8067 - val_loss: 0.4076 - val_acc: 0.8119\n",
      "Epoch 84/100\n",
      "1956/1956 [==============================] - 1s 384us/step - loss: 0.4138 - acc: 0.8119 - val_loss: 0.4104 - val_acc: 0.8160\n",
      "Epoch 85/100\n",
      "1956/1956 [==============================] - 1s 375us/step - loss: 0.4206 - acc: 0.8073 - val_loss: 0.4066 - val_acc: 0.8221\n",
      "Epoch 86/100\n",
      "1956/1956 [==============================] - 1s 384us/step - loss: 0.4228 - acc: 0.8154 - val_loss: 0.4061 - val_acc: 0.8160\n",
      "Epoch 87/100\n",
      "1956/1956 [==============================] - 1s 378us/step - loss: 0.4267 - acc: 0.8165 - val_loss: 0.4101 - val_acc: 0.8139\n",
      "Epoch 88/100\n",
      "1956/1956 [==============================] - 1s 386us/step - loss: 0.4236 - acc: 0.8134 - val_loss: 0.4029 - val_acc: 0.8262\n",
      "Epoch 89/100\n",
      "1956/1956 [==============================] - 1s 378us/step - loss: 0.4160 - acc: 0.8149 - val_loss: 0.4003 - val_acc: 0.8180\n",
      "Epoch 90/100\n",
      "1956/1956 [==============================] - 1s 370us/step - loss: 0.4161 - acc: 0.8098 - val_loss: 0.4002 - val_acc: 0.8282\n",
      "Epoch 91/100\n",
      "1956/1956 [==============================] - 1s 377us/step - loss: 0.4160 - acc: 0.8057 - val_loss: 0.4016 - val_acc: 0.8221\n",
      "Epoch 92/100\n",
      "1956/1956 [==============================] - 1s 373us/step - loss: 0.4043 - acc: 0.8180 - val_loss: 0.3999 - val_acc: 0.8303\n",
      "Epoch 93/100\n",
      "1956/1956 [==============================] - 1s 376us/step - loss: 0.4109 - acc: 0.8170 - val_loss: 0.3964 - val_acc: 0.8160\n",
      "Epoch 94/100\n",
      "1956/1956 [==============================] - 1s 404us/step - loss: 0.4088 - acc: 0.8175 - val_loss: 0.3958 - val_acc: 0.8180\n",
      "Epoch 95/100\n",
      "1956/1956 [==============================] - 1s 372us/step - loss: 0.4128 - acc: 0.8144 - val_loss: 0.3966 - val_acc: 0.8262\n",
      "Epoch 96/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.4068 - acc: 0.8154 - val_loss: 0.3973 - val_acc: 0.8282\n",
      "Epoch 97/100\n",
      "1956/1956 [==============================] - 1s 371us/step - loss: 0.4102 - acc: 0.8113 - val_loss: 0.3966 - val_acc: 0.8282\n",
      "Epoch 98/100\n",
      "1956/1956 [==============================] - 1s 387us/step - loss: 0.4025 - acc: 0.8246 - val_loss: 0.3960 - val_acc: 0.8282\n",
      "Epoch 99/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.4076 - acc: 0.8047 - val_loss: 0.3923 - val_acc: 0.8303\n",
      "Epoch 100/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.4093 - acc: 0.8246 - val_loss: 0.3960 - val_acc: 0.8344\n",
      "Test subject 12, class FirstDigitTouch\n",
      "Train subject 12, class BothStartLoadPhase\n",
      "Train on 1956 samples, validate on 489 samples\n",
      "Epoch 1/100\n",
      "1956/1956 [==============================] - 2s 1ms/step - loss: 0.6974 - acc: 0.5077 - val_loss: 0.6936 - val_acc: 0.4908\n",
      "Epoch 2/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.6951 - acc: 0.4944 - val_loss: 0.6929 - val_acc: 0.4949\n",
      "Epoch 3/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.6953 - acc: 0.5010 - val_loss: 0.6924 - val_acc: 0.5194\n",
      "Epoch 4/100\n",
      "1956/1956 [==============================] - 1s 345us/step - loss: 0.6929 - acc: 0.5235 - val_loss: 0.6919 - val_acc: 0.5174\n",
      "Epoch 5/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.6946 - acc: 0.4964 - val_loss: 0.6916 - val_acc: 0.5470\n",
      "Epoch 6/100\n",
      "1956/1956 [==============================] - 1s 368us/step - loss: 0.6928 - acc: 0.5230 - val_loss: 0.6913 - val_acc: 0.5746\n",
      "Epoch 7/100\n",
      "1956/1956 [==============================] - 1s 376us/step - loss: 0.6925 - acc: 0.5184 - val_loss: 0.6910 - val_acc: 0.5665\n",
      "Epoch 8/100\n",
      "1956/1956 [==============================] - 1s 382us/step - loss: 0.6912 - acc: 0.5266 - val_loss: 0.6907 - val_acc: 0.5644\n",
      "Epoch 9/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.6917 - acc: 0.5235 - val_loss: 0.6904 - val_acc: 0.5706\n",
      "Epoch 10/100\n",
      "1956/1956 [==============================] - 1s 368us/step - loss: 0.6920 - acc: 0.5291 - val_loss: 0.6902 - val_acc: 0.5767\n",
      "Epoch 11/100\n",
      "1956/1956 [==============================] - 1s 400us/step - loss: 0.6917 - acc: 0.5297 - val_loss: 0.6899 - val_acc: 0.5746\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956/1956 [==============================] - 1s 375us/step - loss: 0.6923 - acc: 0.5322 - val_loss: 0.6897 - val_acc: 0.5665\n",
      "Epoch 13/100\n",
      "1956/1956 [==============================] - 1s 375us/step - loss: 0.6902 - acc: 0.5486 - val_loss: 0.6894 - val_acc: 0.5746\n",
      "Epoch 14/100\n",
      "1956/1956 [==============================] - 1s 409us/step - loss: 0.6892 - acc: 0.5445 - val_loss: 0.6892 - val_acc: 0.5746\n",
      "Epoch 15/100\n",
      "1956/1956 [==============================] - 1s 385us/step - loss: 0.6912 - acc: 0.5102 - val_loss: 0.6889 - val_acc: 0.5787\n",
      "Epoch 16/100\n",
      "1956/1956 [==============================] - 1s 370us/step - loss: 0.6920 - acc: 0.5169 - val_loss: 0.6887 - val_acc: 0.5828\n",
      "Epoch 17/100\n",
      "1956/1956 [==============================] - 1s 369us/step - loss: 0.6912 - acc: 0.5251 - val_loss: 0.6884 - val_acc: 0.5849\n",
      "Epoch 18/100\n",
      "1956/1956 [==============================] - 1s 410us/step - loss: 0.6898 - acc: 0.5455 - val_loss: 0.6881 - val_acc: 0.5849\n",
      "Epoch 19/100\n",
      "1956/1956 [==============================] - 1s 401us/step - loss: 0.6902 - acc: 0.5450 - val_loss: 0.6878 - val_acc: 0.5890\n",
      "Epoch 20/100\n",
      "1956/1956 [==============================] - 1s 394us/step - loss: 0.6916 - acc: 0.5194 - val_loss: 0.6876 - val_acc: 0.5930\n",
      "Epoch 21/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.6885 - acc: 0.5562 - val_loss: 0.6873 - val_acc: 0.6033\n",
      "Epoch 22/100\n",
      "1956/1956 [==============================] - 1s 368us/step - loss: 0.6877 - acc: 0.5639 - val_loss: 0.6870 - val_acc: 0.6033\n",
      "Epoch 23/100\n",
      "1956/1956 [==============================] - 1s 387us/step - loss: 0.6903 - acc: 0.5450 - val_loss: 0.6868 - val_acc: 0.5951\n",
      "Epoch 24/100\n",
      "1956/1956 [==============================] - 1s 387us/step - loss: 0.6884 - acc: 0.5532 - val_loss: 0.6864 - val_acc: 0.5971\n",
      "Epoch 25/100\n",
      "1956/1956 [==============================] - 1s 382us/step - loss: 0.6857 - acc: 0.5828 - val_loss: 0.6861 - val_acc: 0.5992\n",
      "Epoch 26/100\n",
      "1956/1956 [==============================] - 1s 368us/step - loss: 0.6884 - acc: 0.5521 - val_loss: 0.6858 - val_acc: 0.5971\n",
      "Epoch 27/100\n",
      "1956/1956 [==============================] - 1s 399us/step - loss: 0.6862 - acc: 0.5711 - val_loss: 0.6854 - val_acc: 0.6094\n",
      "Epoch 28/100\n",
      "1956/1956 [==============================] - 1s 367us/step - loss: 0.6874 - acc: 0.5624 - val_loss: 0.6850 - val_acc: 0.6033\n",
      "Epoch 29/100\n",
      "1956/1956 [==============================] - 1s 388us/step - loss: 0.6858 - acc: 0.5695 - val_loss: 0.6846 - val_acc: 0.5992\n",
      "Epoch 30/100\n",
      "1956/1956 [==============================] - 1s 370us/step - loss: 0.6867 - acc: 0.5619 - val_loss: 0.6842 - val_acc: 0.6033\n",
      "Epoch 31/100\n",
      "1956/1956 [==============================] - 1s 374us/step - loss: 0.6876 - acc: 0.5649 - val_loss: 0.6838 - val_acc: 0.6033\n",
      "Epoch 32/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.6867 - acc: 0.5711 - val_loss: 0.6834 - val_acc: 0.6115\n",
      "Epoch 33/100\n",
      "1956/1956 [==============================] - 1s 379us/step - loss: 0.6857 - acc: 0.5639 - val_loss: 0.6830 - val_acc: 0.6033\n",
      "Epoch 34/100\n",
      "1956/1956 [==============================] - 1s 379us/step - loss: 0.6853 - acc: 0.5726 - val_loss: 0.6826 - val_acc: 0.5971\n",
      "Epoch 35/100\n",
      "1956/1956 [==============================] - 1s 397us/step - loss: 0.6862 - acc: 0.5654 - val_loss: 0.6821 - val_acc: 0.5910\n",
      "Epoch 36/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.6848 - acc: 0.5746 - val_loss: 0.6817 - val_acc: 0.5910\n",
      "Epoch 37/100\n",
      "1956/1956 [==============================] - 1s 409us/step - loss: 0.6865 - acc: 0.5634 - val_loss: 0.6813 - val_acc: 0.5869\n",
      "Epoch 38/100\n",
      "1956/1956 [==============================] - 1s 389us/step - loss: 0.6838 - acc: 0.5884 - val_loss: 0.6808 - val_acc: 0.5849\n",
      "Epoch 39/100\n",
      "1956/1956 [==============================] - 1s 379us/step - loss: 0.6835 - acc: 0.5752 - val_loss: 0.6803 - val_acc: 0.5869\n",
      "Epoch 40/100\n",
      "1956/1956 [==============================] - 1s 420us/step - loss: 0.6840 - acc: 0.5849 - val_loss: 0.6797 - val_acc: 0.5951\n",
      "Epoch 41/100\n",
      "1956/1956 [==============================] - 1s 396us/step - loss: 0.6835 - acc: 0.5803 - val_loss: 0.6792 - val_acc: 0.5971\n",
      "Epoch 42/100\n",
      "1956/1956 [==============================] - 1s 376us/step - loss: 0.6827 - acc: 0.5777 - val_loss: 0.6787 - val_acc: 0.5971\n",
      "Epoch 43/100\n",
      "1956/1956 [==============================] - 1s 374us/step - loss: 0.6823 - acc: 0.5864 - val_loss: 0.6782 - val_acc: 0.5971\n",
      "Epoch 44/100\n",
      "1956/1956 [==============================] - 1s 416us/step - loss: 0.6831 - acc: 0.5854 - val_loss: 0.6776 - val_acc: 0.5971\n",
      "Epoch 45/100\n",
      "1956/1956 [==============================] - 1s 390us/step - loss: 0.6810 - acc: 0.5910 - val_loss: 0.6770 - val_acc: 0.5971\n",
      "Epoch 46/100\n",
      "1956/1956 [==============================] - 1s 387us/step - loss: 0.6813 - acc: 0.5941 - val_loss: 0.6764 - val_acc: 0.5992\n",
      "Epoch 47/100\n",
      "1956/1956 [==============================] - 1s 383us/step - loss: 0.6796 - acc: 0.6109 - val_loss: 0.6758 - val_acc: 0.5971\n",
      "Epoch 48/100\n",
      "1956/1956 [==============================] - 1s 405us/step - loss: 0.6766 - acc: 0.6140 - val_loss: 0.6751 - val_acc: 0.6033\n",
      "Epoch 49/100\n",
      "1956/1956 [==============================] - 1s 375us/step - loss: 0.6802 - acc: 0.5971 - val_loss: 0.6744 - val_acc: 0.6094\n",
      "Epoch 50/100\n",
      "1956/1956 [==============================] - 1s 418us/step - loss: 0.6766 - acc: 0.6207 - val_loss: 0.6736 - val_acc: 0.6135\n",
      "Epoch 51/100\n",
      "1956/1956 [==============================] - 1s 393us/step - loss: 0.6773 - acc: 0.6166 - val_loss: 0.6729 - val_acc: 0.6094\n",
      "Epoch 52/100\n",
      "1956/1956 [==============================] - 1s 408us/step - loss: 0.6757 - acc: 0.6191 - val_loss: 0.6720 - val_acc: 0.6094\n",
      "Epoch 53/100\n",
      "1956/1956 [==============================] - 1s 385us/step - loss: 0.6772 - acc: 0.6022 - val_loss: 0.6713 - val_acc: 0.6155\n",
      "Epoch 54/100\n",
      "1956/1956 [==============================] - 1s 346us/step - loss: 0.6762 - acc: 0.6196 - val_loss: 0.6705 - val_acc: 0.6217\n",
      "Epoch 55/100\n",
      "1956/1956 [==============================] - 1s 379us/step - loss: 0.6744 - acc: 0.6263 - val_loss: 0.6696 - val_acc: 0.6196\n",
      "Epoch 56/100\n",
      "1956/1956 [==============================] - 1s 383us/step - loss: 0.6749 - acc: 0.5951 - val_loss: 0.6688 - val_acc: 0.6155\n",
      "Epoch 57/100\n",
      "1956/1956 [==============================] - 1s 344us/step - loss: 0.6745 - acc: 0.6140 - val_loss: 0.6680 - val_acc: 0.6135\n",
      "Epoch 58/100\n",
      "1956/1956 [==============================] - 1s 426us/step - loss: 0.6700 - acc: 0.6222 - val_loss: 0.6670 - val_acc: 0.6074\n",
      "Epoch 59/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.6720 - acc: 0.6074 - val_loss: 0.6660 - val_acc: 0.6196\n",
      "Epoch 60/100\n",
      "1956/1956 [==============================] - 1s 377us/step - loss: 0.6707 - acc: 0.6155 - val_loss: 0.6649 - val_acc: 0.6196\n",
      "Epoch 61/100\n",
      "1956/1956 [==============================] - 1s 373us/step - loss: 0.6692 - acc: 0.6334 - val_loss: 0.6637 - val_acc: 0.6196\n",
      "Epoch 62/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.6702 - acc: 0.6140 - val_loss: 0.6626 - val_acc: 0.6196\n",
      "Epoch 63/100\n",
      "1956/1956 [==============================] - 1s 408us/step - loss: 0.6702 - acc: 0.6263 - val_loss: 0.6616 - val_acc: 0.6237\n",
      "Epoch 64/100\n",
      "1956/1956 [==============================] - 1s 384us/step - loss: 0.6677 - acc: 0.6263 - val_loss: 0.6603 - val_acc: 0.6258\n",
      "Epoch 65/100\n",
      "1956/1956 [==============================] - 1s 374us/step - loss: 0.6675 - acc: 0.6171 - val_loss: 0.6589 - val_acc: 0.6258\n",
      "Epoch 66/100\n",
      "1956/1956 [==============================] - 1s 404us/step - loss: 0.6659 - acc: 0.6263 - val_loss: 0.6574 - val_acc: 0.6421\n",
      "Epoch 67/100\n",
      "1956/1956 [==============================] - 1s 386us/step - loss: 0.6656 - acc: 0.6237 - val_loss: 0.6560 - val_acc: 0.6401\n",
      "Epoch 68/100\n",
      "1956/1956 [==============================] - 1s 370us/step - loss: 0.6605 - acc: 0.6396 - val_loss: 0.6546 - val_acc: 0.6421\n",
      "Epoch 69/100\n",
      "1956/1956 [==============================] - 1s 371us/step - loss: 0.6622 - acc: 0.6442 - val_loss: 0.6533 - val_acc: 0.6360\n",
      "Epoch 70/100\n",
      "1956/1956 [==============================] - 1s 382us/step - loss: 0.6606 - acc: 0.6375 - val_loss: 0.6516 - val_acc: 0.6421\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956/1956 [==============================] - 1s 382us/step - loss: 0.6586 - acc: 0.6437 - val_loss: 0.6501 - val_acc: 0.6442\n",
      "Epoch 72/100\n",
      "1956/1956 [==============================] - 1s 395us/step - loss: 0.6578 - acc: 0.6483 - val_loss: 0.6483 - val_acc: 0.6442\n",
      "Epoch 73/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.6531 - acc: 0.6467 - val_loss: 0.6464 - val_acc: 0.6524\n",
      "Epoch 74/100\n",
      "1956/1956 [==============================] - 1s 411us/step - loss: 0.6524 - acc: 0.6544 - val_loss: 0.6442 - val_acc: 0.6605\n",
      "Epoch 75/100\n",
      "1956/1956 [==============================] - 1s 367us/step - loss: 0.6516 - acc: 0.6549 - val_loss: 0.6424 - val_acc: 0.6544\n",
      "Epoch 76/100\n",
      "1956/1956 [==============================] - 1s 401us/step - loss: 0.6514 - acc: 0.6524 - val_loss: 0.6404 - val_acc: 0.6626\n",
      "Epoch 77/100\n",
      "1956/1956 [==============================] - 1s 374us/step - loss: 0.6517 - acc: 0.6396 - val_loss: 0.6383 - val_acc: 0.6605\n",
      "Epoch 78/100\n",
      "1956/1956 [==============================] - 1s 388us/step - loss: 0.6495 - acc: 0.6447 - val_loss: 0.6365 - val_acc: 0.6646\n",
      "Epoch 79/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.6436 - acc: 0.6559 - val_loss: 0.6341 - val_acc: 0.6626\n",
      "Epoch 80/100\n",
      "1956/1956 [==============================] - 1s 422us/step - loss: 0.6453 - acc: 0.6580 - val_loss: 0.6320 - val_acc: 0.6646\n",
      "Epoch 81/100\n",
      "1956/1956 [==============================] - 1s 412us/step - loss: 0.6430 - acc: 0.6636 - val_loss: 0.6297 - val_acc: 0.6708\n",
      "Epoch 82/100\n",
      "1956/1956 [==============================] - 1s 380us/step - loss: 0.6403 - acc: 0.6702 - val_loss: 0.6274 - val_acc: 0.6708\n",
      "Epoch 83/100\n",
      "1956/1956 [==============================] - 1s 369us/step - loss: 0.6360 - acc: 0.6610 - val_loss: 0.6250 - val_acc: 0.6687\n",
      "Epoch 84/100\n",
      "1956/1956 [==============================] - 1s 392us/step - loss: 0.6378 - acc: 0.6672 - val_loss: 0.6228 - val_acc: 0.6646\n",
      "Epoch 85/100\n",
      "1956/1956 [==============================] - 1s 406us/step - loss: 0.6339 - acc: 0.6779 - val_loss: 0.6208 - val_acc: 0.6728\n",
      "Epoch 86/100\n",
      "1956/1956 [==============================] - 1s 419us/step - loss: 0.6334 - acc: 0.6779 - val_loss: 0.6178 - val_acc: 0.6769\n",
      "Epoch 87/100\n",
      "1956/1956 [==============================] - 1s 368us/step - loss: 0.6300 - acc: 0.6687 - val_loss: 0.6156 - val_acc: 0.6748\n",
      "Epoch 88/100\n",
      "1956/1956 [==============================] - 1s 401us/step - loss: 0.6301 - acc: 0.6677 - val_loss: 0.6120 - val_acc: 0.6789\n",
      "Epoch 89/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.6235 - acc: 0.6840 - val_loss: 0.6091 - val_acc: 0.6830\n",
      "Epoch 90/100\n",
      "1956/1956 [==============================] - 1s 384us/step - loss: 0.6185 - acc: 0.6876 - val_loss: 0.6069 - val_acc: 0.6830\n",
      "Epoch 91/100\n",
      "1956/1956 [==============================] - 1s 396us/step - loss: 0.6200 - acc: 0.6748 - val_loss: 0.6033 - val_acc: 0.6851\n",
      "Epoch 92/100\n",
      "1956/1956 [==============================] - 1s 383us/step - loss: 0.6138 - acc: 0.6876 - val_loss: 0.6004 - val_acc: 0.6933\n",
      "Epoch 93/100\n",
      "1956/1956 [==============================] - 1s 383us/step - loss: 0.6165 - acc: 0.6697 - val_loss: 0.5971 - val_acc: 0.6953\n",
      "Epoch 94/100\n",
      "1956/1956 [==============================] - 1s 396us/step - loss: 0.6130 - acc: 0.6861 - val_loss: 0.5942 - val_acc: 0.6994\n",
      "Epoch 95/100\n",
      "1956/1956 [==============================] - 1s 385us/step - loss: 0.6073 - acc: 0.7019 - val_loss: 0.5914 - val_acc: 0.6973\n",
      "Epoch 96/100\n",
      "1956/1956 [==============================] - 1s 375us/step - loss: 0.6054 - acc: 0.6938 - val_loss: 0.5883 - val_acc: 0.6933\n",
      "Epoch 97/100\n",
      "1956/1956 [==============================] - 1s 423us/step - loss: 0.6045 - acc: 0.6948 - val_loss: 0.5856 - val_acc: 0.6994\n",
      "Epoch 98/100\n",
      "1956/1956 [==============================] - 1s 382us/step - loss: 0.5978 - acc: 0.6973 - val_loss: 0.5821 - val_acc: 0.7076\n",
      "Epoch 99/100\n",
      "1956/1956 [==============================] - 1s 410us/step - loss: 0.5966 - acc: 0.6989 - val_loss: 0.5791 - val_acc: 0.7014\n",
      "Epoch 100/100\n",
      "1956/1956 [==============================] - 1s 393us/step - loss: 0.5943 - acc: 0.6968 - val_loss: 0.5751 - val_acc: 0.7055\n",
      "Train on 1956 samples, validate on 489 samples\n",
      "Epoch 1/100\n",
      "1956/1956 [==============================] - 1s 390us/step - loss: 0.6074 - acc: 0.6856 - val_loss: 0.5803 - val_acc: 0.6912\n",
      "Epoch 2/100\n",
      "1956/1956 [==============================] - 1s 390us/step - loss: 0.5982 - acc: 0.6968 - val_loss: 0.5805 - val_acc: 0.6953\n",
      "Epoch 3/100\n",
      "1956/1956 [==============================] - 1s 396us/step - loss: 0.5940 - acc: 0.6943 - val_loss: 0.5756 - val_acc: 0.6933\n",
      "Epoch 4/100\n",
      "1956/1956 [==============================] - 1s 409us/step - loss: 0.5973 - acc: 0.6871 - val_loss: 0.5700 - val_acc: 0.6973\n",
      "Epoch 5/100\n",
      "1956/1956 [==============================] - 1s 393us/step - loss: 0.5921 - acc: 0.6994 - val_loss: 0.5675 - val_acc: 0.6912\n",
      "Epoch 6/100\n",
      "1956/1956 [==============================] - 1s 377us/step - loss: 0.5949 - acc: 0.6912 - val_loss: 0.5640 - val_acc: 0.6994\n",
      "Epoch 7/100\n",
      "1956/1956 [==============================] - 1s 422us/step - loss: 0.5888 - acc: 0.6953 - val_loss: 0.5600 - val_acc: 0.7055\n",
      "Epoch 8/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.5853 - acc: 0.7009 - val_loss: 0.5567 - val_acc: 0.7117\n",
      "Epoch 9/100\n",
      "1956/1956 [==============================] - 1s 401us/step - loss: 0.5805 - acc: 0.6973 - val_loss: 0.5558 - val_acc: 0.6994\n",
      "Epoch 10/100\n",
      "1956/1956 [==============================] - 1s 374us/step - loss: 0.5767 - acc: 0.7065 - val_loss: 0.5506 - val_acc: 0.7117\n",
      "Epoch 11/100\n",
      "1956/1956 [==============================] - 1s 377us/step - loss: 0.5698 - acc: 0.7198 - val_loss: 0.5466 - val_acc: 0.7239\n",
      "Epoch 12/100\n",
      "1956/1956 [==============================] - 1s 395us/step - loss: 0.5751 - acc: 0.7065 - val_loss: 0.5439 - val_acc: 0.7198\n",
      "Epoch 13/100\n",
      "1956/1956 [==============================] - 1s 410us/step - loss: 0.5674 - acc: 0.7173 - val_loss: 0.5392 - val_acc: 0.7260\n",
      "Epoch 14/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.5661 - acc: 0.7147 - val_loss: 0.5365 - val_acc: 0.7301\n",
      "Epoch 15/100\n",
      "1956/1956 [==============================] - 1s 411us/step - loss: 0.5659 - acc: 0.7117 - val_loss: 0.5330 - val_acc: 0.7280\n",
      "Epoch 16/100\n",
      "1956/1956 [==============================] - 1s 376us/step - loss: 0.5647 - acc: 0.7091 - val_loss: 0.5344 - val_acc: 0.7260\n",
      "Epoch 17/100\n",
      "1956/1956 [==============================] - 1s 439us/step - loss: 0.5561 - acc: 0.7178 - val_loss: 0.5299 - val_acc: 0.7382\n",
      "Epoch 18/100\n",
      "1956/1956 [==============================] - 1s 379us/step - loss: 0.5597 - acc: 0.7193 - val_loss: 0.5241 - val_acc: 0.7280\n",
      "Epoch 19/100\n",
      "1956/1956 [==============================] - 1s 381us/step - loss: 0.5585 - acc: 0.7178 - val_loss: 0.5214 - val_acc: 0.7301\n",
      "Epoch 20/100\n",
      "1956/1956 [==============================] - 1s 395us/step - loss: 0.5509 - acc: 0.7255 - val_loss: 0.5236 - val_acc: 0.7423\n",
      "Epoch 21/100\n",
      "1956/1956 [==============================] - 1s 414us/step - loss: 0.5520 - acc: 0.7198 - val_loss: 0.5180 - val_acc: 0.7485\n",
      "Epoch 22/100\n",
      "1956/1956 [==============================] - 1s 410us/step - loss: 0.5434 - acc: 0.7244 - val_loss: 0.5164 - val_acc: 0.7423\n",
      "Epoch 23/100\n",
      "1956/1956 [==============================] - 1s 379us/step - loss: 0.5420 - acc: 0.7306 - val_loss: 0.5112 - val_acc: 0.7464\n",
      "Epoch 24/100\n",
      "1956/1956 [==============================] - 1s 376us/step - loss: 0.5486 - acc: 0.7163 - val_loss: 0.5118 - val_acc: 0.7505\n",
      "Epoch 25/100\n",
      "1956/1956 [==============================] - 1s 393us/step - loss: 0.5488 - acc: 0.7178 - val_loss: 0.5056 - val_acc: 0.7444\n",
      "Epoch 26/100\n",
      "1956/1956 [==============================] - 1s 370us/step - loss: 0.5373 - acc: 0.7321 - val_loss: 0.5013 - val_acc: 0.7444\n",
      "Epoch 27/100\n",
      "1956/1956 [==============================] - 1s 380us/step - loss: 0.5350 - acc: 0.7306 - val_loss: 0.5011 - val_acc: 0.7587\n",
      "Epoch 28/100\n",
      "1956/1956 [==============================] - 1s 402us/step - loss: 0.5317 - acc: 0.7423 - val_loss: 0.4967 - val_acc: 0.7546\n",
      "Epoch 29/100\n",
      "1956/1956 [==============================] - 1s 381us/step - loss: 0.5327 - acc: 0.7234 - val_loss: 0.4944 - val_acc: 0.7607\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956/1956 [==============================] - 1s 402us/step - loss: 0.5257 - acc: 0.7439 - val_loss: 0.4913 - val_acc: 0.7607\n",
      "Epoch 31/100\n",
      "1956/1956 [==============================] - 1s 394us/step - loss: 0.5303 - acc: 0.7362 - val_loss: 0.4889 - val_acc: 0.7648\n",
      "Epoch 32/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.5203 - acc: 0.7408 - val_loss: 0.4861 - val_acc: 0.7648\n",
      "Epoch 33/100\n",
      "1956/1956 [==============================] - 1s 376us/step - loss: 0.5225 - acc: 0.7382 - val_loss: 0.4869 - val_acc: 0.7751\n",
      "Epoch 34/100\n",
      "1956/1956 [==============================] - 1s 382us/step - loss: 0.5198 - acc: 0.7444 - val_loss: 0.4781 - val_acc: 0.7587\n",
      "Epoch 35/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.5283 - acc: 0.7275 - val_loss: 0.4793 - val_acc: 0.7771\n",
      "Epoch 36/100\n",
      "1956/1956 [==============================] - 1s 410us/step - loss: 0.5239 - acc: 0.7336 - val_loss: 0.4763 - val_acc: 0.7751\n",
      "Epoch 37/100\n",
      "1956/1956 [==============================] - 1s 368us/step - loss: 0.5149 - acc: 0.7495 - val_loss: 0.4783 - val_acc: 0.7832\n",
      "Epoch 38/100\n",
      "1956/1956 [==============================] - 1s 404us/step - loss: 0.5143 - acc: 0.7464 - val_loss: 0.4709 - val_acc: 0.7771\n",
      "Epoch 39/100\n",
      "1956/1956 [==============================] - 1s 421us/step - loss: 0.5107 - acc: 0.7500 - val_loss: 0.4704 - val_acc: 0.7771\n",
      "Epoch 40/100\n",
      "1956/1956 [==============================] - 1s 387us/step - loss: 0.5089 - acc: 0.7449 - val_loss: 0.4718 - val_acc: 0.7812\n",
      "Epoch 41/100\n",
      "1956/1956 [==============================] - 1s 380us/step - loss: 0.5106 - acc: 0.7444 - val_loss: 0.4665 - val_acc: 0.7812\n",
      "Epoch 42/100\n",
      "1956/1956 [==============================] - 1s 369us/step - loss: 0.5062 - acc: 0.7510 - val_loss: 0.4655 - val_acc: 0.7812\n",
      "Epoch 43/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.4997 - acc: 0.7572 - val_loss: 0.4612 - val_acc: 0.7853\n",
      "Epoch 44/100\n",
      "1956/1956 [==============================] - 1s 372us/step - loss: 0.4968 - acc: 0.7536 - val_loss: 0.4591 - val_acc: 0.7853\n",
      "Epoch 45/100\n",
      "1956/1956 [==============================] - 1s 368us/step - loss: 0.4994 - acc: 0.7464 - val_loss: 0.4558 - val_acc: 0.7894\n",
      "Epoch 46/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.4982 - acc: 0.7526 - val_loss: 0.4563 - val_acc: 0.7873\n",
      "Epoch 47/100\n",
      "1956/1956 [==============================] - 1s 368us/step - loss: 0.4984 - acc: 0.7577 - val_loss: 0.4521 - val_acc: 0.7914\n",
      "Epoch 48/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.4899 - acc: 0.7607 - val_loss: 0.4485 - val_acc: 0.7914\n",
      "Epoch 49/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.4965 - acc: 0.7577 - val_loss: 0.4466 - val_acc: 0.7935\n",
      "Epoch 50/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.4891 - acc: 0.7510 - val_loss: 0.4490 - val_acc: 0.7975\n",
      "Epoch 51/100\n",
      "1956/1956 [==============================] - 1s 367us/step - loss: 0.4886 - acc: 0.7602 - val_loss: 0.4441 - val_acc: 0.7955\n",
      "Epoch 52/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.4848 - acc: 0.7643 - val_loss: 0.4386 - val_acc: 0.7832\n",
      "Epoch 53/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.4847 - acc: 0.7618 - val_loss: 0.4402 - val_acc: 0.7996\n",
      "Epoch 54/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.4717 - acc: 0.7725 - val_loss: 0.4345 - val_acc: 0.7914\n",
      "Epoch 55/100\n",
      "1956/1956 [==============================] - 1s 369us/step - loss: 0.4838 - acc: 0.7592 - val_loss: 0.4326 - val_acc: 0.7894\n",
      "Epoch 56/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.4750 - acc: 0.7638 - val_loss: 0.4330 - val_acc: 0.7996\n",
      "Epoch 57/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.4688 - acc: 0.7807 - val_loss: 0.4327 - val_acc: 0.8037\n",
      "Epoch 58/100\n",
      "1956/1956 [==============================] - 1s 375us/step - loss: 0.4769 - acc: 0.7628 - val_loss: 0.4310 - val_acc: 0.8037\n",
      "Epoch 59/100\n",
      "1956/1956 [==============================] - 1s 401us/step - loss: 0.4758 - acc: 0.7633 - val_loss: 0.4285 - val_acc: 0.8016\n",
      "Epoch 60/100\n",
      "1956/1956 [==============================] - 1s 382us/step - loss: 0.4712 - acc: 0.7791 - val_loss: 0.4227 - val_acc: 0.7894\n",
      "Epoch 61/100\n",
      "1956/1956 [==============================] - 1s 369us/step - loss: 0.4690 - acc: 0.7817 - val_loss: 0.4253 - val_acc: 0.8057\n",
      "Epoch 62/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.4660 - acc: 0.7771 - val_loss: 0.4226 - val_acc: 0.8016\n",
      "Epoch 63/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.4629 - acc: 0.7812 - val_loss: 0.4180 - val_acc: 0.7914\n",
      "Epoch 64/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.4713 - acc: 0.7674 - val_loss: 0.4165 - val_acc: 0.7955\n",
      "Epoch 65/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.4651 - acc: 0.7817 - val_loss: 0.4189 - val_acc: 0.8037\n",
      "Epoch 66/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.4621 - acc: 0.7802 - val_loss: 0.4136 - val_acc: 0.8016\n",
      "Epoch 67/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.4617 - acc: 0.7822 - val_loss: 0.4154 - val_acc: 0.8057\n",
      "Epoch 68/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.4620 - acc: 0.7812 - val_loss: 0.4112 - val_acc: 0.8037\n",
      "Epoch 69/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.4538 - acc: 0.7873 - val_loss: 0.4100 - val_acc: 0.8057\n",
      "Epoch 70/100\n",
      "1956/1956 [==============================] - 1s 368us/step - loss: 0.4561 - acc: 0.7802 - val_loss: 0.4070 - val_acc: 0.8016\n",
      "Epoch 71/100\n",
      "1956/1956 [==============================] - 1s 377us/step - loss: 0.4600 - acc: 0.7883 - val_loss: 0.4069 - val_acc: 0.8057\n",
      "Epoch 72/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.4588 - acc: 0.7935 - val_loss: 0.4049 - val_acc: 0.8016\n",
      "Epoch 73/100\n",
      "1956/1956 [==============================] - 1s 393us/step - loss: 0.4487 - acc: 0.7853 - val_loss: 0.4040 - val_acc: 0.8057\n",
      "Epoch 74/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.4495 - acc: 0.7802 - val_loss: 0.4042 - val_acc: 0.8098\n",
      "Epoch 75/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.4440 - acc: 0.8011 - val_loss: 0.4008 - val_acc: 0.8078\n",
      "Epoch 76/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.4400 - acc: 0.7883 - val_loss: 0.3984 - val_acc: 0.8078\n",
      "Epoch 77/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.4423 - acc: 0.7909 - val_loss: 0.3953 - val_acc: 0.8037\n",
      "Epoch 78/100\n",
      "1956/1956 [==============================] - 1s 342us/step - loss: 0.4431 - acc: 0.8052 - val_loss: 0.3936 - val_acc: 0.8037\n",
      "Epoch 79/100\n",
      "1956/1956 [==============================] - 1s 345us/step - loss: 0.4433 - acc: 0.7914 - val_loss: 0.3941 - val_acc: 0.8098\n",
      "Epoch 80/100\n",
      "1956/1956 [==============================] - 1s 347us/step - loss: 0.4325 - acc: 0.7996 - val_loss: 0.3920 - val_acc: 0.8119\n",
      "Epoch 81/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.4303 - acc: 0.8052 - val_loss: 0.3905 - val_acc: 0.8098\n",
      "Epoch 82/100\n",
      "1956/1956 [==============================] - 1s 368us/step - loss: 0.4362 - acc: 0.7996 - val_loss: 0.3907 - val_acc: 0.8119\n",
      "Epoch 83/100\n",
      "1956/1956 [==============================] - 1s 344us/step - loss: 0.4304 - acc: 0.8011 - val_loss: 0.3906 - val_acc: 0.8119\n",
      "Epoch 84/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.4361 - acc: 0.7914 - val_loss: 0.3873 - val_acc: 0.8139\n",
      "Epoch 85/100\n",
      "1956/1956 [==============================] - 1s 347us/step - loss: 0.4253 - acc: 0.8047 - val_loss: 0.3881 - val_acc: 0.8139\n",
      "Epoch 86/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.4326 - acc: 0.7945 - val_loss: 0.3830 - val_acc: 0.8139\n",
      "Epoch 87/100\n",
      "1956/1956 [==============================] - 1s 346us/step - loss: 0.4301 - acc: 0.8052 - val_loss: 0.3802 - val_acc: 0.8139\n",
      "Epoch 88/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.4265 - acc: 0.8011 - val_loss: 0.3789 - val_acc: 0.8139\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956/1956 [==============================] - 1s 346us/step - loss: 0.4263 - acc: 0.8006 - val_loss: 0.3882 - val_acc: 0.8200\n",
      "Epoch 90/100\n",
      "1956/1956 [==============================] - 1s 373us/step - loss: 0.4161 - acc: 0.8057 - val_loss: 0.3764 - val_acc: 0.8160\n",
      "Epoch 91/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.4264 - acc: 0.8021 - val_loss: 0.3757 - val_acc: 0.8139\n",
      "Epoch 92/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.4182 - acc: 0.8170 - val_loss: 0.3747 - val_acc: 0.8160\n",
      "Epoch 93/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.4181 - acc: 0.8165 - val_loss: 0.3739 - val_acc: 0.8180\n",
      "Epoch 94/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.4115 - acc: 0.8119 - val_loss: 0.3717 - val_acc: 0.8160\n",
      "Epoch 95/100\n",
      "1956/1956 [==============================] - 1s 378us/step - loss: 0.4103 - acc: 0.8067 - val_loss: 0.3681 - val_acc: 0.8139\n",
      "Epoch 96/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.4173 - acc: 0.8067 - val_loss: 0.3684 - val_acc: 0.8180\n",
      "Epoch 97/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.4234 - acc: 0.8037 - val_loss: 0.3726 - val_acc: 0.8262\n",
      "Epoch 98/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.4063 - acc: 0.8221 - val_loss: 0.3668 - val_acc: 0.8221\n",
      "Epoch 99/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.4137 - acc: 0.8154 - val_loss: 0.3649 - val_acc: 0.8221\n",
      "Epoch 100/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.4118 - acc: 0.8149 - val_loss: 0.3650 - val_acc: 0.8241\n",
      "Test subject 12, class BothStartLoadPhase\n",
      "Train subject 12, class LiftOff\n",
      "Train on 1956 samples, validate on 489 samples\n",
      "Epoch 1/100\n",
      "1956/1956 [==============================] - 2s 1ms/step - loss: 0.7029 - acc: 0.4811 - val_loss: 0.6950 - val_acc: 0.4724\n",
      "Epoch 2/100\n",
      "1956/1956 [==============================] - 1s 393us/step - loss: 0.6996 - acc: 0.5010 - val_loss: 0.6963 - val_acc: 0.4724\n",
      "Epoch 3/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.6924 - acc: 0.5184 - val_loss: 0.6967 - val_acc: 0.4703\n",
      "Epoch 4/100\n",
      "1956/1956 [==============================] - 1s 370us/step - loss: 0.6996 - acc: 0.5026 - val_loss: 0.6966 - val_acc: 0.4724\n",
      "Epoch 5/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.6942 - acc: 0.5230 - val_loss: 0.6969 - val_acc: 0.4724\n",
      "Epoch 6/100\n",
      "1956/1956 [==============================] - 1s 409us/step - loss: 0.6993 - acc: 0.4898 - val_loss: 0.6969 - val_acc: 0.4724\n",
      "Epoch 7/100\n",
      "1956/1956 [==============================] - 1s 377us/step - loss: 0.6956 - acc: 0.5056 - val_loss: 0.6969 - val_acc: 0.4724\n",
      "Epoch 8/100\n",
      "1956/1956 [==============================] - 1s 398us/step - loss: 0.6956 - acc: 0.5128 - val_loss: 0.6968 - val_acc: 0.4724\n",
      "Epoch 9/100\n",
      "1956/1956 [==============================] - 1s 375us/step - loss: 0.6970 - acc: 0.5046 - val_loss: 0.6956 - val_acc: 0.4765\n",
      "Epoch 10/100\n",
      "1956/1956 [==============================] - 1s 374us/step - loss: 0.6942 - acc: 0.5066 - val_loss: 0.6951 - val_acc: 0.4744\n",
      "Epoch 11/100\n",
      "1956/1956 [==============================] - 1s 403us/step - loss: 0.6929 - acc: 0.5291 - val_loss: 0.6946 - val_acc: 0.4744\n",
      "Epoch 12/100\n",
      "1956/1956 [==============================] - 1s 374us/step - loss: 0.6937 - acc: 0.5112 - val_loss: 0.6942 - val_acc: 0.4744\n",
      "Epoch 13/100\n",
      "1956/1956 [==============================] - 1s 409us/step - loss: 0.6927 - acc: 0.5297 - val_loss: 0.6950 - val_acc: 0.4744\n",
      "Epoch 14/100\n",
      "1956/1956 [==============================] - 1s 385us/step - loss: 0.6922 - acc: 0.5266 - val_loss: 0.6935 - val_acc: 0.4847\n",
      "Epoch 15/100\n",
      "1956/1956 [==============================] - 1s 376us/step - loss: 0.6909 - acc: 0.5404 - val_loss: 0.6917 - val_acc: 0.5092\n",
      "Epoch 16/100\n",
      "1956/1956 [==============================] - 1s 382us/step - loss: 0.6930 - acc: 0.5092 - val_loss: 0.6920 - val_acc: 0.5072\n",
      "Epoch 17/100\n",
      "1956/1956 [==============================] - 1s 393us/step - loss: 0.6883 - acc: 0.5409 - val_loss: 0.6906 - val_acc: 0.5072\n",
      "Epoch 18/100\n",
      "1956/1956 [==============================] - ETA: 0s - loss: 0.6958 - acc: 0.497 - 1s 371us/step - loss: 0.6952 - acc: 0.5020 - val_loss: 0.6903 - val_acc: 0.5031\n",
      "Epoch 19/100\n",
      "1956/1956 [==============================] - 1s 383us/step - loss: 0.6903 - acc: 0.5245 - val_loss: 0.6911 - val_acc: 0.5072\n",
      "Epoch 20/100\n",
      "1956/1956 [==============================] - 1s 372us/step - loss: 0.6919 - acc: 0.5297 - val_loss: 0.6889 - val_acc: 0.5256\n",
      "Epoch 21/100\n",
      "1956/1956 [==============================] - 1s 369us/step - loss: 0.6878 - acc: 0.5414 - val_loss: 0.6900 - val_acc: 0.5031\n",
      "Epoch 22/100\n",
      "1956/1956 [==============================] - 1s 372us/step - loss: 0.6851 - acc: 0.5619 - val_loss: 0.6897 - val_acc: 0.5072\n",
      "Epoch 23/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6865 - acc: 0.5312 - val_loss: 0.6907 - val_acc: 0.5031\n",
      "Epoch 24/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6864 - acc: 0.5353 - val_loss: 0.6884 - val_acc: 0.5235\n",
      "Epoch 25/100\n",
      "1956/1956 [==============================] - 1s 368us/step - loss: 0.6861 - acc: 0.5491 - val_loss: 0.6875 - val_acc: 0.5297\n",
      "Epoch 26/100\n",
      "1956/1956 [==============================] - 1s 414us/step - loss: 0.6841 - acc: 0.5537 - val_loss: 0.6873 - val_acc: 0.5297\n",
      "Epoch 27/100\n",
      "1956/1956 [==============================] - 1s 408us/step - loss: 0.6854 - acc: 0.5527 - val_loss: 0.6872 - val_acc: 0.5317\n",
      "Epoch 28/100\n",
      "1956/1956 [==============================] - 1s 393us/step - loss: 0.6841 - acc: 0.5557 - val_loss: 0.6870 - val_acc: 0.5337\n",
      "Epoch 29/100\n",
      "1956/1956 [==============================] - 1s 394us/step - loss: 0.6837 - acc: 0.5685 - val_loss: 0.6859 - val_acc: 0.5399\n",
      "Epoch 30/100\n",
      "1956/1956 [==============================] - 1s 386us/step - loss: 0.6848 - acc: 0.5409 - val_loss: 0.6857 - val_acc: 0.5399\n",
      "Epoch 31/100\n",
      "1956/1956 [==============================] - 1s 375us/step - loss: 0.6841 - acc: 0.5542 - val_loss: 0.6847 - val_acc: 0.5440\n",
      "Epoch 32/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.6825 - acc: 0.5639 - val_loss: 0.6833 - val_acc: 0.5562\n",
      "Epoch 33/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.6846 - acc: 0.5634 - val_loss: 0.6831 - val_acc: 0.5562\n",
      "Epoch 34/100\n",
      "1956/1956 [==============================] - 1s 367us/step - loss: 0.6810 - acc: 0.5792 - val_loss: 0.6825 - val_acc: 0.5583\n",
      "Epoch 35/100\n",
      "1956/1956 [==============================] - 1s 367us/step - loss: 0.6802 - acc: 0.5695 - val_loss: 0.6822 - val_acc: 0.5562\n",
      "Epoch 36/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.6793 - acc: 0.5767 - val_loss: 0.6808 - val_acc: 0.5583\n",
      "Epoch 37/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.6807 - acc: 0.5752 - val_loss: 0.6798 - val_acc: 0.5583\n",
      "Epoch 38/100\n",
      "1956/1956 [==============================] - 1s 372us/step - loss: 0.6799 - acc: 0.5608 - val_loss: 0.6803 - val_acc: 0.5603\n",
      "Epoch 39/100\n",
      "1956/1956 [==============================] - 1s 384us/step - loss: 0.6771 - acc: 0.5833 - val_loss: 0.6787 - val_acc: 0.5644\n",
      "Epoch 40/100\n",
      "1956/1956 [==============================] - 1s 370us/step - loss: 0.6797 - acc: 0.5787 - val_loss: 0.6790 - val_acc: 0.5603\n",
      "Epoch 41/100\n",
      "1956/1956 [==============================] - 1s 368us/step - loss: 0.6753 - acc: 0.5874 - val_loss: 0.6769 - val_acc: 0.5726\n",
      "Epoch 42/100\n",
      "1956/1956 [==============================] - 1s 381us/step - loss: 0.6780 - acc: 0.5665 - val_loss: 0.6764 - val_acc: 0.5726\n",
      "Epoch 43/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.6744 - acc: 0.5752 - val_loss: 0.6768 - val_acc: 0.5706\n",
      "Epoch 44/100\n",
      "1956/1956 [==============================] - 1s 382us/step - loss: 0.6758 - acc: 0.5920 - val_loss: 0.6761 - val_acc: 0.5726\n",
      "Epoch 45/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.6778 - acc: 0.5706 - val_loss: 0.6753 - val_acc: 0.5726\n",
      "Epoch 46/100\n",
      "1956/1956 [==============================] - 1s 369us/step - loss: 0.6744 - acc: 0.5874 - val_loss: 0.6748 - val_acc: 0.5767\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.6728 - acc: 0.5920 - val_loss: 0.6744 - val_acc: 0.5767\n",
      "Epoch 48/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.6705 - acc: 0.5925 - val_loss: 0.6718 - val_acc: 0.5828\n",
      "Epoch 49/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.6735 - acc: 0.5864 - val_loss: 0.6737 - val_acc: 0.5767\n",
      "Epoch 50/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.6709 - acc: 0.5951 - val_loss: 0.6713 - val_acc: 0.5828\n",
      "Epoch 51/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.6704 - acc: 0.5792 - val_loss: 0.6706 - val_acc: 0.5787\n",
      "Epoch 52/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.6698 - acc: 0.6074 - val_loss: 0.6698 - val_acc: 0.5787\n",
      "Epoch 53/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.6668 - acc: 0.6007 - val_loss: 0.6684 - val_acc: 0.5787\n",
      "Epoch 54/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.6674 - acc: 0.5838 - val_loss: 0.6681 - val_acc: 0.5787\n",
      "Epoch 55/100\n",
      "1956/1956 [==============================] - 1s 377us/step - loss: 0.6611 - acc: 0.6063 - val_loss: 0.6664 - val_acc: 0.5767\n",
      "Epoch 56/100\n",
      "1956/1956 [==============================] - 1s 372us/step - loss: 0.6665 - acc: 0.6099 - val_loss: 0.6629 - val_acc: 0.5808\n",
      "Epoch 57/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.6662 - acc: 0.5936 - val_loss: 0.6636 - val_acc: 0.5828\n",
      "Epoch 58/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.6627 - acc: 0.6099 - val_loss: 0.6619 - val_acc: 0.5828\n",
      "Epoch 59/100\n",
      "1956/1956 [==============================] - 1s 369us/step - loss: 0.6631 - acc: 0.6094 - val_loss: 0.6635 - val_acc: 0.5787\n",
      "Epoch 60/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.6621 - acc: 0.6022 - val_loss: 0.6631 - val_acc: 0.5828\n",
      "Epoch 61/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.6602 - acc: 0.6253 - val_loss: 0.6624 - val_acc: 0.5828\n",
      "Epoch 62/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.6621 - acc: 0.6033 - val_loss: 0.6633 - val_acc: 0.5849\n",
      "Epoch 63/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.6574 - acc: 0.6212 - val_loss: 0.6576 - val_acc: 0.5910\n",
      "Epoch 64/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.6597 - acc: 0.6150 - val_loss: 0.6552 - val_acc: 0.5930\n",
      "Epoch 65/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.6565 - acc: 0.6222 - val_loss: 0.6548 - val_acc: 0.5890\n",
      "Epoch 66/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.6574 - acc: 0.6176 - val_loss: 0.6547 - val_acc: 0.5951\n",
      "Epoch 67/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.6534 - acc: 0.6263 - val_loss: 0.6492 - val_acc: 0.6094\n",
      "Epoch 68/100\n",
      "1956/1956 [==============================] - 1s 368us/step - loss: 0.6536 - acc: 0.6109 - val_loss: 0.6566 - val_acc: 0.5910\n",
      "Epoch 69/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.6534 - acc: 0.6247 - val_loss: 0.6515 - val_acc: 0.5951\n",
      "Epoch 70/100\n",
      "1956/1956 [==============================] - 1s 379us/step - loss: 0.6496 - acc: 0.6329 - val_loss: 0.6520 - val_acc: 0.5971\n",
      "Epoch 71/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.6438 - acc: 0.6437 - val_loss: 0.6522 - val_acc: 0.5971\n",
      "Epoch 72/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.6463 - acc: 0.6406 - val_loss: 0.6475 - val_acc: 0.6012\n",
      "Epoch 73/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.6437 - acc: 0.6380 - val_loss: 0.6481 - val_acc: 0.5992\n",
      "Epoch 74/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.6437 - acc: 0.6273 - val_loss: 0.6469 - val_acc: 0.6012\n",
      "Epoch 75/100\n",
      "1956/1956 [==============================] - 1s 368us/step - loss: 0.6406 - acc: 0.6304 - val_loss: 0.6456 - val_acc: 0.5992\n",
      "Epoch 76/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.6402 - acc: 0.6345 - val_loss: 0.6414 - val_acc: 0.6074\n",
      "Epoch 77/100\n",
      "1956/1956 [==============================] - 1s 370us/step - loss: 0.6374 - acc: 0.6508 - val_loss: 0.6380 - val_acc: 0.6176\n",
      "Epoch 78/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.6343 - acc: 0.6559 - val_loss: 0.6385 - val_acc: 0.6094\n",
      "Epoch 79/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.6347 - acc: 0.6564 - val_loss: 0.6411 - val_acc: 0.6074\n",
      "Epoch 80/100\n",
      "1956/1956 [==============================] - 1s 368us/step - loss: 0.6311 - acc: 0.6513 - val_loss: 0.6353 - val_acc: 0.6115\n",
      "Epoch 81/100\n",
      "1956/1956 [==============================] - 1s 373us/step - loss: 0.6326 - acc: 0.6564 - val_loss: 0.6302 - val_acc: 0.6299\n",
      "Epoch 82/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6268 - acc: 0.6539 - val_loss: 0.6320 - val_acc: 0.6196\n",
      "Epoch 83/100\n",
      "1956/1956 [==============================] - 1s 373us/step - loss: 0.6318 - acc: 0.6483 - val_loss: 0.6256 - val_acc: 0.6360\n",
      "Epoch 84/100\n",
      "1956/1956 [==============================] - 1s 367us/step - loss: 0.6267 - acc: 0.6585 - val_loss: 0.6308 - val_acc: 0.6155\n",
      "Epoch 85/100\n",
      "1956/1956 [==============================] - 1s 369us/step - loss: 0.6297 - acc: 0.6447 - val_loss: 0.6341 - val_acc: 0.6135\n",
      "Epoch 86/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.6209 - acc: 0.6697 - val_loss: 0.6314 - val_acc: 0.6176\n",
      "Epoch 87/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.6196 - acc: 0.6697 - val_loss: 0.6237 - val_acc: 0.6339\n",
      "Epoch 88/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.6164 - acc: 0.6595 - val_loss: 0.6251 - val_acc: 0.6217\n",
      "Epoch 89/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.6171 - acc: 0.6646 - val_loss: 0.6135 - val_acc: 0.6462\n",
      "Epoch 90/100\n",
      "1956/1956 [==============================] - 1s 368us/step - loss: 0.6178 - acc: 0.6723 - val_loss: 0.6198 - val_acc: 0.6299\n",
      "Epoch 91/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.6132 - acc: 0.6743 - val_loss: 0.6210 - val_acc: 0.6278\n",
      "Epoch 92/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6073 - acc: 0.6738 - val_loss: 0.6183 - val_acc: 0.6299\n",
      "Epoch 93/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.6122 - acc: 0.6723 - val_loss: 0.6257 - val_acc: 0.6421\n",
      "Epoch 94/100\n",
      "1956/1956 [==============================] - 1s 368us/step - loss: 0.6147 - acc: 0.6677 - val_loss: 0.6085 - val_acc: 0.6564\n",
      "Epoch 95/100\n",
      "1956/1956 [==============================] - 1s 376us/step - loss: 0.6116 - acc: 0.6733 - val_loss: 0.6158 - val_acc: 0.6462\n",
      "Epoch 96/100\n",
      "1956/1956 [==============================] - 1s 368us/step - loss: 0.6045 - acc: 0.6830 - val_loss: 0.6193 - val_acc: 0.6442\n",
      "Epoch 97/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.6063 - acc: 0.6754 - val_loss: 0.6089 - val_acc: 0.6626\n",
      "Epoch 98/100\n",
      "1956/1956 [==============================] - 1s 369us/step - loss: 0.6061 - acc: 0.6789 - val_loss: 0.6006 - val_acc: 0.6646\n",
      "Epoch 99/100\n",
      "1956/1956 [==============================] - 1s 370us/step - loss: 0.5942 - acc: 0.6825 - val_loss: 0.6024 - val_acc: 0.6728\n",
      "Epoch 100/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.6046 - acc: 0.6702 - val_loss: 0.5994 - val_acc: 0.6769\n",
      "Train on 1956 samples, validate on 489 samples\n",
      "Epoch 1/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.6019 - acc: 0.6887 - val_loss: 0.5638 - val_acc: 0.7444\n",
      "Epoch 2/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.5956 - acc: 0.6835 - val_loss: 0.5688 - val_acc: 0.7362\n",
      "Epoch 3/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.5957 - acc: 0.6815 - val_loss: 0.5609 - val_acc: 0.7485\n",
      "Epoch 4/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.5970 - acc: 0.6958 - val_loss: 0.5536 - val_acc: 0.7485\n",
      "Epoch 5/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.5901 - acc: 0.6994 - val_loss: 0.5531 - val_acc: 0.7485\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956/1956 [==============================] - 1s 373us/step - loss: 0.5926 - acc: 0.6948 - val_loss: 0.5530 - val_acc: 0.7464\n",
      "Epoch 7/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.5810 - acc: 0.7086 - val_loss: 0.5501 - val_acc: 0.7485\n",
      "Epoch 8/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.5778 - acc: 0.7055 - val_loss: 0.5500 - val_acc: 0.7444\n",
      "Epoch 9/100\n",
      "1956/1956 [==============================] - 1s 378us/step - loss: 0.5834 - acc: 0.6958 - val_loss: 0.5470 - val_acc: 0.7444\n",
      "Epoch 10/100\n",
      "1956/1956 [==============================] - 1s 369us/step - loss: 0.5733 - acc: 0.7142 - val_loss: 0.5491 - val_acc: 0.7526\n",
      "Epoch 11/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.5773 - acc: 0.7019 - val_loss: 0.5491 - val_acc: 0.7485\n",
      "Epoch 12/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.5773 - acc: 0.7147 - val_loss: 0.5447 - val_acc: 0.7464\n",
      "Epoch 13/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.5723 - acc: 0.7045 - val_loss: 0.5444 - val_acc: 0.7444\n",
      "Epoch 14/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.5709 - acc: 0.7142 - val_loss: 0.5381 - val_acc: 0.7505\n",
      "Epoch 15/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.5691 - acc: 0.7122 - val_loss: 0.5373 - val_acc: 0.7505\n",
      "Epoch 16/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.5702 - acc: 0.7050 - val_loss: 0.5389 - val_acc: 0.7505\n",
      "Epoch 17/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.5638 - acc: 0.7168 - val_loss: 0.5377 - val_acc: 0.7505\n",
      "Epoch 18/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.5643 - acc: 0.7244 - val_loss: 0.5385 - val_acc: 0.7485\n",
      "Epoch 19/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.5657 - acc: 0.7183 - val_loss: 0.5318 - val_acc: 0.7546\n",
      "Epoch 20/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.5604 - acc: 0.7203 - val_loss: 0.5321 - val_acc: 0.7485\n",
      "Epoch 21/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.5567 - acc: 0.7336 - val_loss: 0.5292 - val_acc: 0.7485\n",
      "Epoch 22/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.5505 - acc: 0.7178 - val_loss: 0.5308 - val_acc: 0.7444\n",
      "Epoch 23/100\n",
      "1956/1956 [==============================] - 1s 386us/step - loss: 0.5580 - acc: 0.7198 - val_loss: 0.5347 - val_acc: 0.7505\n",
      "Epoch 24/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.5500 - acc: 0.7311 - val_loss: 0.5242 - val_acc: 0.7505\n",
      "Epoch 25/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.5532 - acc: 0.7280 - val_loss: 0.5297 - val_acc: 0.7444\n",
      "Epoch 26/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.5424 - acc: 0.7434 - val_loss: 0.5250 - val_acc: 0.7485\n",
      "Epoch 27/100\n",
      "1956/1956 [==============================] - 1s 367us/step - loss: 0.5449 - acc: 0.7413 - val_loss: 0.5278 - val_acc: 0.7464\n",
      "Epoch 28/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.5450 - acc: 0.7352 - val_loss: 0.5229 - val_acc: 0.7464\n",
      "Epoch 29/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.5446 - acc: 0.7296 - val_loss: 0.5188 - val_acc: 0.7546\n",
      "Epoch 30/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.5431 - acc: 0.7290 - val_loss: 0.5254 - val_acc: 0.7464\n",
      "Epoch 31/100\n",
      "1956/1956 [==============================] - 1s 376us/step - loss: 0.5370 - acc: 0.7377 - val_loss: 0.5183 - val_acc: 0.7546\n",
      "Epoch 32/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.5395 - acc: 0.7439 - val_loss: 0.5189 - val_acc: 0.7526\n",
      "Epoch 33/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.5366 - acc: 0.7372 - val_loss: 0.5183 - val_acc: 0.7546\n",
      "Epoch 34/100\n",
      "1956/1956 [==============================] - 1s 377us/step - loss: 0.5341 - acc: 0.7423 - val_loss: 0.5174 - val_acc: 0.7526\n",
      "Epoch 35/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.5337 - acc: 0.7408 - val_loss: 0.5149 - val_acc: 0.7526\n",
      "Epoch 36/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.5357 - acc: 0.7444 - val_loss: 0.5151 - val_acc: 0.7566\n",
      "Epoch 37/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.5303 - acc: 0.7449 - val_loss: 0.5170 - val_acc: 0.7587\n",
      "Epoch 38/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.5260 - acc: 0.7500 - val_loss: 0.5172 - val_acc: 0.7587\n",
      "Epoch 39/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.5302 - acc: 0.7480 - val_loss: 0.5076 - val_acc: 0.7587\n",
      "Epoch 40/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.5200 - acc: 0.7556 - val_loss: 0.5162 - val_acc: 0.7566\n",
      "Epoch 41/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.5273 - acc: 0.7500 - val_loss: 0.5076 - val_acc: 0.7587\n",
      "Epoch 42/100\n",
      "1956/1956 [==============================] - 1s 368us/step - loss: 0.5236 - acc: 0.7515 - val_loss: 0.5100 - val_acc: 0.7607\n",
      "Epoch 43/100\n",
      "1956/1956 [==============================] - 1s 368us/step - loss: 0.5156 - acc: 0.7531 - val_loss: 0.5107 - val_acc: 0.7607\n",
      "Epoch 44/100\n",
      "1956/1956 [==============================] - 1s 372us/step - loss: 0.5212 - acc: 0.7490 - val_loss: 0.5094 - val_acc: 0.7628\n",
      "Epoch 45/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.5176 - acc: 0.7536 - val_loss: 0.5089 - val_acc: 0.7607\n",
      "Epoch 46/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.5164 - acc: 0.7551 - val_loss: 0.5052 - val_acc: 0.7607\n",
      "Epoch 47/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.5162 - acc: 0.7541 - val_loss: 0.5137 - val_acc: 0.7566\n",
      "Epoch 48/100\n",
      "1956/1956 [==============================] - 1s 385us/step - loss: 0.5087 - acc: 0.7643 - val_loss: 0.5076 - val_acc: 0.7607\n",
      "Epoch 49/100\n",
      "1956/1956 [==============================] - 1s 369us/step - loss: 0.5143 - acc: 0.7592 - val_loss: 0.5065 - val_acc: 0.7607\n",
      "Epoch 50/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.5105 - acc: 0.7638 - val_loss: 0.5039 - val_acc: 0.7566\n",
      "Epoch 51/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.5017 - acc: 0.7766 - val_loss: 0.5034 - val_acc: 0.7587\n",
      "Epoch 52/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.5034 - acc: 0.7684 - val_loss: 0.4975 - val_acc: 0.7546\n",
      "Epoch 53/100\n",
      "1956/1956 [==============================] - 1s 370us/step - loss: 0.5065 - acc: 0.7643 - val_loss: 0.4970 - val_acc: 0.7566\n",
      "Epoch 54/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.5012 - acc: 0.7633 - val_loss: 0.4997 - val_acc: 0.7628\n",
      "Epoch 55/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.5003 - acc: 0.7751 - val_loss: 0.5062 - val_acc: 0.7628\n",
      "Epoch 56/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.4945 - acc: 0.7740 - val_loss: 0.4914 - val_acc: 0.7628\n",
      "Epoch 57/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.4991 - acc: 0.7720 - val_loss: 0.4962 - val_acc: 0.7607\n",
      "Epoch 58/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.4998 - acc: 0.7684 - val_loss: 0.4958 - val_acc: 0.7648\n",
      "Epoch 59/100\n",
      "1956/1956 [==============================] - 1s 367us/step - loss: 0.4998 - acc: 0.7561 - val_loss: 0.4970 - val_acc: 0.7669\n",
      "Epoch 60/100\n",
      "1956/1956 [==============================] - 1s 370us/step - loss: 0.5004 - acc: 0.7674 - val_loss: 0.4958 - val_acc: 0.7669\n",
      "Epoch 61/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.4935 - acc: 0.7699 - val_loss: 0.5024 - val_acc: 0.7689\n",
      "Epoch 62/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.4975 - acc: 0.7628 - val_loss: 0.4942 - val_acc: 0.7689\n",
      "Epoch 63/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.5037 - acc: 0.7633 - val_loss: 0.4961 - val_acc: 0.7730\n",
      "Epoch 64/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.4984 - acc: 0.7664 - val_loss: 0.4944 - val_acc: 0.7689\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.4869 - acc: 0.7771 - val_loss: 0.4932 - val_acc: 0.7710\n",
      "Epoch 66/100\n",
      "1956/1956 [==============================] - 1s 369us/step - loss: 0.4904 - acc: 0.7761 - val_loss: 0.4920 - val_acc: 0.7730\n",
      "Epoch 67/100\n",
      "1956/1956 [==============================] - 1s 369us/step - loss: 0.4868 - acc: 0.7699 - val_loss: 0.4919 - val_acc: 0.7710\n",
      "Epoch 68/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.4886 - acc: 0.7797 - val_loss: 0.4881 - val_acc: 0.7689\n",
      "Epoch 69/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.4922 - acc: 0.7761 - val_loss: 0.4889 - val_acc: 0.7710\n",
      "Epoch 70/100\n",
      "1956/1956 [==============================] - 1s 367us/step - loss: 0.4907 - acc: 0.7797 - val_loss: 0.4832 - val_acc: 0.7730\n",
      "Epoch 71/100\n",
      "1956/1956 [==============================] - 1s 369us/step - loss: 0.4890 - acc: 0.7704 - val_loss: 0.4872 - val_acc: 0.7751\n",
      "Epoch 72/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.4811 - acc: 0.7822 - val_loss: 0.4860 - val_acc: 0.7751\n",
      "Epoch 73/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.4809 - acc: 0.7883 - val_loss: 0.4861 - val_acc: 0.7771\n",
      "Epoch 74/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.4712 - acc: 0.7883 - val_loss: 0.4837 - val_acc: 0.7791\n",
      "Epoch 75/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.4725 - acc: 0.7853 - val_loss: 0.4836 - val_acc: 0.7791\n",
      "Epoch 76/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.4794 - acc: 0.7802 - val_loss: 0.4842 - val_acc: 0.7812\n",
      "Epoch 77/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.4746 - acc: 0.7848 - val_loss: 0.4862 - val_acc: 0.7791\n",
      "Epoch 78/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.4817 - acc: 0.7776 - val_loss: 0.4860 - val_acc: 0.7771\n",
      "Epoch 79/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.4735 - acc: 0.7756 - val_loss: 0.4857 - val_acc: 0.7771\n",
      "Epoch 80/100\n",
      "1956/1956 [==============================] - 1s 367us/step - loss: 0.4675 - acc: 0.7853 - val_loss: 0.4797 - val_acc: 0.7832\n",
      "Epoch 81/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.4664 - acc: 0.7914 - val_loss: 0.4836 - val_acc: 0.7791\n",
      "Epoch 82/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.4652 - acc: 0.7889 - val_loss: 0.4793 - val_acc: 0.7832\n",
      "Epoch 83/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.4678 - acc: 0.7822 - val_loss: 0.4789 - val_acc: 0.7812\n",
      "Epoch 84/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.4664 - acc: 0.7868 - val_loss: 0.4766 - val_acc: 0.7812\n",
      "Epoch 85/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.4589 - acc: 0.8011 - val_loss: 0.4823 - val_acc: 0.7853\n",
      "Epoch 86/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.4689 - acc: 0.7904 - val_loss: 0.4749 - val_acc: 0.7853\n",
      "Epoch 87/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.4576 - acc: 0.7899 - val_loss: 0.4793 - val_acc: 0.7832\n",
      "Epoch 88/100\n",
      "1956/1956 [==============================] - 1s 367us/step - loss: 0.4633 - acc: 0.7832 - val_loss: 0.4792 - val_acc: 0.7873\n",
      "Epoch 89/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.4564 - acc: 0.8011 - val_loss: 0.4724 - val_acc: 0.7832\n",
      "Epoch 90/100\n",
      "1956/1956 [==============================] - 1s 367us/step - loss: 0.4650 - acc: 0.7914 - val_loss: 0.4719 - val_acc: 0.7853\n",
      "Epoch 91/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.4690 - acc: 0.7889 - val_loss: 0.4714 - val_acc: 0.7832\n",
      "Epoch 92/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.4657 - acc: 0.7904 - val_loss: 0.4712 - val_acc: 0.7812\n",
      "Epoch 93/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.4510 - acc: 0.7935 - val_loss: 0.4708 - val_acc: 0.7853\n",
      "Epoch 94/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.4487 - acc: 0.8027 - val_loss: 0.4648 - val_acc: 0.7853\n",
      "Epoch 95/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.4438 - acc: 0.8067 - val_loss: 0.4789 - val_acc: 0.7894\n",
      "Epoch 96/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.4526 - acc: 0.7935 - val_loss: 0.4674 - val_acc: 0.7832\n",
      "Epoch 97/100\n",
      "1956/1956 [==============================] - 1s 367us/step - loss: 0.4468 - acc: 0.7970 - val_loss: 0.4631 - val_acc: 0.7873\n",
      "Epoch 98/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.4475 - acc: 0.8037 - val_loss: 0.4697 - val_acc: 0.7894\n",
      "Epoch 99/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.4576 - acc: 0.7904 - val_loss: 0.4750 - val_acc: 0.7914\n",
      "Epoch 100/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.4447 - acc: 0.7981 - val_loss: 0.4712 - val_acc: 0.7914\n",
      "Test subject 12, class LiftOff\n",
      "Train subject 12, class Replace\n",
      "Train on 1956 samples, validate on 489 samples\n",
      "Epoch 1/100\n",
      "1956/1956 [==============================] - 2s 1ms/step - loss: 0.6941 - acc: 0.5036 - val_loss: 0.6910 - val_acc: 0.5746\n",
      "Epoch 2/100\n",
      "1956/1956 [==============================] - 1s 372us/step - loss: 0.6949 - acc: 0.5015 - val_loss: 0.6905 - val_acc: 0.5910\n",
      "Epoch 3/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.6941 - acc: 0.5036 - val_loss: 0.6901 - val_acc: 0.6012\n",
      "Epoch 4/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6929 - acc: 0.5010 - val_loss: 0.6897 - val_acc: 0.6033\n",
      "Epoch 5/100\n",
      "1956/1956 [==============================] - 1s 368us/step - loss: 0.6926 - acc: 0.5153 - val_loss: 0.6893 - val_acc: 0.5951\n",
      "Epoch 6/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.6930 - acc: 0.5020 - val_loss: 0.6890 - val_acc: 0.6115\n",
      "Epoch 7/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.6927 - acc: 0.5138 - val_loss: 0.6887 - val_acc: 0.6033\n",
      "Epoch 8/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.6923 - acc: 0.5041 - val_loss: 0.6883 - val_acc: 0.6135\n",
      "Epoch 9/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.6908 - acc: 0.5435 - val_loss: 0.6880 - val_acc: 0.6217\n",
      "Epoch 10/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.6904 - acc: 0.5435 - val_loss: 0.6876 - val_acc: 0.6360\n",
      "Epoch 11/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6913 - acc: 0.5343 - val_loss: 0.6872 - val_acc: 0.6483\n",
      "Epoch 12/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.6892 - acc: 0.5389 - val_loss: 0.6868 - val_acc: 0.6667\n",
      "Epoch 13/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.6897 - acc: 0.5378 - val_loss: 0.6865 - val_acc: 0.6626\n",
      "Epoch 14/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.6874 - acc: 0.5501 - val_loss: 0.6860 - val_acc: 0.6687\n",
      "Epoch 15/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.6875 - acc: 0.5542 - val_loss: 0.6856 - val_acc: 0.6708\n",
      "Epoch 16/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.6914 - acc: 0.5184 - val_loss: 0.6851 - val_acc: 0.6687\n",
      "Epoch 17/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.6873 - acc: 0.5527 - val_loss: 0.6848 - val_acc: 0.6646\n",
      "Epoch 18/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.6894 - acc: 0.5399 - val_loss: 0.6843 - val_acc: 0.6667\n",
      "Epoch 19/100\n",
      "1956/1956 [==============================] - 1s 367us/step - loss: 0.6865 - acc: 0.5496 - val_loss: 0.6839 - val_acc: 0.6708\n",
      "Epoch 20/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.6876 - acc: 0.5491 - val_loss: 0.6834 - val_acc: 0.6646\n",
      "Epoch 21/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.6892 - acc: 0.5440 - val_loss: 0.6829 - val_acc: 0.6748\n",
      "Epoch 22/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6879 - acc: 0.5470 - val_loss: 0.6824 - val_acc: 0.6789\n",
      "Epoch 23/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.6861 - acc: 0.5567 - val_loss: 0.6819 - val_acc: 0.6810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.6850 - acc: 0.5741 - val_loss: 0.6813 - val_acc: 0.6830\n",
      "Epoch 25/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.6849 - acc: 0.5695 - val_loss: 0.6808 - val_acc: 0.6769\n",
      "Epoch 26/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.6857 - acc: 0.5726 - val_loss: 0.6802 - val_acc: 0.6892\n",
      "Epoch 27/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.6838 - acc: 0.5706 - val_loss: 0.6796 - val_acc: 0.6912\n",
      "Epoch 28/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.6834 - acc: 0.5813 - val_loss: 0.6789 - val_acc: 0.6933\n",
      "Epoch 29/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.6841 - acc: 0.5920 - val_loss: 0.6783 - val_acc: 0.6810\n",
      "Epoch 30/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.6829 - acc: 0.5869 - val_loss: 0.6776 - val_acc: 0.6953\n",
      "Epoch 31/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.6815 - acc: 0.5854 - val_loss: 0.6767 - val_acc: 0.7014\n",
      "Epoch 32/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.6834 - acc: 0.5844 - val_loss: 0.6760 - val_acc: 0.6953\n",
      "Epoch 33/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.6815 - acc: 0.5818 - val_loss: 0.6751 - val_acc: 0.6912\n",
      "Epoch 34/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.6795 - acc: 0.5961 - val_loss: 0.6743 - val_acc: 0.6810\n",
      "Epoch 35/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.6782 - acc: 0.6007 - val_loss: 0.6733 - val_acc: 0.6892\n",
      "Epoch 36/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.6788 - acc: 0.5905 - val_loss: 0.6723 - val_acc: 0.6871\n",
      "Epoch 37/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.6797 - acc: 0.5961 - val_loss: 0.6711 - val_acc: 0.6912\n",
      "Epoch 38/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.6766 - acc: 0.6115 - val_loss: 0.6700 - val_acc: 0.6892\n",
      "Epoch 39/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.6782 - acc: 0.5992 - val_loss: 0.6690 - val_acc: 0.6810\n",
      "Epoch 40/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.6737 - acc: 0.6258 - val_loss: 0.6676 - val_acc: 0.6810\n",
      "Epoch 41/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.6761 - acc: 0.6079 - val_loss: 0.6665 - val_acc: 0.6810\n",
      "Epoch 42/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.6734 - acc: 0.6253 - val_loss: 0.6651 - val_acc: 0.6830\n",
      "Epoch 43/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.6729 - acc: 0.6268 - val_loss: 0.6636 - val_acc: 0.6810\n",
      "Epoch 44/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.6706 - acc: 0.6421 - val_loss: 0.6620 - val_acc: 0.6810\n",
      "Epoch 45/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.6704 - acc: 0.6396 - val_loss: 0.6602 - val_acc: 0.6871\n",
      "Epoch 46/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.6669 - acc: 0.6385 - val_loss: 0.6586 - val_acc: 0.6830\n",
      "Epoch 47/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.6663 - acc: 0.6442 - val_loss: 0.6568 - val_acc: 0.6810\n",
      "Epoch 48/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.6657 - acc: 0.6329 - val_loss: 0.6547 - val_acc: 0.6871\n",
      "Epoch 49/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.6624 - acc: 0.6580 - val_loss: 0.6527 - val_acc: 0.6769\n",
      "Epoch 50/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.6617 - acc: 0.6580 - val_loss: 0.6506 - val_acc: 0.6769\n",
      "Epoch 51/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.6609 - acc: 0.6534 - val_loss: 0.6484 - val_acc: 0.6789\n",
      "Epoch 52/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.6582 - acc: 0.6493 - val_loss: 0.6457 - val_acc: 0.6769\n",
      "Epoch 53/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.6564 - acc: 0.6616 - val_loss: 0.6427 - val_acc: 0.6871\n",
      "Epoch 54/100\n",
      "1956/1956 [==============================] - ETA: 0s - loss: 0.6550 - acc: 0.673 - 1s 357us/step - loss: 0.6540 - acc: 0.6769 - val_loss: 0.6397 - val_acc: 0.6912\n",
      "Epoch 55/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.6547 - acc: 0.6580 - val_loss: 0.6363 - val_acc: 0.7014\n",
      "Epoch 56/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.6509 - acc: 0.6769 - val_loss: 0.6331 - val_acc: 0.7035\n",
      "Epoch 57/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.6460 - acc: 0.6810 - val_loss: 0.6301 - val_acc: 0.7014\n",
      "Epoch 58/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.6446 - acc: 0.6805 - val_loss: 0.6263 - val_acc: 0.7076\n",
      "Epoch 59/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.6442 - acc: 0.6774 - val_loss: 0.6228 - val_acc: 0.7076\n",
      "Epoch 60/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.6403 - acc: 0.6871 - val_loss: 0.6190 - val_acc: 0.7096\n",
      "Epoch 61/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.6347 - acc: 0.6892 - val_loss: 0.6153 - val_acc: 0.7076\n",
      "Epoch 62/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.6332 - acc: 0.6851 - val_loss: 0.6109 - val_acc: 0.7117\n",
      "Epoch 63/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.6336 - acc: 0.6769 - val_loss: 0.6065 - val_acc: 0.7198\n",
      "Epoch 64/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.6257 - acc: 0.7025 - val_loss: 0.6014 - val_acc: 0.7260\n",
      "Epoch 65/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.6222 - acc: 0.7030 - val_loss: 0.5969 - val_acc: 0.7280\n",
      "Epoch 66/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.6215 - acc: 0.6825 - val_loss: 0.5912 - val_acc: 0.7362\n",
      "Epoch 67/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6222 - acc: 0.6933 - val_loss: 0.5864 - val_acc: 0.7342\n",
      "Epoch 68/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.6123 - acc: 0.7030 - val_loss: 0.5818 - val_acc: 0.7321\n",
      "Epoch 69/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.6114 - acc: 0.7081 - val_loss: 0.5771 - val_acc: 0.7342\n",
      "Epoch 70/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.6036 - acc: 0.7132 - val_loss: 0.5710 - val_acc: 0.7382\n",
      "Epoch 71/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.6036 - acc: 0.7076 - val_loss: 0.5666 - val_acc: 0.7362\n",
      "Epoch 72/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.5941 - acc: 0.7152 - val_loss: 0.5591 - val_acc: 0.7505\n",
      "Epoch 73/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.5882 - acc: 0.7265 - val_loss: 0.5538 - val_acc: 0.7444\n",
      "Epoch 74/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.5874 - acc: 0.7173 - val_loss: 0.5480 - val_acc: 0.7526\n",
      "Epoch 75/100\n",
      "1956/1956 [==============================] - 1s 348us/step - loss: 0.5846 - acc: 0.7168 - val_loss: 0.5412 - val_acc: 0.7648\n",
      "Epoch 76/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.5716 - acc: 0.7352 - val_loss: 0.5346 - val_acc: 0.7648\n",
      "Epoch 77/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.5738 - acc: 0.7311 - val_loss: 0.5300 - val_acc: 0.7526\n",
      "Epoch 78/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.5613 - acc: 0.7444 - val_loss: 0.5216 - val_acc: 0.7648\n",
      "Epoch 79/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.5622 - acc: 0.7393 - val_loss: 0.5156 - val_acc: 0.7648\n",
      "Epoch 80/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.5583 - acc: 0.7408 - val_loss: 0.5122 - val_acc: 0.7587\n",
      "Epoch 81/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.5520 - acc: 0.7428 - val_loss: 0.5044 - val_acc: 0.7689\n",
      "Epoch 82/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.5472 - acc: 0.7439 - val_loss: 0.4961 - val_acc: 0.7751\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.5366 - acc: 0.7495 - val_loss: 0.4907 - val_acc: 0.7710\n",
      "Epoch 84/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.5342 - acc: 0.7531 - val_loss: 0.4821 - val_acc: 0.7751\n",
      "Epoch 85/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.5269 - acc: 0.7582 - val_loss: 0.4784 - val_acc: 0.7689\n",
      "Epoch 86/100\n",
      "1956/1956 [==============================] - 1s 344us/step - loss: 0.5246 - acc: 0.7597 - val_loss: 0.4680 - val_acc: 0.7832\n",
      "Epoch 87/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.5160 - acc: 0.7669 - val_loss: 0.4611 - val_acc: 0.7894\n",
      "Epoch 88/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.5071 - acc: 0.7740 - val_loss: 0.4557 - val_acc: 0.7894\n",
      "Epoch 89/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.5071 - acc: 0.7597 - val_loss: 0.4440 - val_acc: 0.8016\n",
      "Epoch 90/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.4914 - acc: 0.7730 - val_loss: 0.4413 - val_acc: 0.7975\n",
      "Epoch 91/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.4875 - acc: 0.7791 - val_loss: 0.4347 - val_acc: 0.8078\n",
      "Epoch 92/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.4860 - acc: 0.7802 - val_loss: 0.4260 - val_acc: 0.8160\n",
      "Epoch 93/100\n",
      "1956/1956 [==============================] - 1s 346us/step - loss: 0.4763 - acc: 0.7843 - val_loss: 0.4158 - val_acc: 0.8200\n",
      "Epoch 94/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.4786 - acc: 0.7822 - val_loss: 0.4088 - val_acc: 0.8303\n",
      "Epoch 95/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.4631 - acc: 0.7935 - val_loss: 0.4126 - val_acc: 0.8323\n",
      "Epoch 96/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.4683 - acc: 0.7904 - val_loss: 0.4088 - val_acc: 0.8303\n",
      "Epoch 97/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.4544 - acc: 0.7981 - val_loss: 0.3884 - val_acc: 0.8405\n",
      "Epoch 98/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.4467 - acc: 0.8042 - val_loss: 0.3824 - val_acc: 0.8446\n",
      "Epoch 99/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.4430 - acc: 0.8037 - val_loss: 0.3823 - val_acc: 0.8507\n",
      "Epoch 100/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.4319 - acc: 0.8160 - val_loss: 0.3788 - val_acc: 0.8528\n",
      "Train on 1956 samples, validate on 489 samples\n",
      "Epoch 1/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.4261 - acc: 0.8124 - val_loss: 0.3930 - val_acc: 0.8405\n",
      "Epoch 2/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.4123 - acc: 0.8236 - val_loss: 0.3976 - val_acc: 0.8303\n",
      "Epoch 3/100\n",
      "1956/1956 [==============================] - 1s 348us/step - loss: 0.4018 - acc: 0.8257 - val_loss: 0.3932 - val_acc: 0.8344\n",
      "Epoch 4/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.4027 - acc: 0.8303 - val_loss: 0.3847 - val_acc: 0.8384\n",
      "Epoch 5/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.4014 - acc: 0.8262 - val_loss: 0.3871 - val_acc: 0.8323\n",
      "Epoch 6/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.3904 - acc: 0.8364 - val_loss: 0.3792 - val_acc: 0.8344\n",
      "Epoch 7/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.3987 - acc: 0.8257 - val_loss: 0.3847 - val_acc: 0.8405\n",
      "Epoch 8/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.3823 - acc: 0.8369 - val_loss: 0.3800 - val_acc: 0.8384\n",
      "Epoch 9/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.3699 - acc: 0.8461 - val_loss: 0.3826 - val_acc: 0.8425\n",
      "Epoch 10/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.3745 - acc: 0.8395 - val_loss: 0.3696 - val_acc: 0.8405\n",
      "Epoch 11/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.3737 - acc: 0.8390 - val_loss: 0.3720 - val_acc: 0.8425\n",
      "Epoch 12/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.3686 - acc: 0.8507 - val_loss: 0.3629 - val_acc: 0.8446\n",
      "Epoch 13/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.3596 - acc: 0.8466 - val_loss: 0.3882 - val_acc: 0.8384\n",
      "Epoch 14/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.3640 - acc: 0.8471 - val_loss: 0.3855 - val_acc: 0.8384\n",
      "Epoch 15/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.3593 - acc: 0.8528 - val_loss: 0.3727 - val_acc: 0.8507\n",
      "Epoch 16/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.3491 - acc: 0.8471 - val_loss: 0.3602 - val_acc: 0.8528\n",
      "Epoch 17/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.3547 - acc: 0.8492 - val_loss: 0.3704 - val_acc: 0.8528\n",
      "Epoch 18/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.3516 - acc: 0.8502 - val_loss: 0.3651 - val_acc: 0.8528\n",
      "Epoch 19/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.3256 - acc: 0.8722 - val_loss: 0.3645 - val_acc: 0.8528\n",
      "Epoch 20/100\n",
      "1956/1956 [==============================] - 1s 348us/step - loss: 0.3409 - acc: 0.8604 - val_loss: 0.3785 - val_acc: 0.8466\n",
      "Epoch 21/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.3407 - acc: 0.8620 - val_loss: 0.3745 - val_acc: 0.8487\n",
      "Epoch 22/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.3426 - acc: 0.8563 - val_loss: 0.3593 - val_acc: 0.8569\n",
      "Epoch 23/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.3305 - acc: 0.8655 - val_loss: 0.3649 - val_acc: 0.8569\n",
      "Epoch 24/100\n",
      "1956/1956 [==============================] - 1s 345us/step - loss: 0.3357 - acc: 0.8686 - val_loss: 0.3595 - val_acc: 0.8548\n",
      "Epoch 25/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.3354 - acc: 0.8666 - val_loss: 0.3775 - val_acc: 0.8466\n",
      "Epoch 26/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.3401 - acc: 0.8569 - val_loss: 0.3666 - val_acc: 0.8569\n",
      "Epoch 27/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.3212 - acc: 0.8696 - val_loss: 0.3716 - val_acc: 0.8548\n",
      "Epoch 28/100\n",
      "1956/1956 [==============================] - 1s 346us/step - loss: 0.3222 - acc: 0.8707 - val_loss: 0.3671 - val_acc: 0.8569\n",
      "Epoch 29/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.3313 - acc: 0.8640 - val_loss: 0.3558 - val_acc: 0.8609\n",
      "Epoch 30/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.3299 - acc: 0.8625 - val_loss: 0.3798 - val_acc: 0.8507\n",
      "Epoch 31/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.3313 - acc: 0.8615 - val_loss: 0.3529 - val_acc: 0.8630\n",
      "Epoch 32/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.3202 - acc: 0.8696 - val_loss: 0.3587 - val_acc: 0.8609\n",
      "Epoch 33/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.3250 - acc: 0.8686 - val_loss: 0.3466 - val_acc: 0.8650\n",
      "Epoch 34/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.3154 - acc: 0.8681 - val_loss: 0.3638 - val_acc: 0.8589\n",
      "Epoch 35/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.3186 - acc: 0.8742 - val_loss: 0.3535 - val_acc: 0.8630\n",
      "Epoch 36/100\n",
      "1956/1956 [==============================] - 1s 346us/step - loss: 0.3219 - acc: 0.8681 - val_loss: 0.3421 - val_acc: 0.8671\n",
      "Epoch 37/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.3133 - acc: 0.8712 - val_loss: 0.3533 - val_acc: 0.8630\n",
      "Epoch 38/100\n",
      "1956/1956 [==============================] - 1s 347us/step - loss: 0.3260 - acc: 0.8671 - val_loss: 0.3478 - val_acc: 0.8671\n",
      "Epoch 39/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.3171 - acc: 0.8655 - val_loss: 0.3378 - val_acc: 0.8671\n",
      "Epoch 40/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.3223 - acc: 0.8742 - val_loss: 0.3307 - val_acc: 0.8691\n",
      "Epoch 41/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.3136 - acc: 0.8768 - val_loss: 0.3392 - val_acc: 0.8671\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.3073 - acc: 0.8778 - val_loss: 0.3439 - val_acc: 0.8671\n",
      "Epoch 43/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.3140 - acc: 0.8712 - val_loss: 0.3359 - val_acc: 0.8671\n",
      "Epoch 44/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.3072 - acc: 0.8742 - val_loss: 0.3599 - val_acc: 0.8589\n",
      "Epoch 45/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.3114 - acc: 0.8778 - val_loss: 0.3406 - val_acc: 0.8671\n",
      "Epoch 46/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.2976 - acc: 0.8850 - val_loss: 0.3368 - val_acc: 0.8671\n",
      "Epoch 47/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.3092 - acc: 0.8712 - val_loss: 0.3240 - val_acc: 0.8773\n",
      "Epoch 48/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.3076 - acc: 0.8717 - val_loss: 0.3182 - val_acc: 0.8855\n",
      "Epoch 49/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.3031 - acc: 0.8696 - val_loss: 0.3272 - val_acc: 0.8732\n",
      "Epoch 50/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.3043 - acc: 0.8778 - val_loss: 0.3321 - val_acc: 0.8691\n",
      "Epoch 51/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.2995 - acc: 0.8819 - val_loss: 0.3392 - val_acc: 0.8650\n",
      "Epoch 52/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.3007 - acc: 0.8773 - val_loss: 0.3331 - val_acc: 0.8671\n",
      "Epoch 53/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.3032 - acc: 0.8824 - val_loss: 0.3335 - val_acc: 0.8671\n",
      "Epoch 54/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.2951 - acc: 0.8814 - val_loss: 0.3356 - val_acc: 0.8671\n",
      "Epoch 55/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.2961 - acc: 0.8819 - val_loss: 0.3199 - val_acc: 0.8855\n",
      "Epoch 56/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.2982 - acc: 0.8834 - val_loss: 0.3275 - val_acc: 0.8732\n",
      "Epoch 57/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.3007 - acc: 0.8804 - val_loss: 0.3232 - val_acc: 0.8773\n",
      "Epoch 58/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.2975 - acc: 0.8865 - val_loss: 0.3266 - val_acc: 0.8732\n",
      "Epoch 59/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.3023 - acc: 0.8747 - val_loss: 0.3152 - val_acc: 0.8875\n",
      "Epoch 60/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.2925 - acc: 0.8891 - val_loss: 0.3392 - val_acc: 0.8671\n",
      "Epoch 61/100\n",
      "1956/1956 [==============================] - 1s 368us/step - loss: 0.2957 - acc: 0.8829 - val_loss: 0.3244 - val_acc: 0.8773\n",
      "Epoch 62/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.2916 - acc: 0.8793 - val_loss: 0.3248 - val_acc: 0.8773\n",
      "Epoch 63/100\n",
      "1956/1956 [==============================] - 1s 369us/step - loss: 0.2901 - acc: 0.8865 - val_loss: 0.3226 - val_acc: 0.8814\n",
      "Epoch 64/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.2908 - acc: 0.8875 - val_loss: 0.3173 - val_acc: 0.8855\n",
      "Epoch 65/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.2827 - acc: 0.8901 - val_loss: 0.3280 - val_acc: 0.8793\n",
      "Epoch 66/100\n",
      "1956/1956 [==============================] - 1s 347us/step - loss: 0.2828 - acc: 0.8860 - val_loss: 0.3284 - val_acc: 0.8773\n",
      "Epoch 67/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.2895 - acc: 0.8855 - val_loss: 0.3146 - val_acc: 0.8875\n",
      "Epoch 68/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.2934 - acc: 0.8865 - val_loss: 0.3295 - val_acc: 0.8773\n",
      "Epoch 69/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.2830 - acc: 0.8845 - val_loss: 0.3329 - val_acc: 0.8671\n",
      "Epoch 70/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.2903 - acc: 0.8891 - val_loss: 0.3353 - val_acc: 0.8671\n",
      "Epoch 71/100\n",
      "1956/1956 [==============================] - 1s 343us/step - loss: 0.2808 - acc: 0.8891 - val_loss: 0.3311 - val_acc: 0.8732\n",
      "Epoch 72/100\n",
      "1956/1956 [==============================] - 1s 347us/step - loss: 0.2868 - acc: 0.8829 - val_loss: 0.3090 - val_acc: 0.8916\n",
      "Epoch 73/100\n",
      "1956/1956 [==============================] - 1s 342us/step - loss: 0.2808 - acc: 0.8891 - val_loss: 0.3185 - val_acc: 0.8834\n",
      "Epoch 74/100\n",
      "1956/1956 [==============================] - 1s 391us/step - loss: 0.2776 - acc: 0.8870 - val_loss: 0.3101 - val_acc: 0.8916\n",
      "Epoch 75/100\n",
      "1956/1956 [==============================] - 1s 379us/step - loss: 0.2837 - acc: 0.8865 - val_loss: 0.3113 - val_acc: 0.8896\n",
      "Epoch 76/100\n",
      "1956/1956 [==============================] - 1s 348us/step - loss: 0.2727 - acc: 0.8931 - val_loss: 0.3310 - val_acc: 0.8732\n",
      "Epoch 77/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.2870 - acc: 0.8875 - val_loss: 0.3182 - val_acc: 0.8855\n",
      "Epoch 78/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.2730 - acc: 0.8952 - val_loss: 0.3257 - val_acc: 0.8753\n",
      "Epoch 79/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.2751 - acc: 0.8916 - val_loss: 0.3015 - val_acc: 0.8916\n",
      "Epoch 80/100\n",
      "1956/1956 [==============================] - 1s 345us/step - loss: 0.2842 - acc: 0.8845 - val_loss: 0.3028 - val_acc: 0.8937\n",
      "Epoch 81/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.2742 - acc: 0.8942 - val_loss: 0.3084 - val_acc: 0.8916\n",
      "Epoch 82/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.2797 - acc: 0.8911 - val_loss: 0.3225 - val_acc: 0.8773\n",
      "Epoch 83/100\n",
      "1956/1956 [==============================] - 1s 403us/step - loss: 0.2692 - acc: 0.8947 - val_loss: 0.3147 - val_acc: 0.8855\n",
      "Epoch 84/100\n",
      "1956/1956 [==============================] - 1s 383us/step - loss: 0.2742 - acc: 0.8947 - val_loss: 0.3003 - val_acc: 0.8937\n",
      "Epoch 85/100\n",
      "1956/1956 [==============================] - 1s 369us/step - loss: 0.2711 - acc: 0.8916 - val_loss: 0.3329 - val_acc: 0.8753\n",
      "Epoch 86/100\n",
      "1956/1956 [==============================] - 1s 370us/step - loss: 0.2753 - acc: 0.8942 - val_loss: 0.3076 - val_acc: 0.8916\n",
      "Epoch 87/100\n",
      "1956/1956 [==============================] - 1s 371us/step - loss: 0.2703 - acc: 0.8937 - val_loss: 0.3110 - val_acc: 0.8875\n",
      "Epoch 88/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.2647 - acc: 0.9024 - val_loss: 0.3266 - val_acc: 0.8793\n",
      "Epoch 89/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.2631 - acc: 0.8911 - val_loss: 0.3159 - val_acc: 0.8834\n",
      "Epoch 90/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.2757 - acc: 0.8931 - val_loss: 0.3113 - val_acc: 0.8875\n",
      "Epoch 91/100\n",
      "1956/1956 [==============================] - 1s 376us/step - loss: 0.2754 - acc: 0.8901 - val_loss: 0.3180 - val_acc: 0.8834\n",
      "Epoch 92/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.2670 - acc: 0.8962 - val_loss: 0.3234 - val_acc: 0.8855\n",
      "Epoch 93/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.2659 - acc: 0.9003 - val_loss: 0.3084 - val_acc: 0.8875\n",
      "Epoch 94/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.2628 - acc: 0.8937 - val_loss: 0.2863 - val_acc: 0.8998\n",
      "Epoch 95/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.2579 - acc: 0.9013 - val_loss: 0.2943 - val_acc: 0.8978\n",
      "Epoch 96/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.2688 - acc: 0.8962 - val_loss: 0.2967 - val_acc: 0.8937\n",
      "Epoch 97/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.2654 - acc: 0.8972 - val_loss: 0.3075 - val_acc: 0.8875\n",
      "Epoch 98/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.2689 - acc: 0.8931 - val_loss: 0.2867 - val_acc: 0.9018\n",
      "Epoch 99/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.2596 - acc: 0.8993 - val_loss: 0.3039 - val_acc: 0.8875\n",
      "Epoch 100/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.2537 - acc: 0.9044 - val_loss: 0.2924 - val_acc: 0.8978\n",
      "Test subject 12, class Replace\n",
      "Train subject 12, class BothReleased\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1956 samples, validate on 489 samples\n",
      "Epoch 1/100\n",
      "1956/1956 [==============================] - 2s 1ms/step - loss: 0.7056 - acc: 0.4941 - val_loss: 0.6914 - val_acc: 0.5215\n",
      "Epoch 2/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.7019 - acc: 0.4888 - val_loss: 0.6915 - val_acc: 0.5235\n",
      "Epoch 3/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.6984 - acc: 0.4990 - val_loss: 0.6920 - val_acc: 0.5194\n",
      "Epoch 4/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.6984 - acc: 0.4877 - val_loss: 0.6928 - val_acc: 0.5419\n",
      "Epoch 5/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6967 - acc: 0.4969 - val_loss: 0.6936 - val_acc: 0.4867\n",
      "Epoch 6/100\n",
      "1956/1956 [==============================] - 1s 373us/step - loss: 0.6965 - acc: 0.5020 - val_loss: 0.6943 - val_acc: 0.4826\n",
      "Epoch 7/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.6962 - acc: 0.4954 - val_loss: 0.6946 - val_acc: 0.4847\n",
      "Epoch 8/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.6951 - acc: 0.4990 - val_loss: 0.6949 - val_acc: 0.4785\n",
      "Epoch 9/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.6950 - acc: 0.4995 - val_loss: 0.6949 - val_acc: 0.4785\n",
      "Epoch 10/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.6938 - acc: 0.5031 - val_loss: 0.6949 - val_acc: 0.4765\n",
      "Epoch 11/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.6955 - acc: 0.4939 - val_loss: 0.6952 - val_acc: 0.4765\n",
      "Epoch 12/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6945 - acc: 0.4903 - val_loss: 0.6953 - val_acc: 0.4765\n",
      "Epoch 13/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.6930 - acc: 0.5031 - val_loss: 0.6950 - val_acc: 0.4765\n",
      "Epoch 14/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.6935 - acc: 0.5138 - val_loss: 0.6951 - val_acc: 0.4765\n",
      "Epoch 15/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.6924 - acc: 0.5128 - val_loss: 0.6950 - val_acc: 0.4765\n",
      "Epoch 16/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6933 - acc: 0.5112 - val_loss: 0.6949 - val_acc: 0.4765\n",
      "Epoch 17/100\n",
      "1956/1956 [==============================] - 1s 371us/step - loss: 0.6926 - acc: 0.5097 - val_loss: 0.6948 - val_acc: 0.4765\n",
      "Epoch 18/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.6922 - acc: 0.5107 - val_loss: 0.6947 - val_acc: 0.4765\n",
      "Epoch 19/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.6940 - acc: 0.5066 - val_loss: 0.6945 - val_acc: 0.4765\n",
      "Epoch 20/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.6949 - acc: 0.4974 - val_loss: 0.6943 - val_acc: 0.4765\n",
      "Epoch 21/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.6930 - acc: 0.5072 - val_loss: 0.6943 - val_acc: 0.4765\n",
      "Epoch 22/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6914 - acc: 0.5199 - val_loss: 0.6944 - val_acc: 0.4765\n",
      "Epoch 23/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.6933 - acc: 0.5118 - val_loss: 0.6941 - val_acc: 0.4785\n",
      "Epoch 24/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.6920 - acc: 0.5266 - val_loss: 0.6943 - val_acc: 0.4765\n",
      "Epoch 25/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.6922 - acc: 0.5245 - val_loss: 0.6941 - val_acc: 0.4785\n",
      "Epoch 26/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.6918 - acc: 0.5235 - val_loss: 0.6943 - val_acc: 0.4765\n",
      "Epoch 27/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.6912 - acc: 0.5373 - val_loss: 0.6942 - val_acc: 0.4765\n",
      "Epoch 28/100\n",
      "1956/1956 [==============================] - 1s 383us/step - loss: 0.6938 - acc: 0.5092 - val_loss: 0.6943 - val_acc: 0.4765\n",
      "Epoch 29/100\n",
      "1956/1956 [==============================] - 1s 374us/step - loss: 0.6907 - acc: 0.5297 - val_loss: 0.6939 - val_acc: 0.4785\n",
      "Epoch 30/100\n",
      "1956/1956 [==============================] - 1s 377us/step - loss: 0.6929 - acc: 0.5133 - val_loss: 0.6937 - val_acc: 0.4806\n",
      "Epoch 31/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.6913 - acc: 0.5286 - val_loss: 0.6936 - val_acc: 0.4806\n",
      "Epoch 32/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.6927 - acc: 0.5281 - val_loss: 0.6933 - val_acc: 0.4806\n",
      "Epoch 33/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6913 - acc: 0.5184 - val_loss: 0.6928 - val_acc: 0.4806\n",
      "Epoch 34/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.6908 - acc: 0.5261 - val_loss: 0.6930 - val_acc: 0.4806\n",
      "Epoch 35/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6900 - acc: 0.5389 - val_loss: 0.6930 - val_acc: 0.4806\n",
      "Epoch 36/100\n",
      "1956/1956 [==============================] - 1s 378us/step - loss: 0.6925 - acc: 0.5281 - val_loss: 0.6927 - val_acc: 0.4806\n",
      "Epoch 37/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.6918 - acc: 0.5174 - val_loss: 0.6925 - val_acc: 0.4826\n",
      "Epoch 38/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.6930 - acc: 0.5072 - val_loss: 0.6923 - val_acc: 0.4847\n",
      "Epoch 39/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6910 - acc: 0.5194 - val_loss: 0.6924 - val_acc: 0.4847\n",
      "Epoch 40/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.6914 - acc: 0.5215 - val_loss: 0.6921 - val_acc: 0.4908\n",
      "Epoch 41/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.6900 - acc: 0.5291 - val_loss: 0.6916 - val_acc: 0.4928\n",
      "Epoch 42/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.6911 - acc: 0.5343 - val_loss: 0.6914 - val_acc: 0.4949\n",
      "Epoch 43/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6905 - acc: 0.5256 - val_loss: 0.6910 - val_acc: 0.4949\n",
      "Epoch 44/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6933 - acc: 0.4964 - val_loss: 0.6912 - val_acc: 0.4949\n",
      "Epoch 45/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.6890 - acc: 0.5363 - val_loss: 0.6910 - val_acc: 0.4949\n",
      "Epoch 46/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.6894 - acc: 0.5368 - val_loss: 0.6905 - val_acc: 0.4949\n",
      "Epoch 47/100\n",
      "1956/1956 [==============================] - 1s 367us/step - loss: 0.6898 - acc: 0.5276 - val_loss: 0.6905 - val_acc: 0.4949\n",
      "Epoch 48/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6883 - acc: 0.5516 - val_loss: 0.6902 - val_acc: 0.4949\n",
      "Epoch 49/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.6889 - acc: 0.5511 - val_loss: 0.6901 - val_acc: 0.4969\n",
      "Epoch 50/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.6915 - acc: 0.5194 - val_loss: 0.6900 - val_acc: 0.4969\n",
      "Epoch 51/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.6891 - acc: 0.5358 - val_loss: 0.6896 - val_acc: 0.5010\n",
      "Epoch 52/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.6874 - acc: 0.5486 - val_loss: 0.6895 - val_acc: 0.4969\n",
      "Epoch 53/100\n",
      "1956/1956 [==============================] - 1s 370us/step - loss: 0.6878 - acc: 0.5475 - val_loss: 0.6890 - val_acc: 0.5031\n",
      "Epoch 54/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.6893 - acc: 0.5435 - val_loss: 0.6887 - val_acc: 0.5010\n",
      "Epoch 55/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.6872 - acc: 0.5527 - val_loss: 0.6878 - val_acc: 0.5112\n",
      "Epoch 56/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.6887 - acc: 0.5527 - val_loss: 0.6879 - val_acc: 0.5112\n",
      "Epoch 57/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.6875 - acc: 0.5445 - val_loss: 0.6872 - val_acc: 0.5194\n",
      "Epoch 58/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.6896 - acc: 0.5312 - val_loss: 0.6869 - val_acc: 0.5194\n",
      "Epoch 59/100\n",
      "1956/1956 [==============================] - 1s 377us/step - loss: 0.6865 - acc: 0.5629 - val_loss: 0.6863 - val_acc: 0.5256\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.6860 - acc: 0.5603 - val_loss: 0.6859 - val_acc: 0.5317\n",
      "Epoch 61/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.6869 - acc: 0.5629 - val_loss: 0.6858 - val_acc: 0.5256\n",
      "Epoch 62/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6862 - acc: 0.5470 - val_loss: 0.6848 - val_acc: 0.5501\n",
      "Epoch 63/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.6876 - acc: 0.5368 - val_loss: 0.6848 - val_acc: 0.5481\n",
      "Epoch 64/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.6869 - acc: 0.5670 - val_loss: 0.6843 - val_acc: 0.5521\n",
      "Epoch 65/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.6886 - acc: 0.5527 - val_loss: 0.6839 - val_acc: 0.5542\n",
      "Epoch 66/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.6875 - acc: 0.5516 - val_loss: 0.6836 - val_acc: 0.5521\n",
      "Epoch 67/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.6856 - acc: 0.5567 - val_loss: 0.6831 - val_acc: 0.5562\n",
      "Epoch 68/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.6846 - acc: 0.5864 - val_loss: 0.6826 - val_acc: 0.5603\n",
      "Epoch 69/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.6855 - acc: 0.5608 - val_loss: 0.6823 - val_acc: 0.5583\n",
      "Epoch 70/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.6869 - acc: 0.5501 - val_loss: 0.6814 - val_acc: 0.5706\n",
      "Epoch 71/100\n",
      "1956/1956 [==============================] - ETA: 0s - loss: 0.6844 - acc: 0.568 - 1s 354us/step - loss: 0.6838 - acc: 0.5731 - val_loss: 0.6808 - val_acc: 0.5746\n",
      "Epoch 72/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6821 - acc: 0.5925 - val_loss: 0.6802 - val_acc: 0.5787\n",
      "Epoch 73/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.6810 - acc: 0.5884 - val_loss: 0.6795 - val_acc: 0.5869\n",
      "Epoch 74/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.6820 - acc: 0.5828 - val_loss: 0.6787 - val_acc: 0.5910\n",
      "Epoch 75/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.6805 - acc: 0.5890 - val_loss: 0.6779 - val_acc: 0.5951\n",
      "Epoch 76/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.6804 - acc: 0.6007 - val_loss: 0.6768 - val_acc: 0.6053\n",
      "Epoch 77/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.6821 - acc: 0.5844 - val_loss: 0.6761 - val_acc: 0.6074\n",
      "Epoch 78/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.6811 - acc: 0.5777 - val_loss: 0.6752 - val_acc: 0.6155\n",
      "Epoch 79/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6758 - acc: 0.6150 - val_loss: 0.6740 - val_acc: 0.6258\n",
      "Epoch 80/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.6767 - acc: 0.6109 - val_loss: 0.6730 - val_acc: 0.6319\n",
      "Epoch 81/100\n",
      "1956/1956 [==============================] - 1s 378us/step - loss: 0.6783 - acc: 0.6038 - val_loss: 0.6715 - val_acc: 0.6524\n",
      "Epoch 82/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.6781 - acc: 0.5895 - val_loss: 0.6704 - val_acc: 0.6626\n",
      "Epoch 83/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.6754 - acc: 0.6181 - val_loss: 0.6693 - val_acc: 0.6646\n",
      "Epoch 84/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.6732 - acc: 0.6227 - val_loss: 0.6681 - val_acc: 0.6646\n",
      "Epoch 85/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.6739 - acc: 0.6186 - val_loss: 0.6661 - val_acc: 0.6789\n",
      "Epoch 86/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.6689 - acc: 0.6288 - val_loss: 0.6636 - val_acc: 0.6892\n",
      "Epoch 87/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.6724 - acc: 0.6232 - val_loss: 0.6619 - val_acc: 0.6912\n",
      "Epoch 88/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.6716 - acc: 0.6247 - val_loss: 0.6600 - val_acc: 0.6953\n",
      "Epoch 89/100\n",
      "1956/1956 [==============================] - 1s 373us/step - loss: 0.6697 - acc: 0.6155 - val_loss: 0.6583 - val_acc: 0.7055\n",
      "Epoch 90/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.6664 - acc: 0.6299 - val_loss: 0.6558 - val_acc: 0.7239\n",
      "Epoch 91/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.6622 - acc: 0.6590 - val_loss: 0.6531 - val_acc: 0.7321\n",
      "Epoch 92/100\n",
      "1956/1956 [==============================] - 1s 346us/step - loss: 0.6625 - acc: 0.6513 - val_loss: 0.6508 - val_acc: 0.7301\n",
      "Epoch 93/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.6611 - acc: 0.6585 - val_loss: 0.6476 - val_acc: 0.7382\n",
      "Epoch 94/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.6583 - acc: 0.6447 - val_loss: 0.6447 - val_acc: 0.7382\n",
      "Epoch 95/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.6548 - acc: 0.6616 - val_loss: 0.6416 - val_acc: 0.7444\n",
      "Epoch 96/100\n",
      "1956/1956 [==============================] - 1s 341us/step - loss: 0.6491 - acc: 0.6805 - val_loss: 0.6378 - val_acc: 0.7485\n",
      "Epoch 97/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.6466 - acc: 0.6728 - val_loss: 0.6339 - val_acc: 0.7485\n",
      "Epoch 98/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.6463 - acc: 0.6748 - val_loss: 0.6286 - val_acc: 0.7587\n",
      "Epoch 99/100\n",
      "1956/1956 [==============================] - 1s 343us/step - loss: 0.6437 - acc: 0.6805 - val_loss: 0.6243 - val_acc: 0.7526\n",
      "Epoch 100/100\n",
      "1956/1956 [==============================] - 1s 340us/step - loss: 0.6379 - acc: 0.6938 - val_loss: 0.6193 - val_acc: 0.7587\n",
      "Train on 1956 samples, validate on 489 samples\n",
      "Epoch 1/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.6343 - acc: 0.6922 - val_loss: 0.6202 - val_acc: 0.7505\n",
      "Epoch 2/100\n",
      "1956/1956 [==============================] - 1s 344us/step - loss: 0.6329 - acc: 0.6820 - val_loss: 0.6148 - val_acc: 0.7546\n",
      "Epoch 3/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.6212 - acc: 0.7168 - val_loss: 0.6092 - val_acc: 0.7505\n",
      "Epoch 4/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.6203 - acc: 0.6948 - val_loss: 0.6024 - val_acc: 0.7526\n",
      "Epoch 5/100\n",
      "1956/1956 [==============================] - 1s 345us/step - loss: 0.6123 - acc: 0.7214 - val_loss: 0.5948 - val_acc: 0.7546\n",
      "Epoch 6/100\n",
      "1956/1956 [==============================] - 1s 341us/step - loss: 0.6040 - acc: 0.7127 - val_loss: 0.5873 - val_acc: 0.7669\n",
      "Epoch 7/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.5966 - acc: 0.7157 - val_loss: 0.5783 - val_acc: 0.7628\n",
      "Epoch 8/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.5850 - acc: 0.7408 - val_loss: 0.5686 - val_acc: 0.7628\n",
      "Epoch 9/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.5788 - acc: 0.7377 - val_loss: 0.5581 - val_acc: 0.7710\n",
      "Epoch 10/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.5679 - acc: 0.7403 - val_loss: 0.5481 - val_acc: 0.7751\n",
      "Epoch 11/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.5593 - acc: 0.7623 - val_loss: 0.5378 - val_acc: 0.7751\n",
      "Epoch 12/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.5480 - acc: 0.7495 - val_loss: 0.5272 - val_acc: 0.7771\n",
      "Epoch 13/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.5431 - acc: 0.7633 - val_loss: 0.5164 - val_acc: 0.7873\n",
      "Epoch 14/100\n",
      "1956/1956 [==============================] - 1s 372us/step - loss: 0.5320 - acc: 0.7628 - val_loss: 0.5041 - val_acc: 0.7873\n",
      "Epoch 15/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.5187 - acc: 0.7684 - val_loss: 0.4948 - val_acc: 0.7914\n",
      "Epoch 16/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.5103 - acc: 0.7740 - val_loss: 0.4850 - val_acc: 0.7894\n",
      "Epoch 17/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.4991 - acc: 0.7797 - val_loss: 0.4721 - val_acc: 0.8037\n",
      "Epoch 18/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.4894 - acc: 0.7812 - val_loss: 0.4654 - val_acc: 0.7975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.4812 - acc: 0.7791 - val_loss: 0.4529 - val_acc: 0.8139\n",
      "Epoch 20/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.4713 - acc: 0.7955 - val_loss: 0.4487 - val_acc: 0.7975\n",
      "Epoch 21/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.4576 - acc: 0.7950 - val_loss: 0.4354 - val_acc: 0.8200\n",
      "Epoch 22/100\n",
      "1956/1956 [==============================] - 1s 361us/step - loss: 0.4615 - acc: 0.7919 - val_loss: 0.4337 - val_acc: 0.8037\n",
      "Epoch 23/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.4560 - acc: 0.7909 - val_loss: 0.4219 - val_acc: 0.8200\n",
      "Epoch 24/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.4317 - acc: 0.8062 - val_loss: 0.4164 - val_acc: 0.8241\n",
      "Epoch 25/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.4330 - acc: 0.8078 - val_loss: 0.4082 - val_acc: 0.8303\n",
      "Epoch 26/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.4252 - acc: 0.8113 - val_loss: 0.4069 - val_acc: 0.8323\n",
      "Epoch 27/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.4307 - acc: 0.8154 - val_loss: 0.4000 - val_acc: 0.8323\n",
      "Epoch 28/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.4193 - acc: 0.8119 - val_loss: 0.3959 - val_acc: 0.8344\n",
      "Epoch 29/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.4205 - acc: 0.8221 - val_loss: 0.3914 - val_acc: 0.8405\n",
      "Epoch 30/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.4184 - acc: 0.8195 - val_loss: 0.3883 - val_acc: 0.8425\n",
      "Epoch 31/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.4135 - acc: 0.8231 - val_loss: 0.3829 - val_acc: 0.8466\n",
      "Epoch 32/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.4114 - acc: 0.8175 - val_loss: 0.3794 - val_acc: 0.8487\n",
      "Epoch 33/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.4052 - acc: 0.8267 - val_loss: 0.3797 - val_acc: 0.8446\n",
      "Epoch 34/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.3977 - acc: 0.8292 - val_loss: 0.3754 - val_acc: 0.8446\n",
      "Epoch 35/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.4051 - acc: 0.8226 - val_loss: 0.3687 - val_acc: 0.8589\n",
      "Epoch 36/100\n",
      "1956/1956 [==============================] - 1s 370us/step - loss: 0.3882 - acc: 0.8379 - val_loss: 0.3658 - val_acc: 0.8773\n",
      "Epoch 37/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.3935 - acc: 0.8287 - val_loss: 0.3662 - val_acc: 0.8507\n",
      "Epoch 38/100\n",
      "1956/1956 [==============================] - 1s 364us/step - loss: 0.3923 - acc: 0.8349 - val_loss: 0.3614 - val_acc: 0.8569\n",
      "Epoch 39/100\n",
      "1956/1956 [==============================] - 1s 372us/step - loss: 0.3915 - acc: 0.8354 - val_loss: 0.3582 - val_acc: 0.8732\n",
      "Epoch 40/100\n",
      "1956/1956 [==============================] - 1s 369us/step - loss: 0.3891 - acc: 0.8374 - val_loss: 0.3561 - val_acc: 0.8650\n",
      "Epoch 41/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.3833 - acc: 0.8379 - val_loss: 0.3544 - val_acc: 0.8609\n",
      "Epoch 42/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.3835 - acc: 0.8451 - val_loss: 0.3521 - val_acc: 0.8630\n",
      "Epoch 43/100\n",
      "1956/1956 [==============================] - 1s 381us/step - loss: 0.3746 - acc: 0.8482 - val_loss: 0.3489 - val_acc: 0.8712\n",
      "Epoch 44/100\n",
      "1956/1956 [==============================] - 1s 388us/step - loss: 0.3779 - acc: 0.8400 - val_loss: 0.3474 - val_acc: 0.8691\n",
      "Epoch 45/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.3710 - acc: 0.8471 - val_loss: 0.3471 - val_acc: 0.8650\n",
      "Epoch 46/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.3676 - acc: 0.8456 - val_loss: 0.3443 - val_acc: 0.8671\n",
      "Epoch 47/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.3731 - acc: 0.8502 - val_loss: 0.3421 - val_acc: 0.8732\n",
      "Epoch 48/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.3635 - acc: 0.8461 - val_loss: 0.3406 - val_acc: 0.8712\n",
      "Epoch 49/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.3622 - acc: 0.8528 - val_loss: 0.3395 - val_acc: 0.8712\n",
      "Epoch 50/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.3695 - acc: 0.8502 - val_loss: 0.3374 - val_acc: 0.8732\n",
      "Epoch 51/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.3671 - acc: 0.8512 - val_loss: 0.3360 - val_acc: 0.8753\n",
      "Epoch 52/100\n",
      "1956/1956 [==============================] - 1s 351us/step - loss: 0.3703 - acc: 0.8461 - val_loss: 0.3353 - val_acc: 0.8753\n",
      "Epoch 53/100\n",
      "1956/1956 [==============================] - 1s 346us/step - loss: 0.3588 - acc: 0.8579 - val_loss: 0.3342 - val_acc: 0.8753\n",
      "Epoch 54/100\n",
      "1956/1956 [==============================] - 1s 345us/step - loss: 0.3586 - acc: 0.8538 - val_loss: 0.3327 - val_acc: 0.8814\n",
      "Epoch 55/100\n",
      "1956/1956 [==============================] - 1s 343us/step - loss: 0.3556 - acc: 0.8574 - val_loss: 0.3320 - val_acc: 0.8814\n",
      "Epoch 56/100\n",
      "1956/1956 [==============================] - 1s 347us/step - loss: 0.3561 - acc: 0.8584 - val_loss: 0.3309 - val_acc: 0.8855\n",
      "Epoch 57/100\n",
      "1956/1956 [==============================] - 1s 346us/step - loss: 0.3570 - acc: 0.8548 - val_loss: 0.3303 - val_acc: 0.8875\n",
      "Epoch 58/100\n",
      "1956/1956 [==============================] - 1s 345us/step - loss: 0.3492 - acc: 0.8553 - val_loss: 0.3280 - val_acc: 0.8855\n",
      "Epoch 59/100\n",
      "1956/1956 [==============================] - 1s 345us/step - loss: 0.3458 - acc: 0.8640 - val_loss: 0.3269 - val_acc: 0.8896\n",
      "Epoch 60/100\n",
      "1956/1956 [==============================] - 1s 347us/step - loss: 0.3517 - acc: 0.8579 - val_loss: 0.3266 - val_acc: 0.8896\n",
      "Epoch 61/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.3547 - acc: 0.8574 - val_loss: 0.3253 - val_acc: 0.8896\n",
      "Epoch 62/100\n",
      "1956/1956 [==============================] - 1s 343us/step - loss: 0.3573 - acc: 0.8594 - val_loss: 0.3247 - val_acc: 0.8896\n",
      "Epoch 63/100\n",
      "1956/1956 [==============================] - 1s 345us/step - loss: 0.3456 - acc: 0.8609 - val_loss: 0.3236 - val_acc: 0.8896\n",
      "Epoch 64/100\n",
      "1956/1956 [==============================] - 1s 343us/step - loss: 0.3540 - acc: 0.8461 - val_loss: 0.3227 - val_acc: 0.8937\n",
      "Epoch 65/100\n",
      "1956/1956 [==============================] - 1s 348us/step - loss: 0.3410 - acc: 0.8630 - val_loss: 0.3216 - val_acc: 0.8896\n",
      "Epoch 66/100\n",
      "1956/1956 [==============================] - 1s 393us/step - loss: 0.3488 - acc: 0.8604 - val_loss: 0.3208 - val_acc: 0.8937\n",
      "Epoch 67/100\n",
      "1956/1956 [==============================] - 1s 373us/step - loss: 0.3353 - acc: 0.8650 - val_loss: 0.3199 - val_acc: 0.8937\n",
      "Epoch 68/100\n",
      "1956/1956 [==============================] - 1s 397us/step - loss: 0.3385 - acc: 0.8686 - val_loss: 0.3189 - val_acc: 0.8937\n",
      "Epoch 69/100\n",
      "1956/1956 [==============================] - 1s 382us/step - loss: 0.3479 - acc: 0.8635 - val_loss: 0.3182 - val_acc: 0.8916\n",
      "Epoch 70/100\n",
      "1956/1956 [==============================] - 1s 375us/step - loss: 0.3458 - acc: 0.8625 - val_loss: 0.3176 - val_acc: 0.8916\n",
      "Epoch 71/100\n",
      "1956/1956 [==============================] - 1s 402us/step - loss: 0.3331 - acc: 0.8645 - val_loss: 0.3173 - val_acc: 0.8916\n",
      "Epoch 72/100\n",
      "1956/1956 [==============================] - 1s 368us/step - loss: 0.3369 - acc: 0.8635 - val_loss: 0.3160 - val_acc: 0.8937\n",
      "Epoch 73/100\n",
      "1956/1956 [==============================] - 1s 451us/step - loss: 0.3413 - acc: 0.8645 - val_loss: 0.3152 - val_acc: 0.8937\n",
      "Epoch 74/100\n",
      "1956/1956 [==============================] - 1s 428us/step - loss: 0.3411 - acc: 0.8635 - val_loss: 0.3148 - val_acc: 0.8937\n",
      "Epoch 75/100\n",
      "1956/1956 [==============================] - 1s 394us/step - loss: 0.3450 - acc: 0.8655 - val_loss: 0.3145 - val_acc: 0.8937\n",
      "Epoch 76/100\n",
      "1956/1956 [==============================] - 1s 404us/step - loss: 0.3404 - acc: 0.8655 - val_loss: 0.3139 - val_acc: 0.8937\n",
      "Epoch 77/100\n",
      "1956/1956 [==============================] - 1s 431us/step - loss: 0.3344 - acc: 0.8671 - val_loss: 0.3134 - val_acc: 0.8937\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956/1956 [==============================] - 1s 418us/step - loss: 0.3345 - acc: 0.8625 - val_loss: 0.3132 - val_acc: 0.8937\n",
      "Epoch 79/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.3400 - acc: 0.8666 - val_loss: 0.3124 - val_acc: 0.8937\n",
      "Epoch 80/100\n",
      "1956/1956 [==============================] - 1s 390us/step - loss: 0.3424 - acc: 0.8701 - val_loss: 0.3123 - val_acc: 0.8916\n",
      "Epoch 81/100\n",
      "1956/1956 [==============================] - 1s 369us/step - loss: 0.3336 - acc: 0.8650 - val_loss: 0.3113 - val_acc: 0.8937\n",
      "Epoch 82/100\n",
      "1956/1956 [==============================] - 1s 404us/step - loss: 0.3261 - acc: 0.8691 - val_loss: 0.3102 - val_acc: 0.8937\n",
      "Epoch 83/100\n",
      "1956/1956 [==============================] - 1s 395us/step - loss: 0.3322 - acc: 0.8650 - val_loss: 0.3094 - val_acc: 0.8916\n",
      "Epoch 84/100\n",
      "1956/1956 [==============================] - 1s 377us/step - loss: 0.3322 - acc: 0.8645 - val_loss: 0.3088 - val_acc: 0.8978\n",
      "Epoch 85/100\n",
      "1956/1956 [==============================] - 1s 445us/step - loss: 0.3335 - acc: 0.8753 - val_loss: 0.3083 - val_acc: 0.8998\n",
      "Epoch 86/100\n",
      "1956/1956 [==============================] - 1s 385us/step - loss: 0.3343 - acc: 0.8655 - val_loss: 0.3086 - val_acc: 0.8978\n",
      "Epoch 87/100\n",
      "1956/1956 [==============================] - 1s 405us/step - loss: 0.3294 - acc: 0.8753 - val_loss: 0.3077 - val_acc: 0.8957\n",
      "Epoch 88/100\n",
      "1956/1956 [==============================] - 1s 427us/step - loss: 0.3393 - acc: 0.8620 - val_loss: 0.3078 - val_acc: 0.8957\n",
      "Epoch 89/100\n",
      "1956/1956 [==============================] - 1s 381us/step - loss: 0.3281 - acc: 0.8727 - val_loss: 0.3076 - val_acc: 0.8937\n",
      "Epoch 90/100\n",
      "1956/1956 [==============================] - 1s 399us/step - loss: 0.3253 - acc: 0.8691 - val_loss: 0.3063 - val_acc: 0.8957\n",
      "Epoch 91/100\n",
      "1956/1956 [==============================] - 1s 419us/step - loss: 0.3199 - acc: 0.8758 - val_loss: 0.3056 - val_acc: 0.8957\n",
      "Epoch 92/100\n",
      "1956/1956 [==============================] - 1s 375us/step - loss: 0.3240 - acc: 0.8773 - val_loss: 0.3049 - val_acc: 0.8957\n",
      "Epoch 93/100\n",
      "1956/1956 [==============================] - 1s 366us/step - loss: 0.3231 - acc: 0.8778 - val_loss: 0.3038 - val_acc: 0.9018\n",
      "Epoch 94/100\n",
      "1956/1956 [==============================] - 1s 401us/step - loss: 0.3168 - acc: 0.8758 - val_loss: 0.3031 - val_acc: 0.9018\n",
      "Epoch 95/100\n",
      "1956/1956 [==============================] - 1s 393us/step - loss: 0.3198 - acc: 0.8758 - val_loss: 0.3047 - val_acc: 0.8916\n",
      "Epoch 96/100\n",
      "1956/1956 [==============================] - 1s 382us/step - loss: 0.3304 - acc: 0.8686 - val_loss: 0.3046 - val_acc: 0.8916\n",
      "Epoch 97/100\n",
      "1956/1956 [==============================] - 1s 388us/step - loss: 0.3185 - acc: 0.8753 - val_loss: 0.3022 - val_acc: 0.8957\n",
      "Epoch 98/100\n",
      "1956/1956 [==============================] - 1s 423us/step - loss: 0.3168 - acc: 0.8753 - val_loss: 0.3020 - val_acc: 0.8957\n",
      "Epoch 99/100\n",
      "1956/1956 [==============================] - 1s 391us/step - loss: 0.3240 - acc: 0.8732 - val_loss: 0.3021 - val_acc: 0.8937\n",
      "Epoch 100/100\n",
      "1956/1956 [==============================] - 1s 368us/step - loss: 0.3167 - acc: 0.8717 - val_loss: 0.3013 - val_acc: 0.8937\n",
      "Test subject 12, class BothReleased\n",
      "HandStart AUC score = 0.600\n",
      "FirstDigitTouch AUC score = 0.785\n",
      "BothStartLoadPhase AUC score = 0.786\n",
      "LiftOff AUC score = 0.745\n",
      "Replace AUC score = 0.909\n",
      "BothReleased AUC score = 0.867\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "models = []\n",
    "for i in range(N_LABELS):\n",
    "    models.append(init_cnn(WINDOW_SIZE))\n",
    "\n",
    "for subject in TRAIN_SUBJECTS:\n",
    "    prediction_total = []\n",
    "    test_data_total = []\n",
    "    train_data_paths = glob(TRAIN_DATA_PATH % (subject))\n",
    "\n",
    "    \n",
    "    x_raw, y_raw = read_training_data(train_data_paths)\n",
    "    \n",
    "    x_raw, _ = preprocess_data(x_raw, WINDOW_SIZE, SUBSAMPLE)\n",
    "#     y_train = y_raw[::SUBSAMPLE]\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_raw, y_raw[::SUBSAMPLE], test_size=0.33, shuffle=False)\n",
    "    x_train, _, y_train, _ = train_test_split(x_train, y_train, test_size=0.0001, shuffle=True)\n",
    "    print(len(x_test), len(y_test))\n",
    "    \n",
    "    for i in range(N_LABELS):\n",
    "        model = init_cnn(WINDOW_SIZE)\n",
    "        \n",
    "        balanced_x_train, balanced_y_train = remove_imbalance(x_train, y_train[:,i])\n",
    "        \n",
    "\n",
    "            \n",
    "        train_labels = to_categorical(balanced_y_train, num_classes = None)\n",
    "                \n",
    "        print('Train subject %d, class %s' % (subject, COLUMNS[i]))\n",
    "        \n",
    "        x = [balanced_x_train[j::2] for j in range(2)]\n",
    "        y = [train_labels[j::2] for j in range(2)]\n",
    "        result = np.array([])\n",
    "        for sample_x, sample_y in zip(x, y):\n",
    "            model.fit(np.array(sample_x), np.array(sample_y), verbose=1, validation_split=0.2, epochs=EPOCHS)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         test_labels = to_categorical(y_test[:,i], num_classes = None)\n",
    "                \n",
    "        print('Test subject %d, class %s' % (subject, COLUMNS[i]))                \n",
    "        predictions = predict_on_sub(x_test, model, SPLIT_SIZE, BATCH_SIZE)\n",
    "        \n",
    "        test_data_total.append(y_test[:,i][1000::BATCH_SIZE])\n",
    "        prediction_total.append(predictions)\n",
    "        \n",
    "    multiple_metric_auc_score(prediction_total, test_data_total, True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HandStart AUC score = 0.600\n",
      "FirstDigitTouch AUC score = 0.785\n",
      "BothStartLoadPhase AUC score = 0.786\n",
      "LiftOff AUC score = 0.745\n",
      "Replace AUC score = 0.909\n",
      "BothReleased AUC score = 0.867\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "multiple_metric_auc_score(prediction_total, test_data_total, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
