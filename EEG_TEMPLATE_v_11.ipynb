{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, binarize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from scipy import signal\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# constants:\n",
    "SUBSAMPLE = 1  # scales the data by this factor\n",
    "COLUMNS = ['HandStart', 'FirstDigitTouch',\n",
    "        'BothStartLoadPhase', 'LiftOff',\n",
    "        'Replace', 'BothReleased']\n",
    "SUBJECTS = range(1, 13)\n",
    "N_LABELS = 6\n",
    "\n",
    "# Below are the paths to the data. Please pay attention to the % and * signs, these are needed in the loop.\n",
    "TRAIN_DATA_PATH = 'C:/Users/Sebastiaan/Desktop/Programming/MachineLearning/Datasets/EEG/train/subj%d_series*_data.csv'\n",
    "#The path below is for the test data used for a kaggle submission. This is not very relevant to our project.\n",
    "TEST_DATA_PATH = 'C:/Users/Sebastiaan/Desktop/Programming/MachineLearning/Datasets/EEG/test/subj%d_series*_data.csv'\n",
    "#TRAIN_DATA_PATH = 'C:/Users/bas/Documents/MachineLearning/train/subj%d_series*_data.csv' #path on my laptop\n",
    "#TEST_DATA_PATH =  'C:/Users/bas/Documents/MachineLearning/test/subj%d_series*_data.csv' \n",
    "\n",
    "SUBMISSION_FOLDER = 'C:/Users/Sebastiaan/Desktop/Programming/MachineLearning/'\n",
    "SUBMISSION_NAME = 'subbmision_vu_48_sub_pca_4.csv'\n",
    "\n",
    "PCA_COMPONENTS = 0.8\n",
    "CUTT_OFF_FREQUENCY = 2\n",
    "ORDER = 4\n",
    "SAMPLE_FREQUENCY = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_training_data(data_path):\n",
    "    data = pd.read_csv(data_path)\n",
    "    event_path = data_path.replace('_data', '_events')\n",
    "    labels = pd.read_csv(event_path)\n",
    "    clean_data = data.drop(['id'], axis = 1)\n",
    "    labels = labels.drop(['id'], axis = 1)\n",
    "    return clean_data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_test_data(data_path):\n",
    "    data = pd.read_csv(data_path)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scaler_transform(data, scaler):\n",
    "    if scaler == None:\n",
    "        scaler = StandardScaler()\n",
    "        return scaler.fit_transform(data), scaler\n",
    "    else:\n",
    "        return scaler.transform(data)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def butter_worth(data, cut_off, hz, order):\n",
    "    filtered_data = np.empty(np.shape(data))\n",
    "    wn = cut_off / (hz/2)\n",
    "    b, a = signal.butter(order, wn, analog = False)\n",
    "    for i in range(len(data[0])):\n",
    "        filtered_data[:,i] = signal.filtfilt(b, a, data[:,0], padlen = 150)    \n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pca_transform(data, n_components, pca_model):\n",
    "    if pca_model == None:\n",
    "        pca = PCA(n_components, whiten = True) \n",
    "        return pca.fit_transform(data), pca\n",
    "    else:\n",
    "        return pca_model.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_training_data(train_data_paths):\n",
    "    labels_raw = []\n",
    "    features_raw = []\n",
    "    for data_path in train_data_paths:\n",
    "        data, labels = prepare_training_data(data_path)\n",
    "        features_raw.append(data)\n",
    "        labels_raw.append(labels)\n",
    "    features_raw = pd.concat(features_raw)\n",
    "    labels_raw = pd.concat(labels_raw)\n",
    "    x_train = np.asarray(features_raw.astype(float))\n",
    "    y_train = np.asarray(labels_raw.astype(float))\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_test_data(test_data_paths):\n",
    "    test_features_raw = []\n",
    "    ids = []\n",
    "    for data_path in test_data_paths:\n",
    "        data = prepare_test_data(data_path)\n",
    "        test_features_raw.append(data)\n",
    "        ids.append(np.array(data['id']))\n",
    "    test_features_raw = pd.concat(test_features_raw)\n",
    "    ids = np.concatenate(ids)\n",
    "    test_features_raw = test_features_raw.drop(['id'], axis = 1)\n",
    "    x_test = np.asarray(test_features_raw.astype(float))\n",
    "    return x_test, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(x_train, y_train, model, subsample):\n",
    "    model.fit(x_train[::subsample,:], y_train[::subsample])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_prediction(x_test, model):\n",
    "    prediction = model.predict_proba(x_test)[:,1]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def metric_auc_score(predictions, y_test, with_plot):\n",
    "    scores = []\n",
    "    legend_text = []\n",
    "    for i in range(N_LABELS):\n",
    "        fpr, tpr, _  = roc_curve(y_test[:,i], predictions[:,i], 1)\n",
    "        scores.append(roc_auc_score(y_test[:,i], predictions[:,i]))\n",
    "        legend_text.append(COLUMNS[i]+' (area = %.3f)' % (scores[i]))\n",
    "        if with_plot == True:\n",
    "            plt.plot(tpr, fpr)\n",
    "    if with_plot == True:\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC curves')\n",
    "        plt.legend(legend_text)\n",
    "        plt.show()\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def all_auc_scores(prediction_total, test_data_total, subjects, with_plot):\n",
    "    scores = []\n",
    "    for subject in subjects:\n",
    "        scores.append(metric_auc_score(prediction_total[subject-1],\\\n",
    "                                       test_data_total[subject-1], with_plot))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_submission_file(name, ids_total, prediction_total, columns, path):\n",
    "    submission = pd.DataFrame(index = np.concatenate(ids_total), columns = columns,\n",
    "                              data = np.concatenate(prediction_total))\n",
    "    submission.to_csv(path+name, index_label = 'id', float_format = '%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train subject 1, class HandStart\n",
      "Train subject 1, class FirstDigitTouch\n",
      "Train subject 1, class BothStartLoadPhase\n",
      "Train subject 1, class LiftOff\n",
      "Train subject 1, class Replace\n",
      "Train subject 1, class BothReleased\n",
      "Train subject 2, class HandStart\n",
      "Train subject 2, class FirstDigitTouch\n",
      "Train subject 2, class BothStartLoadPhase\n",
      "Train subject 2, class LiftOff\n",
      "Train subject 2, class Replace\n",
      "Train subject 2, class BothReleased\n",
      "Train subject 3, class HandStart\n",
      "Train subject 3, class FirstDigitTouch\n",
      "Train subject 3, class BothStartLoadPhase\n",
      "Train subject 3, class LiftOff\n",
      "Train subject 3, class Replace\n",
      "Train subject 3, class BothReleased\n",
      "Train subject 4, class HandStart\n",
      "Train subject 4, class FirstDigitTouch\n",
      "Train subject 4, class BothStartLoadPhase\n",
      "Train subject 4, class LiftOff\n",
      "Train subject 4, class Replace\n",
      "Train subject 4, class BothReleased\n",
      "Train subject 5, class HandStart\n",
      "Train subject 5, class FirstDigitTouch\n",
      "Train subject 5, class BothStartLoadPhase\n",
      "Train subject 5, class LiftOff\n",
      "Train subject 5, class Replace\n",
      "Train subject 5, class BothReleased\n",
      "Train subject 6, class HandStart\n",
      "Train subject 6, class FirstDigitTouch\n",
      "Train subject 6, class BothStartLoadPhase\n",
      "Train subject 6, class LiftOff\n",
      "Train subject 6, class Replace\n",
      "Train subject 6, class BothReleased\n",
      "Train subject 7, class HandStart\n",
      "Train subject 7, class FirstDigitTouch\n",
      "Train subject 7, class BothStartLoadPhase\n",
      "Train subject 7, class LiftOff\n",
      "Train subject 7, class Replace\n",
      "Train subject 7, class BothReleased\n",
      "Train subject 8, class HandStart\n",
      "Train subject 8, class FirstDigitTouch\n",
      "Train subject 8, class BothStartLoadPhase\n",
      "Train subject 8, class LiftOff\n",
      "Train subject 8, class Replace\n",
      "Train subject 8, class BothReleased\n",
      "Train subject 9, class HandStart\n",
      "Train subject 9, class FirstDigitTouch\n",
      "Train subject 9, class BothStartLoadPhase\n",
      "Train subject 9, class LiftOff\n",
      "Train subject 9, class Replace\n",
      "Train subject 9, class BothReleased\n",
      "Train subject 10, class HandStart\n",
      "Train subject 10, class FirstDigitTouch\n",
      "Train subject 10, class BothStartLoadPhase\n",
      "Train subject 10, class LiftOff\n",
      "Train subject 10, class Replace\n",
      "Train subject 10, class BothReleased\n"
     ]
    }
   ],
   "source": [
    "prediction_total = []\n",
    "test_data_total = []\n",
    "ids_total = []\n",
    "for subject in SUBJECTS:\n",
    "    test_features_raw = []\n",
    "    train_data_paths = glob(TRAIN_DATA_PATH % (subject))\n",
    "    test_data_paths =  glob(TEST_DATA_PATH % (subject))\n",
    "  \n",
    "    x_train, y_train = read_training_data(train_data_paths)  \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2)\n",
    "    \n",
    "    #Below you can put preprocessing functions. You can make a decision in which method to use\n",
    "    #by commenting certain lines or not.\n",
    "#     x_train = butter_worth(x_train, CUTT_OFF_FREQUENCY, SAMPLE_FREQUENCY, ORDER)\n",
    "#     x_test = butter_worth(x_test, CUTT_OFF_FREQUENCY, SAMPLE_FREQUENCY, ORDER)\n",
    "#     x_train, pca_model = pca_transform(x_train, PCA_COMPONENTS, None)\n",
    "#     x_test = pca_transform(x_test, PCA_COMPONENTS, pca_model)\n",
    "    x_train, scaler = scaler_transform(x_train, None)\n",
    "    x_test = scaler_transform(x_test, scaler)\n",
    "    #############################################\n",
    "    \n",
    "    predictions = np.empty((x_test.shape[0],6))\n",
    "    #Below you define the model you want to use.\n",
    "    logreg = LogisticRegression()\n",
    "    for i in range(N_LABELS):\n",
    "        print('Train subject %d, class %s' % (subject, COLUMNS[i]))\n",
    "        model = train_model(x_train, y_train[:,i], logreg, SUBSAMPLE)\n",
    "        predictions[:,i] = make_prediction(x_test, model)\n",
    "    test_data_total.append(y_test)   \n",
    "    prediction_total.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = all_auc_scores(prediction_total, test_data_total, SUBJECTS, with_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Mean Columnwise AUC ROC Score: %.3f' % (np.mean(scores)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The script below is for kaggle submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################KAGGLE SUBMISSION CODE\n",
    "\n",
    "# prediction_total= []\n",
    "# ids_total = []\n",
    "# for subject in SUBJECTS:\n",
    "#     test_features_raw = []\n",
    "#     train_data_paths = glob(TRAIN_DATA_PATH % (subject))\n",
    "#     test_data_paths =  glob(TEST_DATA_PATH % (subject))\n",
    "  \n",
    "#     x_train, y_train = read_training_data(train_data_paths)\n",
    "#     x_test, ids = read_test_data(test_data_paths)\n",
    "#     ids_total.append(ids)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Below you can put preprocessing functions. You can make a decision in which method to use\n",
    "    #by commenting certain lines or not.#     x_train = butter_worth(x_train, CUTT_OFF_FREQUENCY, SAMPLE_FREQUENCY, ORDER)\n",
    "#     x_test = butter_worth(x_test, CUTT_OFF_FREQUENCY, SAMPLE_FREQUENCY, ORDER)\n",
    "#     x_train, pca_model = pca_transform(x_train, PCA_COMPONENTS, None)\n",
    "#     x_test = pca_transform(x_test, PCA_COMPONENTS, pca_model)\n",
    "#     x_train, scaler = scaler_transform(x_train, None)\n",
    "#     x_test = scaler_transform(x_test, scaler)\n",
    "#     #############################################\n",
    "    \n",
    "#     predictions = np.empty((x_test.shape[0],6))\n",
    "#     #Below you define the model you want to use.\n",
    "#     logreg = LogisticRegression()\n",
    "#     for i in range(N_LABELS):\n",
    "#         print('Train subject %d, class %s' % (subject, COLUMNS[i]))\n",
    "#         model = train_model(x_train, y_train[:,i], logreg, SUBSAMPLE)\n",
    "#         predictions[:,i] = make_prediction(x_test, model)\n",
    "        \n",
    "#     prediction_total.append(predictions)\n",
    "\n",
    "# make_submission_file(SUBMISSION_NAME, ids_total, prediction_total, COLUMNS, SUBMISSION_FOLDER)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
