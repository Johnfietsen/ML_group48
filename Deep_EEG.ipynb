{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sebastiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam, Adadelta, SGD\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPool2D, Dropout, Flatten, Conv1D, GlobalAveragePooling1D, Convolution1D\n",
    "from keras.layers.convolutional import MaxPooling2D, MaxPooling1D\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.utils import class_weight\n",
    "from scipy import signal\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants:\n",
    "SUBSAMPLE = 100  # scales the data by this factor\n",
    "COLUMNS = ['HandStart', 'FirstDigitTouch',\n",
    "        'BothStartLoadPhase', 'LiftOff',\n",
    "        'Replace', 'BothReleased']\n",
    "SUBJECTS = range(1, 2)\n",
    "N_LABELS = 6\n",
    "\n",
    "# Below are the paths to the data. Please pay attention to the % and * signs, these are needed in the loop.\n",
    "TRAIN_DATA_PATH = 'C:/Users/Sebastiaan/Desktop/Programming/MachineLearning/Datasets/EEG/train/subj%d_series*_data.csv'\n",
    "# TRAIN_DATA_PATH = 'C:/Users/bas/Documents/MachineLearning/train/subj%d_series*_data.csv'\n",
    "\n",
    "EPOCHS = 5\n",
    "WINDOW_SIZE = 1000\n",
    "SPLIT_SIZE = 50\n",
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_data(data_path):\n",
    "    data = pd.read_csv(data_path)\n",
    "    event_path = data_path.replace('_data', '_events')\n",
    "    labels = pd.read_csv(event_path)\n",
    "    clean_data = data.drop(['id'], axis = 1)\n",
    "    labels = labels.drop(['id'], axis = 1)\n",
    "    return clean_data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(x_raw, WINDOW_SIZE, subsample):\n",
    "    x_raw, scaler = scaler_transform(x_raw[::subsample], None)\n",
    "    x_raw = image_mappping(x_raw, WINDOW_SIZE)\n",
    "    return x_raw, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaler_transform(data, scaler):\n",
    "    if scaler == None:\n",
    "        scaler = Normalizer()\n",
    "        return scaler.fit_transform(data), scaler\n",
    "    else:\n",
    "        return scaler.transform(data)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_training_data(train_data_paths):\n",
    "    labels_raw = []\n",
    "    features_raw = []\n",
    "    for data_path in train_data_paths:\n",
    "        data, labels = prepare_training_data(data_path)\n",
    "        features_raw.append(data)\n",
    "        labels_raw.append(labels)\n",
    "    features_raw = pd.concat(features_raw)\n",
    "    labels_raw = pd.concat(labels_raw)\n",
    "    x_train = np.asarray(features_raw.astype(float))\n",
    "    y_train = np.asarray(labels_raw.astype(float))\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_auc_score(predictions, y_test, with_plot):\n",
    "    scores = []\n",
    "    legend_text = []\n",
    "    for i in range(N_LABELS):\n",
    "        fpr, tpr, _  = roc_curve(y_test[:,i], predictions[:,i], 1)\n",
    "        scores.append(roc_auc_score(y_test[:,i], predictions[:,i]))\n",
    "        legend_text.append(COLUMNS[i]+' (area = %.3f)' % (scores[i]))\n",
    "        if with_plot == True:\n",
    "            plt.plot(fpr, tpr)\n",
    "    if with_plot == True:\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curves')\n",
    "        plt.legend(legend_text)\n",
    "        plt.show()\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_metric_auc_score(prediction_total, test_data_total, with_plot):\n",
    "    legend_text = []\n",
    "    counter = 0\n",
    "    for prediction, test_data in zip(prediction_total, test_data_total):\n",
    "        fpr, tpr, _  = roc_curve(test_data, predictions, pos_label=1)\n",
    "        score = roc_auc_score(test_data, predictions)\n",
    "        legend_text.append(COLUMNS[counter]+' (area = %.3f)' % (score))\n",
    "        print(COLUMNS[counter]+' AUC score = %.3f' % (score))\n",
    "        if with_plot == True:\n",
    "            plt.plot(fpr, tpr)\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.title('ROC Curves')\n",
    "            plt.legend(legend_text)\n",
    "            counter += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_metric_auc_score(predictions, y_test, with_plot, i):\n",
    "    fpr, tpr, _  = roc_curve(y_test, predictions, 1)\n",
    "    score = roc_auc_score(y_test, predictions)\n",
    "    print(COLUMNS[i]+' AUC score = %.3f' % (score))\n",
    "    if with_plot == True:\n",
    "        plt.plot(fpr, tpr)\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curves')\n",
    "        plt.show()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_auc_scores(prediction_total, test_data_total, subjects, with_plot):\n",
    "    scores = []\n",
    "    for subject in subjects:\n",
    "        score = metric_auc_score(prediction_total[subject-1],\n",
    "                                 test_data_total[subject-1], with_plot)\n",
    "        scores.append(score)\n",
    "        print('Mean AUC Score of Subject %d: %.3f' % \\\n",
    "              (subject, np.mean(score)))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_mappping(x_train, WINDOW_SIZE):\n",
    "    result = []\n",
    "    empty_matrix = np.zeros(np.shape(x_train[0:WINDOW_SIZE]))\n",
    "    for i in range(len(x_train)):\n",
    "        if i-WINDOW_SIZE < 0:\n",
    "            result.append(empty_matrix)\n",
    "        else:\n",
    "            result.append(x_train[i-WINDOW_SIZE:i])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_and_shuffle(labels):\n",
    "    when_task = np.where(labels == 1)\n",
    "    when_no_task = np.where(labels == 0)\n",
    "    when_no_task = when_no_task[0][0:len(when_task[0])]\n",
    "    indices = np.concatenate([when_task[0], when_no_task])\n",
    "    np.random.shuffle(indices)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_set(indices, x_train, y_train):\n",
    "    balance_x = []\n",
    "    balance_y = []\n",
    "    for index in indices:\n",
    "        balance_x.append(x_train[index])\n",
    "        balance_y.append(y_train[index])\n",
    "    return np.array(balance_x), np.array(balance_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_imbalance(x_train, y_train):\n",
    "    indices = resample_and_shuffle(y_train)\n",
    "    balanced_x_train, balanced_y_train = balance_set(indices, x_train, y_train)\n",
    "    return balanced_x_train, balanced_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_sub(x_test, model, split_size, batch_size):\n",
    "    split_size = int(len(x_test) / split_size)\n",
    "    sub_x_test = x_test[1000::batch_size]\n",
    "    batch = []\n",
    "    predictions = np.array([])\n",
    "    for i in range(len(sub_x_test)):\n",
    "        batch.append(sub_x_test[i])\n",
    "        if i+1 == len(sub_x_test):\n",
    "            return np.concatenate([predictions, model.predict(np.array(batch))[:,1]])\n",
    "        elif (i+1) % split_size == 0:\n",
    "            predictions = np.concatenate([predictions, model.predict(np.array(batch))[:,1]])\n",
    "            batch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_cnn(window):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(nb_filter=16, filter_length=3, activation='relu', input_shape=(window, 32)))\n",
    "    model.add(MaxPooling1D(3,2))\n",
    "    model.add(Conv1D(nb_filter=32, filter_length=3, activation='relu'))\n",
    "    model.add(Conv1D(nb_filter=64, filter_length=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(3,2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "#     model.summary()\n",
    "    \n",
    "    optimizer = SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)\n",
    "#     optimizer = Adam(lr=1e-6)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\sebastiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "Train subject 1, class HandStart\n",
      "Train on 507 samples, validate on 127 samples\n",
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "prediction_total = []\n",
    "test_data_total = []\n",
    "ids_total = []\n",
    "for subject in SUBJECTS:\n",
    "    test_features_raw = []\n",
    "    train_data_paths = glob(TRAIN_DATA_PATH % (subject))\n",
    "\n",
    "    \n",
    "    x_raw, y_raw = read_training_data(train_data_paths)\n",
    "    \n",
    "    x_raw, _ = preprocess_data(x_raw, WINDOW_SIZE, SUBSAMPLE)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_raw, y_raw[::SUBSAMPLE], test_size=0.2)\n",
    "\n",
    "    \n",
    "    for i in range(N_LABELS):\n",
    "        model = init_cnn(WINDOW_SIZE)\n",
    "        \n",
    "        balanced_x_train, balanced_y_train = remove_imbalance(x_train, y_train[:,i])\n",
    "        \n",
    "        train_labels = to_categorical(balanced_y_train, num_classes = None)\n",
    "        test_labels = to_categorical(y_test[:,i], num_classes = None)\n",
    "                \n",
    "        print('Train subject %d, class %s' % (subject, COLUMNS[i]))        \n",
    "        model.fit(balanced_x_train, train_labels, verbose=1, validation_split=0.2, epochs=1)\n",
    "        \n",
    "        predictions = predict_on_sub(x_test, model, SPLIT_SIZE, BATCH_SIZE)\n",
    "        \n",
    "        test_data_total.append(y_test[:,i][1000::BATCH_SIZE])\n",
    "        prediction_total.append(predictions)\n",
    "        \n",
    "    multiple_metric_auc_score(prediction_total, test_data_total, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_metric_auc_score(prediction_total, test_data_total, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
