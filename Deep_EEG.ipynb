{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sebastiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam, Adadelta, SGD\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPool2D, Dropout, Flatten, Conv1D, GlobalAveragePooling1D, Convolution1D\n",
    "from keras.layers.convolutional import MaxPooling2D, MaxPooling1D\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.utils import class_weight\n",
    "from scipy import signal\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants:\n",
    "SUBSAMPLE = 100  # scales the data by this factor\n",
    "COLUMNS = ['HandStart', 'FirstDigitTouch',\n",
    "        'BothStartLoadPhase', 'LiftOff',\n",
    "        'Replace', 'BothReleased']\n",
    "SUBJECTS = range(1, 2)\n",
    "N_LABELS = 6\n",
    "\n",
    "# Below are the paths to the data. Please pay attention to the % and * signs, these are needed in the loop.\n",
    "TRAIN_DATA_PATH = 'C:/Users/Sebastiaan/Desktop/Programming/MachineLearning/Datasets/EEG/train/subj%d_series*_data.csv'\n",
    "EPOCHS = 5\n",
    "WINDOW_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_data(data_path):\n",
    "    data = pd.read_csv(data_path)\n",
    "    event_path = data_path.replace('_data', '_events')\n",
    "    labels = pd.read_csv(event_path)\n",
    "    clean_data = data.drop(['id'], axis = 1)\n",
    "    labels = labels.drop(['id'], axis = 1)\n",
    "    return clean_data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test_data(data_path):\n",
    "    data = pd.read_csv(data_path)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaler_transform(data, scaler):\n",
    "    if scaler == None:\n",
    "        scaler = Normalizer()\n",
    "        return scaler.fit_transform(data), scaler\n",
    "    else:\n",
    "        return scaler.transform(data)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_training_data(train_data_paths):\n",
    "    labels_raw = []\n",
    "    features_raw = []\n",
    "    for data_path in train_data_paths:\n",
    "        data, labels = prepare_training_data(data_path)\n",
    "        features_raw.append(data)\n",
    "        labels_raw.append(labels)\n",
    "    features_raw = pd.concat(features_raw)\n",
    "    labels_raw = pd.concat(labels_raw)\n",
    "    x_train = np.asarray(features_raw.astype(float))\n",
    "    y_train = np.asarray(labels_raw.astype(float))\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_auc_score(predictions, y_test, with_plot):\n",
    "    scores = []\n",
    "    legend_text = []\n",
    "    for i in range(N_LABELS):\n",
    "        fpr, tpr, _  = roc_curve(y_test[:,i], predictions[:,i], 1)\n",
    "        scores.append(roc_auc_score(y_test[:,i], predictions[:,i]))\n",
    "        legend_text.append(COLUMNS[i]+' (area = %.3f)' % (scores[i]))\n",
    "        if with_plot == True:\n",
    "            plt.plot(fpr, tpr)\n",
    "    if with_plot == True:\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curves')\n",
    "        plt.legend(legend_text)\n",
    "        plt.show()\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_metric_auc_score(predictions, y_test, with_plot, i):\n",
    "    fpr, tpr, _  = roc_curve(y_test, predictions, 1)\n",
    "    score = roc_auc_score(y_test, predictions)\n",
    "    print(COLUMNS[i]+' AUC score = %.3f' % (score))\n",
    "    if with_plot == True:\n",
    "        plt.plot(fpr, tpr)\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curves')\n",
    "        plt.show()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_auc_scores(prediction_total, test_data_total, subjects, with_plot):\n",
    "    scores = []\n",
    "    for subject in subjects:\n",
    "        score = metric_auc_score(prediction_total[subject-1],\n",
    "                                 test_data_total[subject-1], with_plot)\n",
    "        scores.append(score)\n",
    "        print('Mean AUC Score of Subject %d: %.3f' % \\\n",
    "              (subject, np.mean(score)))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_mappping(x_train, WINDOW_SIZE):\n",
    "    result = []\n",
    "    empty_matrix = np.zeros(np.shape(x_train[0:WINDOW_SIZE]))\n",
    "    for i in range(len(x_train)):\n",
    "        if i-WINDOW_SIZE < 0:\n",
    "            result.append(empty_matrix)\n",
    "        else:\n",
    "            result.append(x_train[i-WINDOW_SIZE:i])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_and_shuffle(labels):\n",
    "    when_task = np.where(labels == 1)\n",
    "    when_no_task = np.where(labels == 0)\n",
    "    when_no_task = when_no_task[0][0:len(when_task[0])]\n",
    "    indices = np.concatenate([when_task[0], when_no_task])\n",
    "    np.random.shuffle(indices)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_set(indices, x_train, y_train):\n",
    "    balance_x = []\n",
    "    balance_y = []\n",
    "    for index in indices:\n",
    "        balance_x.append(x_train[index])\n",
    "        balance_y.append(y_train[index])\n",
    "    return np.array(balance_x), np.array(balance_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_sub(x_test, model, split_size, sub_size):\n",
    "    split_size = int(len(x_test) / split_size)\n",
    "    sub_x_test = x_test[1000::sub_size]\n",
    "    batch = []\n",
    "    predictions = np.array([])\n",
    "    for i in range(len(sub_x_test)):\n",
    "        batch.append(sub_x_test[i])\n",
    "        if i+1 == len(sub_x_test):\n",
    "            return np.concatenate([predictions, model.predict(np.array(batch))[:,1]])\n",
    "        elif (i+1) % split_size == 0:\n",
    "            predictions = np.concatenate([predictions, model.predict(np.array(batch))[:,1]])\n",
    "            batch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_cnn(window):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(nb_filter=16, filter_length=3, activation='relu', input_shape=(window, 32)))\n",
    "    model.add(MaxPooling1D(3,2))\n",
    "    model.add(Conv1D(nb_filter=32, filter_length=3, activation='relu'))\n",
    "    model.add(Conv1D(nb_filter=64, filter_length=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(3,2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "#     model.summary()\n",
    "    \n",
    "    optimizer = SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)\n",
    "#     optimizer = Adam(lr=1e-6)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\sebastiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "Train subject 1, class HandStart\n",
      "Train on 49715 samples, validate on 12429 samples\n",
      "Epoch 1/50\n",
      "49715/49715 [==============================] - 245s 5ms/step - loss: 0.6829 - acc: 0.5575 - val_loss: 0.6542 - val_acc: 0.6315\n",
      "Epoch 2/50\n",
      "49715/49715 [==============================] - 245s 5ms/step - loss: 0.6178 - acc: 0.6567 - val_loss: 0.5811 - val_acc: 0.6924\n",
      "Epoch 3/50\n",
      "49715/49715 [==============================] - 245s 5ms/step - loss: 0.5606 - acc: 0.6995 - val_loss: 0.5590 - val_acc: 0.7044\n",
      "Epoch 4/50\n",
      "49715/49715 [==============================] - 243s 5ms/step - loss: 0.5321 - acc: 0.7179 - val_loss: 0.5513 - val_acc: 0.7112\n",
      "Epoch 5/50\n",
      "49715/49715 [==============================] - 256s 5ms/step - loss: 0.5098 - acc: 0.7304 - val_loss: 0.5610 - val_acc: 0.7190\n",
      "Epoch 6/50\n",
      "49715/49715 [==============================] - 237s 5ms/step - loss: 0.4908 - acc: 0.7438 - val_loss: 0.5177 - val_acc: 0.7357\n",
      "Epoch 7/50\n",
      "49715/49715 [==============================] - 253s 5ms/step - loss: 0.4716 - acc: 0.7600 - val_loss: 0.5169 - val_acc: 0.7367\n",
      "Epoch 8/50\n",
      "49715/49715 [==============================] - 222s 4ms/step - loss: 0.4548 - acc: 0.7716 - val_loss: 0.4840 - val_acc: 0.7577\n",
      "Epoch 9/50\n",
      "49715/49715 [==============================] - 261s 5ms/step - loss: 0.4386 - acc: 0.7851 - val_loss: 0.4861 - val_acc: 0.7623\n",
      "Epoch 10/50\n",
      "49715/49715 [==============================] - 223s 4ms/step - loss: 0.4233 - acc: 0.7958 - val_loss: 0.4238 - val_acc: 0.7913\n",
      "Epoch 11/50\n",
      "49715/49715 [==============================] - 230s 5ms/step - loss: 0.4064 - acc: 0.8055 - val_loss: 0.4847 - val_acc: 0.7678\n",
      "Epoch 12/50\n",
      "49715/49715 [==============================] - 240s 5ms/step - loss: 0.3917 - acc: 0.8161 - val_loss: 0.3989 - val_acc: 0.8091\n",
      "Epoch 13/50\n",
      "49715/49715 [==============================] - 232s 5ms/step - loss: 0.3774 - acc: 0.8235 - val_loss: 0.4275 - val_acc: 0.7984\n",
      "Epoch 14/50\n",
      "49715/49715 [==============================] - 241s 5ms/step - loss: 0.3622 - acc: 0.8336 - val_loss: 0.3543 - val_acc: 0.8399\n",
      "Epoch 15/50\n",
      "49715/49715 [==============================] - 226s 5ms/step - loss: 0.3492 - acc: 0.8407 - val_loss: 0.4232 - val_acc: 0.8029\n",
      "Epoch 16/50\n",
      "49715/49715 [==============================] - 237s 5ms/step - loss: 0.3361 - acc: 0.8490 - val_loss: 0.4044 - val_acc: 0.8185\n",
      "Epoch 17/50\n",
      "49715/49715 [==============================] - 218s 4ms/step - loss: 0.3236 - acc: 0.8582 - val_loss: 0.3855 - val_acc: 0.8273\n",
      "Epoch 18/50\n",
      "49715/49715 [==============================] - 219s 4ms/step - loss: 0.3121 - acc: 0.8648 - val_loss: 0.3257 - val_acc: 0.8575\n",
      "Epoch 19/50\n",
      "49715/49715 [==============================] - 212s 4ms/step - loss: 0.2995 - acc: 0.8731 - val_loss: 0.3670 - val_acc: 0.8386\n",
      "Epoch 20/50\n",
      "49715/49715 [==============================] - 226s 5ms/step - loss: 0.2908 - acc: 0.8779 - val_loss: 0.3315 - val_acc: 0.8566\n",
      "Epoch 21/50\n",
      "49715/49715 [==============================] - 203s 4ms/step - loss: 0.2789 - acc: 0.8842 - val_loss: 0.3301 - val_acc: 0.8589\n",
      "Epoch 22/50\n",
      "49715/49715 [==============================] - 217s 4ms/step - loss: 0.2710 - acc: 0.8899 - val_loss: 0.2974 - val_acc: 0.8773\n",
      "Epoch 23/50\n",
      "49715/49715 [==============================] - 219s 4ms/step - loss: 0.2606 - acc: 0.8946 - val_loss: 0.3372 - val_acc: 0.8601\n",
      "Epoch 24/50\n",
      "49715/49715 [==============================] - 208s 4ms/step - loss: 0.2543 - acc: 0.8955 - val_loss: 0.2400 - val_acc: 0.9059\n",
      "Epoch 25/50\n",
      "49715/49715 [==============================] - 220s 4ms/step - loss: 0.2468 - acc: 0.9009 - val_loss: 0.2907 - val_acc: 0.8808\n",
      "Epoch 26/50\n",
      "49715/49715 [==============================] - 208s 4ms/step - loss: 0.2400 - acc: 0.9044 - val_loss: 0.2723 - val_acc: 0.8895\n",
      "Epoch 27/50\n",
      "49715/49715 [==============================] - 228s 5ms/step - loss: 0.2319 - acc: 0.9085 - val_loss: 0.2338 - val_acc: 0.9092\n",
      "Epoch 28/50\n",
      "49715/49715 [==============================] - 225s 5ms/step - loss: 0.2252 - acc: 0.9127 - val_loss: 0.2814 - val_acc: 0.8885\n",
      "Epoch 29/50\n",
      "49715/49715 [==============================] - 206s 4ms/step - loss: 0.2197 - acc: 0.9139 - val_loss: 0.2153 - val_acc: 0.9179\n",
      "Epoch 30/50\n",
      "49715/49715 [==============================] - 207s 4ms/step - loss: 0.2129 - acc: 0.9176 - val_loss: 0.1934 - val_acc: 0.9263\n",
      "Epoch 31/50\n",
      "49715/49715 [==============================] - 224s 5ms/step - loss: 0.2065 - acc: 0.9189 - val_loss: 0.3112 - val_acc: 0.8792\n",
      "Epoch 32/50\n",
      "49715/49715 [==============================] - 222s 4ms/step - loss: 0.2029 - acc: 0.9226 - val_loss: 0.2047 - val_acc: 0.9236\n",
      "Epoch 33/50\n",
      "49715/49715 [==============================] - 220s 4ms/step - loss: 0.1977 - acc: 0.9247 - val_loss: 0.2355 - val_acc: 0.9092\n",
      "Epoch 34/50\n",
      "49715/49715 [==============================] - 224s 5ms/step - loss: 0.1936 - acc: 0.9267 - val_loss: 0.2141 - val_acc: 0.9199\n",
      "Epoch 35/50\n",
      "49715/49715 [==============================] - 214s 4ms/step - loss: 0.1902 - acc: 0.9266 - val_loss: 0.2358 - val_acc: 0.9117\n",
      "Epoch 36/50\n",
      "49715/49715 [==============================] - 207s 4ms/step - loss: 0.1863 - acc: 0.9296 - val_loss: 0.2060 - val_acc: 0.9235\n",
      "Epoch 37/50\n",
      "49715/49715 [==============================] - 210s 4ms/step - loss: 0.1811 - acc: 0.9315 - val_loss: 0.1856 - val_acc: 0.9329\n",
      "Epoch 38/50\n",
      "49715/49715 [==============================] - 209s 4ms/step - loss: 0.1775 - acc: 0.9338 - val_loss: 0.2165 - val_acc: 0.9186\n",
      "Epoch 39/50\n",
      "49715/49715 [==============================] - 215s 4ms/step - loss: 0.1754 - acc: 0.9358 - val_loss: 0.1717 - val_acc: 0.9355\n",
      "Epoch 40/50\n",
      "49715/49715 [==============================] - 215s 4ms/step - loss: 0.1718 - acc: 0.9355 - val_loss: 0.2346 - val_acc: 0.9117\n",
      "Epoch 41/50\n",
      "49715/49715 [==============================] - 207s 4ms/step - loss: 0.1671 - acc: 0.9387 - val_loss: 0.2337 - val_acc: 0.9116\n",
      "Epoch 42/50\n",
      "49715/49715 [==============================] - 199s 4ms/step - loss: 0.1657 - acc: 0.9405 - val_loss: 0.2037 - val_acc: 0.9236\n",
      "Epoch 43/50\n",
      "49715/49715 [==============================] - 213s 4ms/step - loss: 0.1643 - acc: 0.9398 - val_loss: 0.1690 - val_acc: 0.9380\n",
      "Epoch 44/50\n",
      "49715/49715 [==============================] - 221s 4ms/step - loss: 0.1593 - acc: 0.9426 - val_loss: 0.1604 - val_acc: 0.9403\n",
      "Epoch 45/50\n",
      "49715/49715 [==============================] - 218s 4ms/step - loss: 0.1569 - acc: 0.9429 - val_loss: 0.1485 - val_acc: 0.9469\n",
      "Epoch 46/50\n",
      "49715/49715 [==============================] - 194s 4ms/step - loss: 0.1541 - acc: 0.9445 - val_loss: 0.1750 - val_acc: 0.9356\n",
      "Epoch 47/50\n",
      "49715/49715 [==============================] - 205s 4ms/step - loss: 0.1527 - acc: 0.9451 - val_loss: 0.1361 - val_acc: 0.9531\n",
      "Epoch 48/50\n",
      "49715/49715 [==============================] - 219s 4ms/step - loss: 0.1492 - acc: 0.9462 - val_loss: 0.1631 - val_acc: 0.9398\n",
      "Epoch 49/50\n",
      "49715/49715 [==============================] - 208s 4ms/step - loss: 0.1469 - acc: 0.9464 - val_loss: 0.1671 - val_acc: 0.9395\n",
      "Epoch 50/50\n",
      "49715/49715 [==============================] - 214s 4ms/step - loss: 0.1450 - acc: 0.9471 - val_loss: 0.1711 - val_acc: 0.9379\n",
      "HandStart AUC score = 0.988\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAIABJREFUeJzt3XmYXGWZ9/HvL510FrIBCVsWEiAIAVnbiDIzwAASUEEZhDDgiIPmlVdERX1FcVwYvUZxR0GIyCBcyqpA0CiDiKBISOKwB5CQsDRbAoRAkk56qfv945wuik5VdXXSp6qr6/e5rrpS59RT59ynk5y7n+U8jyICMzMzgCG1DsDMzAYOJwUzM8tzUjAzszwnBTMzy3NSMDOzPCcFMzPLc1IwM7M8JwWre5KelNQmaa2kFyRdLml0jzLvlPRHSa9LWiPpZkkze5QZK+kHkp5Oj7Us3Z5Q4rySdJakhyStk9Qq6TpJb83yes2y5KRgg8V7I2I0sB+wP/CF7g8kvQP4H+AmYCdgOnA/cJekXdIyzcBtwF7AbGAs8E7gZWBWiXP+EPgkcBawDbA7cCPw7r4GL2loX79jlomI8Muvun4BTwJHFGyfD/y2YPvPwEVFvvc74Ir0/UeAF4HRFZ5zBtAFzCpT5k/ARwq2TwP+UrAdwMeBx4EVwMXAd3oc4ybg7PT9TsCvgFVp+bMKys0ClgCvpdfxvVr/vfhVny/XFGxQkTQZOBpYlm6PIvmN/7oixa8FjkzfHwH8PiLWVniqw4HWiFi0ZRHzPuDtwEzgl8BJkgQgaWvgXcDVkoYAN5PUcCal5/+UpKPS4/wQ+GFEjAV2Ta/NrM+cFGywuFHS68AzwErgK+n+bUj+nT9f5DvPA939BduWKFNKX8uX8l8R8UpEtJHUaAL4x/SzE4C7I+I54G3AxIg4LyLaI2I58FNgTlq2A9hN0oSIWBsRC/shNmtATgo2WLwvIsYAhwJ78MbNfjWQA3Ys8p0dgZfS9y+XKFNKX8uX8kz3m4gI4Grg5HTXvwK/SN/vDOwk6dXuF/BFYPv089NJ+jQelbRY0nv6ITZrQE4KNqhExB3A5cB30u11wN3AB4oUP5GkcxngD8BRkraq8FS3AZMltZQpsw4YVbC9Q7GQe2xfBZwgaWeSZqVfpfufAVZExPiC15iIOAYgIh6PiJOB7YBvAdf34VrM8pwUbDD6AXCkpP3S7XOAD6XDR8dI2lrS14F3AF9Ly1xJcuP9laQ9JA2RtK2kL0o6pucJIuJx4CLgKkmHSmqWNELSHEnnpMXuA46XNErSbiS/zZcVEfeSdCRfCtwSEa+mHy0CXpP0eUkjJTVJ2lvS2wAknSppYkTkgO7vdPXlh2YGTgo2CEXEKuAK4D/S7b8ARwHHk/QDPEUybPUf0ps7EbGRpLP5UeBWklE8i0iaoe4pcaqzgB8DF5LciJ8A3k/SIQzwfaCdZDTQz3mjKag3V6Wx/LLgmrqA95IMuV1B0ux1KTAuLTIbeFjSWpJO5zkRsaHC85nlKWnGNDMzc03BzMwKOCmYmVmek4KZmeU5KZiZWV7dTcI1YcKEmDZtWq3DMDOrK3/7299eioiJvZWru6Qwbdo0lixZUuswzMzqiqSnKinn5iMzM8tzUjAzszwnBTMzy3NSMDOzPCcFMzPLyywpSLpM0kpJD5X4XJIuSBdHf0DSAVnFYmZmlcmypnA5ycyNpRxNss7tDGAu8JMMYzEzswpk9pxCRNwpaVqZIseRLJoewEJJ4yXtGBH9scThgFI4E21HV3B/66s82LqG1evbUQ3jMrP6cvie27PvlPGZnqOWD69NomApQqA13bdJUpA0l6Q2wdSpU6sS3Oa69+nVXLnwKR5/cS2jmpsAuGfFKyXLy1nBzCq03dgRgzopFLsdFl3cISLmAfMAWlpaBtwCEH9Y+iKX3PkEi59c/ab9e08ay1bNQzlw563ZelQze08aC0BHV45/nDGRXSeOZuKY4bUI2cysqFomhVZgSsH2ZOC5GsWyWSKC7//hcS647XEA9p86nq5c8NVj92L/KeORqwFmVmdqmRTmA2dKuppkgfI19dafcPlfn8wnhLOP3J2zDp9R44jMzLZMZklB0lXAocAESa3AV4BhABFxMbAAOAZYBqwHPpxVLFn4/UPP87WblwIw/8yD2Wdytu18ZmbVkOXoo5N7+TyAj2d1/ix98up7uem+pKVr1rRtnBDMbNCou6mza+3D/72I2x9bBcBFpxzAMW/dscYRmZn1HyeFCn3r94/ykz89kd++65x/ZtL4kTWMyMys/zkpVODI793B4yvXAjB7rx34yrEz2XGcE4KZDT5OCr047+al+YRw5+cOY+q2o2ockZlZdjxLahkX3r6My+5aAcAfP3OIE4KZDXpOCmVcuySZheOiUw5gl4mjaxyNmVn2nBTK2NiRY9utmj3CyMwahpNCCVcufIoXXtvAATtvXetQzMyqxkmhiNc2dPAfNyZrA532zmm1DcbMrIqcFIr4/UMvAHDI7hM5eLcJNY7GzKx6nBSKuPiO5CG1C+bsX+NIzMyqy0mhiOWr1gEwbtSwGkdiZlZdTgo9PPTsGgAO32O7GkdiZlZ9Tgo93HDvswDM/addahyJmVn1OSkUeGHNBn72l+QJ5gM9FNXMGpCTQoHPXnc/AB84cDJDm/yjMbPG4ztfgadfWQ/A+SfsU+NIzMxqw0kh1dmV4+lX1rPflPFIqnU4ZmY14aSQWtPWAcDbp29T40jMzGrHSSH15MtJ09GUbTw9tpk1LieF1E33JUNR99ppbI0jMTOrHSeF1LJ0dbWZTgpm1sCcFFJ/feJl9thhDMOHNtU6FDOzmnFSANZt7ARg3EjPdWRmjc1JAfjtA88DcNReO9Q4EjOz2nJSAB5f+ToA799/Uo0jMTOrLScFYMGDyaI64z1Vtpk1OCcF4IXXNgD4SWYza3gNnxQigq5c8K6Z29c6FDOzmmv4pLCxMwfAvlPG1zgSM7Paa/ik8PcXk05mtxyZmWWcFCTNlvSYpGWSziny+VRJt0u6V9IDko7JMp5iLrljOQAHTvWiOmZmmSUFSU3AhcDRwEzgZEkzexT7EnBtROwPzAEuyiqeUlavbwdglmdHNTPLtKYwC1gWEcsjoh24GjiuR5kAuicbGgc8l2E8Rb2yrp0Jo5s98sjMjGyTwiTgmYLt1nRfoa8Cp0pqBRYAnyh2IElzJS2RtGTVqlX9GuSKl9YxaWtPl21mBtkmhWK/ekeP7ZOByyNiMnAMcKWkTWKKiHkR0RIRLRMnTuy3ALtywcbOHNO3dVIwM4Nsk0IrMKVgezKbNg+dDlwLEBF3AyOACRnG9CbPrm4DYNqErap1SjOzAS3LpLAYmCFpuqRmko7k+T3KPA0cDiBpT5Kk0L/tQ2V0z3m0+/ZjqnVKM7MBLbOkEBGdwJnALcAjJKOMHpZ0nqRj02KfAT4q6X7gKuC0iOjZxJSZRU++Ani1NTOzbkOzPHhELCDpQC7c9+WC90uBg7OMoZzu5qOdt3XzkZkZNPgTzWvaOmodgpnZgNLQSeG1DZ1ss1VzrcMwMxswGjop5HLBW9zJbGaW19BJ4bEXX2dUc1OtwzAzGzAaNilEBO2dOZqHNuyPwMxsEw17R2xNRx5NGj+yxpGYmQ0cDZsUVq3dCMCeO/oZBTOzbg2bFDa0dwGwk2sKZmZ5DZsUVry8DoARwxr2R2BmtomK7oiSmiXtlnUw1dT94NqO41xTMDPr1mtSkPRu4EHg1nR7P0k3ZB1Y1la+lvQpTBwzvMaRmJkNHJXUFM4D3g68ChAR9wF1X2sY1pQs99A0xCuumZl1qyQpdETEqz32VW0m06y0d+YYN3JYrcMwMxtQKpkl9RFJJwJDJE0HPgkszDas7C1/aV2+tmBmZolKagpnAgcCOeDXwAaSxFDXxo4cxmttnbUOw8xsQKmkpnBURHwe+Hz3DknHkySIuvXS6xvZbbvRtQ7DzGxAqaSm8KUi+87t70Cq7fk1G+jM5WodhpnZgFKypiDpKGA2MEnS9wo+GkvSlFTXRgwbwoTRHo5qZlaoXPPRSuAhkj6Ehwv2vw6ck2VQ1fD3F9cy0/MemZm9ScmkEBH3AvdK+kVEbKhiTFXT1tFV6xDMzAaUSjqaJ0n6BjATGNG9MyJ2zyyqjK3bmIw6mrrNqBpHYmY2sFTS0Xw58N+AgKOBa4GrM4wpc8tWrgVgB897ZGb2JpUkhVERcQtARDwREV8CDss2rGw99uLrAOw0bkQvJc3MGkslzUcbJQl4QtLHgGeB7bINqzpmbD+m1iGYmQ0olSSFTwOjgbOAbwDjgH/PMqisrXgpWUthzIhKLt/MrHH0eleMiHvSt68DHwSQNDnLoLI2clgTANtu1VzjSMzMBpayfQqS3ibpfZImpNt7SbqCOp8Qb2NnF01DxNAmr7pmZlao5F1R0n8BvwBOAX4v6VzgduB+oG6HowJs7MgxfKgTgplZT+Waj44D9o2INknbAM+l249VJ7TsbOjsclIwMyui3J1xQ0S0AUTEK8CjgyEhALS15xjV7E5mM7Oeyt0Zd5HUPT22gGkF20TE8b0dXNJs4IdAE3BpRHyzSJkTga+SrOZ2f0T8a+Xhb562jk5GNjdlfRozs7pTLin8S4/tH/flwJKagAuBI4FWYLGk+RGxtKDMDOALwMERsVpSVZ5/WN/elR+BZGZmbyg3Id5tW3jsWcCyiFgOIOlqkn6KpQVlPgpcGBGr03Ou3MJzVqStvcs1BTOzIrLsbZ0EPFOw3ZruK7Q7sLukuyQtTJubNiFprqQlkpasWrVqiwNr6+hilJOCmdkmskwKKrIvemwPBWYAhwInA5dKGr/JlyLmRURLRLRMnDhxiwNb3+6kYGZWTMVJQVJflylrBaYUbE8mGdbas8xNEdERESuAx0iSRKba2rsY4T4FM7NN9JoUJM2S9CDweLq9r6QfVXDsxcAMSdMlNQNzgPk9ytxIOuNq+tT07sDyPsS/Wdx8ZGZWXCU1hQuA9wAvA0TE/VQwdXZEdAJnArcAjwDXRsTDks6TdGxa7BbgZUlLSZ6W/lxEvNz3y+ib9e2dfk7BzKyISu6MQyLiqWT27LyK1rGMiAXAgh77vlzwPoCz01dV5HLBho6ch6SamRVRSVJ4RtIsINJnDz4B/D3bsLKzoTPJZx6Sama2qUqaj84g+U1+KvAicFC6ry6tb0+SgvsUzMw2VUlNoTMi5mQeSZW0pUnBzUdmZpuqpKawWNICSR+SVPfrV7Z1uPnIzKyUXpNCROwKfB04EHhQ0o2S6rbm4OYjM7PSKnp4LSL+GhFnAQcAr5EsvlOX1rd3AjBymIekmpn1VMnDa6MlnSLpZmARsAp4Z+aRZWRDh2sKZmalVPLr8kPAzcD5EfHnjOPJXHfzkfsUzMw2VUlS2CUicplHUiXrPfrIzKykkklB0ncj4jPAryT1nN20opXXBqI2dzSbmZVUrqZwTfpnn1ZcG+ja8n0K7mg2M+up3Mpri9K3e0bEmxKDpDOBLV2ZrSa6m4+GD81yKQkzs/pUyZ3x34vsO72/A6mWtvZORg5rYsiQYmsAmZk1tnJ9CieRrIEwXdKvCz4aA7yadWBZ8VoKZmallWtYX0SyhsJk4MKC/a8D92YZVJbWt3d5OKqZWQnl+hRWACuAP1QvnOy1tXd5OKqZWQnlmo/uiIhDJK0GCoekimR9nG0yjy4D69vdfGRmVkq55qPuJTcnVCOQamnrcPORmVkpJUcfFTzFPAVoiogu4B3A/wG2qkJsmXDzkZlZaZUMSb2RZCnOXYErgD2BX2YaVYbWt3f6wTUzsxIqSQq5iOgAjgd+EBGfACZlG1Z2NnTk3HxkZlZCJUmhU9IHgA8Cv0n3DcsupGwlNQUnBTOzYip9ovkwkqmzl0uaDlyVbVjZWbfRfQpmZqX02rgeEQ9JOgvYTdIewLKI+Eb2ofW/jq4c7V05JE9xYWZWTK9JQdI/AlcCz5I8o7CDpA9GxF1ZB9ffumdIHdbkpGBmVkwlw3C+DxwTEUsBJO1JkiRasgwsC11dyTN4227VXONIzMwGpkr6FJq7EwJARDwC1OVdtTOXJIWmJk+bbWZWTCU1hf+VdAlJ7QDgFOp0QrzOXPI83lBPm21mVlQlSeFjwFnA/yPpU7gT+FGWQWWlozOtKTgpmJkVVTYpSHorsCtwQ0ScX52QsrN2YycAG9IOZzMze7OSjeuSvkgyxcUpwK2Siq3AVldykdQUdhw3ssaRmJkNTOV6XE8B9omIDwBvA87o68ElzZb0mKRlks4pU+4ESSEp0xFN7V1Jn4KHpJqZFVcuKWyMiHUAEbGql7KbkNREsmLb0cBM4GRJM4uUG0PSZ3FPX46/OTo6k6TQ7NFHZmZFletT2KVgbWYBuxau1RwRx/dy7FkkTz8vB5B0NXAcsLRHuf8Ezgc+25fAN8dLa9sBGDbUScHMrJhySeFfemz/uI/HngQ8U7DdCry9sICk/YEpEfEbSSWTgqS5wFyAqVOn9jGMN3QPOhriaS7MzIoqt0bzbVt47GJ33vyynpKGkDwtfVpvB4qIecA8gJaWluileEkd6cNr40bW7SSvZmaZyrIdpZVk1bZuk4HnCrbHAHsDf5L0JHAQMD/Lzmb3KZiZlZfl3XExMEPSdEnNwBxgfveHEbEmIiZExLSImAYsBI6NiCVZBdTRPfpoqJuPzMyKqTgpSBrelwNHRCdwJnAL8AhwbUQ8LOk8Scf2Lcz+8dyaDYCfaDYzK6WSqbNnAT8DxgFTJe0LfCRdlrOsiFgALOix78slyh5aScBbYuyI5HJHeJEdM7OiKqkpXAC8B3gZICLuJ1mJre50z5I6bIj7FMzMiqnk7jgkIp7qsa8uJw/qynlCPDOzciqZJfWZtAkp0qeUPwH8PduwstHd0eyps83MiqukpnAGcDYwFXiRZOhon+dBGgi6coEEQ5wUzMyK6rWmEBErSYaT1r0X0tFHZmZWXCWjj35KwZPI3SJibiYRZagrF8RmPw9tZjb4VdKn8IeC9yOA9/PmOY3qxpAhYvuxfXrcwsysoVTSfHRN4bakK4FbM4soQ51dOYYP9TMKZmalbM6A/enAzv0dSDV05MIjj8zMyqikT2E1b/QpDAFeAUquojaQtXfmGOpV18zMSiqbFCQJ2Bd4Nt2Vi6jfrtpnV7fR2VW34ZuZZa5s81GaAG6IiK70Vdd31AljhtORy9U6DDOzAauSPoVFkg7IPJIqyOWCiaM9+sjMrJSSzUeShqbTX/8D8FFJTwDrSFZUi4iou0TRlQvPe2RmVka5PoVFwAHA+6oUS+a6Irw+s5lZGeWSggAi4okqxZK5iGCol+I0MyupXFKYKOnsUh9GxPcyiCdTXblguJfiNDMrqVxSaAJGk9YYBoOu8AypZmbllEsKz0fEeVWLpApyucDPrpmZlVaugX3Q3T49+sjMrLxySeHwqkVRJc+8sj6/JKeZmW2qZFKIiFeqGUg1TBw7nLUbO2sdhpnZgNVQ4zMjYIdxI2sdhpnZgNVQSaEzl/PU2WZmZTRUUsjl8BPNZmZlNFRSSEYf1ToKM7OBq6FukV3hIalmZuU0VFLI5TwhnplZOQ2VFFxTMDMrr6GSwqvrO2odgpnZgJZpUpA0W9JjkpZJOqfI52dLWirpAUm3Sdo5y3iam4awps2JwcyslMySgqQm4ELgaGAmcLKkmT2K3Qu0RMQ+wPXA+VnFkwQFO4wbkekpzMzqWZY1hVnAsohYHhHtwNXAcYUFIuL2iFifbi4EJmcYDxFBkzuazcxKyjIpTAKeKdhuTfeVcjrwuwzjIRd+eM3MrJxy6ylsqWJ336JTlEo6FWgBDinx+VxgLsDUqVM3O6CuXODBR2ZmpWVZU2gFphRsTwae61lI0hHAucCxEbGx2IEiYl5EtEREy8SJEzcrmIgkH3nlNTOz0rJMCouBGZKmS2oG5gDzCwtI2h+4hCQhrMwwFrqXUXDzkZlZaZklhYjoBM4EbgEeAa6NiIclnSfp2LTYt0nWgb5O0n2S5pc43BbLddcUnBPMzErKsk+BiFgALOix78sF74/I8vyFuldck2sKZmYlNcwTzWlFwdNcmJmV0TBJwc1HZma9a5ik0N6ZA0BFR8qamRk0UFJo6+h6059mZraphkkK3R3NnvvIzKy0hkkK3X0KnvvIzKy0hkkK3TUFjz4yMyutYZJCztNcmJn1qmGSQlcy+MjNR2ZmZTRQUnDzkZlZb5wUzMwsr2GSwsbO5PmEpoa5YjOzvmuYW2RnWlPY0JGrcSRmZgNXwySFbuNHDat1CGZmA1bDJIV8n4JHH5mZldRwSWFok5OCmVkpDZcUmoY0zCWbmfVZw9whO918ZGbWq4ZJCn5Owcysdw2TFF5auxFwUjAzK6dhksKo5ibAy3GamZXTMEkhnSSVEcOaahuImdkA1jBJoXvqbPczm5mV1jBJobumMMRZwcyspIZJCq4pmJn1roGSQvKnawpmZqU1UFJwTcHMrDcNkxTSioJrCmZmZTROUuiuKdQ4DjOzgaxhkkIu7VRwTcHMrLTGSQruaDYz61WmSUHSbEmPSVom6Zwinw+XdE36+T2SpmUVS76juWHSoJlZ32V2i5TUBFwIHA3MBE6WNLNHsdOB1RGxG/B94FtZxeOH18zMepfl782zgGURsTwi2oGrgeN6lDkO+Hn6/nrgcCmbu3bgjmYzs95kmRQmAc8UbLem+4qWiYhOYA2wbc8DSZoraYmkJatWrdqsYKZPGM2737qjp842MytjaIbHLnb3jc0oQ0TMA+YBtLS0bPJ5JY6cuT1Hztx+c75qZtYwsqwptAJTCrYnA8+VKiNpKDAOeCXDmMzMrIwsk8JiYIak6ZKagTnA/B5l5gMfSt+fAPwxup8yMzOzqsus+SgiOiWdCdwCNAGXRcTDks4DlkTEfOBnwJWSlpHUEOZkFY+ZmfUuyz4FImIBsKDHvi8XvN8AfCDLGMzMrHJ+lMvMzPKcFMzMLM9JwczM8pwUzMwsT/U2AlTSKuCpzfz6BOClfgynHviaG4OvuTFsyTXvHBETeytUd0lhS0haEhEttY6jmnzNjcHX3Biqcc1uPjIzszwnBTMzy2u0pDCv1gHUgK+5MfiaG0Pm19xQfQpmZlZeo9UUzMysDCcFMzPLG5RJQdJsSY9JWibpnCKfD5d0Tfr5PZKmVT/K/lXBNZ8taamkByTdJmnnWsTZn3q75oJyJ0gKSXU/fLGSa5Z0Yvp3/bCkX1Y7xv5Wwb/tqZJul3Rv+u/7mFrE2V8kXSZppaSHSnwuSRekP48HJB3QrwFExKB6kUzT/QSwC9AM3A/M7FHm/wIXp+/nANfUOu4qXPNhwKj0/RmNcM1puTHAncBCoKXWcVfh73kGcC+wdbq9Xa3jrsI1zwPOSN/PBJ6sddxbeM3/BBwAPFTi82OA35GsXHkQcE9/nn8w1hRmAcsiYnlEtANXA8f1KHMc8PP0/fXA4ZLqefHmXq85Im6PiPXp5kKSlfDqWSV/zwD/CZwPbKhmcBmp5Jo/ClwYEasBImJllWPsb5VccwBj0/fj2HSFx7oSEXdSfgXK44ArIrEQGC9px/46/2BMCpOAZwq2W9N9RctERCewBti2KtFlo5JrLnQ6yW8a9azXa5a0PzAlIn5TzcAyVMnf8+7A7pLukrRQ0uyqRZeNSq75q8CpklpJ1m/5RHVCq5m+/n/vk0wX2amRYr/x9xx3W0mZelLx9Ug6FWgBDsk0ouyVvWZJQ4DvA6dVK6AqqOTveShJE9KhJLXBP0vaOyJezTi2rFRyzScDl0fEdyW9g2Q1x70jIpd9eDWR6f1rMNYUWoEpBduT2bQ6mS8jaShJlbNcdW2gq+SakXQEcC5wbERsrFJsWentmscAewN/kvQkSdvr/DrvbK703/ZNEdERESuAx0iSRL2q5JpPB64FiIi7gREkE8cNVhX9f99cgzEpLAZmSJouqZmkI3l+jzLzgQ+l708A/hhpD06d6vWa06aUS0gSQr23M0Mv1xwRayJiQkRMi4hpJP0ox0bEktqE2y8q+bd9I8mgAiRNIGlOWl7VKPtXJdf8NHA4gKQ9SZLCqqpGWV3zgX9LRyEdBKyJiOf76+CDrvkoIjolnQncQjJy4bKIeFjSecCSiJgP/IykirmMpIYwp3YRb7kKr/nbwGjgurRP/emIOLZmQW+hCq95UKnwmm8B3iVpKdAFfC4iXq5d1Fumwmv+DPBTSZ8maUY5rZ5/yZN0FUnz34S0n+QrwDCAiLiYpN/kGGAZsB74cL+ev45/dmZm1s8GY/ORmZltJicFMzPLc1IwM7M8JwUzM8tzUjAzszwnBRtwJHVJuq/gNa1M2WmlZpPs4zn/lM7EeX86RcRbNuMYH5P0b+n70yTtVPDZpZJm9nOciyXtV8F3PiVp1Jae2xqDk4INRG0RsV/B68kqnfeUiNiXZLLEb/f1yxFxcURckW6eBuxU8NlHImJpv0T5RpwXUVmcnwKcFKwiTgpWF9IawZ8l/W/6emeRMntJWpTWLh6QNCPdf2rB/kskNfVyujuB3dLvHp7O0/9gOs/98HT/N/XG+hTfSfd9VdJnJZ1AMr/UL9Jzjkx/w2+RdIak8wtiPk3SjzYzzrspmAhN0k8kLVGyjsLX0n1nkSSn2yXdnu57l6S705/jdZJG93IeayBOCjYQjSxoOroh3bcSODIiDgBOAi4o8r2PAT+MiP1Ibsqt6bQHJwEHp/u7gFN6Of97gQcljQAuB06KiLeSzABwhqRtgPcDe0XEPsDXC78cEdcDS0h+o98vItoKPr4eOL5g+yTgms2MczbJtBbdzo2IFmAf4BBJ+0TEBSTz4hwWEYelU198CTgi/VkuAc7u5TzWQAbdNBc2KLSlN8ZCw4Afp23oXSRz+vR0N3CupMnAryPicUmHAwcCi9PpPUaSJJhifiGpDXiSZPrltwArIuLv6ec/Bz4O/JhkfYZLJf0WqHhq7ohYJWl5OmfN4+k57kqP25c4tyKZ9qFw1a0TJc0l+X+9I8mCMw/0+O5B6f670vM0k/zczAAnBasfnwZeBPYlqeFusmhORPxS0j3Au4FbJH2EZJrhn0fEFyoT9lsvAAABc0lEQVQ4xymFE+ZJKrrGRjofzyySSdjmAGcC/9yHa7kGOBF4FLghIkLJHbriOElWIPsmcCFwvKTpwGeBt0XEakmXk0wM15OAWyPi5D7Eaw3EzUdWL8YBz6dz5H+Q5LfkN5G0C7A8bTKZT9KMchtwgqTt0jLbqPL1qR8FpknaLd3+IHBH2gY/LiIWkHTiFhsB9DrJ9N3F/Bp4H8k6ANek+/oUZ0R0kDQDHZQ2PY0F1gFrJG0PHF0iloXAwd3XJGmUpGK1LmtQTgpWLy4CPiRpIUnT0boiZU4CHpJ0H7AHyZKFS0lunv8j6QHgVpKmlV5FxAaSGSivk/QgkAMuJrnB/iY93h0ktZieLgcu7u5o7nHc1cBSYOeIWJTu63OcaV/Fd4HPRsT9JGszPwxcRtIk1W0e8DtJt0fEKpKRUVel51lI8rMyAzxLqpmZFXBNwczM8pwUzMwsz0nBzMzynBTMzCzPScHMzPKcFMzMLM9JwczM8v4/mzg4XWrbkt0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-e786a9f0ab73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_cnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWINDOW_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresample_and_shuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbalance_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "prediction_total = []\n",
    "test_data_total = []\n",
    "ids_total = []\n",
    "for subject in SUBJECTS:\n",
    "    test_features_raw = []\n",
    "    train_data_paths = glob(TRAIN_DATA_PATH % (subject))\n",
    "\n",
    "  \n",
    "    \n",
    "    x_raw, y_raw = read_training_data(train_data_paths)\n",
    "    \n",
    "    x_raw, scaler = scaler_transform(x_raw, None)\n",
    "    \n",
    "    x_raw = image_mappping(x_raw, WINDOW_SIZE)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_raw, y_raw, test_size=0.2)\n",
    "\n",
    "    \n",
    "    for i in range(N_LABELS):\n",
    "        model = init_cnn(WINDOW_SIZE)\n",
    "\n",
    "        indices = resample_and_shuffle(y_train[:,i])\n",
    "        \n",
    "        x_train, y_train = balance_set(indices, x_train, y_train[:,i])\n",
    "\n",
    "        train_labels = to_categorical(y_train, num_classes = None)\n",
    "        test_labels = to_categorical(y_test[:,i], num_classes = None)\n",
    "        \n",
    "#         predictions = np.empty((y_test.shape[0],6))\n",
    "        \n",
    "        print('Train subject %d, class %s' % (subject, COLUMNS[i]))        \n",
    "        model.fit(x_train, train_labels, verbose=1, validation_split=0.2, epochs=50)\n",
    "        \n",
    "        predictions = predict_on_sub(x_test, model, 50, 10)\n",
    "        \n",
    "        single_metric_auc_score(predictions, y_test[:,i][1000::10], True, i)\n",
    "        \n",
    "        prediction_total.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
