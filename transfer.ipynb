{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sebastiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam, Adadelta, SGD\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPool2D, Dropout, Flatten, Conv1D, GlobalAveragePooling1D, Convolution1D\n",
    "from keras.layers.convolutional import MaxPooling2D, MaxPooling1D\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.utils import class_weight\n",
    "from scipy import signal\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants:\n",
    "SUBSAMPLE = 10  # scales the data by this factor\n",
    "COLUMNS = ['HandStart', 'FirstDigitTouch',\n",
    "        'BothStartLoadPhase', 'LiftOff',\n",
    "        'Replace', 'BothReleased']\n",
    "TRAIN_SUBJECTS = range(9, 13)\n",
    "TEST_SUBJECTS = range(9, 13)\n",
    "N_LABELS = 6\n",
    "\n",
    "# Below are the paths to the data. Please pay attention to the % and * signs, these are needed in the loop.\n",
    "TRAIN_DATA_PATH = 'C:/Users/Sebastiaan/Desktop/Programming/MachineLearning/Datasets/EEG/train/subj%d_series*_data.csv'\n",
    "# TRAIN_DATA_PATH = 'C:/Users/bas/Documents/MachineLearning/train/subj%d_series*_data.csv'\n",
    "\n",
    "EPOCHS = 100\n",
    "WINDOW_SIZE = 200\n",
    "SPLIT_SIZE = 50\n",
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_data(data_path):\n",
    "    data = pd.read_csv(data_path)\n",
    "    event_path = data_path.replace('_data', '_events')\n",
    "    labels = pd.read_csv(event_path)\n",
    "    clean_data = data.drop(['id'], axis = 1)\n",
    "    labels = labels.drop(['id'], axis = 1)\n",
    "    return clean_data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(x_raw, WINDOW_SIZE, subsample):\n",
    "    x_raw, scaler = scaler_transform(x_raw[::subsample], None)\n",
    "    x_raw = image_mappping(x_raw, WINDOW_SIZE)\n",
    "    return x_raw, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaler_transform(data, scaler):\n",
    "    if scaler == None:\n",
    "        scaler = Normalizer()\n",
    "        return scaler.fit_transform(data), scaler\n",
    "    else:\n",
    "        return scaler.transform(data)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_training_data(train_data_paths):\n",
    "    labels_raw = []\n",
    "    features_raw = []\n",
    "    for data_path in train_data_paths:\n",
    "        data, labels = prepare_training_data(data_path)\n",
    "        features_raw.append(data)\n",
    "        labels_raw.append(labels)\n",
    "    features_raw = pd.concat(features_raw)\n",
    "    labels_raw = pd.concat(labels_raw)\n",
    "    x_train = np.asarray(features_raw.astype(float))\n",
    "    y_train = np.asarray(labels_raw.astype(float))\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_auc_score(predictions, y_test, with_plot):\n",
    "    scores = []\n",
    "    legend_text = []\n",
    "    for i in range(N_LABELS):\n",
    "        fpr, tpr, _  = roc_curve(y_test[:,i], predictions[:,i], 1)\n",
    "        scores.append(roc_auc_score(y_test[:,i], predictions[:,i]))\n",
    "        legend_text.append(COLUMNS[i]+' (area = %.3f)' % (scores[i]))\n",
    "        if with_plot == True:\n",
    "            plt.plot(fpr, tpr)\n",
    "    if with_plot == True:\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curves')\n",
    "        plt.legend(legend_text)\n",
    "        plt.show()\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_metric_auc_score(prediction_total, test_data_total, with_plot):\n",
    "    legend_text = []\n",
    "    counter = 0\n",
    "    for i in range(len(prediction_total)):\n",
    "        fpr, tpr, _  = roc_curve(test_data_total[i], prediction_total[i], pos_label=1)\n",
    "        score = roc_auc_score(test_data_total[i],prediction_total[i])\n",
    "        legend_text.append(COLUMNS[i]+' (area = %.3f)' % (score))\n",
    "        print(COLUMNS[i]+' AUC score = %.3f' % (score))\n",
    "        plt.plot(fpr, tpr)\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curves')\n",
    "        plt.legend(legend_text)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_metric_auc_score(predictions, y_test, with_plot, i):\n",
    "    fpr, tpr, _  = roc_curve(y_test, predictions, 1)\n",
    "    score = roc_auc_score(y_test, predictions)\n",
    "    print(COLUMNS[i]+' AUC score = %.3f' % (score))\n",
    "    if with_plot == True:\n",
    "        plt.plot(fpr, tpr)\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curves')\n",
    "        plt.show()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_auc_scores(prediction_total, test_data_total, subjects, with_plot):\n",
    "    scores = []\n",
    "    for subject in subjects:\n",
    "        score = metric_auc_score(prediction_total[subject-1],\n",
    "                                 test_data_total[subject-1], with_plot)\n",
    "        scores.append(score)\n",
    "        print('Mean AUC Score of Subject %d: %.3f' % \\\n",
    "              (subject, np.mean(score)))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_mappping(x_train, WINDOW_SIZE):\n",
    "    result = []\n",
    "    empty_matrix = np.zeros(np.shape(x_train[0:WINDOW_SIZE]))\n",
    "    for i in range(len(x_train)):\n",
    "        if i-WINDOW_SIZE < 0:\n",
    "            result.append(empty_matrix)\n",
    "        else:\n",
    "            result.append(x_train[i-WINDOW_SIZE:i])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_and_shuffle(labels):\n",
    "    when_task = np.where(labels == 1)\n",
    "    when_no_task = np.where(labels == 0)\n",
    "    when_no_task = when_no_task[0][0:len(when_task[0])]\n",
    "    indices = np.concatenate([when_task[0], when_no_task])\n",
    "    np.random.shuffle(indices)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_set(indices, x_train, y_train):\n",
    "    balance_x = []\n",
    "    balance_y = []\n",
    "    for index in indices:\n",
    "        balance_x.append(x_train[index])\n",
    "        balance_y.append(y_train[index])\n",
    "    return balance_x, balance_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_imbalance(x_train, y_train):\n",
    "    indices = resample_and_shuffle(y_train)\n",
    "    balanced_x_train, balanced_y_train = balance_set(indices, x_train, y_train)\n",
    "    return balanced_x_train, balanced_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_sub(x_test, model, split_size, batch_size):\n",
    "    split_size = int(len(x_test) / split_size)\n",
    "    sub_x_test = x_test[1000::batch_size]\n",
    "    batch = []\n",
    "    predictions = np.array([])\n",
    "    for i in range(len(sub_x_test)):\n",
    "        batch.append(sub_x_test[i])\n",
    "        if i+1 == len(sub_x_test):\n",
    "            return np.concatenate([predictions, model.predict(np.array(batch))[:,1]])\n",
    "        elif (i+1) % split_size == 0:\n",
    "            predictions = np.concatenate([predictions, model.predict(np.array(batch))[:,1]])\n",
    "            batch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_cnn(window):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(nb_filter=16, filter_length=3, activation='relu', input_shape=(window, 32)))\n",
    "    model.add(MaxPooling1D(3,2))\n",
    "    model.add(Conv1D(nb_filter=32, filter_length=3, activation='relu'))\n",
    "    model.add(Conv1D(nb_filter=64, filter_length=3, activation='relu'))\n",
    "    model.add(MaxPooling1D(3,2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "#     model.summary()\n",
    "    \n",
    "    optimizer = SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)\n",
    "#     optimizer = Adam(lr=1e-6)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\sebastiaan\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "47768 47768\n",
      "Train subject 9, class HandStart\n",
      "Train on 1752 samples, validate on 438 samples\n",
      "Epoch 1/100\n",
      "1752/1752 [==============================] - 2s 1ms/step - loss: 0.7581 - acc: 0.6130 - val_loss: 0.6543 - val_acc: 0.6712\n",
      "Epoch 2/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.6555 - acc: 0.6478 - val_loss: 0.6280 - val_acc: 0.6712\n",
      "Epoch 3/100\n",
      "1752/1752 [==============================] - 1s 320us/step - loss: 0.6040 - acc: 0.6804 - val_loss: 0.5849 - val_acc: 0.6986\n",
      "Epoch 4/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.5804 - acc: 0.6952 - val_loss: 0.5820 - val_acc: 0.7100\n",
      "Epoch 5/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.5622 - acc: 0.7043 - val_loss: 0.5752 - val_acc: 0.7169\n",
      "Epoch 6/100\n",
      "1752/1752 [==============================] - 1s 344us/step - loss: 0.5600 - acc: 0.7123 - val_loss: 0.5729 - val_acc: 0.7169\n",
      "Epoch 7/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.5385 - acc: 0.7186 - val_loss: 0.5634 - val_acc: 0.7237\n",
      "Epoch 8/100\n",
      "1752/1752 [==============================] - 1s 346us/step - loss: 0.5308 - acc: 0.7220 - val_loss: 0.5596 - val_acc: 0.7306\n",
      "Epoch 9/100\n",
      "1752/1752 [==============================] - 1s 354us/step - loss: 0.5381 - acc: 0.7249 - val_loss: 0.5579 - val_acc: 0.7192\n",
      "Epoch 10/100\n",
      "1752/1752 [==============================] - 1s 361us/step - loss: 0.5190 - acc: 0.7317 - val_loss: 0.5545 - val_acc: 0.7215\n",
      "Epoch 11/100\n",
      "1752/1752 [==============================] - 1s 346us/step - loss: 0.5259 - acc: 0.7306 - val_loss: 0.5539 - val_acc: 0.7215\n",
      "Epoch 12/100\n",
      "1752/1752 [==============================] - 1s 341us/step - loss: 0.5178 - acc: 0.7466 - val_loss: 0.5417 - val_acc: 0.7306\n",
      "Epoch 13/100\n",
      "1752/1752 [==============================] - 1s 338us/step - loss: 0.5056 - acc: 0.7529 - val_loss: 0.5512 - val_acc: 0.7260\n",
      "Epoch 14/100\n",
      "1752/1752 [==============================] - 1s 337us/step - loss: 0.5054 - acc: 0.7466 - val_loss: 0.5406 - val_acc: 0.7260\n",
      "Epoch 15/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.4972 - acc: 0.7608 - val_loss: 0.5253 - val_acc: 0.7306\n",
      "Epoch 16/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.5061 - acc: 0.7489 - val_loss: 0.5231 - val_acc: 0.7329\n",
      "Epoch 17/100\n",
      "1752/1752 [==============================] - 1s 341us/step - loss: 0.4974 - acc: 0.7534 - val_loss: 0.5160 - val_acc: 0.7420\n",
      "Epoch 18/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.4842 - acc: 0.7557 - val_loss: 0.5240 - val_acc: 0.7374\n",
      "Epoch 19/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.4894 - acc: 0.7546 - val_loss: 0.5092 - val_acc: 0.7397\n",
      "Epoch 20/100\n",
      "1752/1752 [==============================] - 1s 335us/step - loss: 0.4937 - acc: 0.7597 - val_loss: 0.5124 - val_acc: 0.7420\n",
      "Epoch 21/100\n",
      "1752/1752 [==============================] - 1s 321us/step - loss: 0.4827 - acc: 0.7517 - val_loss: 0.5216 - val_acc: 0.7306\n",
      "Epoch 22/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.4833 - acc: 0.7523 - val_loss: 0.5182 - val_acc: 0.7329\n",
      "Epoch 23/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.4697 - acc: 0.7705 - val_loss: 0.5124 - val_acc: 0.7420\n",
      "Epoch 24/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.4802 - acc: 0.7688 - val_loss: 0.5061 - val_acc: 0.7374\n",
      "Epoch 25/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.4689 - acc: 0.7700 - val_loss: 0.4772 - val_acc: 0.7603\n",
      "Epoch 26/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.4708 - acc: 0.7654 - val_loss: 0.4985 - val_acc: 0.7420\n",
      "Epoch 27/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.4651 - acc: 0.7780 - val_loss: 0.4819 - val_acc: 0.7580\n",
      "Epoch 28/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.4666 - acc: 0.7705 - val_loss: 0.4721 - val_acc: 0.7648\n",
      "Epoch 29/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.4671 - acc: 0.7728 - val_loss: 0.4933 - val_acc: 0.7557\n",
      "Epoch 30/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.4644 - acc: 0.7740 - val_loss: 0.4750 - val_acc: 0.7626\n",
      "Epoch 31/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.4663 - acc: 0.7717 - val_loss: 0.4805 - val_acc: 0.7648\n",
      "Epoch 32/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.4520 - acc: 0.7808 - val_loss: 0.4625 - val_acc: 0.7785\n",
      "Epoch 33/100\n",
      "1752/1752 [==============================] - 1s 338us/step - loss: 0.4499 - acc: 0.7842 - val_loss: 0.4766 - val_acc: 0.7740\n",
      "Epoch 34/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.4532 - acc: 0.7831 - val_loss: 0.4604 - val_acc: 0.7648\n",
      "Epoch 35/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.4568 - acc: 0.7728 - val_loss: 0.4674 - val_acc: 0.7717\n",
      "Epoch 36/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.4528 - acc: 0.7820 - val_loss: 0.4580 - val_acc: 0.7648\n",
      "Epoch 37/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.4446 - acc: 0.7797 - val_loss: 0.4476 - val_acc: 0.7785\n",
      "Epoch 38/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.4426 - acc: 0.7837 - val_loss: 0.4663 - val_acc: 0.7694\n",
      "Epoch 39/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.4524 - acc: 0.7780 - val_loss: 0.4473 - val_acc: 0.7831\n",
      "Epoch 40/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.4538 - acc: 0.7888 - val_loss: 0.4447 - val_acc: 0.7763\n",
      "Epoch 41/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.4370 - acc: 0.7962 - val_loss: 0.4467 - val_acc: 0.7785\n",
      "Epoch 42/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.4276 - acc: 0.7934 - val_loss: 0.4464 - val_acc: 0.7922\n",
      "Epoch 43/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.4352 - acc: 0.7871 - val_loss: 0.4438 - val_acc: 0.8014\n",
      "Epoch 44/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.4279 - acc: 0.7951 - val_loss: 0.4295 - val_acc: 0.7968\n",
      "Epoch 45/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.4226 - acc: 0.7968 - val_loss: 0.4342 - val_acc: 0.8059\n",
      "Epoch 46/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.4181 - acc: 0.8105 - val_loss: 0.4327 - val_acc: 0.8105\n",
      "Epoch 47/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.4199 - acc: 0.8048 - val_loss: 0.4246 - val_acc: 0.8105\n",
      "Epoch 48/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.4269 - acc: 0.7997 - val_loss: 0.4351 - val_acc: 0.8014\n",
      "Epoch 49/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.4164 - acc: 0.8071 - val_loss: 0.4144 - val_acc: 0.8082\n",
      "Epoch 50/100\n",
      "1752/1752 [==============================] - 1s 335us/step - loss: 0.4182 - acc: 0.8037 - val_loss: 0.4290 - val_acc: 0.8014\n",
      "Epoch 51/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.4102 - acc: 0.8105 - val_loss: 0.4112 - val_acc: 0.8174\n",
      "Epoch 52/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.4183 - acc: 0.8031 - val_loss: 0.4255 - val_acc: 0.8128\n",
      "Epoch 53/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.4083 - acc: 0.8048 - val_loss: 0.4148 - val_acc: 0.8174\n",
      "Epoch 54/100\n",
      "1752/1752 [==============================] - ETA: 0s - loss: 0.4120 - acc: 0.811 - 1s 328us/step - loss: 0.4144 - acc: 0.8122 - val_loss: 0.4039 - val_acc: 0.8219\n",
      "Epoch 55/100\n",
      "1752/1752 [==============================] - 1s 337us/step - loss: 0.3953 - acc: 0.8202 - val_loss: 0.4126 - val_acc: 0.8128\n",
      "Epoch 56/100\n",
      "1752/1752 [==============================] - 1s 343us/step - loss: 0.4023 - acc: 0.8151 - val_loss: 0.4033 - val_acc: 0.8219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "1752/1752 [==============================] - 1s 341us/step - loss: 0.3944 - acc: 0.8208 - val_loss: 0.4100 - val_acc: 0.8151\n",
      "Epoch 58/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.3998 - acc: 0.8185 - val_loss: 0.3976 - val_acc: 0.8174\n",
      "Epoch 59/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.3967 - acc: 0.8191 - val_loss: 0.4151 - val_acc: 0.8082\n",
      "Epoch 60/100\n",
      "1752/1752 [==============================] - 1s 341us/step - loss: 0.3974 - acc: 0.8151 - val_loss: 0.3863 - val_acc: 0.8356\n",
      "Epoch 61/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.3865 - acc: 0.8248 - val_loss: 0.3872 - val_acc: 0.8242\n",
      "Epoch 62/100\n",
      "1752/1752 [==============================] - 1s 320us/step - loss: 0.3906 - acc: 0.8265 - val_loss: 0.3958 - val_acc: 0.8196\n",
      "Epoch 63/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.3867 - acc: 0.8253 - val_loss: 0.3940 - val_acc: 0.8219\n",
      "Epoch 64/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.3914 - acc: 0.8225 - val_loss: 0.3888 - val_acc: 0.8174\n",
      "Epoch 65/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.3862 - acc: 0.8168 - val_loss: 0.3998 - val_acc: 0.8151\n",
      "Epoch 66/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.3842 - acc: 0.8253 - val_loss: 0.3905 - val_acc: 0.8196\n",
      "Epoch 67/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.3906 - acc: 0.8265 - val_loss: 0.3851 - val_acc: 0.8219\n",
      "Epoch 68/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.3783 - acc: 0.8316 - val_loss: 0.3827 - val_acc: 0.8265\n",
      "Epoch 69/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.3825 - acc: 0.8253 - val_loss: 0.3756 - val_acc: 0.8311\n",
      "Epoch 70/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.3794 - acc: 0.8242 - val_loss: 0.3757 - val_acc: 0.8333\n",
      "Epoch 71/100\n",
      "1752/1752 [==============================] - 1s 318us/step - loss: 0.3777 - acc: 0.8368 - val_loss: 0.3804 - val_acc: 0.8311\n",
      "Epoch 72/100\n",
      "1752/1752 [==============================] - 1s 339us/step - loss: 0.3738 - acc: 0.8430 - val_loss: 0.3769 - val_acc: 0.8356\n",
      "Epoch 73/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.3691 - acc: 0.8436 - val_loss: 0.3747 - val_acc: 0.8311\n",
      "Epoch 74/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.3718 - acc: 0.8345 - val_loss: 0.3674 - val_acc: 0.8425\n",
      "Epoch 75/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.3660 - acc: 0.8316 - val_loss: 0.3747 - val_acc: 0.8356\n",
      "Epoch 76/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.3743 - acc: 0.8413 - val_loss: 0.3713 - val_acc: 0.8379\n",
      "Epoch 77/100\n",
      "1752/1752 [==============================] - 1s 342us/step - loss: 0.3588 - acc: 0.8362 - val_loss: 0.3713 - val_acc: 0.8356\n",
      "Epoch 78/100\n",
      "1752/1752 [==============================] - 1s 339us/step - loss: 0.3665 - acc: 0.8311 - val_loss: 0.3697 - val_acc: 0.8379\n",
      "Epoch 79/100\n",
      "1752/1752 [==============================] - 1s 361us/step - loss: 0.3580 - acc: 0.8430 - val_loss: 0.3637 - val_acc: 0.8333\n",
      "Epoch 80/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.3650 - acc: 0.8465 - val_loss: 0.3676 - val_acc: 0.8402\n",
      "Epoch 81/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.3557 - acc: 0.8550 - val_loss: 0.3739 - val_acc: 0.8356\n",
      "Epoch 82/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.3547 - acc: 0.8419 - val_loss: 0.3887 - val_acc: 0.8174\n",
      "Epoch 83/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.3695 - acc: 0.8390 - val_loss: 0.3513 - val_acc: 0.8516\n",
      "Epoch 84/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.3745 - acc: 0.8288 - val_loss: 0.3635 - val_acc: 0.8402\n",
      "Epoch 85/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.3475 - acc: 0.8522 - val_loss: 0.3602 - val_acc: 0.8402\n",
      "Epoch 86/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.3568 - acc: 0.8493 - val_loss: 0.3942 - val_acc: 0.8219\n",
      "Epoch 87/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.3601 - acc: 0.8459 - val_loss: 0.3607 - val_acc: 0.8333\n",
      "Epoch 88/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.3551 - acc: 0.8505 - val_loss: 0.3714 - val_acc: 0.8311\n",
      "Epoch 89/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.3435 - acc: 0.8470 - val_loss: 0.3714 - val_acc: 0.8288\n",
      "Epoch 90/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.3481 - acc: 0.8510 - val_loss: 0.3569 - val_acc: 0.8402\n",
      "Epoch 91/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.3458 - acc: 0.8567 - val_loss: 0.3469 - val_acc: 0.8402\n",
      "Epoch 92/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.3482 - acc: 0.8459 - val_loss: 0.3510 - val_acc: 0.8493\n",
      "Epoch 93/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.3366 - acc: 0.8533 - val_loss: 0.3672 - val_acc: 0.8402\n",
      "Epoch 94/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.3442 - acc: 0.8482 - val_loss: 0.3668 - val_acc: 0.8356\n",
      "Epoch 95/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.3446 - acc: 0.8573 - val_loss: 0.3444 - val_acc: 0.8516\n",
      "Epoch 96/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.3454 - acc: 0.8459 - val_loss: 0.3538 - val_acc: 0.8447\n",
      "Epoch 97/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.3408 - acc: 0.8516 - val_loss: 0.3420 - val_acc: 0.8584\n",
      "Epoch 98/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.3371 - acc: 0.8619 - val_loss: 0.3618 - val_acc: 0.8425\n",
      "Epoch 99/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.3511 - acc: 0.8505 - val_loss: 0.3495 - val_acc: 0.8402\n",
      "Epoch 100/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.3392 - acc: 0.8533 - val_loss: 0.3570 - val_acc: 0.8447\n",
      "Train on 1752 samples, validate on 438 samples\n",
      "Epoch 1/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.3904 - acc: 0.8271 - val_loss: 0.3365 - val_acc: 0.8493\n",
      "Epoch 2/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.3753 - acc: 0.8339 - val_loss: 0.3599 - val_acc: 0.8447\n",
      "Epoch 3/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.3688 - acc: 0.8311 - val_loss: 0.3421 - val_acc: 0.8493\n",
      "Epoch 4/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.3677 - acc: 0.8436 - val_loss: 0.3415 - val_acc: 0.8516\n",
      "Epoch 5/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.3640 - acc: 0.8373 - val_loss: 0.3312 - val_acc: 0.8516\n",
      "Epoch 6/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.3649 - acc: 0.8430 - val_loss: 0.3469 - val_acc: 0.8539\n",
      "Epoch 7/100\n",
      "1752/1752 [==============================] - 1s 339us/step - loss: 0.3638 - acc: 0.8419 - val_loss: 0.3344 - val_acc: 0.8539\n",
      "Epoch 8/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.3405 - acc: 0.8539 - val_loss: 0.3609 - val_acc: 0.8584\n",
      "Epoch 9/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.3544 - acc: 0.8396 - val_loss: 0.3365 - val_acc: 0.8676\n",
      "Epoch 10/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.3475 - acc: 0.8442 - val_loss: 0.3390 - val_acc: 0.8699\n",
      "Epoch 11/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.3416 - acc: 0.8567 - val_loss: 0.3432 - val_acc: 0.8607\n",
      "Epoch 12/100\n",
      "1752/1752 [==============================] - 1s 343us/step - loss: 0.3380 - acc: 0.8562 - val_loss: 0.3138 - val_acc: 0.8744\n",
      "Epoch 13/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.3453 - acc: 0.8516 - val_loss: 0.3247 - val_acc: 0.8699\n",
      "Epoch 14/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.3484 - acc: 0.8459 - val_loss: 0.3246 - val_acc: 0.8790\n",
      "Epoch 15/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.3464 - acc: 0.8510 - val_loss: 0.3304 - val_acc: 0.8721\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1752/1752 [==============================] - 1s 340us/step - loss: 0.3210 - acc: 0.8676 - val_loss: 0.3266 - val_acc: 0.8790\n",
      "Epoch 17/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.3318 - acc: 0.8653 - val_loss: 0.3222 - val_acc: 0.8744\n",
      "Epoch 18/100\n",
      "1752/1752 [==============================] - 1s 346us/step - loss: 0.3333 - acc: 0.8687 - val_loss: 0.3216 - val_acc: 0.8721\n",
      "Epoch 19/100\n",
      "1752/1752 [==============================] - 1s 337us/step - loss: 0.3442 - acc: 0.8522 - val_loss: 0.3287 - val_acc: 0.8676\n",
      "Epoch 20/100\n",
      "1752/1752 [==============================] - 1s 351us/step - loss: 0.3210 - acc: 0.8636 - val_loss: 0.3162 - val_acc: 0.8767\n",
      "Epoch 21/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.3236 - acc: 0.8716 - val_loss: 0.3099 - val_acc: 0.8790\n",
      "Epoch 22/100\n",
      "1752/1752 [==============================] - 1s 335us/step - loss: 0.3165 - acc: 0.8693 - val_loss: 0.3198 - val_acc: 0.8676\n",
      "Epoch 23/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.3191 - acc: 0.8710 - val_loss: 0.3280 - val_acc: 0.8676\n",
      "Epoch 24/100\n",
      "1752/1752 [==============================] - 1s 343us/step - loss: 0.3212 - acc: 0.8761 - val_loss: 0.3510 - val_acc: 0.8584\n",
      "Epoch 25/100\n",
      "1752/1752 [==============================] - 1s 344us/step - loss: 0.3235 - acc: 0.8619 - val_loss: 0.3288 - val_acc: 0.8699\n",
      "Epoch 26/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.3190 - acc: 0.8710 - val_loss: 0.3022 - val_acc: 0.8744\n",
      "Epoch 27/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.3198 - acc: 0.8647 - val_loss: 0.3072 - val_acc: 0.8836\n",
      "Epoch 28/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.3167 - acc: 0.8653 - val_loss: 0.3048 - val_acc: 0.8858\n",
      "Epoch 29/100\n",
      "1752/1752 [==============================] - 1s 339us/step - loss: 0.3209 - acc: 0.8590 - val_loss: 0.3127 - val_acc: 0.8790\n",
      "Epoch 30/100\n",
      "1752/1752 [==============================] - 1s 347us/step - loss: 0.3118 - acc: 0.8744 - val_loss: 0.3163 - val_acc: 0.8676\n",
      "Epoch 31/100\n",
      "1752/1752 [==============================] - 1s 349us/step - loss: 0.3058 - acc: 0.8750 - val_loss: 0.3076 - val_acc: 0.8813\n",
      "Epoch 32/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.3080 - acc: 0.8733 - val_loss: 0.3037 - val_acc: 0.8813\n",
      "Epoch 33/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.3144 - acc: 0.8716 - val_loss: 0.3224 - val_acc: 0.8721\n",
      "Epoch 34/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.2989 - acc: 0.8756 - val_loss: 0.3163 - val_acc: 0.8699\n",
      "Epoch 35/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.3011 - acc: 0.8807 - val_loss: 0.2962 - val_acc: 0.8858\n",
      "Epoch 36/100\n",
      "1752/1752 [==============================] - 1s 343us/step - loss: 0.3046 - acc: 0.8744 - val_loss: 0.3146 - val_acc: 0.8790\n",
      "Epoch 37/100\n",
      "1752/1752 [==============================] - 1s 357us/step - loss: 0.3139 - acc: 0.8761 - val_loss: 0.3096 - val_acc: 0.8767\n",
      "Epoch 38/100\n",
      "1752/1752 [==============================] - 1s 349us/step - loss: 0.3055 - acc: 0.8773 - val_loss: 0.3129 - val_acc: 0.8744\n",
      "Epoch 39/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.3012 - acc: 0.8716 - val_loss: 0.3018 - val_acc: 0.8813\n",
      "Epoch 40/100\n",
      "1752/1752 [==============================] - 1s 345us/step - loss: 0.2904 - acc: 0.8841 - val_loss: 0.3052 - val_acc: 0.8790\n",
      "Epoch 41/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.2951 - acc: 0.8801 - val_loss: 0.3099 - val_acc: 0.8767\n",
      "Epoch 42/100\n",
      "1752/1752 [==============================] - 1s 351us/step - loss: 0.2981 - acc: 0.8801 - val_loss: 0.3055 - val_acc: 0.8790\n",
      "Epoch 43/100\n",
      "1752/1752 [==============================] - 1s 343us/step - loss: 0.2830 - acc: 0.8847 - val_loss: 0.3127 - val_acc: 0.8767\n",
      "Epoch 44/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.3001 - acc: 0.8750 - val_loss: 0.2956 - val_acc: 0.9018\n",
      "Epoch 45/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.2995 - acc: 0.8761 - val_loss: 0.2987 - val_acc: 0.8904\n",
      "Epoch 46/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.2988 - acc: 0.8836 - val_loss: 0.3294 - val_acc: 0.8676\n",
      "Epoch 47/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.2909 - acc: 0.8836 - val_loss: 0.2930 - val_acc: 0.8881\n",
      "Epoch 48/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.2998 - acc: 0.8853 - val_loss: 0.2857 - val_acc: 0.8973\n",
      "Epoch 49/100\n",
      "1752/1752 [==============================] - 1s 349us/step - loss: 0.2893 - acc: 0.8870 - val_loss: 0.3080 - val_acc: 0.8721\n",
      "Epoch 50/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.2949 - acc: 0.8744 - val_loss: 0.2965 - val_acc: 0.8927\n",
      "Epoch 51/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.2877 - acc: 0.8864 - val_loss: 0.3120 - val_acc: 0.8721\n",
      "Epoch 52/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.2801 - acc: 0.8830 - val_loss: 0.2815 - val_acc: 0.9018\n",
      "Epoch 53/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.2866 - acc: 0.8893 - val_loss: 0.2923 - val_acc: 0.8927\n",
      "Epoch 54/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.2872 - acc: 0.8881 - val_loss: 0.2807 - val_acc: 0.8995\n",
      "Epoch 55/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.2853 - acc: 0.8876 - val_loss: 0.2938 - val_acc: 0.8973\n",
      "Epoch 56/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.2796 - acc: 0.8904 - val_loss: 0.2970 - val_acc: 0.8813\n",
      "Epoch 57/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.2768 - acc: 0.8938 - val_loss: 0.2922 - val_acc: 0.8927\n",
      "Epoch 58/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.2783 - acc: 0.8893 - val_loss: 0.3031 - val_acc: 0.8836\n",
      "Epoch 59/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.2778 - acc: 0.8944 - val_loss: 0.2867 - val_acc: 0.9018\n",
      "Epoch 60/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.2751 - acc: 0.8904 - val_loss: 0.2897 - val_acc: 0.8973\n",
      "Epoch 61/100\n",
      "1752/1752 [==============================] - 1s 320us/step - loss: 0.2691 - acc: 0.8933 - val_loss: 0.2863 - val_acc: 0.9018\n",
      "Epoch 62/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.2742 - acc: 0.8910 - val_loss: 0.2902 - val_acc: 0.8950\n",
      "Epoch 63/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.2735 - acc: 0.8990 - val_loss: 0.2734 - val_acc: 0.9110\n",
      "Epoch 64/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.2720 - acc: 0.8898 - val_loss: 0.2808 - val_acc: 0.9041\n",
      "Epoch 65/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.2795 - acc: 0.8898 - val_loss: 0.2886 - val_acc: 0.8950\n",
      "Epoch 66/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.2762 - acc: 0.8950 - val_loss: 0.2902 - val_acc: 0.8927\n",
      "Epoch 67/100\n",
      "1752/1752 [==============================] - 1s 317us/step - loss: 0.2773 - acc: 0.8881 - val_loss: 0.2894 - val_acc: 0.8927\n",
      "Epoch 68/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.2649 - acc: 0.8978 - val_loss: 0.2743 - val_acc: 0.9018\n",
      "Epoch 69/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.2733 - acc: 0.8950 - val_loss: 0.3134 - val_acc: 0.8767\n",
      "Epoch 70/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.2710 - acc: 0.8927 - val_loss: 0.3083 - val_acc: 0.8790\n",
      "Epoch 71/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.2750 - acc: 0.8955 - val_loss: 0.3043 - val_acc: 0.8813\n",
      "Epoch 72/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.2650 - acc: 0.8967 - val_loss: 0.3019 - val_acc: 0.8767\n",
      "Epoch 73/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.2675 - acc: 0.8938 - val_loss: 0.2776 - val_acc: 0.9018\n",
      "Epoch 74/100\n",
      "1752/1752 [==============================] - 1s 335us/step - loss: 0.2658 - acc: 0.8978 - val_loss: 0.2884 - val_acc: 0.8927\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.2625 - acc: 0.9058 - val_loss: 0.2846 - val_acc: 0.8927\n",
      "Epoch 76/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.2647 - acc: 0.9024 - val_loss: 0.3056 - val_acc: 0.8790\n",
      "Epoch 77/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.2740 - acc: 0.8921 - val_loss: 0.2872 - val_acc: 0.8950\n",
      "Epoch 78/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.2586 - acc: 0.9041 - val_loss: 0.2925 - val_acc: 0.8927\n",
      "Epoch 79/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.2573 - acc: 0.9047 - val_loss: 0.2938 - val_acc: 0.8813\n",
      "Epoch 80/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.2633 - acc: 0.8967 - val_loss: 0.2770 - val_acc: 0.8904\n",
      "Epoch 81/100\n",
      "1752/1752 [==============================] - 1s 318us/step - loss: 0.2676 - acc: 0.8927 - val_loss: 0.2861 - val_acc: 0.8836\n",
      "Epoch 82/100\n",
      "1752/1752 [==============================] - 1s 319us/step - loss: 0.2630 - acc: 0.8910 - val_loss: 0.2927 - val_acc: 0.8881\n",
      "Epoch 83/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.2581 - acc: 0.9001 - val_loss: 0.2921 - val_acc: 0.8881\n",
      "Epoch 84/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.2522 - acc: 0.9098 - val_loss: 0.2686 - val_acc: 0.9041\n",
      "Epoch 85/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.2640 - acc: 0.9018 - val_loss: 0.2683 - val_acc: 0.9018\n",
      "Epoch 86/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.2494 - acc: 0.9035 - val_loss: 0.2857 - val_acc: 0.8904\n",
      "Epoch 87/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.2571 - acc: 0.8990 - val_loss: 0.2872 - val_acc: 0.8950\n",
      "Epoch 88/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.2551 - acc: 0.8984 - val_loss: 0.2690 - val_acc: 0.9064\n",
      "Epoch 89/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.2433 - acc: 0.9155 - val_loss: 0.2886 - val_acc: 0.8881\n",
      "Epoch 90/100\n",
      "1752/1752 [==============================] - 1s 335us/step - loss: 0.2477 - acc: 0.9104 - val_loss: 0.2815 - val_acc: 0.8927\n",
      "Epoch 91/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.2505 - acc: 0.9018 - val_loss: 0.2611 - val_acc: 0.9087\n",
      "Epoch 92/100\n",
      "1752/1752 [==============================] - 1s 335us/step - loss: 0.2556 - acc: 0.9070 - val_loss: 0.2855 - val_acc: 0.8904\n",
      "Epoch 93/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.2509 - acc: 0.9053 - val_loss: 0.2887 - val_acc: 0.8881\n",
      "Epoch 94/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.2417 - acc: 0.9075 - val_loss: 0.2736 - val_acc: 0.8995\n",
      "Epoch 95/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.2491 - acc: 0.9018 - val_loss: 0.2555 - val_acc: 0.9087\n",
      "Epoch 96/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.2528 - acc: 0.9053 - val_loss: 0.2594 - val_acc: 0.9087\n",
      "Epoch 97/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.2386 - acc: 0.9115 - val_loss: 0.2783 - val_acc: 0.8950\n",
      "Epoch 98/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.2486 - acc: 0.9070 - val_loss: 0.2795 - val_acc: 0.8927\n",
      "Epoch 99/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.2453 - acc: 0.9013 - val_loss: 0.2779 - val_acc: 0.8927\n",
      "Epoch 100/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.2437 - acc: 0.9087 - val_loss: 0.2591 - val_acc: 0.9087\n",
      "Test subject 9, class HandStart\n",
      "Train subject 9, class FirstDigitTouch\n",
      "Train on 1751 samples, validate on 438 samples\n",
      "Epoch 1/100\n",
      "1751/1751 [==============================] - 1s 628us/step - loss: 0.7296 - acc: 0.7339 - val_loss: 0.4740 - val_acc: 0.7900\n",
      "Epoch 2/100\n",
      "1751/1751 [==============================] - 1s 317us/step - loss: 0.4884 - acc: 0.7955 - val_loss: 0.4186 - val_acc: 0.8265\n",
      "Epoch 3/100\n",
      "1751/1751 [==============================] - 1s 315us/step - loss: 0.4311 - acc: 0.8172 - val_loss: 0.3822 - val_acc: 0.8470\n",
      "Epoch 4/100\n",
      "1751/1751 [==============================] - 1s 321us/step - loss: 0.3832 - acc: 0.8344 - val_loss: 0.3470 - val_acc: 0.8630\n",
      "Epoch 5/100\n",
      "1751/1751 [==============================] - 1s 315us/step - loss: 0.3816 - acc: 0.8452 - val_loss: 0.3509 - val_acc: 0.8562\n",
      "Epoch 6/100\n",
      "1751/1751 [==============================] - 1s 326us/step - loss: 0.3542 - acc: 0.8532 - val_loss: 0.3552 - val_acc: 0.8493\n",
      "Epoch 7/100\n",
      "1751/1751 [==============================] - 1s 324us/step - loss: 0.3295 - acc: 0.8641 - val_loss: 0.3187 - val_acc: 0.8630\n",
      "Epoch 8/100\n",
      "1751/1751 [==============================] - 1s 329us/step - loss: 0.3306 - acc: 0.8755 - val_loss: 0.3186 - val_acc: 0.8699\n",
      "Epoch 9/100\n",
      "1751/1751 [==============================] - 1s 323us/step - loss: 0.2970 - acc: 0.8789 - val_loss: 0.3066 - val_acc: 0.8721\n",
      "Epoch 10/100\n",
      "1751/1751 [==============================] - 1s 332us/step - loss: 0.3029 - acc: 0.8789 - val_loss: 0.2995 - val_acc: 0.8836\n",
      "Epoch 11/100\n",
      "1751/1751 [==============================] - 1s 326us/step - loss: 0.2831 - acc: 0.8955 - val_loss: 0.2968 - val_acc: 0.8858\n",
      "Epoch 12/100\n",
      "1751/1751 [==============================] - 1s 325us/step - loss: 0.2793 - acc: 0.8943 - val_loss: 0.2812 - val_acc: 0.9041\n",
      "Epoch 13/100\n",
      "1751/1751 [==============================] - 1s 331us/step - loss: 0.2719 - acc: 0.8995 - val_loss: 0.2921 - val_acc: 0.8950\n",
      "Epoch 14/100\n",
      "1751/1751 [==============================] - 1s 330us/step - loss: 0.2603 - acc: 0.9058 - val_loss: 0.2830 - val_acc: 0.9018\n",
      "Epoch 15/100\n",
      "1751/1751 [==============================] - 1s 329us/step - loss: 0.2442 - acc: 0.9109 - val_loss: 0.2714 - val_acc: 0.9018\n",
      "Epoch 16/100\n",
      "1751/1751 [==============================] - 1s 326us/step - loss: 0.2512 - acc: 0.9075 - val_loss: 0.2742 - val_acc: 0.8995\n",
      "Epoch 17/100\n",
      "1751/1751 [==============================] - 1s 331us/step - loss: 0.2304 - acc: 0.9160 - val_loss: 0.2813 - val_acc: 0.9018\n",
      "Epoch 18/100\n",
      "1751/1751 [==============================] - 1s 329us/step - loss: 0.2267 - acc: 0.9189 - val_loss: 0.2704 - val_acc: 0.9041\n",
      "Epoch 19/100\n",
      "1751/1751 [==============================] - 1s 333us/step - loss: 0.2299 - acc: 0.9155 - val_loss: 0.2685 - val_acc: 0.9064\n",
      "Epoch 20/100\n",
      "1751/1751 [==============================] - 1s 325us/step - loss: 0.2423 - acc: 0.9143 - val_loss: 0.2490 - val_acc: 0.9087\n",
      "Epoch 21/100\n",
      "1751/1751 [==============================] - 1s 327us/step - loss: 0.2162 - acc: 0.9252 - val_loss: 0.2624 - val_acc: 0.9041\n",
      "Epoch 22/100\n",
      "1751/1751 [==============================] - 1s 326us/step - loss: 0.2158 - acc: 0.9263 - val_loss: 0.2550 - val_acc: 0.9064\n",
      "Epoch 23/100\n",
      "1751/1751 [==============================] - 1s 328us/step - loss: 0.2040 - acc: 0.9298 - val_loss: 0.2531 - val_acc: 0.9087\n",
      "Epoch 24/100\n",
      "1751/1751 [==============================] - 1s 325us/step - loss: 0.2154 - acc: 0.9263 - val_loss: 0.2558 - val_acc: 0.9041\n",
      "Epoch 25/100\n",
      "1751/1751 [==============================] - 1s 329us/step - loss: 0.2090 - acc: 0.9275 - val_loss: 0.2614 - val_acc: 0.9064\n",
      "Epoch 26/100\n",
      "1751/1751 [==============================] - 1s 331us/step - loss: 0.1939 - acc: 0.9246 - val_loss: 0.2431 - val_acc: 0.9132\n",
      "Epoch 27/100\n",
      "1751/1751 [==============================] - 1s 329us/step - loss: 0.2062 - acc: 0.9292 - val_loss: 0.2435 - val_acc: 0.9132\n",
      "Epoch 28/100\n",
      "1751/1751 [==============================] - 1s 329us/step - loss: 0.1946 - acc: 0.9338 - val_loss: 0.2406 - val_acc: 0.9110\n",
      "Epoch 29/100\n",
      "1751/1751 [==============================] - 1s 334us/step - loss: 0.1966 - acc: 0.9263 - val_loss: 0.2275 - val_acc: 0.9201\n",
      "Epoch 30/100\n",
      "1751/1751 [==============================] - 1s 324us/step - loss: 0.1869 - acc: 0.9338 - val_loss: 0.2490 - val_acc: 0.9132\n",
      "Epoch 31/100\n",
      "1751/1751 [==============================] - 1s 332us/step - loss: 0.1880 - acc: 0.9320 - val_loss: 0.2402 - val_acc: 0.9178\n",
      "Epoch 32/100\n",
      "1751/1751 [==============================] - 1s 326us/step - loss: 0.1849 - acc: 0.9349 - val_loss: 0.2353 - val_acc: 0.9132\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1751/1751 [==============================] - 1s 332us/step - loss: 0.1822 - acc: 0.9383 - val_loss: 0.2301 - val_acc: 0.9224\n",
      "Epoch 34/100\n",
      "1751/1751 [==============================] - 1s 332us/step - loss: 0.1725 - acc: 0.9377 - val_loss: 0.2161 - val_acc: 0.9338\n",
      "Epoch 35/100\n",
      "1751/1751 [==============================] - 1s 333us/step - loss: 0.1743 - acc: 0.9377 - val_loss: 0.2457 - val_acc: 0.9110\n",
      "Epoch 36/100\n",
      "1751/1751 [==============================] - 1s 343us/step - loss: 0.1818 - acc: 0.9395 - val_loss: 0.2174 - val_acc: 0.9315\n",
      "Epoch 37/100\n",
      "1751/1751 [==============================] - 1s 332us/step - loss: 0.1877 - acc: 0.9366 - val_loss: 0.2280 - val_acc: 0.9178\n",
      "Epoch 38/100\n",
      "1751/1751 [==============================] - 1s 325us/step - loss: 0.1663 - acc: 0.9429 - val_loss: 0.2234 - val_acc: 0.9201\n",
      "Epoch 39/100\n",
      "1751/1751 [==============================] - 1s 326us/step - loss: 0.1618 - acc: 0.9452 - val_loss: 0.2182 - val_acc: 0.9292\n",
      "Epoch 40/100\n",
      "1751/1751 [==============================] - 1s 322us/step - loss: 0.1676 - acc: 0.9423 - val_loss: 0.2185 - val_acc: 0.9201\n",
      "Epoch 41/100\n",
      "1751/1751 [==============================] - 1s 333us/step - loss: 0.1571 - acc: 0.9412 - val_loss: 0.2452 - val_acc: 0.9132\n",
      "Epoch 42/100\n",
      "1751/1751 [==============================] - 1s 337us/step - loss: 0.1739 - acc: 0.9412 - val_loss: 0.2326 - val_acc: 0.9155\n",
      "Epoch 43/100\n",
      "1751/1751 [==============================] - 1s 334us/step - loss: 0.1685 - acc: 0.9463 - val_loss: 0.2219 - val_acc: 0.9269\n",
      "Epoch 44/100\n",
      "1751/1751 [==============================] - 1s 332us/step - loss: 0.1643 - acc: 0.9435 - val_loss: 0.2104 - val_acc: 0.9384\n",
      "Epoch 45/100\n",
      "1751/1751 [==============================] - 1s 334us/step - loss: 0.1701 - acc: 0.9480 - val_loss: 0.2074 - val_acc: 0.9315\n",
      "Epoch 46/100\n",
      "1751/1751 [==============================] - 1s 331us/step - loss: 0.1641 - acc: 0.9480 - val_loss: 0.2056 - val_acc: 0.9338\n",
      "Epoch 47/100\n",
      "1751/1751 [==============================] - 1s 331us/step - loss: 0.1517 - acc: 0.9492 - val_loss: 0.2015 - val_acc: 0.9338\n",
      "Epoch 48/100\n",
      "1751/1751 [==============================] - 1s 327us/step - loss: 0.1537 - acc: 0.9486 - val_loss: 0.2199 - val_acc: 0.9201\n",
      "Epoch 49/100\n",
      "1751/1751 [==============================] - 1s 322us/step - loss: 0.1580 - acc: 0.9469 - val_loss: 0.2072 - val_acc: 0.9292\n",
      "Epoch 50/100\n",
      "1751/1751 [==============================] - 1s 325us/step - loss: 0.1495 - acc: 0.9486 - val_loss: 0.2140 - val_acc: 0.9292\n",
      "Epoch 51/100\n",
      "1751/1751 [==============================] - 1s 326us/step - loss: 0.1410 - acc: 0.9532 - val_loss: 0.2180 - val_acc: 0.9247\n",
      "Epoch 52/100\n",
      "1751/1751 [==============================] - 1s 335us/step - loss: 0.1512 - acc: 0.9492 - val_loss: 0.2130 - val_acc: 0.9292\n",
      "Epoch 53/100\n",
      "1751/1751 [==============================] - 1s 339us/step - loss: 0.1533 - acc: 0.9497 - val_loss: 0.2173 - val_acc: 0.9292\n",
      "Epoch 54/100\n",
      "1751/1751 [==============================] - 1s 357us/step - loss: 0.1476 - acc: 0.9526 - val_loss: 0.2255 - val_acc: 0.9247\n",
      "Epoch 55/100\n",
      "1751/1751 [==============================] - 1s 341us/step - loss: 0.1514 - acc: 0.9543 - val_loss: 0.2136 - val_acc: 0.9292\n",
      "Epoch 56/100\n",
      "1751/1751 [==============================] - 1s 333us/step - loss: 0.1465 - acc: 0.9520 - val_loss: 0.1909 - val_acc: 0.9429\n",
      "Epoch 57/100\n",
      "1751/1751 [==============================] - 1s 332us/step - loss: 0.1540 - acc: 0.9423 - val_loss: 0.2221 - val_acc: 0.9315\n",
      "Epoch 58/100\n",
      "1751/1751 [==============================] - 1s 335us/step - loss: 0.1504 - acc: 0.9480 - val_loss: 0.2188 - val_acc: 0.9292\n",
      "Epoch 59/100\n",
      "1751/1751 [==============================] - 1s 346us/step - loss: 0.1463 - acc: 0.9480 - val_loss: 0.1986 - val_acc: 0.9361\n",
      "Epoch 60/100\n",
      "1751/1751 [==============================] - 1s 346us/step - loss: 0.1385 - acc: 0.9572 - val_loss: 0.2246 - val_acc: 0.9247\n",
      "Epoch 61/100\n",
      "1751/1751 [==============================] - 1s 328us/step - loss: 0.1510 - acc: 0.9463 - val_loss: 0.2008 - val_acc: 0.9338\n",
      "Epoch 62/100\n",
      "1751/1751 [==============================] - 1s 338us/step - loss: 0.1443 - acc: 0.9503 - val_loss: 0.2161 - val_acc: 0.9269\n",
      "Epoch 63/100\n",
      "1751/1751 [==============================] - 1s 340us/step - loss: 0.1464 - acc: 0.9480 - val_loss: 0.2153 - val_acc: 0.9315\n",
      "Epoch 64/100\n",
      "1751/1751 [==============================] - 1s 327us/step - loss: 0.1346 - acc: 0.9583 - val_loss: 0.1881 - val_acc: 0.9452\n",
      "Epoch 65/100\n",
      "1751/1751 [==============================] - 1s 322us/step - loss: 0.1354 - acc: 0.9566 - val_loss: 0.2162 - val_acc: 0.9269\n",
      "Epoch 66/100\n",
      "1751/1751 [==============================] - 1s 326us/step - loss: 0.1433 - acc: 0.9486 - val_loss: 0.2213 - val_acc: 0.9269\n",
      "Epoch 67/100\n",
      "1751/1751 [==============================] - 1s 335us/step - loss: 0.1365 - acc: 0.9537 - val_loss: 0.1823 - val_acc: 0.9429\n",
      "Epoch 68/100\n",
      "1751/1751 [==============================] - 1s 326us/step - loss: 0.1316 - acc: 0.9572 - val_loss: 0.2039 - val_acc: 0.9315\n",
      "Epoch 69/100\n",
      "1751/1751 [==============================] - 1s 337us/step - loss: 0.1351 - acc: 0.9589 - val_loss: 0.1870 - val_acc: 0.9406\n",
      "Epoch 70/100\n",
      "1751/1751 [==============================] - 1s 344us/step - loss: 0.1370 - acc: 0.9577 - val_loss: 0.2112 - val_acc: 0.9292\n",
      "Epoch 71/100\n",
      "1751/1751 [==============================] - 1s 337us/step - loss: 0.1351 - acc: 0.9543 - val_loss: 0.1883 - val_acc: 0.9361\n",
      "Epoch 72/100\n",
      "1751/1751 [==============================] - 1s 344us/step - loss: 0.1374 - acc: 0.9555 - val_loss: 0.1760 - val_acc: 0.9452\n",
      "Epoch 73/100\n",
      "1751/1751 [==============================] - 1s 337us/step - loss: 0.1314 - acc: 0.9577 - val_loss: 0.1893 - val_acc: 0.9384\n",
      "Epoch 74/100\n",
      "1751/1751 [==============================] - 1s 344us/step - loss: 0.1347 - acc: 0.9520 - val_loss: 0.1930 - val_acc: 0.9384\n",
      "Epoch 75/100\n",
      "1751/1751 [==============================] - 1s 341us/step - loss: 0.1391 - acc: 0.9543 - val_loss: 0.1901 - val_acc: 0.9384\n",
      "Epoch 76/100\n",
      "1751/1751 [==============================] - 1s 342us/step - loss: 0.1362 - acc: 0.9537 - val_loss: 0.1876 - val_acc: 0.9384\n",
      "Epoch 77/100\n",
      "1751/1751 [==============================] - 1s 346us/step - loss: 0.1396 - acc: 0.9543 - val_loss: 0.2157 - val_acc: 0.9269\n",
      "Epoch 78/100\n",
      "1751/1751 [==============================] - 1s 345us/step - loss: 0.1233 - acc: 0.9617 - val_loss: 0.2070 - val_acc: 0.9315\n",
      "Epoch 79/100\n",
      "1751/1751 [==============================] - 1s 345us/step - loss: 0.1358 - acc: 0.9543 - val_loss: 0.2178 - val_acc: 0.9292\n",
      "Epoch 80/100\n",
      "1751/1751 [==============================] - 1s 351us/step - loss: 0.1381 - acc: 0.9532 - val_loss: 0.2122 - val_acc: 0.9315\n",
      "Epoch 81/100\n",
      "1751/1751 [==============================] - 1s 340us/step - loss: 0.1310 - acc: 0.9566 - val_loss: 0.1923 - val_acc: 0.9384\n",
      "Epoch 82/100\n",
      "1751/1751 [==============================] - 1s 333us/step - loss: 0.1324 - acc: 0.9600 - val_loss: 0.2200 - val_acc: 0.9292\n",
      "Epoch 83/100\n",
      "1751/1751 [==============================] - 1s 344us/step - loss: 0.1200 - acc: 0.9634 - val_loss: 0.2106 - val_acc: 0.9315\n",
      "Epoch 84/100\n",
      "1751/1751 [==============================] - 1s 339us/step - loss: 0.1255 - acc: 0.9572 - val_loss: 0.2071 - val_acc: 0.9315\n",
      "Epoch 85/100\n",
      "1751/1751 [==============================] - 1s 323us/step - loss: 0.1324 - acc: 0.9555 - val_loss: 0.2081 - val_acc: 0.9292\n",
      "Epoch 86/100\n",
      "1751/1751 [==============================] - 1s 356us/step - loss: 0.1251 - acc: 0.9555 - val_loss: 0.2038 - val_acc: 0.9292\n",
      "Epoch 87/100\n",
      "1751/1751 [==============================] - 1s 357us/step - loss: 0.1226 - acc: 0.9572 - val_loss: 0.2011 - val_acc: 0.9338\n",
      "Epoch 88/100\n",
      "1751/1751 [==============================] - 1s 349us/step - loss: 0.1233 - acc: 0.9600 - val_loss: 0.1954 - val_acc: 0.9338\n",
      "Epoch 89/100\n",
      "1751/1751 [==============================] - 1s 332us/step - loss: 0.1243 - acc: 0.9657 - val_loss: 0.2102 - val_acc: 0.9315\n",
      "Epoch 90/100\n",
      "1751/1751 [==============================] - 1s 336us/step - loss: 0.1300 - acc: 0.9549 - val_loss: 0.1937 - val_acc: 0.9338\n",
      "Epoch 91/100\n",
      "1751/1751 [==============================] - 1s 348us/step - loss: 0.1355 - acc: 0.9583 - val_loss: 0.2201 - val_acc: 0.9338\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1751/1751 [==============================] - 1s 366us/step - loss: 0.1275 - acc: 0.9629 - val_loss: 0.1829 - val_acc: 0.9429\n",
      "Epoch 93/100\n",
      "1751/1751 [==============================] - 1s 353us/step - loss: 0.1293 - acc: 0.9572 - val_loss: 0.2087 - val_acc: 0.9338\n",
      "Epoch 94/100\n",
      "1751/1751 [==============================] - 1s 365us/step - loss: 0.1208 - acc: 0.9617 - val_loss: 0.1847 - val_acc: 0.9429\n",
      "Epoch 95/100\n",
      "1751/1751 [==============================] - 1s 327us/step - loss: 0.1188 - acc: 0.9595 - val_loss: 0.2094 - val_acc: 0.9315\n",
      "Epoch 96/100\n",
      "1751/1751 [==============================] - 1s 350us/step - loss: 0.1249 - acc: 0.9640 - val_loss: 0.2037 - val_acc: 0.9315\n",
      "Epoch 97/100\n",
      "1751/1751 [==============================] - 1s 364us/step - loss: 0.1287 - acc: 0.9577 - val_loss: 0.1725 - val_acc: 0.9452\n",
      "Epoch 98/100\n",
      "1751/1751 [==============================] - 1s 333us/step - loss: 0.1159 - acc: 0.9629 - val_loss: 0.2132 - val_acc: 0.9315\n",
      "Epoch 99/100\n",
      "1751/1751 [==============================] - 1s 332us/step - loss: 0.1162 - acc: 0.9634 - val_loss: 0.1953 - val_acc: 0.9384\n",
      "Epoch 100/100\n",
      "1751/1751 [==============================] - 1s 348us/step - loss: 0.1214 - acc: 0.9634 - val_loss: 0.1922 - val_acc: 0.9429\n",
      "Train on 1751 samples, validate on 438 samples\n",
      "Epoch 1/100\n",
      "1751/1751 [==============================] - 1s 331us/step - loss: 0.1690 - acc: 0.9537 - val_loss: 0.1628 - val_acc: 0.9498\n",
      "Epoch 2/100\n",
      "1751/1751 [==============================] - 1s 334us/step - loss: 0.1618 - acc: 0.9492 - val_loss: 0.1505 - val_acc: 0.9498\n",
      "Epoch 3/100\n",
      "1751/1751 [==============================] - 1s 343us/step - loss: 0.1557 - acc: 0.9520 - val_loss: 0.1488 - val_acc: 0.9543\n",
      "Epoch 4/100\n",
      "1751/1751 [==============================] - 1s 328us/step - loss: 0.1664 - acc: 0.9429 - val_loss: 0.1450 - val_acc: 0.9566\n",
      "Epoch 5/100\n",
      "1751/1751 [==============================] - 1s 343us/step - loss: 0.1535 - acc: 0.9520 - val_loss: 0.1408 - val_acc: 0.9635\n",
      "Epoch 6/100\n",
      "1751/1751 [==============================] - 1s 336us/step - loss: 0.1619 - acc: 0.9457 - val_loss: 0.1465 - val_acc: 0.9566\n",
      "Epoch 7/100\n",
      "1751/1751 [==============================] - 1s 324us/step - loss: 0.1577 - acc: 0.9423 - val_loss: 0.1424 - val_acc: 0.9566\n",
      "Epoch 8/100\n",
      "1751/1751 [==============================] - 1s 330us/step - loss: 0.1624 - acc: 0.9497 - val_loss: 0.1340 - val_acc: 0.9612\n",
      "Epoch 9/100\n",
      "1751/1751 [==============================] - 1s 332us/step - loss: 0.1541 - acc: 0.9503 - val_loss: 0.1365 - val_acc: 0.9612\n",
      "Epoch 10/100\n",
      "1751/1751 [==============================] - 1s 330us/step - loss: 0.1714 - acc: 0.9417 - val_loss: 0.1539 - val_acc: 0.9498\n",
      "Epoch 11/100\n",
      "1751/1751 [==============================] - 1s 340us/step - loss: 0.1530 - acc: 0.9503 - val_loss: 0.1387 - val_acc: 0.9612\n",
      "Epoch 12/100\n",
      "1751/1751 [==============================] - 1s 325us/step - loss: 0.1480 - acc: 0.9515 - val_loss: 0.1507 - val_acc: 0.9521\n",
      "Epoch 13/100\n",
      "1751/1751 [==============================] - 1s 327us/step - loss: 0.1530 - acc: 0.9492 - val_loss: 0.1515 - val_acc: 0.9498\n",
      "Epoch 14/100\n",
      "1751/1751 [==============================] - 1s 334us/step - loss: 0.1409 - acc: 0.9560 - val_loss: 0.1455 - val_acc: 0.9589\n",
      "Epoch 15/100\n",
      "1751/1751 [==============================] - 1s 328us/step - loss: 0.1372 - acc: 0.9555 - val_loss: 0.1389 - val_acc: 0.9566\n",
      "Epoch 16/100\n",
      "1751/1751 [==============================] - 1s 329us/step - loss: 0.1444 - acc: 0.9509 - val_loss: 0.1494 - val_acc: 0.9543\n",
      "Epoch 17/100\n",
      "1751/1751 [==============================] - 1s 331us/step - loss: 0.1397 - acc: 0.9532 - val_loss: 0.1462 - val_acc: 0.9543\n",
      "Epoch 18/100\n",
      "1751/1751 [==============================] - 1s 326us/step - loss: 0.1480 - acc: 0.9555 - val_loss: 0.1296 - val_acc: 0.9589\n",
      "Epoch 19/100\n",
      "1751/1751 [==============================] - 1s 328us/step - loss: 0.1466 - acc: 0.9469 - val_loss: 0.1366 - val_acc: 0.9612\n",
      "Epoch 20/100\n",
      "1751/1751 [==============================] - 1s 338us/step - loss: 0.1481 - acc: 0.9537 - val_loss: 0.1364 - val_acc: 0.9566\n",
      "Epoch 21/100\n",
      "1751/1751 [==============================] - 1s 323us/step - loss: 0.1369 - acc: 0.9566 - val_loss: 0.1354 - val_acc: 0.9566\n",
      "Epoch 22/100\n",
      "1751/1751 [==============================] - 1s 324us/step - loss: 0.1309 - acc: 0.9606 - val_loss: 0.1306 - val_acc: 0.9589\n",
      "Epoch 23/100\n",
      "1751/1751 [==============================] - 1s 323us/step - loss: 0.1376 - acc: 0.9600 - val_loss: 0.1354 - val_acc: 0.9589\n",
      "Epoch 24/100\n",
      "1751/1751 [==============================] - 1s 333us/step - loss: 0.1342 - acc: 0.9543 - val_loss: 0.1408 - val_acc: 0.9589\n",
      "Epoch 25/100\n",
      "1751/1751 [==============================] - 1s 338us/step - loss: 0.1330 - acc: 0.9560 - val_loss: 0.1311 - val_acc: 0.9612\n",
      "Epoch 26/100\n",
      "1751/1751 [==============================] - 1s 325us/step - loss: 0.1317 - acc: 0.9612 - val_loss: 0.1471 - val_acc: 0.9498\n",
      "Epoch 27/100\n",
      "1751/1751 [==============================] - 1s 330us/step - loss: 0.1335 - acc: 0.9606 - val_loss: 0.1344 - val_acc: 0.9589\n",
      "Epoch 28/100\n",
      "1751/1751 [==============================] - ETA: 0s - loss: 0.1301 - acc: 0.957 - 1s 328us/step - loss: 0.1271 - acc: 0.9583 - val_loss: 0.1361 - val_acc: 0.9543\n",
      "Epoch 29/100\n",
      "1751/1751 [==============================] - 1s 331us/step - loss: 0.1312 - acc: 0.9577 - val_loss: 0.1425 - val_acc: 0.9521\n",
      "Epoch 30/100\n",
      "1751/1751 [==============================] - 1s 331us/step - loss: 0.1265 - acc: 0.9583 - val_loss: 0.1307 - val_acc: 0.9612\n",
      "Epoch 31/100\n",
      "1751/1751 [==============================] - 1s 334us/step - loss: 0.1328 - acc: 0.9566 - val_loss: 0.1396 - val_acc: 0.9521\n",
      "Epoch 32/100\n",
      "1751/1751 [==============================] - 1s 333us/step - loss: 0.1243 - acc: 0.9600 - val_loss: 0.1311 - val_acc: 0.9566\n",
      "Epoch 33/100\n",
      "1751/1751 [==============================] - 1s 331us/step - loss: 0.1259 - acc: 0.9589 - val_loss: 0.1324 - val_acc: 0.9589\n",
      "Epoch 34/100\n",
      "1751/1751 [==============================] - 1s 326us/step - loss: 0.1254 - acc: 0.9612 - val_loss: 0.1360 - val_acc: 0.9589\n",
      "Epoch 35/100\n",
      "1751/1751 [==============================] - 1s 327us/step - loss: 0.1271 - acc: 0.9617 - val_loss: 0.1296 - val_acc: 0.9566\n",
      "Epoch 36/100\n",
      "1751/1751 [==============================] - 1s 334us/step - loss: 0.1241 - acc: 0.9560 - val_loss: 0.1391 - val_acc: 0.9566\n",
      "Epoch 37/100\n",
      "1751/1751 [==============================] - 1s 335us/step - loss: 0.1240 - acc: 0.9623 - val_loss: 0.1389 - val_acc: 0.9589\n",
      "Epoch 38/100\n",
      "1751/1751 [==============================] - 1s 330us/step - loss: 0.1198 - acc: 0.9640 - val_loss: 0.1332 - val_acc: 0.9589\n",
      "Epoch 39/100\n",
      "1751/1751 [==============================] - 1s 339us/step - loss: 0.1163 - acc: 0.9640 - val_loss: 0.1280 - val_acc: 0.9658\n",
      "Epoch 40/100\n",
      "1751/1751 [==============================] - 1s 327us/step - loss: 0.1205 - acc: 0.9623 - val_loss: 0.1248 - val_acc: 0.9635\n",
      "Epoch 41/100\n",
      "1751/1751 [==============================] - 1s 333us/step - loss: 0.1215 - acc: 0.9600 - val_loss: 0.1331 - val_acc: 0.9612\n",
      "Epoch 42/100\n",
      "1751/1751 [==============================] - 1s 337us/step - loss: 0.1186 - acc: 0.9612 - val_loss: 0.1405 - val_acc: 0.9521\n",
      "Epoch 43/100\n",
      "1751/1751 [==============================] - 1s 320us/step - loss: 0.1222 - acc: 0.9600 - val_loss: 0.1251 - val_acc: 0.9635\n",
      "Epoch 44/100\n",
      "1751/1751 [==============================] - 1s 341us/step - loss: 0.1187 - acc: 0.9640 - val_loss: 0.1302 - val_acc: 0.9566\n",
      "Epoch 45/100\n",
      "1751/1751 [==============================] - 1s 327us/step - loss: 0.1238 - acc: 0.9623 - val_loss: 0.1312 - val_acc: 0.9566\n",
      "Epoch 46/100\n",
      "1751/1751 [==============================] - 1s 330us/step - loss: 0.1183 - acc: 0.9629 - val_loss: 0.1296 - val_acc: 0.9589\n",
      "Epoch 47/100\n",
      "1751/1751 [==============================] - 1s 333us/step - loss: 0.1146 - acc: 0.9640 - val_loss: 0.1221 - val_acc: 0.9680\n",
      "Epoch 48/100\n",
      "1751/1751 [==============================] - 1s 329us/step - loss: 0.1190 - acc: 0.9623 - val_loss: 0.1321 - val_acc: 0.9612\n",
      "Epoch 49/100\n",
      "1751/1751 [==============================] - 1s 329us/step - loss: 0.1105 - acc: 0.9703 - val_loss: 0.1284 - val_acc: 0.9612\n",
      "Epoch 50/100\n",
      "1751/1751 [==============================] - 1s 324us/step - loss: 0.1160 - acc: 0.9652 - val_loss: 0.1298 - val_acc: 0.9635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "1751/1751 [==============================] - 1s 325us/step - loss: 0.1149 - acc: 0.9657 - val_loss: 0.1237 - val_acc: 0.9635\n",
      "Epoch 52/100\n",
      "1751/1751 [==============================] - 1s 333us/step - loss: 0.1155 - acc: 0.9663 - val_loss: 0.1345 - val_acc: 0.9612\n",
      "Epoch 53/100\n",
      "1751/1751 [==============================] - 1s 336us/step - loss: 0.1158 - acc: 0.9623 - val_loss: 0.1303 - val_acc: 0.9635\n",
      "Epoch 54/100\n",
      "1751/1751 [==============================] - 1s 333us/step - loss: 0.1090 - acc: 0.9686 - val_loss: 0.1343 - val_acc: 0.9612\n",
      "Epoch 55/100\n",
      "1751/1751 [==============================] - 1s 328us/step - loss: 0.1108 - acc: 0.9629 - val_loss: 0.1262 - val_acc: 0.9635\n",
      "Epoch 56/100\n",
      "1751/1751 [==============================] - 1s 330us/step - loss: 0.1044 - acc: 0.9680 - val_loss: 0.1398 - val_acc: 0.9589\n",
      "Epoch 57/100\n",
      "1751/1751 [==============================] - 1s 325us/step - loss: 0.1064 - acc: 0.9680 - val_loss: 0.1237 - val_acc: 0.9635\n",
      "Epoch 58/100\n",
      "1751/1751 [==============================] - 1s 329us/step - loss: 0.1073 - acc: 0.9657 - val_loss: 0.1344 - val_acc: 0.9612\n",
      "Epoch 59/100\n",
      "1751/1751 [==============================] - 1s 322us/step - loss: 0.1060 - acc: 0.9680 - val_loss: 0.1283 - val_acc: 0.9635\n",
      "Epoch 60/100\n",
      "1751/1751 [==============================] - 1s 328us/step - loss: 0.1061 - acc: 0.9680 - val_loss: 0.1416 - val_acc: 0.9589\n",
      "Epoch 61/100\n",
      "1751/1751 [==============================] - 1s 329us/step - loss: 0.1233 - acc: 0.9600 - val_loss: 0.1327 - val_acc: 0.9589\n",
      "Epoch 62/100\n",
      "1751/1751 [==============================] - 1s 327us/step - loss: 0.1019 - acc: 0.9686 - val_loss: 0.1266 - val_acc: 0.9635\n",
      "Epoch 63/100\n",
      "1751/1751 [==============================] - 1s 326us/step - loss: 0.1056 - acc: 0.9680 - val_loss: 0.1334 - val_acc: 0.9589\n",
      "Epoch 64/100\n",
      "1751/1751 [==============================] - 1s 331us/step - loss: 0.1136 - acc: 0.9634 - val_loss: 0.1301 - val_acc: 0.9635\n",
      "Epoch 65/100\n",
      "1751/1751 [==============================] - 1s 326us/step - loss: 0.1051 - acc: 0.9692 - val_loss: 0.1135 - val_acc: 0.9658\n",
      "Epoch 66/100\n",
      "1751/1751 [==============================] - 1s 332us/step - loss: 0.1070 - acc: 0.9669 - val_loss: 0.1261 - val_acc: 0.9658\n",
      "Epoch 67/100\n",
      "1751/1751 [==============================] - 1s 323us/step - loss: 0.1078 - acc: 0.9674 - val_loss: 0.1285 - val_acc: 0.9612\n",
      "Epoch 68/100\n",
      "1751/1751 [==============================] - 1s 326us/step - loss: 0.1013 - acc: 0.9680 - val_loss: 0.1221 - val_acc: 0.9635\n",
      "Epoch 69/100\n",
      "1751/1751 [==============================] - 1s 324us/step - loss: 0.1126 - acc: 0.9589 - val_loss: 0.1189 - val_acc: 0.9658\n",
      "Epoch 70/100\n",
      "1751/1751 [==============================] - 1s 327us/step - loss: 0.0994 - acc: 0.9709 - val_loss: 0.1234 - val_acc: 0.9658\n",
      "Epoch 71/100\n",
      "1751/1751 [==============================] - 1s 332us/step - loss: 0.1013 - acc: 0.9709 - val_loss: 0.1217 - val_acc: 0.9635\n",
      "Epoch 72/100\n",
      "1751/1751 [==============================] - 1s 338us/step - loss: 0.1054 - acc: 0.9623 - val_loss: 0.1131 - val_acc: 0.9680\n",
      "Epoch 73/100\n",
      "1751/1751 [==============================] - 1s 329us/step - loss: 0.0990 - acc: 0.9692 - val_loss: 0.1176 - val_acc: 0.9680\n",
      "Epoch 74/100\n",
      "1751/1751 [==============================] - 1s 326us/step - loss: 0.1082 - acc: 0.9663 - val_loss: 0.1295 - val_acc: 0.9635\n",
      "Epoch 75/100\n",
      "1751/1751 [==============================] - 1s 331us/step - loss: 0.0974 - acc: 0.9709 - val_loss: 0.1226 - val_acc: 0.9635\n",
      "Epoch 76/100\n",
      "1751/1751 [==============================] - 1s 336us/step - loss: 0.1062 - acc: 0.9652 - val_loss: 0.1259 - val_acc: 0.9635\n",
      "Epoch 77/100\n",
      "1751/1751 [==============================] - 1s 324us/step - loss: 0.0913 - acc: 0.9737 - val_loss: 0.1202 - val_acc: 0.9658\n",
      "Epoch 78/100\n",
      "1751/1751 [==============================] - 1s 325us/step - loss: 0.0978 - acc: 0.9737 - val_loss: 0.1330 - val_acc: 0.9589\n",
      "Epoch 79/100\n",
      "1751/1751 [==============================] - 1s 338us/step - loss: 0.1013 - acc: 0.9686 - val_loss: 0.1228 - val_acc: 0.9635\n",
      "Epoch 80/100\n",
      "1751/1751 [==============================] - 1s 329us/step - loss: 0.0992 - acc: 0.9714 - val_loss: 0.1320 - val_acc: 0.9612\n",
      "Epoch 81/100\n",
      "1751/1751 [==============================] - 1s 335us/step - loss: 0.1092 - acc: 0.9674 - val_loss: 0.1242 - val_acc: 0.9635\n",
      "Epoch 82/100\n",
      "1751/1751 [==============================] - 1s 324us/step - loss: 0.1008 - acc: 0.9680 - val_loss: 0.1188 - val_acc: 0.9658\n",
      "Epoch 83/100\n",
      "1751/1751 [==============================] - 1s 337us/step - loss: 0.0987 - acc: 0.9709 - val_loss: 0.1256 - val_acc: 0.9658\n",
      "Epoch 84/100\n",
      "1751/1751 [==============================] - 1s 328us/step - loss: 0.0962 - acc: 0.9737 - val_loss: 0.1228 - val_acc: 0.9658\n",
      "Epoch 85/100\n",
      "1751/1751 [==============================] - 1s 326us/step - loss: 0.0995 - acc: 0.9726 - val_loss: 0.1137 - val_acc: 0.9658\n",
      "Epoch 86/100\n",
      "1751/1751 [==============================] - 1s 320us/step - loss: 0.0910 - acc: 0.9720 - val_loss: 0.1262 - val_acc: 0.9635\n",
      "Epoch 87/100\n",
      "1751/1751 [==============================] - 1s 338us/step - loss: 0.0978 - acc: 0.9697 - val_loss: 0.1181 - val_acc: 0.9658\n",
      "Epoch 88/100\n",
      "1751/1751 [==============================] - 1s 335us/step - loss: 0.0956 - acc: 0.9709 - val_loss: 0.1270 - val_acc: 0.9635\n",
      "Epoch 89/100\n",
      "1751/1751 [==============================] - 1s 331us/step - loss: 0.1011 - acc: 0.9669 - val_loss: 0.1303 - val_acc: 0.9635\n",
      "Epoch 90/100\n",
      "1751/1751 [==============================] - 1s 328us/step - loss: 0.0929 - acc: 0.9720 - val_loss: 0.1215 - val_acc: 0.9635\n",
      "Epoch 91/100\n",
      "1751/1751 [==============================] - 1s 332us/step - loss: 0.0971 - acc: 0.9703 - val_loss: 0.1251 - val_acc: 0.9612\n",
      "Epoch 92/100\n",
      "1751/1751 [==============================] - 1s 320us/step - loss: 0.0900 - acc: 0.9732 - val_loss: 0.1260 - val_acc: 0.9658\n",
      "Epoch 93/100\n",
      "1751/1751 [==============================] - 1s 325us/step - loss: 0.0962 - acc: 0.9703 - val_loss: 0.1225 - val_acc: 0.9658\n",
      "Epoch 94/100\n",
      "1751/1751 [==============================] - 1s 331us/step - loss: 0.0969 - acc: 0.9697 - val_loss: 0.1240 - val_acc: 0.9635\n",
      "Epoch 95/100\n",
      "1751/1751 [==============================] - 1s 333us/step - loss: 0.0922 - acc: 0.9726 - val_loss: 0.1203 - val_acc: 0.9635\n",
      "Epoch 96/100\n",
      "1751/1751 [==============================] - 1s 333us/step - loss: 0.0899 - acc: 0.9777 - val_loss: 0.1213 - val_acc: 0.9658\n",
      "Epoch 97/100\n",
      "1751/1751 [==============================] - 1s 332us/step - loss: 0.0922 - acc: 0.9709 - val_loss: 0.1264 - val_acc: 0.9635\n",
      "Epoch 98/100\n",
      "1751/1751 [==============================] - 1s 333us/step - loss: 0.0857 - acc: 0.9720 - val_loss: 0.1249 - val_acc: 0.9635\n",
      "Epoch 99/100\n",
      "1751/1751 [==============================] - 1s 329us/step - loss: 0.0856 - acc: 0.9726 - val_loss: 0.1166 - val_acc: 0.9680\n",
      "Epoch 100/100\n",
      "1751/1751 [==============================] - 1s 331us/step - loss: 0.0965 - acc: 0.9703 - val_loss: 0.1107 - val_acc: 0.9703\n",
      "Test subject 9, class FirstDigitTouch\n",
      "Train subject 9, class BothStartLoadPhase\n",
      "Train on 1752 samples, validate on 438 samples\n",
      "Epoch 1/100\n",
      "1752/1752 [==============================] - 1s 523us/step - loss: 0.7020 - acc: 0.7363 - val_loss: 0.5275 - val_acc: 0.7671\n",
      "Epoch 2/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.4747 - acc: 0.7979 - val_loss: 0.4650 - val_acc: 0.8059\n",
      "Epoch 3/100\n",
      "1752/1752 [==============================] - 1s 335us/step - loss: 0.4427 - acc: 0.8082 - val_loss: 0.4358 - val_acc: 0.8379\n",
      "Epoch 4/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.3962 - acc: 0.8379 - val_loss: 0.4181 - val_acc: 0.8379\n",
      "Epoch 5/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.3804 - acc: 0.8385 - val_loss: 0.3981 - val_acc: 0.8562\n",
      "Epoch 6/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.3785 - acc: 0.8482 - val_loss: 0.3915 - val_acc: 0.8562\n",
      "Epoch 7/100\n",
      "1752/1752 [==============================] - 1s 321us/step - loss: 0.3623 - acc: 0.8505 - val_loss: 0.3838 - val_acc: 0.8516\n",
      "Epoch 8/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.3385 - acc: 0.8744 - val_loss: 0.3662 - val_acc: 0.8676\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.3306 - acc: 0.8676 - val_loss: 0.3566 - val_acc: 0.8744\n",
      "Epoch 10/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.3160 - acc: 0.8784 - val_loss: 0.3478 - val_acc: 0.8790\n",
      "Epoch 11/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.3083 - acc: 0.8836 - val_loss: 0.3416 - val_acc: 0.8836\n",
      "Epoch 12/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.3025 - acc: 0.8847 - val_loss: 0.3407 - val_acc: 0.8813\n",
      "Epoch 13/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.2934 - acc: 0.8893 - val_loss: 0.3310 - val_acc: 0.8858\n",
      "Epoch 14/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.2949 - acc: 0.8944 - val_loss: 0.3219 - val_acc: 0.8904\n",
      "Epoch 15/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.2857 - acc: 0.8990 - val_loss: 0.3193 - val_acc: 0.8904\n",
      "Epoch 16/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.2971 - acc: 0.8927 - val_loss: 0.3149 - val_acc: 0.8927\n",
      "Epoch 17/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.2745 - acc: 0.8944 - val_loss: 0.3065 - val_acc: 0.8995\n",
      "Epoch 18/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.2607 - acc: 0.9092 - val_loss: 0.3073 - val_acc: 0.8927\n",
      "Epoch 19/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.2648 - acc: 0.9092 - val_loss: 0.3020 - val_acc: 0.8950\n",
      "Epoch 20/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.2599 - acc: 0.9041 - val_loss: 0.2939 - val_acc: 0.9041\n",
      "Epoch 21/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.2477 - acc: 0.9184 - val_loss: 0.2889 - val_acc: 0.9064\n",
      "Epoch 22/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.2489 - acc: 0.9104 - val_loss: 0.2865 - val_acc: 0.9064\n",
      "Epoch 23/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.2513 - acc: 0.9058 - val_loss: 0.2833 - val_acc: 0.9087\n",
      "Epoch 24/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.2333 - acc: 0.9144 - val_loss: 0.2850 - val_acc: 0.9041\n",
      "Epoch 25/100\n",
      "1752/1752 [==============================] - ETA: 0s - loss: 0.2286 - acc: 0.920 - 1s 331us/step - loss: 0.2328 - acc: 0.9184 - val_loss: 0.2837 - val_acc: 0.9041\n",
      "Epoch 26/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.2313 - acc: 0.9224 - val_loss: 0.2748 - val_acc: 0.9110\n",
      "Epoch 27/100\n",
      "1752/1752 [==============================] - 1s 339us/step - loss: 0.2387 - acc: 0.9138 - val_loss: 0.2723 - val_acc: 0.9110\n",
      "Epoch 28/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.2288 - acc: 0.9201 - val_loss: 0.2691 - val_acc: 0.9132\n",
      "Epoch 29/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.2120 - acc: 0.9344 - val_loss: 0.2658 - val_acc: 0.9064\n",
      "Epoch 30/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.2182 - acc: 0.9252 - val_loss: 0.2623 - val_acc: 0.9087\n",
      "Epoch 31/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.2141 - acc: 0.9241 - val_loss: 0.2619 - val_acc: 0.9110\n",
      "Epoch 32/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.2182 - acc: 0.9247 - val_loss: 0.2539 - val_acc: 0.9132\n",
      "Epoch 33/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.2085 - acc: 0.9275 - val_loss: 0.2532 - val_acc: 0.9132\n",
      "Epoch 34/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.2090 - acc: 0.9229 - val_loss: 0.2549 - val_acc: 0.9132\n",
      "Epoch 35/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.2181 - acc: 0.9172 - val_loss: 0.2520 - val_acc: 0.9155\n",
      "Epoch 36/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.2084 - acc: 0.9247 - val_loss: 0.2429 - val_acc: 0.9201\n",
      "Epoch 37/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.1990 - acc: 0.9287 - val_loss: 0.2413 - val_acc: 0.9178\n",
      "Epoch 38/100\n",
      "1752/1752 [==============================] - 1s 335us/step - loss: 0.2048 - acc: 0.9252 - val_loss: 0.2386 - val_acc: 0.9201\n",
      "Epoch 39/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.1901 - acc: 0.9395 - val_loss: 0.2425 - val_acc: 0.9178\n",
      "Epoch 40/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.1945 - acc: 0.9269 - val_loss: 0.2414 - val_acc: 0.9201\n",
      "Epoch 41/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.1908 - acc: 0.9355 - val_loss: 0.2330 - val_acc: 0.9224\n",
      "Epoch 42/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.1884 - acc: 0.9366 - val_loss: 0.2378 - val_acc: 0.9178\n",
      "Epoch 43/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.1872 - acc: 0.9304 - val_loss: 0.2372 - val_acc: 0.9201\n",
      "Epoch 44/100\n",
      "1752/1752 [==============================] - 1s 341us/step - loss: 0.1862 - acc: 0.9366 - val_loss: 0.2283 - val_acc: 0.9247\n",
      "Epoch 45/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.1905 - acc: 0.9389 - val_loss: 0.2268 - val_acc: 0.9292\n",
      "Epoch 46/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.1748 - acc: 0.9389 - val_loss: 0.2205 - val_acc: 0.9292\n",
      "Epoch 47/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.1824 - acc: 0.9326 - val_loss: 0.2203 - val_acc: 0.9292\n",
      "Epoch 48/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.1832 - acc: 0.9372 - val_loss: 0.2223 - val_acc: 0.9292\n",
      "Epoch 49/100\n",
      "1752/1752 [==============================] - 1s 341us/step - loss: 0.1721 - acc: 0.9401 - val_loss: 0.2215 - val_acc: 0.9224\n",
      "Epoch 50/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.1685 - acc: 0.9412 - val_loss: 0.2210 - val_acc: 0.9315\n",
      "Epoch 51/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.1734 - acc: 0.9441 - val_loss: 0.2188 - val_acc: 0.9247\n",
      "Epoch 52/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.1710 - acc: 0.9412 - val_loss: 0.2139 - val_acc: 0.9292\n",
      "Epoch 53/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.1670 - acc: 0.9424 - val_loss: 0.2137 - val_acc: 0.9247\n",
      "Epoch 54/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.1669 - acc: 0.9441 - val_loss: 0.2101 - val_acc: 0.9315\n",
      "Epoch 55/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.1689 - acc: 0.9378 - val_loss: 0.2111 - val_acc: 0.9292\n",
      "Epoch 56/100\n",
      "1752/1752 [==============================] - 1s 340us/step - loss: 0.1594 - acc: 0.9481 - val_loss: 0.2069 - val_acc: 0.9292\n",
      "Epoch 57/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.1670 - acc: 0.9395 - val_loss: 0.2100 - val_acc: 0.9269\n",
      "Epoch 58/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.1619 - acc: 0.9372 - val_loss: 0.2046 - val_acc: 0.9361\n",
      "Epoch 59/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.1560 - acc: 0.9452 - val_loss: 0.2053 - val_acc: 0.9338\n",
      "Epoch 60/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.1670 - acc: 0.9378 - val_loss: 0.2026 - val_acc: 0.9315\n",
      "Epoch 61/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.1575 - acc: 0.9469 - val_loss: 0.2011 - val_acc: 0.9361\n",
      "Epoch 62/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.1556 - acc: 0.9509 - val_loss: 0.2044 - val_acc: 0.9338\n",
      "Epoch 63/100\n",
      "1752/1752 [==============================] - 1s 339us/step - loss: 0.1546 - acc: 0.9441 - val_loss: 0.1996 - val_acc: 0.9361\n",
      "Epoch 64/100\n",
      "1752/1752 [==============================] - 1s 338us/step - loss: 0.1508 - acc: 0.9515 - val_loss: 0.2032 - val_acc: 0.9338\n",
      "Epoch 65/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.1528 - acc: 0.9526 - val_loss: 0.2026 - val_acc: 0.9361\n",
      "Epoch 66/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.1525 - acc: 0.9475 - val_loss: 0.2014 - val_acc: 0.9315\n",
      "Epoch 67/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.1560 - acc: 0.9469 - val_loss: 0.1953 - val_acc: 0.9315\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1752/1752 [==============================] - 1s 335us/step - loss: 0.1436 - acc: 0.9555 - val_loss: 0.1971 - val_acc: 0.9361\n",
      "Epoch 69/100\n",
      "1752/1752 [==============================] - 1s 342us/step - loss: 0.1537 - acc: 0.9458 - val_loss: 0.1973 - val_acc: 0.9338\n",
      "Epoch 70/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.1473 - acc: 0.9475 - val_loss: 0.1958 - val_acc: 0.9361\n",
      "Epoch 71/100\n",
      "1752/1752 [==============================] - 1s 346us/step - loss: 0.1484 - acc: 0.9498 - val_loss: 0.1969 - val_acc: 0.9384\n",
      "Epoch 72/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.1429 - acc: 0.9543 - val_loss: 0.1950 - val_acc: 0.9384\n",
      "Epoch 73/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.1415 - acc: 0.9532 - val_loss: 0.1959 - val_acc: 0.9361\n",
      "Epoch 74/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.1502 - acc: 0.9446 - val_loss: 0.1966 - val_acc: 0.9361\n",
      "Epoch 75/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.1424 - acc: 0.9492 - val_loss: 0.1925 - val_acc: 0.9361\n",
      "Epoch 76/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.1421 - acc: 0.9486 - val_loss: 0.1926 - val_acc: 0.9361\n",
      "Epoch 77/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.1400 - acc: 0.9549 - val_loss: 0.1924 - val_acc: 0.9384\n",
      "Epoch 78/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.1331 - acc: 0.9566 - val_loss: 0.1930 - val_acc: 0.9338\n",
      "Epoch 79/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.1393 - acc: 0.9526 - val_loss: 0.1914 - val_acc: 0.9384\n",
      "Epoch 80/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.1410 - acc: 0.9503 - val_loss: 0.1880 - val_acc: 0.9384\n",
      "Epoch 81/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.1388 - acc: 0.9532 - val_loss: 0.1861 - val_acc: 0.9429\n",
      "Epoch 82/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.1445 - acc: 0.9566 - val_loss: 0.1898 - val_acc: 0.9361\n",
      "Epoch 83/100\n",
      "1752/1752 [==============================] - 1s 337us/step - loss: 0.1403 - acc: 0.9492 - val_loss: 0.1889 - val_acc: 0.9361\n",
      "Epoch 84/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.1320 - acc: 0.9578 - val_loss: 0.1846 - val_acc: 0.9384\n",
      "Epoch 85/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.1312 - acc: 0.9589 - val_loss: 0.1878 - val_acc: 0.9384\n",
      "Epoch 86/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.1368 - acc: 0.9538 - val_loss: 0.1862 - val_acc: 0.9406\n",
      "Epoch 87/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.1279 - acc: 0.9606 - val_loss: 0.1878 - val_acc: 0.9361\n",
      "Epoch 88/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.1262 - acc: 0.9578 - val_loss: 0.1880 - val_acc: 0.9384\n",
      "Epoch 89/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.1288 - acc: 0.9595 - val_loss: 0.1831 - val_acc: 0.9406\n",
      "Epoch 90/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.1346 - acc: 0.9538 - val_loss: 0.1838 - val_acc: 0.9406\n",
      "Epoch 91/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.1313 - acc: 0.9578 - val_loss: 0.1822 - val_acc: 0.9406\n",
      "Epoch 92/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.1329 - acc: 0.9521 - val_loss: 0.1833 - val_acc: 0.9384\n",
      "Epoch 93/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.1285 - acc: 0.9578 - val_loss: 0.1798 - val_acc: 0.9406\n",
      "Epoch 94/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.1249 - acc: 0.9595 - val_loss: 0.1837 - val_acc: 0.9406\n",
      "Epoch 95/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.1200 - acc: 0.9618 - val_loss: 0.1820 - val_acc: 0.9406\n",
      "Epoch 96/100\n",
      "1752/1752 [==============================] - 1s 339us/step - loss: 0.1241 - acc: 0.9595 - val_loss: 0.1831 - val_acc: 0.9384\n",
      "Epoch 97/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.1251 - acc: 0.9566 - val_loss: 0.1800 - val_acc: 0.9429\n",
      "Epoch 98/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.1281 - acc: 0.9572 - val_loss: 0.1796 - val_acc: 0.9406\n",
      "Epoch 99/100\n",
      "1752/1752 [==============================] - 1s 343us/step - loss: 0.1240 - acc: 0.9566 - val_loss: 0.1771 - val_acc: 0.9429\n",
      "Epoch 100/100\n",
      "1752/1752 [==============================] - 1s 346us/step - loss: 0.1278 - acc: 0.9583 - val_loss: 0.1792 - val_acc: 0.9406\n",
      "Train on 1752 samples, validate on 438 samples\n",
      "Epoch 1/100\n",
      "1752/1752 [==============================] - 1s 354us/step - loss: 0.1897 - acc: 0.9418 - val_loss: 0.1639 - val_acc: 0.9475\n",
      "Epoch 2/100\n",
      "1752/1752 [==============================] - 1s 351us/step - loss: 0.1863 - acc: 0.9401 - val_loss: 0.1542 - val_acc: 0.9566\n",
      "Epoch 3/100\n",
      "1752/1752 [==============================] - 1s 351us/step - loss: 0.1761 - acc: 0.9469 - val_loss: 0.1542 - val_acc: 0.9543\n",
      "Epoch 4/100\n",
      "1752/1752 [==============================] - 1s 353us/step - loss: 0.1782 - acc: 0.9441 - val_loss: 0.1566 - val_acc: 0.9521\n",
      "Epoch 5/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.1744 - acc: 0.9446 - val_loss: 0.1584 - val_acc: 0.9498\n",
      "Epoch 6/100\n",
      "1752/1752 [==============================] - 1s 343us/step - loss: 0.1819 - acc: 0.9458 - val_loss: 0.1600 - val_acc: 0.9429\n",
      "Epoch 7/100\n",
      "1752/1752 [==============================] - 1s 362us/step - loss: 0.1761 - acc: 0.9469 - val_loss: 0.1546 - val_acc: 0.9498\n",
      "Epoch 8/100\n",
      "1752/1752 [==============================] - 1s 355us/step - loss: 0.1722 - acc: 0.9509 - val_loss: 0.1523 - val_acc: 0.9521\n",
      "Epoch 9/100\n",
      "1752/1752 [==============================] - 1s 357us/step - loss: 0.1732 - acc: 0.9481 - val_loss: 0.1537 - val_acc: 0.9475\n",
      "Epoch 10/100\n",
      "1752/1752 [==============================] - 1s 339us/step - loss: 0.1725 - acc: 0.9406 - val_loss: 0.1499 - val_acc: 0.9543\n",
      "Epoch 11/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.1737 - acc: 0.9435 - val_loss: 0.1560 - val_acc: 0.9452\n",
      "Epoch 12/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.1669 - acc: 0.9509 - val_loss: 0.1495 - val_acc: 0.9543\n",
      "Epoch 13/100\n",
      "1752/1752 [==============================] - 1s 339us/step - loss: 0.1648 - acc: 0.9503 - val_loss: 0.1560 - val_acc: 0.9475\n",
      "Epoch 14/100\n",
      "1752/1752 [==============================] - 1s 337us/step - loss: 0.1634 - acc: 0.9509 - val_loss: 0.1520 - val_acc: 0.9521\n",
      "Epoch 15/100\n",
      "1752/1752 [==============================] - 1s 344us/step - loss: 0.1665 - acc: 0.9441 - val_loss: 0.1475 - val_acc: 0.9521\n",
      "Epoch 16/100\n",
      "1752/1752 [==============================] - 1s 348us/step - loss: 0.1633 - acc: 0.9532 - val_loss: 0.1485 - val_acc: 0.9543\n",
      "Epoch 17/100\n",
      "1752/1752 [==============================] - 1s 340us/step - loss: 0.1684 - acc: 0.9532 - val_loss: 0.1512 - val_acc: 0.9498\n",
      "Epoch 18/100\n",
      "1752/1752 [==============================] - 1s 337us/step - loss: 0.1624 - acc: 0.9521 - val_loss: 0.1505 - val_acc: 0.9521\n",
      "Epoch 19/100\n",
      "1752/1752 [==============================] - 1s 346us/step - loss: 0.1610 - acc: 0.9503 - val_loss: 0.1574 - val_acc: 0.9498\n",
      "Epoch 20/100\n",
      "1752/1752 [==============================] - 1s 365us/step - loss: 0.1709 - acc: 0.9469 - val_loss: 0.1555 - val_acc: 0.9452\n",
      "Epoch 21/100\n",
      "1752/1752 [==============================] - 1s 341us/step - loss: 0.1545 - acc: 0.9555 - val_loss: 0.1503 - val_acc: 0.9521\n",
      "Epoch 22/100\n",
      "1752/1752 [==============================] - 1s 401us/step - loss: 0.1607 - acc: 0.9509 - val_loss: 0.1486 - val_acc: 0.9521\n",
      "Epoch 23/100\n",
      "1752/1752 [==============================] - 1s 388us/step - loss: 0.1553 - acc: 0.9509 - val_loss: 0.1496 - val_acc: 0.9521\n",
      "Epoch 24/100\n",
      "1752/1752 [==============================] - 1s 349us/step - loss: 0.1558 - acc: 0.9532 - val_loss: 0.1481 - val_acc: 0.9521\n",
      "Epoch 25/100\n",
      "1752/1752 [==============================] - 1s 371us/step - loss: 0.1629 - acc: 0.9463 - val_loss: 0.1436 - val_acc: 0.9543\n",
      "Epoch 26/100\n",
      "1752/1752 [==============================] - 1s 367us/step - loss: 0.1567 - acc: 0.9521 - val_loss: 0.1492 - val_acc: 0.9521\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1752/1752 [==============================] - 1s 367us/step - loss: 0.1572 - acc: 0.9486 - val_loss: 0.1430 - val_acc: 0.9543\n",
      "Epoch 28/100\n",
      "1752/1752 [==============================] - 1s 341us/step - loss: 0.1582 - acc: 0.9492 - val_loss: 0.1391 - val_acc: 0.9543\n",
      "Epoch 29/100\n",
      "1752/1752 [==============================] - 1s 339us/step - loss: 0.1514 - acc: 0.9543 - val_loss: 0.1412 - val_acc: 0.9566\n",
      "Epoch 30/100\n",
      "1752/1752 [==============================] - 1s 348us/step - loss: 0.1609 - acc: 0.9538 - val_loss: 0.1412 - val_acc: 0.9566\n",
      "Epoch 31/100\n",
      "1752/1752 [==============================] - 1s 347us/step - loss: 0.1534 - acc: 0.9566 - val_loss: 0.1385 - val_acc: 0.9566\n",
      "Epoch 32/100\n",
      "1752/1752 [==============================] - 1s 344us/step - loss: 0.1500 - acc: 0.9526 - val_loss: 0.1453 - val_acc: 0.9566\n",
      "Epoch 33/100\n",
      "1752/1752 [==============================] - 1s 348us/step - loss: 0.1530 - acc: 0.9549 - val_loss: 0.1424 - val_acc: 0.9566\n",
      "Epoch 34/100\n",
      "1752/1752 [==============================] - 1s 353us/step - loss: 0.1519 - acc: 0.9538 - val_loss: 0.1405 - val_acc: 0.9589\n",
      "Epoch 35/100\n",
      "1752/1752 [==============================] - 1s 335us/step - loss: 0.1575 - acc: 0.9532 - val_loss: 0.1415 - val_acc: 0.9566\n",
      "Epoch 36/100\n",
      "1752/1752 [==============================] - 1s 347us/step - loss: 0.1508 - acc: 0.9572 - val_loss: 0.1427 - val_acc: 0.9566\n",
      "Epoch 37/100\n",
      "1752/1752 [==============================] - 1s 358us/step - loss: 0.1536 - acc: 0.9532 - val_loss: 0.1495 - val_acc: 0.9543\n",
      "Epoch 38/100\n",
      "1752/1752 [==============================] - 1s 377us/step - loss: 0.1460 - acc: 0.9566 - val_loss: 0.1511 - val_acc: 0.9521\n",
      "Epoch 39/100\n",
      "1752/1752 [==============================] - 1s 351us/step - loss: 0.1479 - acc: 0.9589 - val_loss: 0.1449 - val_acc: 0.9543\n",
      "Epoch 40/100\n",
      "1752/1752 [==============================] - 1s 360us/step - loss: 0.1525 - acc: 0.9515 - val_loss: 0.1429 - val_acc: 0.9566\n",
      "Epoch 41/100\n",
      "1752/1752 [==============================] - 1s 362us/step - loss: 0.1443 - acc: 0.9578 - val_loss: 0.1398 - val_acc: 0.9566\n",
      "Epoch 42/100\n",
      "1752/1752 [==============================] - 1s 350us/step - loss: 0.1422 - acc: 0.9618 - val_loss: 0.1419 - val_acc: 0.9543\n",
      "Epoch 43/100\n",
      "1752/1752 [==============================] - 1s 363us/step - loss: 0.1415 - acc: 0.9555 - val_loss: 0.1420 - val_acc: 0.9543\n",
      "Epoch 44/100\n",
      "1752/1752 [==============================] - 1s 348us/step - loss: 0.1391 - acc: 0.9566 - val_loss: 0.1460 - val_acc: 0.9566\n",
      "Epoch 45/100\n",
      "1752/1752 [==============================] - 1s 349us/step - loss: 0.1500 - acc: 0.9589 - val_loss: 0.1360 - val_acc: 0.9612\n",
      "Epoch 46/100\n",
      "1752/1752 [==============================] - 1s 349us/step - loss: 0.1445 - acc: 0.9572 - val_loss: 0.1400 - val_acc: 0.9589\n",
      "Epoch 47/100\n",
      "1752/1752 [==============================] - 1s 342us/step - loss: 0.1503 - acc: 0.9561 - val_loss: 0.1412 - val_acc: 0.9589\n",
      "Epoch 48/100\n",
      "1752/1752 [==============================] - 1s 347us/step - loss: 0.1385 - acc: 0.9572 - val_loss: 0.1368 - val_acc: 0.9589\n",
      "Epoch 49/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.1374 - acc: 0.9612 - val_loss: 0.1434 - val_acc: 0.9589\n",
      "Epoch 50/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.1393 - acc: 0.9629 - val_loss: 0.1404 - val_acc: 0.9589\n",
      "Epoch 51/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.1416 - acc: 0.9606 - val_loss: 0.1391 - val_acc: 0.9566\n",
      "Epoch 52/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.1401 - acc: 0.9589 - val_loss: 0.1382 - val_acc: 0.9566\n",
      "Epoch 53/100\n",
      "1752/1752 [==============================] - 1s 337us/step - loss: 0.1397 - acc: 0.9555 - val_loss: 0.1427 - val_acc: 0.9566\n",
      "Epoch 54/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.1433 - acc: 0.9555 - val_loss: 0.1368 - val_acc: 0.9589\n",
      "Epoch 55/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.1348 - acc: 0.9618 - val_loss: 0.1399 - val_acc: 0.9589\n",
      "Epoch 56/100\n",
      "1752/1752 [==============================] - 1s 339us/step - loss: 0.1354 - acc: 0.9635 - val_loss: 0.1401 - val_acc: 0.9589\n",
      "Epoch 57/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.1367 - acc: 0.9595 - val_loss: 0.1399 - val_acc: 0.9589\n",
      "Epoch 58/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.1407 - acc: 0.9623 - val_loss: 0.1406 - val_acc: 0.9566\n",
      "Epoch 59/100\n",
      "1752/1752 [==============================] - 1s 348us/step - loss: 0.1346 - acc: 0.9618 - val_loss: 0.1437 - val_acc: 0.9589\n",
      "Epoch 60/100\n",
      "1752/1752 [==============================] - 1s 346us/step - loss: 0.1363 - acc: 0.9561 - val_loss: 0.1383 - val_acc: 0.9589\n",
      "Epoch 61/100\n",
      "1752/1752 [==============================] - 1s 344us/step - loss: 0.1383 - acc: 0.9572 - val_loss: 0.1424 - val_acc: 0.9589\n",
      "Epoch 62/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.1411 - acc: 0.9561 - val_loss: 0.1378 - val_acc: 0.9566\n",
      "Epoch 63/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.1334 - acc: 0.9623 - val_loss: 0.1504 - val_acc: 0.9543\n",
      "Epoch 64/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.1368 - acc: 0.9561 - val_loss: 0.1355 - val_acc: 0.9589\n",
      "Epoch 65/100\n",
      "1752/1752 [==============================] - 1s 320us/step - loss: 0.1326 - acc: 0.9600 - val_loss: 0.1369 - val_acc: 0.9589\n",
      "Epoch 66/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.1356 - acc: 0.9618 - val_loss: 0.1332 - val_acc: 0.9566\n",
      "Epoch 67/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.1257 - acc: 0.9658 - val_loss: 0.1392 - val_acc: 0.9566\n",
      "Epoch 68/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.1339 - acc: 0.9583 - val_loss: 0.1370 - val_acc: 0.9589\n",
      "Epoch 69/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.1300 - acc: 0.9589 - val_loss: 0.1384 - val_acc: 0.9589\n",
      "Epoch 70/100\n",
      "1752/1752 [==============================] - 1s 321us/step - loss: 0.1375 - acc: 0.9640 - val_loss: 0.1402 - val_acc: 0.9589\n",
      "Epoch 71/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.1297 - acc: 0.9629 - val_loss: 0.1411 - val_acc: 0.9589\n",
      "Epoch 72/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.1265 - acc: 0.9595 - val_loss: 0.1384 - val_acc: 0.9566\n",
      "Epoch 73/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.1313 - acc: 0.9635 - val_loss: 0.1374 - val_acc: 0.9566\n",
      "Epoch 74/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.1298 - acc: 0.9600 - val_loss: 0.1410 - val_acc: 0.9566\n",
      "Epoch 75/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.1325 - acc: 0.9635 - val_loss: 0.1372 - val_acc: 0.9589\n",
      "Epoch 76/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.1226 - acc: 0.9686 - val_loss: 0.1382 - val_acc: 0.9566\n",
      "Epoch 77/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.1306 - acc: 0.9629 - val_loss: 0.1414 - val_acc: 0.9566\n",
      "Epoch 78/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.1376 - acc: 0.9595 - val_loss: 0.1412 - val_acc: 0.9566\n",
      "Epoch 79/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.1287 - acc: 0.9635 - val_loss: 0.1332 - val_acc: 0.9589\n",
      "Epoch 80/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.1290 - acc: 0.9618 - val_loss: 0.1297 - val_acc: 0.9589\n",
      "Epoch 81/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.1210 - acc: 0.9669 - val_loss: 0.1387 - val_acc: 0.9566\n",
      "Epoch 82/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.1247 - acc: 0.9618 - val_loss: 0.1367 - val_acc: 0.9566\n",
      "Epoch 83/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.1258 - acc: 0.9640 - val_loss: 0.1393 - val_acc: 0.9566\n",
      "Epoch 84/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.1352 - acc: 0.9623 - val_loss: 0.1383 - val_acc: 0.9566\n",
      "Epoch 85/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.1241 - acc: 0.9640 - val_loss: 0.1308 - val_acc: 0.9589\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.1260 - acc: 0.9658 - val_loss: 0.1320 - val_acc: 0.9589\n",
      "Epoch 87/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.1248 - acc: 0.9680 - val_loss: 0.1388 - val_acc: 0.9566\n",
      "Epoch 88/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.1278 - acc: 0.9618 - val_loss: 0.1443 - val_acc: 0.9566\n",
      "Epoch 89/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.1292 - acc: 0.9618 - val_loss: 0.1397 - val_acc: 0.9566\n",
      "Epoch 90/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.1240 - acc: 0.9612 - val_loss: 0.1307 - val_acc: 0.9589\n",
      "Epoch 91/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.1244 - acc: 0.9600 - val_loss: 0.1330 - val_acc: 0.9566\n",
      "Epoch 92/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.1231 - acc: 0.9652 - val_loss: 0.1332 - val_acc: 0.9589\n",
      "Epoch 93/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.1255 - acc: 0.9623 - val_loss: 0.1332 - val_acc: 0.9566\n",
      "Epoch 94/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.1207 - acc: 0.9623 - val_loss: 0.1366 - val_acc: 0.9566\n",
      "Epoch 95/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.1210 - acc: 0.9629 - val_loss: 0.1410 - val_acc: 0.9566\n",
      "Epoch 96/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.1209 - acc: 0.9640 - val_loss: 0.1315 - val_acc: 0.9589\n",
      "Epoch 97/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.1219 - acc: 0.9663 - val_loss: 0.1357 - val_acc: 0.9543\n",
      "Epoch 98/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.1227 - acc: 0.9658 - val_loss: 0.1390 - val_acc: 0.9543\n",
      "Epoch 99/100\n",
      "1752/1752 [==============================] - 1s 321us/step - loss: 0.1159 - acc: 0.9629 - val_loss: 0.1331 - val_acc: 0.9589\n",
      "Epoch 100/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.1203 - acc: 0.9623 - val_loss: 0.1263 - val_acc: 0.9566\n",
      "Test subject 9, class BothStartLoadPhase\n",
      "Train subject 9, class LiftOff\n",
      "Train on 1751 samples, validate on 438 samples\n",
      "Epoch 1/100\n",
      "1751/1751 [==============================] - 1s 539us/step - loss: 0.5452 - acc: 0.7596 - val_loss: 0.3976 - val_acc: 0.8128\n",
      "Epoch 2/100\n",
      "1751/1751 [==============================] - 1s 320us/step - loss: 0.4207 - acc: 0.8184 - val_loss: 0.3646 - val_acc: 0.8379\n",
      "Epoch 3/100\n",
      "1751/1751 [==============================] - 1s 321us/step - loss: 0.3672 - acc: 0.8441 - val_loss: 0.3373 - val_acc: 0.8607\n",
      "Epoch 4/100\n",
      "1751/1751 [==============================] - 1s 335us/step - loss: 0.3442 - acc: 0.8641 - val_loss: 0.3191 - val_acc: 0.8721\n",
      "Epoch 5/100\n",
      "1751/1751 [==============================] - 1s 332us/step - loss: 0.3260 - acc: 0.8778 - val_loss: 0.3124 - val_acc: 0.8721\n",
      "Epoch 6/100\n",
      "1751/1751 [==============================] - 1s 319us/step - loss: 0.3169 - acc: 0.8812 - val_loss: 0.2967 - val_acc: 0.8836\n",
      "Epoch 7/100\n",
      "1751/1751 [==============================] - 1s 327us/step - loss: 0.3262 - acc: 0.8721 - val_loss: 0.2845 - val_acc: 0.8813\n",
      "Epoch 8/100\n",
      "1751/1751 [==============================] - 1s 327us/step - loss: 0.2994 - acc: 0.8903 - val_loss: 0.2845 - val_acc: 0.8790\n",
      "Epoch 9/100\n",
      "1751/1751 [==============================] - 1s 320us/step - loss: 0.2922 - acc: 0.8966 - val_loss: 0.2869 - val_acc: 0.8836\n",
      "Epoch 10/100\n",
      "1751/1751 [==============================] - 1s 335us/step - loss: 0.2822 - acc: 0.8955 - val_loss: 0.2745 - val_acc: 0.8881\n",
      "Epoch 11/100\n",
      "1751/1751 [==============================] - 1s 324us/step - loss: 0.2809 - acc: 0.8972 - val_loss: 0.2779 - val_acc: 0.8950\n",
      "Epoch 12/100\n",
      "1751/1751 [==============================] - 1s 329us/step - loss: 0.2644 - acc: 0.9046 - val_loss: 0.2735 - val_acc: 0.8881\n",
      "Epoch 13/100\n",
      "1751/1751 [==============================] - 1s 322us/step - loss: 0.2557 - acc: 0.9115 - val_loss: 0.2586 - val_acc: 0.8927\n",
      "Epoch 14/100\n",
      "1751/1751 [==============================] - 1s 322us/step - loss: 0.2559 - acc: 0.9018 - val_loss: 0.2555 - val_acc: 0.9018\n",
      "Epoch 15/100\n",
      "1751/1751 [==============================] - 1s 326us/step - loss: 0.2473 - acc: 0.9052 - val_loss: 0.2690 - val_acc: 0.8973\n",
      "Epoch 16/100\n",
      "1751/1751 [==============================] - 1s 323us/step - loss: 0.2467 - acc: 0.9115 - val_loss: 0.2647 - val_acc: 0.8995\n",
      "Epoch 17/100\n",
      "1751/1751 [==============================] - 1s 322us/step - loss: 0.2360 - acc: 0.9172 - val_loss: 0.2574 - val_acc: 0.9064\n",
      "Epoch 18/100\n",
      "1751/1751 [==============================] - 1s 327us/step - loss: 0.2589 - acc: 0.9086 - val_loss: 0.2529 - val_acc: 0.9041\n",
      "Epoch 19/100\n",
      "1751/1751 [==============================] - 1s 328us/step - loss: 0.2345 - acc: 0.9183 - val_loss: 0.2569 - val_acc: 0.9064\n",
      "Epoch 20/100\n",
      "1751/1751 [==============================] - 1s 326us/step - loss: 0.2225 - acc: 0.9229 - val_loss: 0.2439 - val_acc: 0.9110\n",
      "Epoch 21/100\n",
      "1751/1751 [==============================] - 1s 322us/step - loss: 0.2290 - acc: 0.9195 - val_loss: 0.2570 - val_acc: 0.9041\n",
      "Epoch 22/100\n",
      "1751/1751 [==============================] - 1s 323us/step - loss: 0.2256 - acc: 0.9206 - val_loss: 0.2573 - val_acc: 0.9018\n",
      "Epoch 23/100\n",
      "1751/1751 [==============================] - 1s 331us/step - loss: 0.2284 - acc: 0.9212 - val_loss: 0.2574 - val_acc: 0.9041\n",
      "Epoch 24/100\n",
      "1751/1751 [==============================] - 1s 321us/step - loss: 0.2275 - acc: 0.9166 - val_loss: 0.2408 - val_acc: 0.9087\n",
      "Epoch 25/100\n",
      "1751/1751 [==============================] - 1s 322us/step - loss: 0.2166 - acc: 0.9212 - val_loss: 0.2487 - val_acc: 0.9064\n",
      "Epoch 26/100\n",
      "1751/1751 [==============================] - 1s 321us/step - loss: 0.2089 - acc: 0.9269 - val_loss: 0.2429 - val_acc: 0.9110\n",
      "Epoch 27/100\n",
      "1751/1751 [==============================] - 1s 327us/step - loss: 0.2059 - acc: 0.9309 - val_loss: 0.2411 - val_acc: 0.9041\n",
      "Epoch 28/100\n",
      "1751/1751 [==============================] - 1s 322us/step - loss: 0.2129 - acc: 0.9246 - val_loss: 0.2358 - val_acc: 0.9064\n",
      "Epoch 29/100\n",
      "1751/1751 [==============================] - 1s 328us/step - loss: 0.2135 - acc: 0.9206 - val_loss: 0.2514 - val_acc: 0.9064\n",
      "Epoch 30/100\n",
      "1751/1751 [==============================] - 1s 326us/step - loss: 0.2053 - acc: 0.9229 - val_loss: 0.2290 - val_acc: 0.9132\n",
      "Epoch 31/100\n",
      "1751/1751 [==============================] - 1s 327us/step - loss: 0.2047 - acc: 0.9240 - val_loss: 0.2421 - val_acc: 0.9064\n",
      "Epoch 32/100\n",
      "1751/1751 [==============================] - 1s 343us/step - loss: 0.1970 - acc: 0.9332 - val_loss: 0.2257 - val_acc: 0.9178\n",
      "Epoch 33/100\n",
      "1751/1751 [==============================] - 1s 320us/step - loss: 0.1884 - acc: 0.9383 - val_loss: 0.2304 - val_acc: 0.9110\n",
      "Epoch 34/100\n",
      "1751/1751 [==============================] - 1s 332us/step - loss: 0.1894 - acc: 0.9315 - val_loss: 0.2395 - val_acc: 0.9087\n",
      "Epoch 35/100\n",
      "1751/1751 [==============================] - 1s 323us/step - loss: 0.1883 - acc: 0.9406 - val_loss: 0.2394 - val_acc: 0.9087\n",
      "Epoch 36/100\n",
      "1751/1751 [==============================] - 1s 328us/step - loss: 0.1867 - acc: 0.9389 - val_loss: 0.2380 - val_acc: 0.9064\n",
      "Epoch 37/100\n",
      "1751/1751 [==============================] - 1s 330us/step - loss: 0.1940 - acc: 0.9240 - val_loss: 0.2388 - val_acc: 0.9064\n",
      "Epoch 38/100\n",
      "1751/1751 [==============================] - 1s 321us/step - loss: 0.1874 - acc: 0.9372 - val_loss: 0.2321 - val_acc: 0.9132\n",
      "Epoch 39/100\n",
      "1751/1751 [==============================] - 1s 324us/step - loss: 0.1725 - acc: 0.9423 - val_loss: 0.2296 - val_acc: 0.9132\n",
      "Epoch 40/100\n",
      "1751/1751 [==============================] - 1s 320us/step - loss: 0.1783 - acc: 0.9355 - val_loss: 0.2476 - val_acc: 0.9064\n",
      "Epoch 41/100\n",
      "1751/1751 [==============================] - 1s 334us/step - loss: 0.1862 - acc: 0.9395 - val_loss: 0.2285 - val_acc: 0.9178\n",
      "Epoch 42/100\n",
      "1751/1751 [==============================] - 1s 325us/step - loss: 0.1844 - acc: 0.9355 - val_loss: 0.2394 - val_acc: 0.9064\n",
      "Epoch 43/100\n",
      "1751/1751 [==============================] - 1s 330us/step - loss: 0.1774 - acc: 0.9372 - val_loss: 0.2214 - val_acc: 0.9155\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1751/1751 [==============================] - 1s 324us/step - loss: 0.1710 - acc: 0.9429 - val_loss: 0.2343 - val_acc: 0.9132\n",
      "Epoch 45/100\n",
      "1751/1751 [==============================] - 1s 330us/step - loss: 0.1721 - acc: 0.9406 - val_loss: 0.2368 - val_acc: 0.9110\n",
      "Epoch 46/100\n",
      "1751/1751 [==============================] - 1s 327us/step - loss: 0.1742 - acc: 0.9332 - val_loss: 0.2306 - val_acc: 0.9132\n",
      "Epoch 47/100\n",
      "1751/1751 [==============================] - 1s 328us/step - loss: 0.1741 - acc: 0.9412 - val_loss: 0.2247 - val_acc: 0.9201\n",
      "Epoch 48/100\n",
      "1751/1751 [==============================] - 1s 318us/step - loss: 0.1638 - acc: 0.9429 - val_loss: 0.2177 - val_acc: 0.9178\n",
      "Epoch 49/100\n",
      "1751/1751 [==============================] - 1s 326us/step - loss: 0.1728 - acc: 0.9463 - val_loss: 0.2320 - val_acc: 0.9132\n",
      "Epoch 50/100\n",
      "1751/1751 [==============================] - 1s 321us/step - loss: 0.1674 - acc: 0.9463 - val_loss: 0.2303 - val_acc: 0.9178\n",
      "Epoch 51/100\n",
      "1751/1751 [==============================] - 1s 333us/step - loss: 0.1714 - acc: 0.9446 - val_loss: 0.2179 - val_acc: 0.9178\n",
      "Epoch 52/100\n",
      "1751/1751 [==============================] - 1s 331us/step - loss: 0.1678 - acc: 0.9429 - val_loss: 0.2278 - val_acc: 0.9087\n",
      "Epoch 53/100\n",
      "1751/1751 [==============================] - 1s 324us/step - loss: 0.1712 - acc: 0.9440 - val_loss: 0.2233 - val_acc: 0.9201\n",
      "Epoch 54/100\n",
      "1751/1751 [==============================] - 1s 328us/step - loss: 0.1630 - acc: 0.9463 - val_loss: 0.2169 - val_acc: 0.9178\n",
      "Epoch 55/100\n",
      "1751/1751 [==============================] - 1s 318us/step - loss: 0.1754 - acc: 0.9383 - val_loss: 0.2226 - val_acc: 0.9201\n",
      "Epoch 56/100\n",
      "1751/1751 [==============================] - 1s 321us/step - loss: 0.1650 - acc: 0.9435 - val_loss: 0.2351 - val_acc: 0.9110\n",
      "Epoch 57/100\n",
      "1751/1751 [==============================] - 1s 328us/step - loss: 0.1609 - acc: 0.9486 - val_loss: 0.2244 - val_acc: 0.9178\n",
      "Epoch 58/100\n",
      "1751/1751 [==============================] - 1s 324us/step - loss: 0.1670 - acc: 0.9446 - val_loss: 0.2167 - val_acc: 0.9178\n",
      "Epoch 59/100\n",
      "1751/1751 [==============================] - 1s 328us/step - loss: 0.1668 - acc: 0.9423 - val_loss: 0.2220 - val_acc: 0.9155\n",
      "Epoch 60/100\n",
      "1751/1751 [==============================] - 1s 324us/step - loss: 0.1650 - acc: 0.9412 - val_loss: 0.2212 - val_acc: 0.9155\n",
      "Epoch 61/100\n",
      "1751/1751 [==============================] - 1s 338us/step - loss: 0.1567 - acc: 0.9509 - val_loss: 0.2369 - val_acc: 0.9110\n",
      "Epoch 62/100\n",
      "1751/1751 [==============================] - 1s 329us/step - loss: 0.1553 - acc: 0.9509 - val_loss: 0.2245 - val_acc: 0.9178\n",
      "Epoch 63/100\n",
      "1751/1751 [==============================] - 1s 325us/step - loss: 0.1599 - acc: 0.9435 - val_loss: 0.2300 - val_acc: 0.9155\n",
      "Epoch 64/100\n",
      "1751/1751 [==============================] - 1s 326us/step - loss: 0.1524 - acc: 0.9475 - val_loss: 0.2122 - val_acc: 0.9269\n",
      "Epoch 65/100\n",
      "1751/1751 [==============================] - 1s 339us/step - loss: 0.1588 - acc: 0.9440 - val_loss: 0.2214 - val_acc: 0.9201\n",
      "Epoch 66/100\n",
      "1751/1751 [==============================] - 1s 326us/step - loss: 0.1577 - acc: 0.9457 - val_loss: 0.2299 - val_acc: 0.9110\n",
      "Epoch 67/100\n",
      "1751/1751 [==============================] - 1s 327us/step - loss: 0.1583 - acc: 0.9440 - val_loss: 0.2082 - val_acc: 0.9269\n",
      "Epoch 68/100\n",
      "1751/1751 [==============================] - 1s 322us/step - loss: 0.1559 - acc: 0.9463 - val_loss: 0.2117 - val_acc: 0.9247\n",
      "Epoch 69/100\n",
      "1751/1751 [==============================] - 1s 323us/step - loss: 0.1593 - acc: 0.9469 - val_loss: 0.2290 - val_acc: 0.9155\n",
      "Epoch 70/100\n",
      "1751/1751 [==============================] - 1s 322us/step - loss: 0.1565 - acc: 0.9480 - val_loss: 0.2244 - val_acc: 0.9155\n",
      "Epoch 71/100\n",
      "1751/1751 [==============================] - 1s 328us/step - loss: 0.1440 - acc: 0.9520 - val_loss: 0.2107 - val_acc: 0.9269\n",
      "Epoch 72/100\n",
      "1751/1751 [==============================] - 1s 342us/step - loss: 0.1530 - acc: 0.9452 - val_loss: 0.2273 - val_acc: 0.9178\n",
      "Epoch 73/100\n",
      "1751/1751 [==============================] - 1s 332us/step - loss: 0.1554 - acc: 0.9520 - val_loss: 0.2253 - val_acc: 0.9178\n",
      "Epoch 74/100\n",
      "1751/1751 [==============================] - ETA: 0s - loss: 0.1577 - acc: 0.954 - 1s 328us/step - loss: 0.1582 - acc: 0.9537 - val_loss: 0.2256 - val_acc: 0.9155\n",
      "Epoch 75/100\n",
      "1751/1751 [==============================] - 1s 324us/step - loss: 0.1440 - acc: 0.9543 - val_loss: 0.2029 - val_acc: 0.9292\n",
      "Epoch 76/100\n",
      "1751/1751 [==============================] - 1s 326us/step - loss: 0.1493 - acc: 0.9555 - val_loss: 0.2148 - val_acc: 0.9201\n",
      "Epoch 77/100\n",
      "1751/1751 [==============================] - 1s 320us/step - loss: 0.1519 - acc: 0.9497 - val_loss: 0.2121 - val_acc: 0.9247\n",
      "Epoch 78/100\n",
      "1751/1751 [==============================] - 1s 317us/step - loss: 0.1465 - acc: 0.9497 - val_loss: 0.2181 - val_acc: 0.9224\n",
      "Epoch 79/100\n",
      "1751/1751 [==============================] - 1s 317us/step - loss: 0.1418 - acc: 0.9532 - val_loss: 0.1962 - val_acc: 0.9338\n",
      "Epoch 80/100\n",
      "1751/1751 [==============================] - 1s 325us/step - loss: 0.1475 - acc: 0.9480 - val_loss: 0.1995 - val_acc: 0.9338\n",
      "Epoch 81/100\n",
      "1751/1751 [==============================] - 1s 326us/step - loss: 0.1390 - acc: 0.9589 - val_loss: 0.2113 - val_acc: 0.9247\n",
      "Epoch 82/100\n",
      "1751/1751 [==============================] - 1s 329us/step - loss: 0.1397 - acc: 0.9503 - val_loss: 0.1989 - val_acc: 0.9338\n",
      "Epoch 83/100\n",
      "1751/1751 [==============================] - 1s 328us/step - loss: 0.1391 - acc: 0.9589 - val_loss: 0.2107 - val_acc: 0.9247\n",
      "Epoch 84/100\n",
      "1751/1751 [==============================] - 1s 319us/step - loss: 0.1402 - acc: 0.9555 - val_loss: 0.2047 - val_acc: 0.9315\n",
      "Epoch 85/100\n",
      "1751/1751 [==============================] - 1s 332us/step - loss: 0.1381 - acc: 0.9589 - val_loss: 0.2164 - val_acc: 0.9224\n",
      "Epoch 86/100\n",
      "1751/1751 [==============================] - 1s 321us/step - loss: 0.1380 - acc: 0.9543 - val_loss: 0.1976 - val_acc: 0.9315\n",
      "Epoch 87/100\n",
      "1751/1751 [==============================] - 1s 324us/step - loss: 0.1379 - acc: 0.9537 - val_loss: 0.2053 - val_acc: 0.9292\n",
      "Epoch 88/100\n",
      "1751/1751 [==============================] - 1s 318us/step - loss: 0.1415 - acc: 0.9503 - val_loss: 0.2066 - val_acc: 0.9292\n",
      "Epoch 89/100\n",
      "1751/1751 [==============================] - 1s 321us/step - loss: 0.1391 - acc: 0.9560 - val_loss: 0.2125 - val_acc: 0.9201\n",
      "Epoch 90/100\n",
      "1751/1751 [==============================] - 1s 321us/step - loss: 0.1413 - acc: 0.9566 - val_loss: 0.2064 - val_acc: 0.9247\n",
      "Epoch 91/100\n",
      "1751/1751 [==============================] - 1s 326us/step - loss: 0.1331 - acc: 0.9566 - val_loss: 0.2084 - val_acc: 0.9201\n",
      "Epoch 92/100\n",
      "1751/1751 [==============================] - 1s 324us/step - loss: 0.1400 - acc: 0.9577 - val_loss: 0.2096 - val_acc: 0.9247\n",
      "Epoch 93/100\n",
      "1751/1751 [==============================] - 1s 325us/step - loss: 0.1337 - acc: 0.9560 - val_loss: 0.2036 - val_acc: 0.9269\n",
      "Epoch 94/100\n",
      "1751/1751 [==============================] - 1s 317us/step - loss: 0.1331 - acc: 0.9577 - val_loss: 0.2107 - val_acc: 0.9201\n",
      "Epoch 95/100\n",
      "1751/1751 [==============================] - 1s 320us/step - loss: 0.1398 - acc: 0.9572 - val_loss: 0.2057 - val_acc: 0.9269\n",
      "Epoch 96/100\n",
      "1751/1751 [==============================] - 1s 327us/step - loss: 0.1301 - acc: 0.9623 - val_loss: 0.1929 - val_acc: 0.9406\n",
      "Epoch 97/100\n",
      "1751/1751 [==============================] - 1s 322us/step - loss: 0.1424 - acc: 0.9520 - val_loss: 0.2076 - val_acc: 0.9269\n",
      "Epoch 98/100\n",
      "1751/1751 [==============================] - 1s 329us/step - loss: 0.1425 - acc: 0.9515 - val_loss: 0.2084 - val_acc: 0.9224\n",
      "Epoch 99/100\n",
      "1751/1751 [==============================] - 1s 328us/step - loss: 0.1277 - acc: 0.9617 - val_loss: 0.1897 - val_acc: 0.9384\n",
      "Epoch 100/100\n",
      "1751/1751 [==============================] - 1s 322us/step - loss: 0.1323 - acc: 0.9589 - val_loss: 0.1867 - val_acc: 0.9384\n",
      "Train on 1751 samples, validate on 438 samples\n",
      "Epoch 1/100\n",
      "1751/1751 [==============================] - 1s 325us/step - loss: 0.1808 - acc: 0.9435 - val_loss: 0.1665 - val_acc: 0.9521\n",
      "Epoch 2/100\n",
      "1751/1751 [==============================] - 1s 323us/step - loss: 0.1699 - acc: 0.9429 - val_loss: 0.1608 - val_acc: 0.9498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100\n",
      "1751/1751 [==============================] - 1s 324us/step - loss: 0.1736 - acc: 0.9452 - val_loss: 0.1599 - val_acc: 0.9498\n",
      "Epoch 4/100\n",
      "1751/1751 [==============================] - 1s 326us/step - loss: 0.1759 - acc: 0.9412 - val_loss: 0.1540 - val_acc: 0.9521\n",
      "Epoch 5/100\n",
      "1751/1751 [==============================] - 1s 321us/step - loss: 0.1693 - acc: 0.9480 - val_loss: 0.1528 - val_acc: 0.9521\n",
      "Epoch 6/100\n",
      "1751/1751 [==============================] - 1s 325us/step - loss: 0.1531 - acc: 0.9503 - val_loss: 0.1490 - val_acc: 0.9543\n",
      "Epoch 7/100\n",
      "1751/1751 [==============================] - 1s 327us/step - loss: 0.1674 - acc: 0.9412 - val_loss: 0.1596 - val_acc: 0.9521\n",
      "Epoch 8/100\n",
      "1751/1751 [==============================] - 1s 328us/step - loss: 0.1650 - acc: 0.9486 - val_loss: 0.1530 - val_acc: 0.9543\n",
      "Epoch 9/100\n",
      "1751/1751 [==============================] - 1s 326us/step - loss: 0.1648 - acc: 0.9486 - val_loss: 0.1553 - val_acc: 0.9543\n",
      "Epoch 10/100\n",
      "1751/1751 [==============================] - 1s 323us/step - loss: 0.1543 - acc: 0.9503 - val_loss: 0.1492 - val_acc: 0.9566\n",
      "Epoch 11/100\n",
      "1751/1751 [==============================] - 1s 322us/step - loss: 0.1637 - acc: 0.9452 - val_loss: 0.1487 - val_acc: 0.9566\n",
      "Epoch 12/100\n",
      "1751/1751 [==============================] - 1s 328us/step - loss: 0.1549 - acc: 0.9486 - val_loss: 0.1508 - val_acc: 0.9543\n",
      "Epoch 13/100\n",
      "1751/1751 [==============================] - 1s 332us/step - loss: 0.1602 - acc: 0.9497 - val_loss: 0.1580 - val_acc: 0.9521\n",
      "Epoch 14/100\n",
      "1751/1751 [==============================] - 1s 322us/step - loss: 0.1599 - acc: 0.9503 - val_loss: 0.1495 - val_acc: 0.9543\n",
      "Epoch 15/100\n",
      "1751/1751 [==============================] - 1s 330us/step - loss: 0.1587 - acc: 0.9497 - val_loss: 0.1495 - val_acc: 0.9543\n",
      "Epoch 16/100\n",
      "1751/1751 [==============================] - 1s 322us/step - loss: 0.1495 - acc: 0.9497 - val_loss: 0.1403 - val_acc: 0.9566\n",
      "Epoch 17/100\n",
      "1751/1751 [==============================] - 1s 325us/step - loss: 0.1512 - acc: 0.9515 - val_loss: 0.1455 - val_acc: 0.9589\n",
      "Epoch 18/100\n",
      "1751/1751 [==============================] - 1s 318us/step - loss: 0.1556 - acc: 0.9486 - val_loss: 0.1457 - val_acc: 0.9589\n",
      "Epoch 19/100\n",
      "1751/1751 [==============================] - 1s 327us/step - loss: 0.1538 - acc: 0.9520 - val_loss: 0.1559 - val_acc: 0.9498\n",
      "Epoch 20/100\n",
      "1751/1751 [==============================] - 1s 327us/step - loss: 0.1510 - acc: 0.9509 - val_loss: 0.1515 - val_acc: 0.9498\n",
      "Epoch 21/100\n",
      "1751/1751 [==============================] - 1s 329us/step - loss: 0.1497 - acc: 0.9515 - val_loss: 0.1575 - val_acc: 0.9498\n",
      "Epoch 22/100\n",
      "1751/1751 [==============================] - 1s 326us/step - loss: 0.1456 - acc: 0.9549 - val_loss: 0.1478 - val_acc: 0.9566\n",
      "Epoch 23/100\n",
      "1751/1751 [==============================] - 1s 325us/step - loss: 0.1516 - acc: 0.9515 - val_loss: 0.1443 - val_acc: 0.9566\n",
      "Epoch 24/100\n",
      "1751/1751 [==============================] - 1s 326us/step - loss: 0.1466 - acc: 0.9577 - val_loss: 0.1404 - val_acc: 0.9589\n",
      "Epoch 25/100\n",
      "1751/1751 [==============================] - 1s 323us/step - loss: 0.1445 - acc: 0.9509 - val_loss: 0.1478 - val_acc: 0.9521\n",
      "Epoch 26/100\n",
      "1751/1751 [==============================] - 1s 329us/step - loss: 0.1465 - acc: 0.9532 - val_loss: 0.1473 - val_acc: 0.9566\n",
      "Epoch 27/100\n",
      "1751/1751 [==============================] - 1s 328us/step - loss: 0.1499 - acc: 0.9532 - val_loss: 0.1365 - val_acc: 0.9589\n",
      "Epoch 28/100\n",
      "1751/1751 [==============================] - 1s 325us/step - loss: 0.1553 - acc: 0.9526 - val_loss: 0.1374 - val_acc: 0.9589\n",
      "Epoch 29/100\n",
      "1751/1751 [==============================] - 1s 329us/step - loss: 0.1455 - acc: 0.9543 - val_loss: 0.1417 - val_acc: 0.9566\n",
      "Epoch 30/100\n",
      "1751/1751 [==============================] - 1s 323us/step - loss: 0.1363 - acc: 0.9577 - val_loss: 0.1458 - val_acc: 0.9543\n",
      "Epoch 31/100\n",
      "1751/1751 [==============================] - 1s 322us/step - loss: 0.1400 - acc: 0.9555 - val_loss: 0.1384 - val_acc: 0.9589\n",
      "Epoch 32/100\n",
      "1751/1751 [==============================] - 1s 326us/step - loss: 0.1391 - acc: 0.9577 - val_loss: 0.1470 - val_acc: 0.9498\n",
      "Epoch 33/100\n",
      "1751/1751 [==============================] - 1s 317us/step - loss: 0.1486 - acc: 0.9486 - val_loss: 0.1445 - val_acc: 0.9566\n",
      "Epoch 34/100\n",
      "1751/1751 [==============================] - 1s 319us/step - loss: 0.1330 - acc: 0.9595 - val_loss: 0.1406 - val_acc: 0.9589\n",
      "Epoch 35/100\n",
      "1751/1751 [==============================] - 1s 321us/step - loss: 0.1392 - acc: 0.9543 - val_loss: 0.1429 - val_acc: 0.9566\n",
      "Epoch 36/100\n",
      "1751/1751 [==============================] - 1s 326us/step - loss: 0.1402 - acc: 0.9549 - val_loss: 0.1360 - val_acc: 0.9635\n",
      "Epoch 37/100\n",
      "1751/1751 [==============================] - 1s 323us/step - loss: 0.1429 - acc: 0.9537 - val_loss: 0.1406 - val_acc: 0.9589\n",
      "Epoch 38/100\n",
      "1751/1751 [==============================] - 1s 319us/step - loss: 0.1396 - acc: 0.9606 - val_loss: 0.1335 - val_acc: 0.9658\n",
      "Epoch 39/100\n",
      "1751/1751 [==============================] - 1s 325us/step - loss: 0.1374 - acc: 0.9577 - val_loss: 0.1360 - val_acc: 0.9658\n",
      "Epoch 40/100\n",
      "1751/1751 [==============================] - 1s 322us/step - loss: 0.1430 - acc: 0.9555 - val_loss: 0.1423 - val_acc: 0.9521\n",
      "Epoch 41/100\n",
      "1751/1751 [==============================] - 1s 326us/step - loss: 0.1402 - acc: 0.9577 - val_loss: 0.1340 - val_acc: 0.9658\n",
      "Epoch 42/100\n",
      "1751/1751 [==============================] - 1s 324us/step - loss: 0.1371 - acc: 0.9583 - val_loss: 0.1402 - val_acc: 0.9589\n",
      "Epoch 43/100\n",
      "1751/1751 [==============================] - 1s 330us/step - loss: 0.1383 - acc: 0.9577 - val_loss: 0.1407 - val_acc: 0.9543\n",
      "Epoch 44/100\n",
      "1751/1751 [==============================] - 1s 318us/step - loss: 0.1342 - acc: 0.9640 - val_loss: 0.1364 - val_acc: 0.9589\n",
      "Epoch 45/100\n",
      "1751/1751 [==============================] - 1s 323us/step - loss: 0.1396 - acc: 0.9543 - val_loss: 0.1401 - val_acc: 0.9566\n",
      "Epoch 46/100\n",
      "1751/1751 [==============================] - 1s 320us/step - loss: 0.1298 - acc: 0.9652 - val_loss: 0.1358 - val_acc: 0.9612\n",
      "Epoch 47/100\n",
      "1751/1751 [==============================] - 1s 325us/step - loss: 0.1316 - acc: 0.9623 - val_loss: 0.1354 - val_acc: 0.9612\n",
      "Epoch 48/100\n",
      "1751/1751 [==============================] - 1s 326us/step - loss: 0.1308 - acc: 0.9560 - val_loss: 0.1323 - val_acc: 0.9658\n",
      "Epoch 49/100\n",
      "1751/1751 [==============================] - 1s 326us/step - loss: 0.1303 - acc: 0.9589 - val_loss: 0.1361 - val_acc: 0.9612\n",
      "Epoch 50/100\n",
      "1751/1751 [==============================] - 1s 323us/step - loss: 0.1308 - acc: 0.9589 - val_loss: 0.1398 - val_acc: 0.9589\n",
      "Epoch 51/100\n",
      "1751/1751 [==============================] - 1s 323us/step - loss: 0.1371 - acc: 0.9543 - val_loss: 0.1351 - val_acc: 0.9635\n",
      "Epoch 52/100\n",
      "1751/1751 [==============================] - 1s 323us/step - loss: 0.1291 - acc: 0.9595 - val_loss: 0.1315 - val_acc: 0.9635\n",
      "Epoch 53/100\n",
      "1751/1751 [==============================] - 1s 324us/step - loss: 0.1391 - acc: 0.9560 - val_loss: 0.1306 - val_acc: 0.9635\n",
      "Epoch 54/100\n",
      "1751/1751 [==============================] - 1s 323us/step - loss: 0.1365 - acc: 0.9617 - val_loss: 0.1383 - val_acc: 0.9589\n",
      "Epoch 55/100\n",
      "1751/1751 [==============================] - 1s 320us/step - loss: 0.1274 - acc: 0.9617 - val_loss: 0.1380 - val_acc: 0.9589\n",
      "Epoch 56/100\n",
      "1751/1751 [==============================] - 1s 323us/step - loss: 0.1308 - acc: 0.9589 - val_loss: 0.1419 - val_acc: 0.9543\n",
      "Epoch 57/100\n",
      "1751/1751 [==============================] - 1s 328us/step - loss: 0.1354 - acc: 0.9566 - val_loss: 0.1431 - val_acc: 0.9543\n",
      "Epoch 58/100\n",
      "1751/1751 [==============================] - 1s 321us/step - loss: 0.1326 - acc: 0.9629 - val_loss: 0.1349 - val_acc: 0.9635\n",
      "Epoch 59/100\n",
      "1751/1751 [==============================] - 1s 327us/step - loss: 0.1340 - acc: 0.9549 - val_loss: 0.1382 - val_acc: 0.9566\n",
      "Epoch 60/100\n",
      "1751/1751 [==============================] - 1s 326us/step - loss: 0.1226 - acc: 0.9566 - val_loss: 0.1335 - val_acc: 0.9658\n",
      "Epoch 61/100\n",
      "1751/1751 [==============================] - 1s 329us/step - loss: 0.1343 - acc: 0.9549 - val_loss: 0.1374 - val_acc: 0.9543\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1751/1751 [==============================] - 1s 325us/step - loss: 0.1318 - acc: 0.9612 - val_loss: 0.1415 - val_acc: 0.9566\n",
      "Epoch 63/100\n",
      "1751/1751 [==============================] - 1s 321us/step - loss: 0.1277 - acc: 0.9623 - val_loss: 0.1349 - val_acc: 0.9612\n",
      "Epoch 64/100\n",
      "1751/1751 [==============================] - 1s 324us/step - loss: 0.1235 - acc: 0.9606 - val_loss: 0.1286 - val_acc: 0.9635\n",
      "Epoch 65/100\n",
      "1751/1751 [==============================] - 1s 325us/step - loss: 0.1174 - acc: 0.9657 - val_loss: 0.1312 - val_acc: 0.9635\n",
      "Epoch 66/100\n",
      "1751/1751 [==============================] - 1s 326us/step - loss: 0.1202 - acc: 0.9652 - val_loss: 0.1317 - val_acc: 0.9635\n",
      "Epoch 67/100\n",
      "1751/1751 [==============================] - 1s 329us/step - loss: 0.1230 - acc: 0.9657 - val_loss: 0.1323 - val_acc: 0.9612\n",
      "Epoch 68/100\n",
      "1751/1751 [==============================] - 1s 324us/step - loss: 0.1191 - acc: 0.9646 - val_loss: 0.1311 - val_acc: 0.9635\n",
      "Epoch 69/100\n",
      "1751/1751 [==============================] - 1s 322us/step - loss: 0.1191 - acc: 0.9629 - val_loss: 0.1354 - val_acc: 0.9566\n",
      "Epoch 70/100\n",
      "1751/1751 [==============================] - 1s 331us/step - loss: 0.1166 - acc: 0.9634 - val_loss: 0.1385 - val_acc: 0.9566\n",
      "Epoch 71/100\n",
      "1751/1751 [==============================] - 1s 322us/step - loss: 0.1163 - acc: 0.9617 - val_loss: 0.1345 - val_acc: 0.9543\n",
      "Epoch 72/100\n",
      "1751/1751 [==============================] - 1s 323us/step - loss: 0.1208 - acc: 0.9623 - val_loss: 0.1370 - val_acc: 0.9566\n",
      "Epoch 73/100\n",
      "1751/1751 [==============================] - 1s 323us/step - loss: 0.1226 - acc: 0.9600 - val_loss: 0.1295 - val_acc: 0.9635\n",
      "Epoch 74/100\n",
      "1751/1751 [==============================] - 1s 324us/step - loss: 0.1103 - acc: 0.9657 - val_loss: 0.1358 - val_acc: 0.9566\n",
      "Epoch 75/100\n",
      "1751/1751 [==============================] - 1s 322us/step - loss: 0.1182 - acc: 0.9617 - val_loss: 0.1303 - val_acc: 0.9612\n",
      "Epoch 76/100\n",
      "1751/1751 [==============================] - 1s 322us/step - loss: 0.1170 - acc: 0.9680 - val_loss: 0.1346 - val_acc: 0.9566\n",
      "Epoch 77/100\n",
      "1751/1751 [==============================] - 1s 327us/step - loss: 0.1266 - acc: 0.9595 - val_loss: 0.1398 - val_acc: 0.9543\n",
      "Epoch 78/100\n",
      "1751/1751 [==============================] - 1s 329us/step - loss: 0.1245 - acc: 0.9606 - val_loss: 0.1342 - val_acc: 0.9612\n",
      "Epoch 79/100\n",
      "1751/1751 [==============================] - 1s 316us/step - loss: 0.1224 - acc: 0.9612 - val_loss: 0.1321 - val_acc: 0.9566\n",
      "Epoch 80/100\n",
      "1751/1751 [==============================] - 1s 318us/step - loss: 0.1163 - acc: 0.9686 - val_loss: 0.1355 - val_acc: 0.9612\n",
      "Epoch 81/100\n",
      "1751/1751 [==============================] - 1s 323us/step - loss: 0.1149 - acc: 0.9663 - val_loss: 0.1397 - val_acc: 0.9543\n",
      "Epoch 82/100\n",
      "1751/1751 [==============================] - 1s 319us/step - loss: 0.1134 - acc: 0.9629 - val_loss: 0.1357 - val_acc: 0.9589\n",
      "Epoch 83/100\n",
      "1751/1751 [==============================] - 1s 324us/step - loss: 0.1200 - acc: 0.9623 - val_loss: 0.1341 - val_acc: 0.9589\n",
      "Epoch 84/100\n",
      "1751/1751 [==============================] - 1s 328us/step - loss: 0.1187 - acc: 0.9612 - val_loss: 0.1254 - val_acc: 0.9612\n",
      "Epoch 85/100\n",
      "1751/1751 [==============================] - 1s 317us/step - loss: 0.1164 - acc: 0.9640 - val_loss: 0.1367 - val_acc: 0.9589\n",
      "Epoch 86/100\n",
      "1751/1751 [==============================] - 1s 321us/step - loss: 0.1152 - acc: 0.9600 - val_loss: 0.1346 - val_acc: 0.9589\n",
      "Epoch 87/100\n",
      "1751/1751 [==============================] - 1s 330us/step - loss: 0.1117 - acc: 0.9652 - val_loss: 0.1271 - val_acc: 0.9635\n",
      "Epoch 88/100\n",
      "1751/1751 [==============================] - 1s 321us/step - loss: 0.1220 - acc: 0.9606 - val_loss: 0.1308 - val_acc: 0.9612\n",
      "Epoch 89/100\n",
      "1751/1751 [==============================] - 1s 321us/step - loss: 0.1175 - acc: 0.9634 - val_loss: 0.1353 - val_acc: 0.9589\n",
      "Epoch 90/100\n",
      "1751/1751 [==============================] - 1s 327us/step - loss: 0.1135 - acc: 0.9606 - val_loss: 0.1316 - val_acc: 0.9612\n",
      "Epoch 91/100\n",
      "1751/1751 [==============================] - 1s 319us/step - loss: 0.1247 - acc: 0.9566 - val_loss: 0.1358 - val_acc: 0.9566\n",
      "Epoch 92/100\n",
      "1751/1751 [==============================] - 1s 330us/step - loss: 0.1118 - acc: 0.9629 - val_loss: 0.1323 - val_acc: 0.9566\n",
      "Epoch 93/100\n",
      "1751/1751 [==============================] - 1s 329us/step - loss: 0.1170 - acc: 0.9652 - val_loss: 0.1365 - val_acc: 0.9543\n",
      "Epoch 94/100\n",
      "1751/1751 [==============================] - 1s 330us/step - loss: 0.1123 - acc: 0.9617 - val_loss: 0.1304 - val_acc: 0.9612\n",
      "Epoch 95/100\n",
      "1751/1751 [==============================] - 1s 333us/step - loss: 0.1163 - acc: 0.9634 - val_loss: 0.1251 - val_acc: 0.9635\n",
      "Epoch 96/100\n",
      "1751/1751 [==============================] - 1s 318us/step - loss: 0.1119 - acc: 0.9634 - val_loss: 0.1238 - val_acc: 0.9635\n",
      "Epoch 97/100\n",
      "1751/1751 [==============================] - 1s 323us/step - loss: 0.1118 - acc: 0.9646 - val_loss: 0.1316 - val_acc: 0.9566\n",
      "Epoch 98/100\n",
      "1751/1751 [==============================] - 1s 328us/step - loss: 0.1124 - acc: 0.9634 - val_loss: 0.1297 - val_acc: 0.9589\n",
      "Epoch 99/100\n",
      "1751/1751 [==============================] - 1s 323us/step - loss: 0.1204 - acc: 0.9657 - val_loss: 0.1303 - val_acc: 0.9566\n",
      "Epoch 100/100\n",
      "1751/1751 [==============================] - 1s 325us/step - loss: 0.1159 - acc: 0.9663 - val_loss: 0.1339 - val_acc: 0.9566\n",
      "Test subject 9, class LiftOff\n",
      "Train subject 9, class Replace\n",
      "Train on 1752 samples, validate on 438 samples\n",
      "Epoch 1/100\n",
      "1752/1752 [==============================] - 1s 506us/step - loss: 0.6933 - acc: 0.8082 - val_loss: 0.5106 - val_acc: 0.8128\n",
      "Epoch 2/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.5625 - acc: 0.8179 - val_loss: 0.4599 - val_acc: 0.8265\n",
      "Epoch 3/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.5166 - acc: 0.8493 - val_loss: 0.4223 - val_acc: 0.8584\n",
      "Epoch 4/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.4804 - acc: 0.8493 - val_loss: 0.3947 - val_acc: 0.8699\n",
      "Epoch 5/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.4463 - acc: 0.8647 - val_loss: 0.3627 - val_acc: 0.8858\n",
      "Epoch 6/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.4203 - acc: 0.8653 - val_loss: 0.3417 - val_acc: 0.8881\n",
      "Epoch 7/100\n",
      "1752/1752 [==============================] - 1s 321us/step - loss: 0.4106 - acc: 0.8682 - val_loss: 0.3250 - val_acc: 0.8881\n",
      "Epoch 8/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.3931 - acc: 0.8733 - val_loss: 0.3085 - val_acc: 0.8881\n",
      "Epoch 9/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.3772 - acc: 0.8767 - val_loss: 0.2925 - val_acc: 0.8881\n",
      "Epoch 10/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.3642 - acc: 0.8767 - val_loss: 0.2891 - val_acc: 0.8881\n",
      "Epoch 11/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.3419 - acc: 0.8847 - val_loss: 0.2715 - val_acc: 0.8904\n",
      "Epoch 12/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.3159 - acc: 0.8904 - val_loss: 0.2657 - val_acc: 0.8950\n",
      "Epoch 13/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.3170 - acc: 0.8898 - val_loss: 0.2560 - val_acc: 0.8973\n",
      "Epoch 14/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.2981 - acc: 0.8921 - val_loss: 0.2532 - val_acc: 0.8995\n",
      "Epoch 15/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.3036 - acc: 0.8921 - val_loss: 0.2529 - val_acc: 0.9018\n",
      "Epoch 16/100\n",
      "1752/1752 [==============================] - 1s 318us/step - loss: 0.2951 - acc: 0.8933 - val_loss: 0.2394 - val_acc: 0.8950\n",
      "Epoch 17/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.2814 - acc: 0.8916 - val_loss: 0.2344 - val_acc: 0.8973\n",
      "Epoch 18/100\n",
      "1752/1752 [==============================] - 1s 321us/step - loss: 0.2794 - acc: 0.9013 - val_loss: 0.2408 - val_acc: 0.8995\n",
      "Epoch 19/100\n",
      "1752/1752 [==============================] - 1s 319us/step - loss: 0.2635 - acc: 0.9018 - val_loss: 0.2309 - val_acc: 0.8950\n",
      "Epoch 20/100\n",
      "1752/1752 [==============================] - 1s 319us/step - loss: 0.2500 - acc: 0.9018 - val_loss: 0.2234 - val_acc: 0.9018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.2681 - acc: 0.9053 - val_loss: 0.2250 - val_acc: 0.8995\n",
      "Epoch 22/100\n",
      "1752/1752 [==============================] - 1s 318us/step - loss: 0.2512 - acc: 0.9030 - val_loss: 0.2252 - val_acc: 0.9041\n",
      "Epoch 23/100\n",
      "1752/1752 [==============================] - 1s 321us/step - loss: 0.2508 - acc: 0.9070 - val_loss: 0.2247 - val_acc: 0.9018\n",
      "Epoch 24/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.2432 - acc: 0.9087 - val_loss: 0.2188 - val_acc: 0.9110\n",
      "Epoch 25/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.2400 - acc: 0.9092 - val_loss: 0.2157 - val_acc: 0.9087\n",
      "Epoch 26/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.2459 - acc: 0.9132 - val_loss: 0.2120 - val_acc: 0.9064\n",
      "Epoch 27/100\n",
      "1752/1752 [==============================] - 1s 319us/step - loss: 0.2513 - acc: 0.9075 - val_loss: 0.2118 - val_acc: 0.9110\n",
      "Epoch 28/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.2524 - acc: 0.9115 - val_loss: 0.2119 - val_acc: 0.9132\n",
      "Epoch 29/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.2371 - acc: 0.9132 - val_loss: 0.2122 - val_acc: 0.9132\n",
      "Epoch 30/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.2337 - acc: 0.9092 - val_loss: 0.2122 - val_acc: 0.9132\n",
      "Epoch 31/100\n",
      "1752/1752 [==============================] - 1s 321us/step - loss: 0.2320 - acc: 0.9064 - val_loss: 0.2069 - val_acc: 0.9087\n",
      "Epoch 32/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.2297 - acc: 0.9121 - val_loss: 0.2086 - val_acc: 0.9132\n",
      "Epoch 33/100\n",
      "1752/1752 [==============================] - 1s 321us/step - loss: 0.2241 - acc: 0.9167 - val_loss: 0.2077 - val_acc: 0.9132\n",
      "Epoch 34/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.2230 - acc: 0.9115 - val_loss: 0.2017 - val_acc: 0.9087\n",
      "Epoch 35/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.2163 - acc: 0.9189 - val_loss: 0.1988 - val_acc: 0.9132\n",
      "Epoch 36/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.2150 - acc: 0.9212 - val_loss: 0.1991 - val_acc: 0.9132\n",
      "Epoch 37/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.2198 - acc: 0.9132 - val_loss: 0.2014 - val_acc: 0.9132\n",
      "Epoch 38/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.2200 - acc: 0.9155 - val_loss: 0.1992 - val_acc: 0.9132\n",
      "Epoch 39/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.2155 - acc: 0.9161 - val_loss: 0.1986 - val_acc: 0.9132\n",
      "Epoch 40/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.2051 - acc: 0.9138 - val_loss: 0.1948 - val_acc: 0.9155\n",
      "Epoch 41/100\n",
      "1752/1752 [==============================] - 1s 317us/step - loss: 0.2066 - acc: 0.9189 - val_loss: 0.1959 - val_acc: 0.9155\n",
      "Epoch 42/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.2075 - acc: 0.9252 - val_loss: 0.1970 - val_acc: 0.9132\n",
      "Epoch 43/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.2054 - acc: 0.9252 - val_loss: 0.1953 - val_acc: 0.9132\n",
      "Epoch 44/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.1944 - acc: 0.9212 - val_loss: 0.1909 - val_acc: 0.9178\n",
      "Epoch 45/100\n",
      "1752/1752 [==============================] - 1s 321us/step - loss: 0.2075 - acc: 0.9161 - val_loss: 0.1922 - val_acc: 0.9155\n",
      "Epoch 46/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.1962 - acc: 0.9241 - val_loss: 0.1902 - val_acc: 0.9155\n",
      "Epoch 47/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.1923 - acc: 0.9287 - val_loss: 0.1897 - val_acc: 0.9155\n",
      "Epoch 48/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.1999 - acc: 0.9224 - val_loss: 0.1875 - val_acc: 0.9178\n",
      "Epoch 49/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.2015 - acc: 0.9212 - val_loss: 0.1882 - val_acc: 0.9178\n",
      "Epoch 50/100\n",
      "1752/1752 [==============================] - 1s 317us/step - loss: 0.2030 - acc: 0.9224 - val_loss: 0.1859 - val_acc: 0.9178\n",
      "Epoch 51/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.1880 - acc: 0.9309 - val_loss: 0.1835 - val_acc: 0.9155\n",
      "Epoch 52/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.1863 - acc: 0.9315 - val_loss: 0.1848 - val_acc: 0.9178\n",
      "Epoch 53/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.1838 - acc: 0.9298 - val_loss: 0.1839 - val_acc: 0.9178\n",
      "Epoch 54/100\n",
      "1752/1752 [==============================] - 1s 319us/step - loss: 0.1924 - acc: 0.9292 - val_loss: 0.1830 - val_acc: 0.9178\n",
      "Epoch 55/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.1876 - acc: 0.9269 - val_loss: 0.1809 - val_acc: 0.9178\n",
      "Epoch 56/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.1926 - acc: 0.9252 - val_loss: 0.1813 - val_acc: 0.9178\n",
      "Epoch 57/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.1929 - acc: 0.9298 - val_loss: 0.1810 - val_acc: 0.9178\n",
      "Epoch 58/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.1775 - acc: 0.9332 - val_loss: 0.1797 - val_acc: 0.9178\n",
      "Epoch 59/100\n",
      "1752/1752 [==============================] - 1s 321us/step - loss: 0.1837 - acc: 0.9304 - val_loss: 0.1799 - val_acc: 0.9178\n",
      "Epoch 60/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.1775 - acc: 0.9298 - val_loss: 0.1800 - val_acc: 0.9178\n",
      "Epoch 61/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.1768 - acc: 0.9298 - val_loss: 0.1780 - val_acc: 0.9178\n",
      "Epoch 62/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.1842 - acc: 0.9269 - val_loss: 0.1785 - val_acc: 0.9178\n",
      "Epoch 63/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.1762 - acc: 0.9304 - val_loss: 0.1755 - val_acc: 0.9178\n",
      "Epoch 64/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.1818 - acc: 0.9309 - val_loss: 0.1775 - val_acc: 0.9201\n",
      "Epoch 65/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.1741 - acc: 0.9326 - val_loss: 0.1752 - val_acc: 0.9178\n",
      "Epoch 66/100\n",
      "1752/1752 [==============================] - 1s 320us/step - loss: 0.1782 - acc: 0.9264 - val_loss: 0.1781 - val_acc: 0.9224\n",
      "Epoch 67/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.1719 - acc: 0.9326 - val_loss: 0.1751 - val_acc: 0.9178\n",
      "Epoch 68/100\n",
      "1752/1752 [==============================] - 1s 321us/step - loss: 0.1771 - acc: 0.9287 - val_loss: 0.1741 - val_acc: 0.9178\n",
      "Epoch 69/100\n",
      "1752/1752 [==============================] - 1s 320us/step - loss: 0.1730 - acc: 0.9338 - val_loss: 0.1723 - val_acc: 0.9178\n",
      "Epoch 70/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.1672 - acc: 0.9349 - val_loss: 0.1726 - val_acc: 0.9201\n",
      "Epoch 71/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.1731 - acc: 0.9304 - val_loss: 0.1741 - val_acc: 0.9201\n",
      "Epoch 72/100\n",
      "1752/1752 [==============================] - 1s 319us/step - loss: 0.1675 - acc: 0.9292 - val_loss: 0.1709 - val_acc: 0.9201\n",
      "Epoch 73/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.1732 - acc: 0.9321 - val_loss: 0.1714 - val_acc: 0.9224\n",
      "Epoch 74/100\n",
      "1752/1752 [==============================] - 1s 339us/step - loss: 0.1787 - acc: 0.9309 - val_loss: 0.1700 - val_acc: 0.9247\n",
      "Epoch 75/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.1705 - acc: 0.9292 - val_loss: 0.1696 - val_acc: 0.9247\n",
      "Epoch 76/100\n",
      "1752/1752 [==============================] - 1s 320us/step - loss: 0.1705 - acc: 0.9326 - val_loss: 0.1696 - val_acc: 0.9224\n",
      "Epoch 77/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.1685 - acc: 0.9366 - val_loss: 0.1700 - val_acc: 0.9201\n",
      "Epoch 78/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.1635 - acc: 0.9355 - val_loss: 0.1675 - val_acc: 0.9224\n",
      "Epoch 79/100\n",
      "1752/1752 [==============================] - 1s 335us/step - loss: 0.1624 - acc: 0.9372 - val_loss: 0.1678 - val_acc: 0.9224\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.1629 - acc: 0.9361 - val_loss: 0.1675 - val_acc: 0.9224\n",
      "Epoch 81/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.1655 - acc: 0.9372 - val_loss: 0.1683 - val_acc: 0.9224\n",
      "Epoch 82/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.1646 - acc: 0.9366 - val_loss: 0.1670 - val_acc: 0.9247\n",
      "Epoch 83/100\n",
      "1752/1752 [==============================] - 1s 319us/step - loss: 0.1629 - acc: 0.9366 - val_loss: 0.1667 - val_acc: 0.9247\n",
      "Epoch 84/100\n",
      "1752/1752 [==============================] - 1s 321us/step - loss: 0.1710 - acc: 0.9361 - val_loss: 0.1665 - val_acc: 0.9247\n",
      "Epoch 85/100\n",
      "1752/1752 [==============================] - 1s 320us/step - loss: 0.1624 - acc: 0.9326 - val_loss: 0.1698 - val_acc: 0.9224\n",
      "Epoch 86/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.1599 - acc: 0.9401 - val_loss: 0.1654 - val_acc: 0.9247\n",
      "Epoch 87/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.1588 - acc: 0.9401 - val_loss: 0.1652 - val_acc: 0.9247\n",
      "Epoch 88/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.1630 - acc: 0.9344 - val_loss: 0.1657 - val_acc: 0.9247\n",
      "Epoch 89/100\n",
      "1752/1752 [==============================] - 1s 317us/step - loss: 0.1604 - acc: 0.9418 - val_loss: 0.1676 - val_acc: 0.9224\n",
      "Epoch 90/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.1594 - acc: 0.9344 - val_loss: 0.1648 - val_acc: 0.9247\n",
      "Epoch 91/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.1597 - acc: 0.9406 - val_loss: 0.1637 - val_acc: 0.9247\n",
      "Epoch 92/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.1573 - acc: 0.9372 - val_loss: 0.1629 - val_acc: 0.9247\n",
      "Epoch 93/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.1472 - acc: 0.9429 - val_loss: 0.1639 - val_acc: 0.9269\n",
      "Epoch 94/100\n",
      "1752/1752 [==============================] - 1s 321us/step - loss: 0.1557 - acc: 0.9372 - val_loss: 0.1627 - val_acc: 0.9247\n",
      "Epoch 95/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.1547 - acc: 0.9366 - val_loss: 0.1633 - val_acc: 0.9247\n",
      "Epoch 96/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.1558 - acc: 0.9378 - val_loss: 0.1629 - val_acc: 0.9224\n",
      "Epoch 97/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.1482 - acc: 0.9458 - val_loss: 0.1620 - val_acc: 0.9224\n",
      "Epoch 98/100\n",
      "1752/1752 [==============================] - 1s 321us/step - loss: 0.1465 - acc: 0.9401 - val_loss: 0.1616 - val_acc: 0.9224\n",
      "Epoch 99/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.1556 - acc: 0.9412 - val_loss: 0.1628 - val_acc: 0.9247\n",
      "Epoch 100/100\n",
      "1752/1752 [==============================] - 1s 319us/step - loss: 0.1567 - acc: 0.9389 - val_loss: 0.1620 - val_acc: 0.9247\n",
      "Train on 1752 samples, validate on 438 samples\n",
      "Epoch 1/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.1791 - acc: 0.9321 - val_loss: 0.1735 - val_acc: 0.9452\n",
      "Epoch 2/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.1753 - acc: 0.9332 - val_loss: 0.1720 - val_acc: 0.9452\n",
      "Epoch 3/100\n",
      "1752/1752 [==============================] - 1s 319us/step - loss: 0.1654 - acc: 0.9406 - val_loss: 0.1699 - val_acc: 0.9384\n",
      "Epoch 4/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.1709 - acc: 0.9338 - val_loss: 0.1683 - val_acc: 0.9429\n",
      "Epoch 5/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.1706 - acc: 0.9378 - val_loss: 0.1672 - val_acc: 0.9406\n",
      "Epoch 6/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.1786 - acc: 0.9384 - val_loss: 0.1680 - val_acc: 0.9452\n",
      "Epoch 7/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.1604 - acc: 0.9458 - val_loss: 0.1659 - val_acc: 0.9429\n",
      "Epoch 8/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.1682 - acc: 0.9389 - val_loss: 0.1677 - val_acc: 0.9452\n",
      "Epoch 9/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.1649 - acc: 0.9412 - val_loss: 0.1652 - val_acc: 0.9406\n",
      "Epoch 10/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.1661 - acc: 0.9418 - val_loss: 0.1642 - val_acc: 0.9429\n",
      "Epoch 11/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.1595 - acc: 0.9418 - val_loss: 0.1626 - val_acc: 0.9406\n",
      "Epoch 12/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.1555 - acc: 0.9429 - val_loss: 0.1637 - val_acc: 0.9452\n",
      "Epoch 13/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.1609 - acc: 0.9475 - val_loss: 0.1623 - val_acc: 0.9406\n",
      "Epoch 14/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.1656 - acc: 0.9429 - val_loss: 0.1616 - val_acc: 0.9475\n",
      "Epoch 15/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.1634 - acc: 0.9446 - val_loss: 0.1608 - val_acc: 0.9406\n",
      "Epoch 16/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.1558 - acc: 0.9463 - val_loss: 0.1609 - val_acc: 0.9452\n",
      "Epoch 17/100\n",
      "1752/1752 [==============================] - 1s 335us/step - loss: 0.1553 - acc: 0.9446 - val_loss: 0.1586 - val_acc: 0.9475\n",
      "Epoch 18/100\n",
      "1752/1752 [==============================] - 1s 321us/step - loss: 0.1648 - acc: 0.9372 - val_loss: 0.1588 - val_acc: 0.9429\n",
      "Epoch 19/100\n",
      "1752/1752 [==============================] - 1s 321us/step - loss: 0.1696 - acc: 0.9463 - val_loss: 0.1602 - val_acc: 0.9452\n",
      "Epoch 20/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.1505 - acc: 0.9452 - val_loss: 0.1575 - val_acc: 0.9452\n",
      "Epoch 21/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.1502 - acc: 0.9446 - val_loss: 0.1565 - val_acc: 0.9452\n",
      "Epoch 22/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.1477 - acc: 0.9498 - val_loss: 0.1549 - val_acc: 0.9429\n",
      "Epoch 23/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.1493 - acc: 0.9521 - val_loss: 0.1572 - val_acc: 0.9452\n",
      "Epoch 24/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.1551 - acc: 0.9452 - val_loss: 0.1547 - val_acc: 0.9452\n",
      "Epoch 25/100\n",
      "1752/1752 [==============================] - 1s 355us/step - loss: 0.1513 - acc: 0.9429 - val_loss: 0.1551 - val_acc: 0.9452\n",
      "Epoch 26/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.1499 - acc: 0.9463 - val_loss: 0.1541 - val_acc: 0.9452\n",
      "Epoch 27/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.1452 - acc: 0.9509 - val_loss: 0.1546 - val_acc: 0.9452\n",
      "Epoch 28/100\n",
      "1752/1752 [==============================] - ETA: 0s - loss: 0.1488 - acc: 0.946 - 1s 331us/step - loss: 0.1486 - acc: 0.9469 - val_loss: 0.1521 - val_acc: 0.9498\n",
      "Epoch 29/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.1451 - acc: 0.9509 - val_loss: 0.1511 - val_acc: 0.9475\n",
      "Epoch 30/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.1527 - acc: 0.9441 - val_loss: 0.1517 - val_acc: 0.9498\n",
      "Epoch 31/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.1529 - acc: 0.9503 - val_loss: 0.1514 - val_acc: 0.9498\n",
      "Epoch 32/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.1433 - acc: 0.9515 - val_loss: 0.1510 - val_acc: 0.9498\n",
      "Epoch 33/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.1389 - acc: 0.9492 - val_loss: 0.1493 - val_acc: 0.9452\n",
      "Epoch 34/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.1452 - acc: 0.9475 - val_loss: 0.1493 - val_acc: 0.9498\n",
      "Epoch 35/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.1443 - acc: 0.9526 - val_loss: 0.1488 - val_acc: 0.9475\n",
      "Epoch 36/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.1418 - acc: 0.9469 - val_loss: 0.1475 - val_acc: 0.9475\n",
      "Epoch 37/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.1437 - acc: 0.9526 - val_loss: 0.1481 - val_acc: 0.9498\n",
      "Epoch 38/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.1416 - acc: 0.9486 - val_loss: 0.1477 - val_acc: 0.9475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.1449 - acc: 0.9469 - val_loss: 0.1488 - val_acc: 0.9475\n",
      "Epoch 40/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.1509 - acc: 0.9446 - val_loss: 0.1471 - val_acc: 0.9498\n",
      "Epoch 41/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.1444 - acc: 0.9515 - val_loss: 0.1475 - val_acc: 0.9452\n",
      "Epoch 42/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.1452 - acc: 0.9503 - val_loss: 0.1465 - val_acc: 0.9475\n",
      "Epoch 43/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.1369 - acc: 0.9521 - val_loss: 0.1448 - val_acc: 0.9475\n",
      "Epoch 44/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.1391 - acc: 0.9538 - val_loss: 0.1447 - val_acc: 0.9475\n",
      "Epoch 45/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.1378 - acc: 0.9492 - val_loss: 0.1450 - val_acc: 0.9475\n",
      "Epoch 46/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.1371 - acc: 0.9481 - val_loss: 0.1434 - val_acc: 0.9475\n",
      "Epoch 47/100\n",
      "1752/1752 [==============================] - 1s 338us/step - loss: 0.1420 - acc: 0.9509 - val_loss: 0.1441 - val_acc: 0.9475\n",
      "Epoch 48/100\n",
      "1752/1752 [==============================] - 1s 338us/step - loss: 0.1286 - acc: 0.9578 - val_loss: 0.1439 - val_acc: 0.9498\n",
      "Epoch 49/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.1335 - acc: 0.9503 - val_loss: 0.1434 - val_acc: 0.9498\n",
      "Epoch 50/100\n",
      "1752/1752 [==============================] - 1s 343us/step - loss: 0.1389 - acc: 0.9481 - val_loss: 0.1429 - val_acc: 0.9498\n",
      "Epoch 51/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.1392 - acc: 0.9515 - val_loss: 0.1427 - val_acc: 0.9475\n",
      "Epoch 52/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.1261 - acc: 0.9606 - val_loss: 0.1413 - val_acc: 0.9498\n",
      "Epoch 53/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.1382 - acc: 0.9555 - val_loss: 0.1405 - val_acc: 0.9498\n",
      "Epoch 54/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.1310 - acc: 0.9578 - val_loss: 0.1415 - val_acc: 0.9498\n",
      "Epoch 55/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.1296 - acc: 0.9549 - val_loss: 0.1396 - val_acc: 0.9498\n",
      "Epoch 56/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.1298 - acc: 0.9543 - val_loss: 0.1401 - val_acc: 0.9521\n",
      "Epoch 57/100\n",
      "1752/1752 [==============================] - 1s 337us/step - loss: 0.1347 - acc: 0.9561 - val_loss: 0.1399 - val_acc: 0.9498\n",
      "Epoch 58/100\n",
      "1752/1752 [==============================] - 1s 317us/step - loss: 0.1341 - acc: 0.9566 - val_loss: 0.1411 - val_acc: 0.9521\n",
      "Epoch 59/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.1279 - acc: 0.9600 - val_loss: 0.1411 - val_acc: 0.9498\n",
      "Epoch 60/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.1298 - acc: 0.9572 - val_loss: 0.1396 - val_acc: 0.9498\n",
      "Epoch 61/100\n",
      "1752/1752 [==============================] - 1s 320us/step - loss: 0.1374 - acc: 0.9532 - val_loss: 0.1422 - val_acc: 0.9498\n",
      "Epoch 62/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.1297 - acc: 0.9549 - val_loss: 0.1390 - val_acc: 0.9475\n",
      "Epoch 63/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.1291 - acc: 0.9583 - val_loss: 0.1399 - val_acc: 0.9498\n",
      "Epoch 64/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.1317 - acc: 0.9583 - val_loss: 0.1390 - val_acc: 0.9498\n",
      "Epoch 65/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.1273 - acc: 0.9572 - val_loss: 0.1384 - val_acc: 0.9498\n",
      "Epoch 66/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.1213 - acc: 0.9595 - val_loss: 0.1379 - val_acc: 0.9498\n",
      "Epoch 67/100\n",
      "1752/1752 [==============================] - 1s 320us/step - loss: 0.1236 - acc: 0.9612 - val_loss: 0.1366 - val_acc: 0.9475\n",
      "Epoch 68/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.1283 - acc: 0.9572 - val_loss: 0.1369 - val_acc: 0.9521\n",
      "Epoch 69/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.1281 - acc: 0.9583 - val_loss: 0.1391 - val_acc: 0.9498\n",
      "Epoch 70/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.1261 - acc: 0.9549 - val_loss: 0.1353 - val_acc: 0.9498\n",
      "Epoch 71/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.1286 - acc: 0.9521 - val_loss: 0.1374 - val_acc: 0.9521\n",
      "Epoch 72/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.1155 - acc: 0.9623 - val_loss: 0.1366 - val_acc: 0.9521\n",
      "Epoch 73/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.1270 - acc: 0.9521 - val_loss: 0.1352 - val_acc: 0.9475\n",
      "Epoch 74/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.1279 - acc: 0.9595 - val_loss: 0.1362 - val_acc: 0.9475\n",
      "Epoch 75/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.1254 - acc: 0.9589 - val_loss: 0.1360 - val_acc: 0.9521\n",
      "Epoch 76/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.1310 - acc: 0.9595 - val_loss: 0.1358 - val_acc: 0.9521\n",
      "Epoch 77/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.1181 - acc: 0.9652 - val_loss: 0.1352 - val_acc: 0.9498\n",
      "Epoch 78/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.1274 - acc: 0.9595 - val_loss: 0.1358 - val_acc: 0.9521\n",
      "Epoch 79/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.1189 - acc: 0.9583 - val_loss: 0.1345 - val_acc: 0.9521\n",
      "Epoch 80/100\n",
      "1752/1752 [==============================] - 1s 319us/step - loss: 0.1204 - acc: 0.9595 - val_loss: 0.1346 - val_acc: 0.9521\n",
      "Epoch 81/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.1211 - acc: 0.9589 - val_loss: 0.1356 - val_acc: 0.9521\n",
      "Epoch 82/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.1386 - acc: 0.9549 - val_loss: 0.1342 - val_acc: 0.9521\n",
      "Epoch 83/100\n",
      "1752/1752 [==============================] - 1s 347us/step - loss: 0.1162 - acc: 0.9623 - val_loss: 0.1346 - val_acc: 0.9521\n",
      "Epoch 84/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.1177 - acc: 0.9606 - val_loss: 0.1336 - val_acc: 0.9498\n",
      "Epoch 85/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.1164 - acc: 0.9640 - val_loss: 0.1338 - val_acc: 0.9521\n",
      "Epoch 86/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.1248 - acc: 0.9555 - val_loss: 0.1345 - val_acc: 0.9521\n",
      "Epoch 87/100\n",
      "1752/1752 [==============================] - 1s 337us/step - loss: 0.1090 - acc: 0.9663 - val_loss: 0.1331 - val_acc: 0.9498\n",
      "Epoch 88/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.1161 - acc: 0.9589 - val_loss: 0.1325 - val_acc: 0.9521\n",
      "Epoch 89/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.1151 - acc: 0.9618 - val_loss: 0.1330 - val_acc: 0.9521\n",
      "Epoch 90/100\n",
      "1752/1752 [==============================] - 1s 321us/step - loss: 0.1163 - acc: 0.9623 - val_loss: 0.1342 - val_acc: 0.9521\n",
      "Epoch 91/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.1216 - acc: 0.9589 - val_loss: 0.1322 - val_acc: 0.9521\n",
      "Epoch 92/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.1140 - acc: 0.9635 - val_loss: 0.1337 - val_acc: 0.9521\n",
      "Epoch 93/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.1187 - acc: 0.9561 - val_loss: 0.1330 - val_acc: 0.9521\n",
      "Epoch 94/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.1120 - acc: 0.9612 - val_loss: 0.1325 - val_acc: 0.9521\n",
      "Epoch 95/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.1126 - acc: 0.9595 - val_loss: 0.1316 - val_acc: 0.9521\n",
      "Epoch 96/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.1137 - acc: 0.9652 - val_loss: 0.1329 - val_acc: 0.9521\n",
      "Epoch 97/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.1176 - acc: 0.9623 - val_loss: 0.1312 - val_acc: 0.9521\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.1101 - acc: 0.9652 - val_loss: 0.1323 - val_acc: 0.9521\n",
      "Epoch 99/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.1211 - acc: 0.9606 - val_loss: 0.1312 - val_acc: 0.9521\n",
      "Epoch 100/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.1120 - acc: 0.9640 - val_loss: 0.1304 - val_acc: 0.9475\n",
      "Test subject 9, class Replace\n",
      "Train subject 9, class BothReleased\n",
      "Train on 1752 samples, validate on 438 samples\n",
      "Epoch 1/100\n",
      "1752/1752 [==============================] - 1s 513us/step - loss: 0.6308 - acc: 0.7808 - val_loss: 0.5568 - val_acc: 0.7945\n",
      "Epoch 2/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.4666 - acc: 0.8168 - val_loss: 0.4918 - val_acc: 0.8128\n",
      "Epoch 3/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.4354 - acc: 0.8185 - val_loss: 0.4445 - val_acc: 0.8219\n",
      "Epoch 4/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.3879 - acc: 0.8305 - val_loss: 0.4183 - val_acc: 0.8265\n",
      "Epoch 5/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.3653 - acc: 0.8402 - val_loss: 0.4005 - val_acc: 0.8288\n",
      "Epoch 6/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.3550 - acc: 0.8487 - val_loss: 0.3758 - val_acc: 0.8425\n",
      "Epoch 7/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.3439 - acc: 0.8590 - val_loss: 0.3643 - val_acc: 0.8493\n",
      "Epoch 8/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.3322 - acc: 0.8596 - val_loss: 0.3507 - val_acc: 0.8516\n",
      "Epoch 9/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.3113 - acc: 0.8801 - val_loss: 0.3362 - val_acc: 0.8584\n",
      "Epoch 10/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.3126 - acc: 0.8693 - val_loss: 0.3282 - val_acc: 0.8562\n",
      "Epoch 11/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.3163 - acc: 0.8676 - val_loss: 0.3220 - val_acc: 0.8607\n",
      "Epoch 12/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.2959 - acc: 0.8796 - val_loss: 0.3087 - val_acc: 0.8790\n",
      "Epoch 13/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.2914 - acc: 0.8818 - val_loss: 0.3026 - val_acc: 0.8790\n",
      "Epoch 14/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.2870 - acc: 0.8836 - val_loss: 0.2960 - val_acc: 0.8836\n",
      "Epoch 15/100\n",
      "1752/1752 [==============================] - 1s 337us/step - loss: 0.2871 - acc: 0.8847 - val_loss: 0.2935 - val_acc: 0.8813\n",
      "Epoch 16/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.2740 - acc: 0.8938 - val_loss: 0.2905 - val_acc: 0.8881\n",
      "Epoch 17/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.2627 - acc: 0.8921 - val_loss: 0.2827 - val_acc: 0.8973\n",
      "Epoch 18/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.2717 - acc: 0.8858 - val_loss: 0.2782 - val_acc: 0.8973\n",
      "Epoch 19/100\n",
      "1752/1752 [==============================] - 1s 339us/step - loss: 0.2649 - acc: 0.8978 - val_loss: 0.2802 - val_acc: 0.8995\n",
      "Epoch 20/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.2645 - acc: 0.8916 - val_loss: 0.2713 - val_acc: 0.9041\n",
      "Epoch 21/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.2537 - acc: 0.8933 - val_loss: 0.2721 - val_acc: 0.9018\n",
      "Epoch 22/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.2627 - acc: 0.9035 - val_loss: 0.2667 - val_acc: 0.9018\n",
      "Epoch 23/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.2515 - acc: 0.9024 - val_loss: 0.2677 - val_acc: 0.9064\n",
      "Epoch 24/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.2533 - acc: 0.8950 - val_loss: 0.2617 - val_acc: 0.9110\n",
      "Epoch 25/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.2442 - acc: 0.9081 - val_loss: 0.2587 - val_acc: 0.9110\n",
      "Epoch 26/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.2480 - acc: 0.9058 - val_loss: 0.2554 - val_acc: 0.9155\n",
      "Epoch 27/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.2473 - acc: 0.9035 - val_loss: 0.2546 - val_acc: 0.9132\n",
      "Epoch 28/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.2396 - acc: 0.9087 - val_loss: 0.2517 - val_acc: 0.9132\n",
      "Epoch 29/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.2456 - acc: 0.9075 - val_loss: 0.2516 - val_acc: 0.9178\n",
      "Epoch 30/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.2305 - acc: 0.9132 - val_loss: 0.2489 - val_acc: 0.9201\n",
      "Epoch 31/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.2273 - acc: 0.9110 - val_loss: 0.2460 - val_acc: 0.9224\n",
      "Epoch 32/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.2233 - acc: 0.9201 - val_loss: 0.2431 - val_acc: 0.9224\n",
      "Epoch 33/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.2231 - acc: 0.9172 - val_loss: 0.2425 - val_acc: 0.9201\n",
      "Epoch 34/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.2148 - acc: 0.9144 - val_loss: 0.2413 - val_acc: 0.9247\n",
      "Epoch 35/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.2170 - acc: 0.9184 - val_loss: 0.2414 - val_acc: 0.9247\n",
      "Epoch 36/100\n",
      "1752/1752 [==============================] - 1s 335us/step - loss: 0.2305 - acc: 0.9104 - val_loss: 0.2415 - val_acc: 0.9201\n",
      "Epoch 37/100\n",
      "1752/1752 [==============================] - 1s 335us/step - loss: 0.2255 - acc: 0.9178 - val_loss: 0.2392 - val_acc: 0.9201\n",
      "Epoch 38/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.2166 - acc: 0.9201 - val_loss: 0.2363 - val_acc: 0.9201\n",
      "Epoch 39/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.2088 - acc: 0.9229 - val_loss: 0.2337 - val_acc: 0.9224\n",
      "Epoch 40/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.2141 - acc: 0.9161 - val_loss: 0.2346 - val_acc: 0.9201\n",
      "Epoch 41/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.2084 - acc: 0.9218 - val_loss: 0.2323 - val_acc: 0.9178\n",
      "Epoch 42/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.2143 - acc: 0.9207 - val_loss: 0.2350 - val_acc: 0.9201\n",
      "Epoch 43/100\n",
      "1752/1752 [==============================] - 1s 335us/step - loss: 0.2083 - acc: 0.9241 - val_loss: 0.2305 - val_acc: 0.9201\n",
      "Epoch 44/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.2092 - acc: 0.9218 - val_loss: 0.2320 - val_acc: 0.9224\n",
      "Epoch 45/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.2089 - acc: 0.9218 - val_loss: 0.2299 - val_acc: 0.9201\n",
      "Epoch 46/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.1967 - acc: 0.9326 - val_loss: 0.2270 - val_acc: 0.9224\n",
      "Epoch 47/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.1956 - acc: 0.9247 - val_loss: 0.2281 - val_acc: 0.9224\n",
      "Epoch 48/100\n",
      "1752/1752 [==============================] - 1s 335us/step - loss: 0.2042 - acc: 0.9235 - val_loss: 0.2261 - val_acc: 0.9224\n",
      "Epoch 49/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.2093 - acc: 0.9195 - val_loss: 0.2267 - val_acc: 0.9224\n",
      "Epoch 50/100\n",
      "1752/1752 [==============================] - 1s 335us/step - loss: 0.1934 - acc: 0.9224 - val_loss: 0.2256 - val_acc: 0.9247\n",
      "Epoch 51/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.1942 - acc: 0.9212 - val_loss: 0.2237 - val_acc: 0.9201\n",
      "Epoch 52/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.1919 - acc: 0.9281 - val_loss: 0.2223 - val_acc: 0.9247\n",
      "Epoch 53/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.1913 - acc: 0.9292 - val_loss: 0.2215 - val_acc: 0.9247\n",
      "Epoch 54/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.1999 - acc: 0.9218 - val_loss: 0.2219 - val_acc: 0.9201\n",
      "Epoch 55/100\n",
      "1752/1752 [==============================] - 1s 341us/step - loss: 0.1898 - acc: 0.9275 - val_loss: 0.2214 - val_acc: 0.9201\n",
      "Epoch 56/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.1915 - acc: 0.9269 - val_loss: 0.2202 - val_acc: 0.9247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "1752/1752 [==============================] - 1s 321us/step - loss: 0.1861 - acc: 0.9332 - val_loss: 0.2193 - val_acc: 0.9201\n",
      "Epoch 58/100\n",
      "1752/1752 [==============================] - 1s 341us/step - loss: 0.1915 - acc: 0.9287 - val_loss: 0.2191 - val_acc: 0.9201\n",
      "Epoch 59/100\n",
      "1752/1752 [==============================] - 1s 338us/step - loss: 0.1903 - acc: 0.9292 - val_loss: 0.2199 - val_acc: 0.9201\n",
      "Epoch 60/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.1980 - acc: 0.9258 - val_loss: 0.2173 - val_acc: 0.9224\n",
      "Epoch 61/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.1900 - acc: 0.9332 - val_loss: 0.2169 - val_acc: 0.9201\n",
      "Epoch 62/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.1860 - acc: 0.9281 - val_loss: 0.2159 - val_acc: 0.9224\n",
      "Epoch 63/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.1868 - acc: 0.9298 - val_loss: 0.2172 - val_acc: 0.9224\n",
      "Epoch 64/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.1854 - acc: 0.9275 - val_loss: 0.2168 - val_acc: 0.9201\n",
      "Epoch 65/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.1788 - acc: 0.9304 - val_loss: 0.2154 - val_acc: 0.9201\n",
      "Epoch 66/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.1767 - acc: 0.9349 - val_loss: 0.2142 - val_acc: 0.9269\n",
      "Epoch 67/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.1855 - acc: 0.9292 - val_loss: 0.2121 - val_acc: 0.9247\n",
      "Epoch 68/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.1848 - acc: 0.9315 - val_loss: 0.2116 - val_acc: 0.9224\n",
      "Epoch 69/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.1752 - acc: 0.9332 - val_loss: 0.2117 - val_acc: 0.9224\n",
      "Epoch 70/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.1757 - acc: 0.9315 - val_loss: 0.2117 - val_acc: 0.9224\n",
      "Epoch 71/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.1846 - acc: 0.9326 - val_loss: 0.2108 - val_acc: 0.9247\n",
      "Epoch 72/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.1777 - acc: 0.9332 - val_loss: 0.2099 - val_acc: 0.9247\n",
      "Epoch 73/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.1721 - acc: 0.9366 - val_loss: 0.2095 - val_acc: 0.9315\n",
      "Epoch 74/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.1836 - acc: 0.9315 - val_loss: 0.2076 - val_acc: 0.9315\n",
      "Epoch 75/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.1730 - acc: 0.9332 - val_loss: 0.2098 - val_acc: 0.9201\n",
      "Epoch 76/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.1794 - acc: 0.9338 - val_loss: 0.2070 - val_acc: 0.9292\n",
      "Epoch 77/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.1750 - acc: 0.9338 - val_loss: 0.2063 - val_acc: 0.9224\n",
      "Epoch 78/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.1686 - acc: 0.9378 - val_loss: 0.2057 - val_acc: 0.9247\n",
      "Epoch 79/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.1751 - acc: 0.9349 - val_loss: 0.2064 - val_acc: 0.9224\n",
      "Epoch 80/100\n",
      "1752/1752 [==============================] - 1s 338us/step - loss: 0.1711 - acc: 0.9378 - val_loss: 0.2050 - val_acc: 0.9292\n",
      "Epoch 81/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.1707 - acc: 0.9366 - val_loss: 0.2055 - val_acc: 0.9247\n",
      "Epoch 82/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.1677 - acc: 0.9389 - val_loss: 0.2057 - val_acc: 0.9269\n",
      "Epoch 83/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.1700 - acc: 0.9355 - val_loss: 0.2037 - val_acc: 0.9269\n",
      "Epoch 84/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.1695 - acc: 0.9384 - val_loss: 0.2045 - val_acc: 0.9269\n",
      "Epoch 85/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.1682 - acc: 0.9349 - val_loss: 0.2047 - val_acc: 0.9247\n",
      "Epoch 86/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.1675 - acc: 0.9435 - val_loss: 0.2041 - val_acc: 0.9269\n",
      "Epoch 87/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.1653 - acc: 0.9395 - val_loss: 0.2041 - val_acc: 0.9269\n",
      "Epoch 88/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.1654 - acc: 0.9389 - val_loss: 0.2040 - val_acc: 0.9224\n",
      "Epoch 89/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.1706 - acc: 0.9389 - val_loss: 0.2017 - val_acc: 0.9292\n",
      "Epoch 90/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.1654 - acc: 0.9401 - val_loss: 0.2014 - val_acc: 0.9292\n",
      "Epoch 91/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.1611 - acc: 0.9418 - val_loss: 0.2000 - val_acc: 0.9315\n",
      "Epoch 92/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.1662 - acc: 0.9435 - val_loss: 0.2005 - val_acc: 0.9292\n",
      "Epoch 93/100\n",
      "1752/1752 [==============================] - 1s 339us/step - loss: 0.1612 - acc: 0.9372 - val_loss: 0.2009 - val_acc: 0.9269\n",
      "Epoch 94/100\n",
      "1752/1752 [==============================] - ETA: 0s - loss: 0.1482 - acc: 0.945 - 1s 323us/step - loss: 0.1583 - acc: 0.9406 - val_loss: 0.2012 - val_acc: 0.9269\n",
      "Epoch 95/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.1615 - acc: 0.9401 - val_loss: 0.2024 - val_acc: 0.9269\n",
      "Epoch 96/100\n",
      "1752/1752 [==============================] - 1s 337us/step - loss: 0.1629 - acc: 0.9389 - val_loss: 0.2006 - val_acc: 0.9292\n",
      "Epoch 97/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.1623 - acc: 0.9441 - val_loss: 0.2015 - val_acc: 0.9269\n",
      "Epoch 98/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.1593 - acc: 0.9418 - val_loss: 0.2004 - val_acc: 0.9315\n",
      "Epoch 99/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.1568 - acc: 0.9429 - val_loss: 0.2005 - val_acc: 0.9338\n",
      "Epoch 100/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.1580 - acc: 0.9418 - val_loss: 0.1985 - val_acc: 0.9338\n",
      "Train on 1752 samples, validate on 438 samples\n",
      "Epoch 1/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.1718 - acc: 0.9372 - val_loss: 0.1712 - val_acc: 0.9315\n",
      "Epoch 2/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.1768 - acc: 0.9355 - val_loss: 0.1719 - val_acc: 0.9292\n",
      "Epoch 3/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.1691 - acc: 0.9384 - val_loss: 0.1647 - val_acc: 0.9384\n",
      "Epoch 4/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.1627 - acc: 0.9424 - val_loss: 0.1711 - val_acc: 0.9315\n",
      "Epoch 5/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.1663 - acc: 0.9435 - val_loss: 0.1675 - val_acc: 0.9315\n",
      "Epoch 6/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.1718 - acc: 0.9441 - val_loss: 0.1684 - val_acc: 0.9315\n",
      "Epoch 7/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.1638 - acc: 0.9412 - val_loss: 0.1628 - val_acc: 0.9406\n",
      "Epoch 8/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.1615 - acc: 0.9406 - val_loss: 0.1730 - val_acc: 0.9269\n",
      "Epoch 9/100\n",
      "1752/1752 [==============================] - 1s 348us/step - loss: 0.1605 - acc: 0.9412 - val_loss: 0.1628 - val_acc: 0.9384\n",
      "Epoch 10/100\n",
      "1752/1752 [==============================] - 1s 388us/step - loss: 0.1575 - acc: 0.9435 - val_loss: 0.1639 - val_acc: 0.9338\n",
      "Epoch 11/100\n",
      "1752/1752 [==============================] - 1s 385us/step - loss: 0.1549 - acc: 0.9463 - val_loss: 0.1611 - val_acc: 0.9384\n",
      "Epoch 12/100\n",
      "1752/1752 [==============================] - 1s 377us/step - loss: 0.1655 - acc: 0.9412 - val_loss: 0.1618 - val_acc: 0.9384\n",
      "Epoch 13/100\n",
      "1752/1752 [==============================] - 1s 378us/step - loss: 0.1536 - acc: 0.9492 - val_loss: 0.1663 - val_acc: 0.9338\n",
      "Epoch 14/100\n",
      "1752/1752 [==============================] - 1s 348us/step - loss: 0.1616 - acc: 0.9395 - val_loss: 0.1585 - val_acc: 0.9406\n",
      "Epoch 15/100\n",
      "1752/1752 [==============================] - 1s 388us/step - loss: 0.1508 - acc: 0.9498 - val_loss: 0.1612 - val_acc: 0.9384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "1752/1752 [==============================] - 1s 363us/step - loss: 0.1514 - acc: 0.9521 - val_loss: 0.1619 - val_acc: 0.9384\n",
      "Epoch 17/100\n",
      "1752/1752 [==============================] - 1s 353us/step - loss: 0.1495 - acc: 0.9486 - val_loss: 0.1629 - val_acc: 0.9384\n",
      "Epoch 18/100\n",
      "1752/1752 [==============================] - 1s 354us/step - loss: 0.1504 - acc: 0.9458 - val_loss: 0.1601 - val_acc: 0.9384\n",
      "Epoch 19/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.1513 - acc: 0.9486 - val_loss: 0.1589 - val_acc: 0.9406\n",
      "Epoch 20/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.1487 - acc: 0.9475 - val_loss: 0.1632 - val_acc: 0.9384\n",
      "Epoch 21/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.1497 - acc: 0.9469 - val_loss: 0.1580 - val_acc: 0.9406\n",
      "Epoch 22/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.1444 - acc: 0.9503 - val_loss: 0.1569 - val_acc: 0.9429\n",
      "Epoch 23/100\n",
      "1752/1752 [==============================] - 1s 349us/step - loss: 0.1435 - acc: 0.9503 - val_loss: 0.1589 - val_acc: 0.9406\n",
      "Epoch 24/100\n",
      "1752/1752 [==============================] - 1s 349us/step - loss: 0.1509 - acc: 0.9492 - val_loss: 0.1633 - val_acc: 0.9361\n",
      "Epoch 25/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.1514 - acc: 0.9486 - val_loss: 0.1599 - val_acc: 0.9361\n",
      "Epoch 26/100\n",
      "1752/1752 [==============================] - 1s 335us/step - loss: 0.1468 - acc: 0.9481 - val_loss: 0.1539 - val_acc: 0.9475\n",
      "Epoch 27/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.1378 - acc: 0.9555 - val_loss: 0.1525 - val_acc: 0.9475\n",
      "Epoch 28/100\n",
      "1752/1752 [==============================] - 1s 337us/step - loss: 0.1458 - acc: 0.9543 - val_loss: 0.1574 - val_acc: 0.9406\n",
      "Epoch 29/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.1425 - acc: 0.9509 - val_loss: 0.1605 - val_acc: 0.9361\n",
      "Epoch 30/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.1381 - acc: 0.9572 - val_loss: 0.1574 - val_acc: 0.9429\n",
      "Epoch 31/100\n",
      "1752/1752 [==============================] - 1s 325us/step - loss: 0.1445 - acc: 0.9469 - val_loss: 0.1556 - val_acc: 0.9429\n",
      "Epoch 32/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.1453 - acc: 0.9555 - val_loss: 0.1577 - val_acc: 0.9406\n",
      "Epoch 33/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.1451 - acc: 0.9515 - val_loss: 0.1519 - val_acc: 0.9475\n",
      "Epoch 34/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.1317 - acc: 0.9618 - val_loss: 0.1504 - val_acc: 0.9521\n",
      "Epoch 35/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.1351 - acc: 0.9572 - val_loss: 0.1534 - val_acc: 0.9475\n",
      "Epoch 36/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.1429 - acc: 0.9526 - val_loss: 0.1598 - val_acc: 0.9384\n",
      "Epoch 37/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.1328 - acc: 0.9532 - val_loss: 0.1586 - val_acc: 0.9406\n",
      "Epoch 38/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.1409 - acc: 0.9543 - val_loss: 0.1570 - val_acc: 0.9429\n",
      "Epoch 39/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.1362 - acc: 0.9543 - val_loss: 0.1567 - val_acc: 0.9429\n",
      "Epoch 40/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.1354 - acc: 0.9526 - val_loss: 0.1575 - val_acc: 0.9361\n",
      "Epoch 41/100\n",
      "1752/1752 [==============================] - 1s 327us/step - loss: 0.1305 - acc: 0.9583 - val_loss: 0.1536 - val_acc: 0.9429\n",
      "Epoch 42/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.1314 - acc: 0.9606 - val_loss: 0.1555 - val_acc: 0.9406\n",
      "Epoch 43/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.1432 - acc: 0.9481 - val_loss: 0.1538 - val_acc: 0.9452\n",
      "Epoch 44/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.1313 - acc: 0.9578 - val_loss: 0.1489 - val_acc: 0.9498\n",
      "Epoch 45/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.1344 - acc: 0.9555 - val_loss: 0.1550 - val_acc: 0.9429\n",
      "Epoch 46/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.1302 - acc: 0.9572 - val_loss: 0.1515 - val_acc: 0.9475\n",
      "Epoch 47/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.1341 - acc: 0.9549 - val_loss: 0.1479 - val_acc: 0.9543\n",
      "Epoch 48/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.1338 - acc: 0.9543 - val_loss: 0.1524 - val_acc: 0.9452\n",
      "Epoch 49/100\n",
      "1752/1752 [==============================] - 1s 323us/step - loss: 0.1256 - acc: 0.9583 - val_loss: 0.1523 - val_acc: 0.9475\n",
      "Epoch 50/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.1322 - acc: 0.9595 - val_loss: 0.1500 - val_acc: 0.9498\n",
      "Epoch 51/100\n",
      "1752/1752 [==============================] - 1s 328us/step - loss: 0.1285 - acc: 0.9595 - val_loss: 0.1533 - val_acc: 0.9452\n",
      "Epoch 52/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.1353 - acc: 0.9549 - val_loss: 0.1541 - val_acc: 0.9429\n",
      "Epoch 53/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.1222 - acc: 0.9618 - val_loss: 0.1539 - val_acc: 0.9475\n",
      "Epoch 54/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.1290 - acc: 0.9618 - val_loss: 0.1540 - val_acc: 0.9452\n",
      "Epoch 55/100\n",
      "1752/1752 [==============================] - 1s 322us/step - loss: 0.1289 - acc: 0.9595 - val_loss: 0.1563 - val_acc: 0.9429\n",
      "Epoch 56/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.1317 - acc: 0.9583 - val_loss: 0.1506 - val_acc: 0.9498\n",
      "Epoch 57/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.1243 - acc: 0.9629 - val_loss: 0.1565 - val_acc: 0.9429\n",
      "Epoch 58/100\n",
      "1752/1752 [==============================] - 1s 340us/step - loss: 0.1249 - acc: 0.9589 - val_loss: 0.1529 - val_acc: 0.9475\n",
      "Epoch 59/100\n",
      "1752/1752 [==============================] - 1s 353us/step - loss: 0.1306 - acc: 0.9555 - val_loss: 0.1536 - val_acc: 0.9475\n",
      "Epoch 60/100\n",
      "1752/1752 [==============================] - 1s 337us/step - loss: 0.1277 - acc: 0.9595 - val_loss: 0.1518 - val_acc: 0.9498\n",
      "Epoch 61/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.1190 - acc: 0.9623 - val_loss: 0.1524 - val_acc: 0.9475\n",
      "Epoch 62/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.1160 - acc: 0.9663 - val_loss: 0.1491 - val_acc: 0.9521\n",
      "Epoch 63/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.1338 - acc: 0.9509 - val_loss: 0.1506 - val_acc: 0.9498\n",
      "Epoch 64/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.1218 - acc: 0.9595 - val_loss: 0.1454 - val_acc: 0.9612\n",
      "Epoch 65/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.1182 - acc: 0.9680 - val_loss: 0.1480 - val_acc: 0.9612\n",
      "Epoch 66/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.1248 - acc: 0.9589 - val_loss: 0.1467 - val_acc: 0.9612\n",
      "Epoch 67/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.1278 - acc: 0.9612 - val_loss: 0.1539 - val_acc: 0.9521\n",
      "Epoch 68/100\n",
      "1752/1752 [==============================] - 1s 338us/step - loss: 0.1258 - acc: 0.9600 - val_loss: 0.1489 - val_acc: 0.9566\n",
      "Epoch 69/100\n",
      "1752/1752 [==============================] - 1s 378us/step - loss: 0.1304 - acc: 0.9561 - val_loss: 0.1507 - val_acc: 0.9521\n",
      "Epoch 70/100\n",
      "1752/1752 [==============================] - 1s 360us/step - loss: 0.1195 - acc: 0.9646 - val_loss: 0.1501 - val_acc: 0.9543\n",
      "Epoch 71/100\n",
      "1752/1752 [==============================] - 1s 350us/step - loss: 0.1122 - acc: 0.9669 - val_loss: 0.1505 - val_acc: 0.9543\n",
      "Epoch 72/100\n",
      "1752/1752 [==============================] - 1s 379us/step - loss: 0.1220 - acc: 0.9606 - val_loss: 0.1558 - val_acc: 0.9498\n",
      "Epoch 73/100\n",
      "1752/1752 [==============================] - 1s 338us/step - loss: 0.1227 - acc: 0.9595 - val_loss: 0.1535 - val_acc: 0.9475\n",
      "Epoch 74/100\n",
      "1752/1752 [==============================] - 1s 343us/step - loss: 0.1222 - acc: 0.9623 - val_loss: 0.1545 - val_acc: 0.9498\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1752/1752 [==============================] - 1s 344us/step - loss: 0.1173 - acc: 0.9652 - val_loss: 0.1504 - val_acc: 0.9521\n",
      "Epoch 76/100\n",
      "1752/1752 [==============================] - 1s 336us/step - loss: 0.1275 - acc: 0.9623 - val_loss: 0.1500 - val_acc: 0.9521\n",
      "Epoch 77/100\n",
      "1752/1752 [==============================] - 1s 351us/step - loss: 0.1143 - acc: 0.9623 - val_loss: 0.1507 - val_acc: 0.9498\n",
      "Epoch 78/100\n",
      "1752/1752 [==============================] - 1s 344us/step - loss: 0.1195 - acc: 0.9572 - val_loss: 0.1467 - val_acc: 0.9543\n",
      "Epoch 79/100\n",
      "1752/1752 [==============================] - 1s 344us/step - loss: 0.1200 - acc: 0.9612 - val_loss: 0.1497 - val_acc: 0.9521\n",
      "Epoch 80/100\n",
      "1752/1752 [==============================] - 1s 349us/step - loss: 0.1238 - acc: 0.9612 - val_loss: 0.1474 - val_acc: 0.9543\n",
      "Epoch 81/100\n",
      "1752/1752 [==============================] - 1s 357us/step - loss: 0.1244 - acc: 0.9595 - val_loss: 0.1490 - val_acc: 0.9543\n",
      "Epoch 82/100\n",
      "1752/1752 [==============================] - 1s 349us/step - loss: 0.1257 - acc: 0.9595 - val_loss: 0.1469 - val_acc: 0.9543\n",
      "Epoch 83/100\n",
      "1752/1752 [==============================] - 1s 346us/step - loss: 0.1153 - acc: 0.9600 - val_loss: 0.1453 - val_acc: 0.9566\n",
      "Epoch 84/100\n",
      "1752/1752 [==============================] - 1s 331us/step - loss: 0.1165 - acc: 0.9640 - val_loss: 0.1457 - val_acc: 0.9566\n",
      "Epoch 85/100\n",
      "1752/1752 [==============================] - 1s 352us/step - loss: 0.1177 - acc: 0.9606 - val_loss: 0.1479 - val_acc: 0.9543\n",
      "Epoch 86/100\n",
      "1752/1752 [==============================] - 1s 326us/step - loss: 0.1173 - acc: 0.9618 - val_loss: 0.1450 - val_acc: 0.9543\n",
      "Epoch 87/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.1115 - acc: 0.9692 - val_loss: 0.1452 - val_acc: 0.9543\n",
      "Epoch 88/100\n",
      "1752/1752 [==============================] - 1s 352us/step - loss: 0.1208 - acc: 0.9623 - val_loss: 0.1496 - val_acc: 0.9543\n",
      "Epoch 89/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.1205 - acc: 0.9618 - val_loss: 0.1465 - val_acc: 0.9543\n",
      "Epoch 90/100\n",
      "1752/1752 [==============================] - 1s 348us/step - loss: 0.1216 - acc: 0.9646 - val_loss: 0.1482 - val_acc: 0.9543\n",
      "Epoch 91/100\n",
      "1752/1752 [==============================] - 1s 347us/step - loss: 0.1111 - acc: 0.9652 - val_loss: 0.1476 - val_acc: 0.9543\n",
      "Epoch 92/100\n",
      "1752/1752 [==============================] - 1s 334us/step - loss: 0.1154 - acc: 0.9652 - val_loss: 0.1481 - val_acc: 0.9543\n",
      "Epoch 93/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.1160 - acc: 0.9640 - val_loss: 0.1478 - val_acc: 0.9521\n",
      "Epoch 94/100\n",
      "1752/1752 [==============================] - 1s 333us/step - loss: 0.1102 - acc: 0.9697 - val_loss: 0.1430 - val_acc: 0.9589\n",
      "Epoch 95/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.1126 - acc: 0.9663 - val_loss: 0.1437 - val_acc: 0.9566\n",
      "Epoch 96/100\n",
      "1752/1752 [==============================] - 1s 330us/step - loss: 0.1166 - acc: 0.9618 - val_loss: 0.1518 - val_acc: 0.9521\n",
      "Epoch 97/100\n",
      "1752/1752 [==============================] - 1s 332us/step - loss: 0.1124 - acc: 0.9646 - val_loss: 0.1448 - val_acc: 0.9566\n",
      "Epoch 98/100\n",
      "1752/1752 [==============================] - 1s 329us/step - loss: 0.1068 - acc: 0.9675 - val_loss: 0.1419 - val_acc: 0.9566\n",
      "Epoch 99/100\n",
      "1752/1752 [==============================] - 1s 324us/step - loss: 0.1156 - acc: 0.9635 - val_loss: 0.1420 - val_acc: 0.9566\n",
      "Epoch 100/100\n",
      "1752/1752 [==============================] - 1s 339us/step - loss: 0.1095 - acc: 0.9663 - val_loss: 0.1397 - val_acc: 0.9612\n",
      "Test subject 9, class BothReleased\n",
      "HandStart AUC score = 0.649\n",
      "FirstDigitTouch AUC score = 0.897\n",
      "BothStartLoadPhase AUC score = 0.889\n",
      "LiftOff AUC score = 0.864\n",
      "Replace AUC score = 0.899\n",
      "BothReleased AUC score = 0.873\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49069 49069\n",
      "Train subject 10, class HandStart\n",
      "Train on 1944 samples, validate on 486 samples\n",
      "Epoch 1/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 1.1731 - acc: 0.6116 - val_loss: 0.7018 - val_acc: 0.6235\n",
      "Epoch 2/100\n",
      "1944/1944 [==============================] - 1s 334us/step - loss: 0.6547 - acc: 0.6348 - val_loss: 0.6618 - val_acc: 0.6440\n",
      "Epoch 3/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.6243 - acc: 0.6610 - val_loss: 0.6209 - val_acc: 0.6687\n",
      "Epoch 4/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.6068 - acc: 0.6667 - val_loss: 0.6227 - val_acc: 0.6749\n",
      "Epoch 5/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.5949 - acc: 0.6831 - val_loss: 0.6201 - val_acc: 0.6728\n",
      "Epoch 6/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.5712 - acc: 0.6975 - val_loss: 0.6009 - val_acc: 0.6955\n",
      "Epoch 7/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.5655 - acc: 0.7068 - val_loss: 0.5977 - val_acc: 0.6975\n",
      "Epoch 8/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.5627 - acc: 0.7022 - val_loss: 0.5812 - val_acc: 0.7119\n",
      "Epoch 9/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.5472 - acc: 0.7109 - val_loss: 0.5640 - val_acc: 0.7160\n",
      "Epoch 10/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.5417 - acc: 0.7279 - val_loss: 0.5572 - val_acc: 0.7346\n",
      "Epoch 11/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.5397 - acc: 0.7202 - val_loss: 0.5589 - val_acc: 0.7305\n",
      "Epoch 12/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.5332 - acc: 0.7207 - val_loss: 0.5270 - val_acc: 0.7181\n",
      "Epoch 13/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.5234 - acc: 0.7330 - val_loss: 0.5425 - val_acc: 0.7366\n",
      "Epoch 14/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.5225 - acc: 0.7330 - val_loss: 0.5366 - val_acc: 0.7407\n",
      "Epoch 15/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.5170 - acc: 0.7346 - val_loss: 0.5253 - val_acc: 0.7531\n",
      "Epoch 16/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.5083 - acc: 0.7479 - val_loss: 0.5319 - val_acc: 0.7428\n",
      "Epoch 17/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.5113 - acc: 0.7490 - val_loss: 0.5228 - val_acc: 0.7490\n",
      "Epoch 18/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.5044 - acc: 0.7515 - val_loss: 0.5177 - val_acc: 0.7469\n",
      "Epoch 19/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.4993 - acc: 0.7510 - val_loss: 0.5331 - val_acc: 0.7346\n",
      "Epoch 20/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.5013 - acc: 0.7505 - val_loss: 0.5108 - val_acc: 0.7572\n",
      "Epoch 21/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.5022 - acc: 0.7464 - val_loss: 0.5371 - val_acc: 0.7305\n",
      "Epoch 22/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.4840 - acc: 0.7654 - val_loss: 0.5267 - val_acc: 0.7428\n",
      "Epoch 23/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.4823 - acc: 0.7608 - val_loss: 0.5249 - val_acc: 0.7428\n",
      "Epoch 24/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.4816 - acc: 0.7721 - val_loss: 0.5522 - val_acc: 0.7222\n",
      "Epoch 25/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.4760 - acc: 0.7726 - val_loss: 0.5305 - val_acc: 0.7366\n",
      "Epoch 26/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.4716 - acc: 0.7690 - val_loss: 0.5198 - val_acc: 0.7449\n",
      "Epoch 27/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.4713 - acc: 0.7731 - val_loss: 0.5076 - val_acc: 0.7593\n",
      "Epoch 28/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.4698 - acc: 0.7814 - val_loss: 0.4941 - val_acc: 0.7593\n",
      "Epoch 29/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.4668 - acc: 0.7829 - val_loss: 0.5029 - val_acc: 0.7613\n",
      "Epoch 30/100\n",
      "1944/1944 [==============================] - 1s 336us/step - loss: 0.4626 - acc: 0.7850 - val_loss: 0.5015 - val_acc: 0.7613\n",
      "Epoch 31/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.4638 - acc: 0.7860 - val_loss: 0.4994 - val_acc: 0.7593\n",
      "Epoch 32/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.4640 - acc: 0.7721 - val_loss: 0.4969 - val_acc: 0.7634\n",
      "Epoch 33/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.4611 - acc: 0.7834 - val_loss: 0.4951 - val_acc: 0.7634\n",
      "Epoch 34/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.4557 - acc: 0.7876 - val_loss: 0.5294 - val_acc: 0.7469\n",
      "Epoch 35/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.4464 - acc: 0.7912 - val_loss: 0.5078 - val_acc: 0.7634\n",
      "Epoch 36/100\n",
      "1944/1944 [==============================] - 1s 336us/step - loss: 0.4495 - acc: 0.7968 - val_loss: 0.4984 - val_acc: 0.7716\n",
      "Epoch 37/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.4489 - acc: 0.7948 - val_loss: 0.4839 - val_acc: 0.7634\n",
      "Epoch 38/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.4505 - acc: 0.7855 - val_loss: 0.4990 - val_acc: 0.7613\n",
      "Epoch 39/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.4409 - acc: 0.7968 - val_loss: 0.5009 - val_acc: 0.7695\n",
      "Epoch 40/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.4424 - acc: 0.8035 - val_loss: 0.4826 - val_acc: 0.7675\n",
      "Epoch 41/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.4476 - acc: 0.7906 - val_loss: 0.5138 - val_acc: 0.7675\n",
      "Epoch 42/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.4355 - acc: 0.7989 - val_loss: 0.4801 - val_acc: 0.7654\n",
      "Epoch 43/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.4408 - acc: 0.7906 - val_loss: 0.4850 - val_acc: 0.7675\n",
      "Epoch 44/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.4337 - acc: 0.8056 - val_loss: 0.4875 - val_acc: 0.7737\n",
      "Epoch 45/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.4332 - acc: 0.7927 - val_loss: 0.4627 - val_acc: 0.7716\n",
      "Epoch 46/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.4259 - acc: 0.8020 - val_loss: 0.4847 - val_acc: 0.7757\n",
      "Epoch 47/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.4336 - acc: 0.7948 - val_loss: 0.4743 - val_acc: 0.7778\n",
      "Epoch 48/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.4307 - acc: 0.7989 - val_loss: 0.4598 - val_acc: 0.7819\n",
      "Epoch 49/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.4307 - acc: 0.8025 - val_loss: 0.4791 - val_acc: 0.7798\n",
      "Epoch 50/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.4224 - acc: 0.8143 - val_loss: 0.4849 - val_acc: 0.7819\n",
      "Epoch 51/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.4128 - acc: 0.8138 - val_loss: 0.4720 - val_acc: 0.7819\n",
      "Epoch 52/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.4153 - acc: 0.8112 - val_loss: 0.4834 - val_acc: 0.7716\n",
      "Epoch 53/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.4164 - acc: 0.8056 - val_loss: 0.5046 - val_acc: 0.7716\n",
      "Epoch 54/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.4116 - acc: 0.8215 - val_loss: 0.4636 - val_acc: 0.7860\n",
      "Epoch 55/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.4092 - acc: 0.8133 - val_loss: 0.4769 - val_acc: 0.7798\n",
      "Epoch 56/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.4081 - acc: 0.8143 - val_loss: 0.4642 - val_acc: 0.7860\n",
      "Epoch 57/100\n",
      "1944/1944 [==============================] - 1s 334us/step - loss: 0.4122 - acc: 0.8128 - val_loss: 0.4710 - val_acc: 0.7840\n",
      "Epoch 58/100\n",
      "1944/1944 [==============================] - 1s 334us/step - loss: 0.3991 - acc: 0.8246 - val_loss: 0.4680 - val_acc: 0.7901\n",
      "Epoch 59/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.4048 - acc: 0.8169 - val_loss: 0.4711 - val_acc: 0.7860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.4015 - acc: 0.8261 - val_loss: 0.4614 - val_acc: 0.7984\n",
      "Epoch 61/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.4031 - acc: 0.8158 - val_loss: 0.4760 - val_acc: 0.7860\n",
      "Epoch 62/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.3972 - acc: 0.8184 - val_loss: 0.4462 - val_acc: 0.8045\n",
      "Epoch 63/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.3967 - acc: 0.8308 - val_loss: 0.4605 - val_acc: 0.7942\n",
      "Epoch 64/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.3984 - acc: 0.8128 - val_loss: 0.4599 - val_acc: 0.7984\n",
      "Epoch 65/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.3954 - acc: 0.8277 - val_loss: 0.4741 - val_acc: 0.7881\n",
      "Epoch 66/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.3968 - acc: 0.8246 - val_loss: 0.4567 - val_acc: 0.8025\n",
      "Epoch 67/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.3875 - acc: 0.8328 - val_loss: 0.4758 - val_acc: 0.7901\n",
      "Epoch 68/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.3897 - acc: 0.8272 - val_loss: 0.4881 - val_acc: 0.7860\n",
      "Epoch 69/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.3846 - acc: 0.8318 - val_loss: 0.4707 - val_acc: 0.7901\n",
      "Epoch 70/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.3853 - acc: 0.8277 - val_loss: 0.4576 - val_acc: 0.8045\n",
      "Epoch 71/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.3892 - acc: 0.8354 - val_loss: 0.4882 - val_acc: 0.7881\n",
      "Epoch 72/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.3843 - acc: 0.8308 - val_loss: 0.4661 - val_acc: 0.7984\n",
      "Epoch 73/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.3740 - acc: 0.8333 - val_loss: 0.4468 - val_acc: 0.8045\n",
      "Epoch 74/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.3825 - acc: 0.8405 - val_loss: 0.4592 - val_acc: 0.7984\n",
      "Epoch 75/100\n",
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.3795 - acc: 0.8318 - val_loss: 0.4780 - val_acc: 0.7942\n",
      "Epoch 76/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.3786 - acc: 0.8374 - val_loss: 0.4627 - val_acc: 0.8045\n",
      "Epoch 77/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.3738 - acc: 0.8462 - val_loss: 0.4535 - val_acc: 0.8066\n",
      "Epoch 78/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.3803 - acc: 0.8359 - val_loss: 0.4571 - val_acc: 0.8086\n",
      "Epoch 79/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.3704 - acc: 0.8380 - val_loss: 0.4395 - val_acc: 0.8148\n",
      "Epoch 80/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.3700 - acc: 0.8385 - val_loss: 0.4423 - val_acc: 0.8045\n",
      "Epoch 81/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.3675 - acc: 0.8431 - val_loss: 0.4324 - val_acc: 0.8169\n",
      "Epoch 82/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.3650 - acc: 0.8421 - val_loss: 0.4313 - val_acc: 0.8169\n",
      "Epoch 83/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.3628 - acc: 0.8405 - val_loss: 0.4381 - val_acc: 0.8148\n",
      "Epoch 84/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.3667 - acc: 0.8436 - val_loss: 0.4435 - val_acc: 0.8107\n",
      "Epoch 85/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.3694 - acc: 0.8374 - val_loss: 0.4422 - val_acc: 0.8189\n",
      "Epoch 86/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.3682 - acc: 0.8436 - val_loss: 0.4433 - val_acc: 0.8128\n",
      "Epoch 87/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.3679 - acc: 0.8400 - val_loss: 0.4259 - val_acc: 0.8230\n",
      "Epoch 88/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.3615 - acc: 0.8405 - val_loss: 0.4573 - val_acc: 0.8107\n",
      "Epoch 89/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.3523 - acc: 0.8467 - val_loss: 0.4443 - val_acc: 0.8189\n",
      "Epoch 90/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.3530 - acc: 0.8457 - val_loss: 0.4475 - val_acc: 0.8210\n",
      "Epoch 91/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.3567 - acc: 0.8488 - val_loss: 0.4327 - val_acc: 0.8230\n",
      "Epoch 92/100\n",
      "1944/1944 [==============================] - 1s 334us/step - loss: 0.3579 - acc: 0.8426 - val_loss: 0.4423 - val_acc: 0.8189\n",
      "Epoch 93/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.3531 - acc: 0.8555 - val_loss: 0.4549 - val_acc: 0.8189\n",
      "Epoch 94/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.3522 - acc: 0.8524 - val_loss: 0.4316 - val_acc: 0.8272\n",
      "Epoch 95/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.3532 - acc: 0.8524 - val_loss: 0.4375 - val_acc: 0.8230\n",
      "Epoch 96/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.3468 - acc: 0.8621 - val_loss: 0.4318 - val_acc: 0.8251\n",
      "Epoch 97/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.3477 - acc: 0.8555 - val_loss: 0.4225 - val_acc: 0.8230\n",
      "Epoch 98/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.3430 - acc: 0.8575 - val_loss: 0.4542 - val_acc: 0.8148\n",
      "Epoch 99/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.3460 - acc: 0.8519 - val_loss: 0.4486 - val_acc: 0.8189\n",
      "Epoch 100/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.3433 - acc: 0.8565 - val_loss: 0.4371 - val_acc: 0.8230\n",
      "Train on 1944 samples, validate on 486 samples\n",
      "Epoch 1/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.3881 - acc: 0.8236 - val_loss: 0.3928 - val_acc: 0.8354\n",
      "Epoch 2/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.3890 - acc: 0.8266 - val_loss: 0.3953 - val_acc: 0.8374\n",
      "Epoch 3/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.3695 - acc: 0.8400 - val_loss: 0.3908 - val_acc: 0.8374\n",
      "Epoch 4/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.3779 - acc: 0.8390 - val_loss: 0.3861 - val_acc: 0.8416\n",
      "Epoch 5/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.3786 - acc: 0.8426 - val_loss: 0.3829 - val_acc: 0.8416\n",
      "Epoch 6/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.3682 - acc: 0.8452 - val_loss: 0.3774 - val_acc: 0.8292\n",
      "Epoch 7/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.3642 - acc: 0.8549 - val_loss: 0.3891 - val_acc: 0.8436\n",
      "Epoch 8/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.3645 - acc: 0.8513 - val_loss: 0.3857 - val_acc: 0.8333\n",
      "Epoch 9/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.3565 - acc: 0.8534 - val_loss: 0.3823 - val_acc: 0.8416\n",
      "Epoch 10/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.3614 - acc: 0.8405 - val_loss: 0.3810 - val_acc: 0.8457\n",
      "Epoch 11/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.3547 - acc: 0.8549 - val_loss: 0.3872 - val_acc: 0.8477\n",
      "Epoch 12/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.3668 - acc: 0.8405 - val_loss: 0.3862 - val_acc: 0.8498\n",
      "Epoch 13/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.3527 - acc: 0.8575 - val_loss: 0.3796 - val_acc: 0.8477\n",
      "Epoch 14/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.3644 - acc: 0.8462 - val_loss: 0.3727 - val_acc: 0.8539\n",
      "Epoch 15/100\n",
      "1944/1944 [==============================] - 1s 319us/step - loss: 0.3485 - acc: 0.8549 - val_loss: 0.3643 - val_acc: 0.8477\n",
      "Epoch 16/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.3487 - acc: 0.8601 - val_loss: 0.3791 - val_acc: 0.8457\n",
      "Epoch 17/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.3480 - acc: 0.8627 - val_loss: 0.3684 - val_acc: 0.8519\n",
      "Epoch 18/100\n",
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.3540 - acc: 0.8565 - val_loss: 0.3788 - val_acc: 0.8519\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.3438 - acc: 0.8585 - val_loss: 0.3678 - val_acc: 0.8519\n",
      "Epoch 20/100\n",
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.3469 - acc: 0.8513 - val_loss: 0.3733 - val_acc: 0.8560\n",
      "Epoch 21/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.3432 - acc: 0.8647 - val_loss: 0.3756 - val_acc: 0.8498\n",
      "Epoch 22/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.3549 - acc: 0.8534 - val_loss: 0.3728 - val_acc: 0.8560\n",
      "Epoch 23/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.3412 - acc: 0.8657 - val_loss: 0.3636 - val_acc: 0.8560\n",
      "Epoch 24/100\n",
      "1944/1944 [==============================] - 1s 321us/step - loss: 0.3360 - acc: 0.8678 - val_loss: 0.3792 - val_acc: 0.8560\n",
      "Epoch 25/100\n",
      "1944/1944 [==============================] - 1s 334us/step - loss: 0.3385 - acc: 0.8632 - val_loss: 0.3677 - val_acc: 0.8560\n",
      "Epoch 26/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.3337 - acc: 0.8632 - val_loss: 0.3607 - val_acc: 0.8539\n",
      "Epoch 27/100\n",
      "1944/1944 [==============================] - 1s 321us/step - loss: 0.3359 - acc: 0.8637 - val_loss: 0.3517 - val_acc: 0.8560\n",
      "Epoch 28/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.3352 - acc: 0.8596 - val_loss: 0.3618 - val_acc: 0.8580\n",
      "Epoch 29/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.3257 - acc: 0.8740 - val_loss: 0.3662 - val_acc: 0.8621\n",
      "Epoch 30/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.3292 - acc: 0.8709 - val_loss: 0.3647 - val_acc: 0.8601\n",
      "Epoch 31/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.3350 - acc: 0.8663 - val_loss: 0.3596 - val_acc: 0.8601\n",
      "Epoch 32/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.3300 - acc: 0.8683 - val_loss: 0.3535 - val_acc: 0.8663\n",
      "Epoch 33/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.3299 - acc: 0.8668 - val_loss: 0.3575 - val_acc: 0.8621\n",
      "Epoch 34/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.3256 - acc: 0.8719 - val_loss: 0.3551 - val_acc: 0.8683\n",
      "Epoch 35/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.3305 - acc: 0.8642 - val_loss: 0.3683 - val_acc: 0.8601\n",
      "Epoch 36/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.3359 - acc: 0.8575 - val_loss: 0.3547 - val_acc: 0.8642\n",
      "Epoch 37/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.3283 - acc: 0.8663 - val_loss: 0.3613 - val_acc: 0.8580\n",
      "Epoch 38/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.3197 - acc: 0.8771 - val_loss: 0.3538 - val_acc: 0.8704\n",
      "Epoch 39/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.3257 - acc: 0.8704 - val_loss: 0.3490 - val_acc: 0.8663\n",
      "Epoch 40/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.3300 - acc: 0.8647 - val_loss: 0.3633 - val_acc: 0.8580\n",
      "Epoch 41/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.3077 - acc: 0.8781 - val_loss: 0.3557 - val_acc: 0.8663\n",
      "Epoch 42/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.3318 - acc: 0.8616 - val_loss: 0.3589 - val_acc: 0.8663\n",
      "Epoch 43/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.3226 - acc: 0.8668 - val_loss: 0.3425 - val_acc: 0.8663\n",
      "Epoch 44/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.3113 - acc: 0.8848 - val_loss: 0.3389 - val_acc: 0.8724\n",
      "Epoch 45/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.3170 - acc: 0.8745 - val_loss: 0.3478 - val_acc: 0.8663\n",
      "Epoch 46/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.3146 - acc: 0.8724 - val_loss: 0.3431 - val_acc: 0.8704\n",
      "Epoch 47/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.3197 - acc: 0.8750 - val_loss: 0.3509 - val_acc: 0.8663\n",
      "Epoch 48/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.3143 - acc: 0.8822 - val_loss: 0.3557 - val_acc: 0.8683\n",
      "Epoch 49/100\n",
      "1944/1944 [==============================] - 1s 321us/step - loss: 0.3145 - acc: 0.8735 - val_loss: 0.3455 - val_acc: 0.8663\n",
      "Epoch 50/100\n",
      "1944/1944 [==============================] - 1s 321us/step - loss: 0.3145 - acc: 0.8688 - val_loss: 0.3510 - val_acc: 0.8642\n",
      "Epoch 51/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.3183 - acc: 0.8750 - val_loss: 0.3439 - val_acc: 0.8704\n",
      "Epoch 52/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.3127 - acc: 0.8740 - val_loss: 0.3503 - val_acc: 0.8642\n",
      "Epoch 53/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.3142 - acc: 0.8776 - val_loss: 0.3431 - val_acc: 0.8704\n",
      "Epoch 54/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.3087 - acc: 0.8786 - val_loss: 0.3545 - val_acc: 0.8642\n",
      "Epoch 55/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.3072 - acc: 0.8822 - val_loss: 0.3356 - val_acc: 0.8724\n",
      "Epoch 56/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.3100 - acc: 0.8765 - val_loss: 0.3329 - val_acc: 0.8724\n",
      "Epoch 57/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.3045 - acc: 0.8801 - val_loss: 0.3403 - val_acc: 0.8704\n",
      "Epoch 58/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.3174 - acc: 0.8729 - val_loss: 0.3416 - val_acc: 0.8765\n",
      "Epoch 59/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.3091 - acc: 0.8755 - val_loss: 0.3413 - val_acc: 0.8683\n",
      "Epoch 60/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.3007 - acc: 0.8848 - val_loss: 0.3484 - val_acc: 0.8663\n",
      "Epoch 61/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.3021 - acc: 0.8848 - val_loss: 0.3448 - val_acc: 0.8663\n",
      "Epoch 62/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.3048 - acc: 0.8786 - val_loss: 0.3465 - val_acc: 0.8621\n",
      "Epoch 63/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.3018 - acc: 0.8812 - val_loss: 0.3435 - val_acc: 0.8663\n",
      "Epoch 64/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.2923 - acc: 0.8930 - val_loss: 0.3355 - val_acc: 0.8704\n",
      "Epoch 65/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.2915 - acc: 0.8935 - val_loss: 0.3485 - val_acc: 0.8704\n",
      "Epoch 66/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.2945 - acc: 0.8956 - val_loss: 0.3354 - val_acc: 0.8683\n",
      "Epoch 67/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.3031 - acc: 0.8925 - val_loss: 0.3418 - val_acc: 0.8704\n",
      "Epoch 68/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.2881 - acc: 0.8930 - val_loss: 0.3212 - val_acc: 0.8807\n",
      "Epoch 69/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.2967 - acc: 0.8817 - val_loss: 0.3353 - val_acc: 0.8724\n",
      "Epoch 70/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.2922 - acc: 0.8925 - val_loss: 0.3359 - val_acc: 0.8765\n",
      "Epoch 71/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.2981 - acc: 0.8868 - val_loss: 0.3332 - val_acc: 0.8786\n",
      "Epoch 72/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.2943 - acc: 0.8873 - val_loss: 0.3470 - val_acc: 0.8704\n",
      "Epoch 73/100\n",
      "1944/1944 [==============================] - 1s 319us/step - loss: 0.2901 - acc: 0.8884 - val_loss: 0.3278 - val_acc: 0.8807\n",
      "Epoch 74/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.2943 - acc: 0.8879 - val_loss: 0.3342 - val_acc: 0.8724\n",
      "Epoch 75/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.2903 - acc: 0.8920 - val_loss: 0.3307 - val_acc: 0.8724\n",
      "Epoch 76/100\n",
      "1944/1944 [==============================] - 1s 334us/step - loss: 0.2775 - acc: 0.8992 - val_loss: 0.3243 - val_acc: 0.8827\n",
      "Epoch 77/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.2924 - acc: 0.8920 - val_loss: 0.3342 - val_acc: 0.8745\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.2883 - acc: 0.8930 - val_loss: 0.3325 - val_acc: 0.8745\n",
      "Epoch 79/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.2814 - acc: 0.8956 - val_loss: 0.3197 - val_acc: 0.8909\n",
      "Epoch 80/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.2871 - acc: 0.8884 - val_loss: 0.3265 - val_acc: 0.8745\n",
      "Epoch 81/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.2762 - acc: 0.8961 - val_loss: 0.3342 - val_acc: 0.8765\n",
      "Epoch 82/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.2854 - acc: 0.8940 - val_loss: 0.3132 - val_acc: 0.8868\n",
      "Epoch 83/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.2840 - acc: 0.8961 - val_loss: 0.3171 - val_acc: 0.8868\n",
      "Epoch 84/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.2878 - acc: 0.8930 - val_loss: 0.3189 - val_acc: 0.8889\n",
      "Epoch 85/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.2816 - acc: 0.8884 - val_loss: 0.3166 - val_acc: 0.8868\n",
      "Epoch 86/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.2772 - acc: 0.9007 - val_loss: 0.3303 - val_acc: 0.8745\n",
      "Epoch 87/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.2806 - acc: 0.8925 - val_loss: 0.3180 - val_acc: 0.8827\n",
      "Epoch 88/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.2830 - acc: 0.8915 - val_loss: 0.3241 - val_acc: 0.8807\n",
      "Epoch 89/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.2835 - acc: 0.8879 - val_loss: 0.3183 - val_acc: 0.8868\n",
      "Epoch 90/100\n",
      "1944/1944 [==============================] - 1s 321us/step - loss: 0.2723 - acc: 0.8981 - val_loss: 0.3233 - val_acc: 0.8827\n",
      "Epoch 91/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.2691 - acc: 0.9007 - val_loss: 0.3150 - val_acc: 0.8951\n",
      "Epoch 92/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.2883 - acc: 0.8909 - val_loss: 0.3177 - val_acc: 0.8889\n",
      "Epoch 93/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.2797 - acc: 0.8951 - val_loss: 0.3120 - val_acc: 0.8889\n",
      "Epoch 94/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.2710 - acc: 0.8925 - val_loss: 0.3149 - val_acc: 0.8889\n",
      "Epoch 95/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.2767 - acc: 0.8940 - val_loss: 0.3172 - val_acc: 0.8848\n",
      "Epoch 96/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.2797 - acc: 0.8889 - val_loss: 0.3091 - val_acc: 0.8889\n",
      "Epoch 97/100\n",
      "1944/1944 [==============================] - 1s 337us/step - loss: 0.2732 - acc: 0.8930 - val_loss: 0.3021 - val_acc: 0.8992\n",
      "Epoch 98/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.2840 - acc: 0.8899 - val_loss: 0.3110 - val_acc: 0.8971\n",
      "Epoch 99/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.2768 - acc: 0.8981 - val_loss: 0.3086 - val_acc: 0.8930\n",
      "Epoch 100/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.2634 - acc: 0.9033 - val_loss: 0.3145 - val_acc: 0.8868\n",
      "Test subject 10, class HandStart\n",
      "Train subject 10, class FirstDigitTouch\n",
      "Train on 1944 samples, validate on 486 samples\n",
      "Epoch 1/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.6082 - acc: 0.8133 - val_loss: 0.3533 - val_acc: 0.8745\n",
      "Epoch 2/100\n",
      "1944/1944 [==============================] - ETA: 0s - loss: 0.3655 - acc: 0.862 - 1s 323us/step - loss: 0.3679 - acc: 0.8606 - val_loss: 0.2855 - val_acc: 0.8971\n",
      "Epoch 3/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.3305 - acc: 0.8745 - val_loss: 0.2826 - val_acc: 0.8992\n",
      "Epoch 4/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.3065 - acc: 0.8832 - val_loss: 0.2733 - val_acc: 0.9033\n",
      "Epoch 5/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.3036 - acc: 0.8853 - val_loss: 0.2583 - val_acc: 0.9095\n",
      "Epoch 6/100\n",
      "1944/1944 [==============================] - 1s 334us/step - loss: 0.2862 - acc: 0.8940 - val_loss: 0.2535 - val_acc: 0.9095\n",
      "Epoch 7/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.2856 - acc: 0.8940 - val_loss: 0.2444 - val_acc: 0.9136\n",
      "Epoch 8/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.2683 - acc: 0.8992 - val_loss: 0.2428 - val_acc: 0.9115\n",
      "Epoch 9/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.2599 - acc: 0.9059 - val_loss: 0.2394 - val_acc: 0.9095\n",
      "Epoch 10/100\n",
      "1944/1944 [==============================] - 1s 337us/step - loss: 0.2547 - acc: 0.9105 - val_loss: 0.2336 - val_acc: 0.9136\n",
      "Epoch 11/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.2541 - acc: 0.9141 - val_loss: 0.2304 - val_acc: 0.9156\n",
      "Epoch 12/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.2571 - acc: 0.9059 - val_loss: 0.2272 - val_acc: 0.9198\n",
      "Epoch 13/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.2484 - acc: 0.9115 - val_loss: 0.2251 - val_acc: 0.9239\n",
      "Epoch 14/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.2409 - acc: 0.9156 - val_loss: 0.2239 - val_acc: 0.9239\n",
      "Epoch 15/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.2349 - acc: 0.9187 - val_loss: 0.2247 - val_acc: 0.9259\n",
      "Epoch 16/100\n",
      "1944/1944 [==============================] - 1s 356us/step - loss: 0.2380 - acc: 0.9218 - val_loss: 0.2189 - val_acc: 0.9280\n",
      "Epoch 17/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.2483 - acc: 0.9203 - val_loss: 0.2271 - val_acc: 0.9259\n",
      "Epoch 18/100\n",
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.2372 - acc: 0.9192 - val_loss: 0.2221 - val_acc: 0.9321\n",
      "Epoch 19/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.2294 - acc: 0.9239 - val_loss: 0.2174 - val_acc: 0.9362\n",
      "Epoch 20/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.2294 - acc: 0.9218 - val_loss: 0.2173 - val_acc: 0.9362\n",
      "Epoch 21/100\n",
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.2320 - acc: 0.9228 - val_loss: 0.2157 - val_acc: 0.9383\n",
      "Epoch 22/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.2236 - acc: 0.9290 - val_loss: 0.2133 - val_acc: 0.9362\n",
      "Epoch 23/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.2175 - acc: 0.9316 - val_loss: 0.2112 - val_acc: 0.9383\n",
      "Epoch 24/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.2174 - acc: 0.9275 - val_loss: 0.2083 - val_acc: 0.9383\n",
      "Epoch 25/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.2182 - acc: 0.9244 - val_loss: 0.2109 - val_acc: 0.9342\n",
      "Epoch 26/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.2165 - acc: 0.9306 - val_loss: 0.2056 - val_acc: 0.9383\n",
      "Epoch 27/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.2179 - acc: 0.9321 - val_loss: 0.2036 - val_acc: 0.9383\n",
      "Epoch 28/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.2171 - acc: 0.9311 - val_loss: 0.2078 - val_acc: 0.9362\n",
      "Epoch 29/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.2092 - acc: 0.9347 - val_loss: 0.2038 - val_acc: 0.9383\n",
      "Epoch 30/100\n",
      "1944/1944 [==============================] - 1s 337us/step - loss: 0.2065 - acc: 0.9367 - val_loss: 0.2128 - val_acc: 0.9342\n",
      "Epoch 31/100\n",
      "1944/1944 [==============================] - 1s 336us/step - loss: 0.2118 - acc: 0.9331 - val_loss: 0.2019 - val_acc: 0.9383\n",
      "Epoch 32/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.2077 - acc: 0.9383 - val_loss: 0.2054 - val_acc: 0.9383\n",
      "Epoch 33/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.2174 - acc: 0.9316 - val_loss: 0.1982 - val_acc: 0.9383\n",
      "Epoch 34/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.2031 - acc: 0.9342 - val_loss: 0.1982 - val_acc: 0.9383\n",
      "Epoch 35/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.2105 - acc: 0.9311 - val_loss: 0.2017 - val_acc: 0.9383\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.2037 - acc: 0.9321 - val_loss: 0.2012 - val_acc: 0.9383\n",
      "Epoch 37/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.2019 - acc: 0.9362 - val_loss: 0.2007 - val_acc: 0.9383\n",
      "Epoch 38/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.2013 - acc: 0.9372 - val_loss: 0.1983 - val_acc: 0.9383\n",
      "Epoch 39/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.2056 - acc: 0.9347 - val_loss: 0.1933 - val_acc: 0.9383\n",
      "Epoch 40/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.2057 - acc: 0.9347 - val_loss: 0.1962 - val_acc: 0.9403\n",
      "Epoch 41/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.2015 - acc: 0.9357 - val_loss: 0.1924 - val_acc: 0.9383\n",
      "Epoch 42/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.1926 - acc: 0.9383 - val_loss: 0.1928 - val_acc: 0.9383\n",
      "Epoch 43/100\n",
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.2013 - acc: 0.9352 - val_loss: 0.1920 - val_acc: 0.9403\n",
      "Epoch 44/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.1932 - acc: 0.9388 - val_loss: 0.1948 - val_acc: 0.9403\n",
      "Epoch 45/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.1945 - acc: 0.9378 - val_loss: 0.1896 - val_acc: 0.9403\n",
      "Epoch 46/100\n",
      "1944/1944 [==============================] - 1s 355us/step - loss: 0.1901 - acc: 0.9398 - val_loss: 0.1939 - val_acc: 0.9403\n",
      "Epoch 47/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.1954 - acc: 0.9367 - val_loss: 0.1912 - val_acc: 0.9403\n",
      "Epoch 48/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.1879 - acc: 0.9424 - val_loss: 0.1946 - val_acc: 0.9403\n",
      "Epoch 49/100\n",
      "1944/1944 [==============================] - 1s 363us/step - loss: 0.1938 - acc: 0.9419 - val_loss: 0.1892 - val_acc: 0.9403\n",
      "Epoch 50/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.1877 - acc: 0.9434 - val_loss: 0.1888 - val_acc: 0.9403\n",
      "Epoch 51/100\n",
      "1944/1944 [==============================] - 1s 361us/step - loss: 0.1863 - acc: 0.9398 - val_loss: 0.1908 - val_acc: 0.9383\n",
      "Epoch 52/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.1866 - acc: 0.9372 - val_loss: 0.1894 - val_acc: 0.9403\n",
      "Epoch 53/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.1835 - acc: 0.9403 - val_loss: 0.1867 - val_acc: 0.9403\n",
      "Epoch 54/100\n",
      "1944/1944 [==============================] - 1s 336us/step - loss: 0.1822 - acc: 0.9429 - val_loss: 0.1865 - val_acc: 0.9444\n",
      "Epoch 55/100\n",
      "1944/1944 [==============================] - 1s 356us/step - loss: 0.1820 - acc: 0.9434 - val_loss: 0.1855 - val_acc: 0.9424\n",
      "Epoch 56/100\n",
      "1944/1944 [==============================] - 1s 336us/step - loss: 0.1790 - acc: 0.9480 - val_loss: 0.1861 - val_acc: 0.9444\n",
      "Epoch 57/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.1862 - acc: 0.9419 - val_loss: 0.1931 - val_acc: 0.9444\n",
      "Epoch 58/100\n",
      "1944/1944 [==============================] - 1s 361us/step - loss: 0.1854 - acc: 0.9403 - val_loss: 0.1840 - val_acc: 0.9424\n",
      "Epoch 59/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.1825 - acc: 0.9455 - val_loss: 0.1849 - val_acc: 0.9424\n",
      "Epoch 60/100\n",
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.1840 - acc: 0.9419 - val_loss: 0.1833 - val_acc: 0.9444\n",
      "Epoch 61/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.1824 - acc: 0.9419 - val_loss: 0.1865 - val_acc: 0.9465\n",
      "Epoch 62/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.1791 - acc: 0.9383 - val_loss: 0.1832 - val_acc: 0.9424\n",
      "Epoch 63/100\n",
      "1944/1944 [==============================] - 1s 337us/step - loss: 0.1806 - acc: 0.9419 - val_loss: 0.1835 - val_acc: 0.9444\n",
      "Epoch 64/100\n",
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.1758 - acc: 0.9460 - val_loss: 0.1794 - val_acc: 0.9465\n",
      "Epoch 65/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1809 - acc: 0.9460 - val_loss: 0.1815 - val_acc: 0.9465\n",
      "Epoch 66/100\n",
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.1838 - acc: 0.9450 - val_loss: 0.1789 - val_acc: 0.9486\n",
      "Epoch 67/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.1722 - acc: 0.9444 - val_loss: 0.1861 - val_acc: 0.9444\n",
      "Epoch 68/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1725 - acc: 0.9434 - val_loss: 0.1869 - val_acc: 0.9444\n",
      "Epoch 69/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.1764 - acc: 0.9414 - val_loss: 0.1826 - val_acc: 0.9424\n",
      "Epoch 70/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.1700 - acc: 0.9506 - val_loss: 0.1812 - val_acc: 0.9465\n",
      "Epoch 71/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.1783 - acc: 0.9434 - val_loss: 0.1787 - val_acc: 0.9444\n",
      "Epoch 72/100\n",
      "1944/1944 [==============================] - 1s 334us/step - loss: 0.1697 - acc: 0.9475 - val_loss: 0.1769 - val_acc: 0.9486\n",
      "Epoch 73/100\n",
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.1765 - acc: 0.9450 - val_loss: 0.1726 - val_acc: 0.9465\n",
      "Epoch 74/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.1742 - acc: 0.9460 - val_loss: 0.1781 - val_acc: 0.9465\n",
      "Epoch 75/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1747 - acc: 0.9491 - val_loss: 0.1737 - val_acc: 0.9486\n",
      "Epoch 76/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.1740 - acc: 0.9496 - val_loss: 0.1770 - val_acc: 0.9444\n",
      "Epoch 77/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.1647 - acc: 0.9475 - val_loss: 0.1773 - val_acc: 0.9465\n",
      "Epoch 78/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.1713 - acc: 0.9444 - val_loss: 0.1732 - val_acc: 0.9465\n",
      "Epoch 79/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1641 - acc: 0.9486 - val_loss: 0.1772 - val_acc: 0.9465\n",
      "Epoch 80/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.1595 - acc: 0.9522 - val_loss: 0.1725 - val_acc: 0.9486\n",
      "Epoch 81/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.1728 - acc: 0.9460 - val_loss: 0.1700 - val_acc: 0.9465\n",
      "Epoch 82/100\n",
      "1944/1944 [==============================] - 1s 337us/step - loss: 0.1624 - acc: 0.9470 - val_loss: 0.1687 - val_acc: 0.9486\n",
      "Epoch 83/100\n",
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.1654 - acc: 0.9480 - val_loss: 0.1706 - val_acc: 0.9486\n",
      "Epoch 84/100\n",
      "1944/1944 [==============================] - 1s 334us/step - loss: 0.1619 - acc: 0.9511 - val_loss: 0.1744 - val_acc: 0.9486\n",
      "Epoch 85/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.1651 - acc: 0.9470 - val_loss: 0.1663 - val_acc: 0.9506\n",
      "Epoch 86/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.1642 - acc: 0.9532 - val_loss: 0.1672 - val_acc: 0.9506\n",
      "Epoch 87/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.1606 - acc: 0.9537 - val_loss: 0.1693 - val_acc: 0.9506\n",
      "Epoch 88/100\n",
      "1944/1944 [==============================] - 1s 336us/step - loss: 0.1576 - acc: 0.9470 - val_loss: 0.1714 - val_acc: 0.9506\n",
      "Epoch 89/100\n",
      "1944/1944 [==============================] - 1s 336us/step - loss: 0.1626 - acc: 0.9501 - val_loss: 0.1716 - val_acc: 0.9506\n",
      "Epoch 90/100\n",
      "1944/1944 [==============================] - 1s 334us/step - loss: 0.1524 - acc: 0.9511 - val_loss: 0.1694 - val_acc: 0.9506\n",
      "Epoch 91/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.1648 - acc: 0.9475 - val_loss: 0.1705 - val_acc: 0.9486\n",
      "Epoch 92/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.1601 - acc: 0.9491 - val_loss: 0.1710 - val_acc: 0.9506\n",
      "Epoch 93/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.1657 - acc: 0.9480 - val_loss: 0.1659 - val_acc: 0.9506\n",
      "Epoch 94/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.1639 - acc: 0.9511 - val_loss: 0.1652 - val_acc: 0.9486\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.1538 - acc: 0.9547 - val_loss: 0.1611 - val_acc: 0.9506\n",
      "Epoch 96/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.1577 - acc: 0.9506 - val_loss: 0.1625 - val_acc: 0.9506\n",
      "Epoch 97/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.1530 - acc: 0.9516 - val_loss: 0.1690 - val_acc: 0.9527\n",
      "Epoch 98/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.1578 - acc: 0.9501 - val_loss: 0.1635 - val_acc: 0.9486\n",
      "Epoch 99/100\n",
      "1944/1944 [==============================] - 1s 336us/step - loss: 0.1592 - acc: 0.9506 - val_loss: 0.1650 - val_acc: 0.9506\n",
      "Epoch 100/100\n",
      "1944/1944 [==============================] - 1s 334us/step - loss: 0.1527 - acc: 0.9511 - val_loss: 0.1648 - val_acc: 0.9527\n",
      "Train on 1944 samples, validate on 486 samples\n",
      "Epoch 1/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.2008 - acc: 0.9378 - val_loss: 0.2149 - val_acc: 0.9383\n",
      "Epoch 2/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.1924 - acc: 0.9357 - val_loss: 0.2162 - val_acc: 0.9362\n",
      "Epoch 3/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1988 - acc: 0.9388 - val_loss: 0.2077 - val_acc: 0.9424\n",
      "Epoch 4/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.1945 - acc: 0.9342 - val_loss: 0.2069 - val_acc: 0.9403\n",
      "Epoch 5/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.1960 - acc: 0.9357 - val_loss: 0.2050 - val_acc: 0.9424\n",
      "Epoch 6/100\n",
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.1865 - acc: 0.9383 - val_loss: 0.2045 - val_acc: 0.9403\n",
      "Epoch 7/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.1845 - acc: 0.9408 - val_loss: 0.2080 - val_acc: 0.9403\n",
      "Epoch 8/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.1886 - acc: 0.9419 - val_loss: 0.2092 - val_acc: 0.9403\n",
      "Epoch 9/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.1864 - acc: 0.9429 - val_loss: 0.2009 - val_acc: 0.9424\n",
      "Epoch 10/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.1858 - acc: 0.9414 - val_loss: 0.2009 - val_acc: 0.9424\n",
      "Epoch 11/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.1862 - acc: 0.9424 - val_loss: 0.2046 - val_acc: 0.9403\n",
      "Epoch 12/100\n",
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.1785 - acc: 0.9475 - val_loss: 0.2050 - val_acc: 0.9424\n",
      "Epoch 13/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1919 - acc: 0.9398 - val_loss: 0.2025 - val_acc: 0.9424\n",
      "Epoch 14/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.1830 - acc: 0.9419 - val_loss: 0.1985 - val_acc: 0.9424\n",
      "Epoch 15/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.1788 - acc: 0.9408 - val_loss: 0.1972 - val_acc: 0.9444\n",
      "Epoch 16/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.1829 - acc: 0.9424 - val_loss: 0.2011 - val_acc: 0.9444\n",
      "Epoch 17/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.1727 - acc: 0.9419 - val_loss: 0.1946 - val_acc: 0.9444\n",
      "Epoch 18/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.1735 - acc: 0.9470 - val_loss: 0.1957 - val_acc: 0.9444\n",
      "Epoch 19/100\n",
      "1944/1944 [==============================] - 1s 392us/step - loss: 0.1777 - acc: 0.9429 - val_loss: 0.1945 - val_acc: 0.9444\n",
      "Epoch 20/100\n",
      "1944/1944 [==============================] - 1s 364us/step - loss: 0.1744 - acc: 0.9450 - val_loss: 0.1997 - val_acc: 0.9403\n",
      "Epoch 21/100\n",
      "1944/1944 [==============================] - 1s 365us/step - loss: 0.1813 - acc: 0.9429 - val_loss: 0.1975 - val_acc: 0.9424\n",
      "Epoch 22/100\n",
      "1944/1944 [==============================] - 1s 389us/step - loss: 0.1787 - acc: 0.9414 - val_loss: 0.2019 - val_acc: 0.9383\n",
      "Epoch 23/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.1736 - acc: 0.9470 - val_loss: 0.2016 - val_acc: 0.9403\n",
      "Epoch 24/100\n",
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.1649 - acc: 0.9486 - val_loss: 0.1980 - val_acc: 0.9403\n",
      "Epoch 25/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.1699 - acc: 0.9465 - val_loss: 0.2010 - val_acc: 0.9424\n",
      "Epoch 26/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.1696 - acc: 0.9491 - val_loss: 0.1887 - val_acc: 0.9486\n",
      "Epoch 27/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.1735 - acc: 0.9455 - val_loss: 0.1971 - val_acc: 0.9424\n",
      "Epoch 28/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.1746 - acc: 0.9460 - val_loss: 0.2053 - val_acc: 0.9342\n",
      "Epoch 29/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.1660 - acc: 0.9486 - val_loss: 0.1975 - val_acc: 0.9383\n",
      "Epoch 30/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.1712 - acc: 0.9439 - val_loss: 0.1992 - val_acc: 0.9383\n",
      "Epoch 31/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.1622 - acc: 0.9470 - val_loss: 0.1889 - val_acc: 0.9486\n",
      "Epoch 32/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1696 - acc: 0.9434 - val_loss: 0.1940 - val_acc: 0.9465\n",
      "Epoch 33/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.1726 - acc: 0.9475 - val_loss: 0.1900 - val_acc: 0.9486\n",
      "Epoch 34/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1607 - acc: 0.9516 - val_loss: 0.1937 - val_acc: 0.9403\n",
      "Epoch 35/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1686 - acc: 0.9444 - val_loss: 0.1998 - val_acc: 0.9362\n",
      "Epoch 36/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.1704 - acc: 0.9429 - val_loss: 0.1944 - val_acc: 0.9383\n",
      "Epoch 37/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.1647 - acc: 0.9480 - val_loss: 0.1908 - val_acc: 0.9465\n",
      "Epoch 38/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.1639 - acc: 0.9480 - val_loss: 0.1870 - val_acc: 0.9486\n",
      "Epoch 39/100\n",
      "1944/1944 [==============================] - 1s 334us/step - loss: 0.1584 - acc: 0.9506 - val_loss: 0.1866 - val_acc: 0.9486\n",
      "Epoch 40/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1645 - acc: 0.9465 - val_loss: 0.1904 - val_acc: 0.9444\n",
      "Epoch 41/100\n",
      "1944/1944 [==============================] - 1s 320us/step - loss: 0.1614 - acc: 0.9501 - val_loss: 0.1890 - val_acc: 0.9424\n",
      "Epoch 42/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1617 - acc: 0.9511 - val_loss: 0.1989 - val_acc: 0.9362\n",
      "Epoch 43/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.1491 - acc: 0.9558 - val_loss: 0.1813 - val_acc: 0.9506\n",
      "Epoch 44/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.1531 - acc: 0.9486 - val_loss: 0.1905 - val_acc: 0.9444\n",
      "Epoch 45/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1568 - acc: 0.9480 - val_loss: 0.1833 - val_acc: 0.9486\n",
      "Epoch 46/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1546 - acc: 0.9516 - val_loss: 0.1883 - val_acc: 0.9444\n",
      "Epoch 47/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.1579 - acc: 0.9532 - val_loss: 0.1947 - val_acc: 0.9424\n",
      "Epoch 48/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.1623 - acc: 0.9465 - val_loss: 0.1855 - val_acc: 0.9444\n",
      "Epoch 49/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.1564 - acc: 0.9522 - val_loss: 0.1879 - val_acc: 0.9424\n",
      "Epoch 50/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.1554 - acc: 0.9532 - val_loss: 0.1930 - val_acc: 0.9424\n",
      "Epoch 51/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.1544 - acc: 0.9532 - val_loss: 0.1829 - val_acc: 0.9465\n",
      "Epoch 52/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.1618 - acc: 0.9496 - val_loss: 0.1952 - val_acc: 0.9403\n",
      "Epoch 53/100\n",
      "1944/1944 [==============================] - 1s 321us/step - loss: 0.1537 - acc: 0.9516 - val_loss: 0.1887 - val_acc: 0.9444\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.1577 - acc: 0.9522 - val_loss: 0.1914 - val_acc: 0.9444\n",
      "Epoch 55/100\n",
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.1479 - acc: 0.9552 - val_loss: 0.1944 - val_acc: 0.9424\n",
      "Epoch 56/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.1525 - acc: 0.9537 - val_loss: 0.1907 - val_acc: 0.9444\n",
      "Epoch 57/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1559 - acc: 0.9522 - val_loss: 0.1927 - val_acc: 0.9403\n",
      "Epoch 58/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1604 - acc: 0.9547 - val_loss: 0.1920 - val_acc: 0.9424\n",
      "Epoch 59/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1487 - acc: 0.9486 - val_loss: 0.1916 - val_acc: 0.9424\n",
      "Epoch 60/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.1461 - acc: 0.9568 - val_loss: 0.1893 - val_acc: 0.9424\n",
      "Epoch 61/100\n",
      "1944/1944 [==============================] - 1s 316us/step - loss: 0.1477 - acc: 0.9547 - val_loss: 0.1883 - val_acc: 0.9444\n",
      "Epoch 62/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1502 - acc: 0.9568 - val_loss: 0.1927 - val_acc: 0.9424\n",
      "Epoch 63/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.1523 - acc: 0.9527 - val_loss: 0.1880 - val_acc: 0.9444\n",
      "Epoch 64/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.1454 - acc: 0.9552 - val_loss: 0.1860 - val_acc: 0.9465\n",
      "Epoch 65/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.1499 - acc: 0.9532 - val_loss: 0.1902 - val_acc: 0.9444\n",
      "Epoch 66/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1489 - acc: 0.9522 - val_loss: 0.1905 - val_acc: 0.9444\n",
      "Epoch 67/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.1509 - acc: 0.9558 - val_loss: 0.1879 - val_acc: 0.9465\n",
      "Epoch 68/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1463 - acc: 0.9501 - val_loss: 0.1872 - val_acc: 0.9465\n",
      "Epoch 69/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.1483 - acc: 0.9547 - val_loss: 0.1983 - val_acc: 0.9383\n",
      "Epoch 70/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.1573 - acc: 0.9444 - val_loss: 0.1898 - val_acc: 0.9465\n",
      "Epoch 71/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.1447 - acc: 0.9527 - val_loss: 0.1798 - val_acc: 0.9486\n",
      "Epoch 72/100\n",
      "1944/1944 [==============================] - 1s 321us/step - loss: 0.1423 - acc: 0.9527 - val_loss: 0.1865 - val_acc: 0.9465\n",
      "Epoch 73/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.1449 - acc: 0.9558 - val_loss: 0.1933 - val_acc: 0.9444\n",
      "Epoch 74/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1420 - acc: 0.9547 - val_loss: 0.1880 - val_acc: 0.9444\n",
      "Epoch 75/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.1449 - acc: 0.9588 - val_loss: 0.1990 - val_acc: 0.9403\n",
      "Epoch 76/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.1451 - acc: 0.9552 - val_loss: 0.1940 - val_acc: 0.9444\n",
      "Epoch 77/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.1418 - acc: 0.9552 - val_loss: 0.1859 - val_acc: 0.9465\n",
      "Epoch 78/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1385 - acc: 0.9558 - val_loss: 0.1904 - val_acc: 0.9465\n",
      "Epoch 79/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1337 - acc: 0.9563 - val_loss: 0.1944 - val_acc: 0.9444\n",
      "Epoch 80/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.1393 - acc: 0.9588 - val_loss: 0.1946 - val_acc: 0.9444\n",
      "Epoch 81/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.1474 - acc: 0.9558 - val_loss: 0.1939 - val_acc: 0.9444\n",
      "Epoch 82/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.1415 - acc: 0.9568 - val_loss: 0.2003 - val_acc: 0.9424\n",
      "Epoch 83/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1347 - acc: 0.9604 - val_loss: 0.1851 - val_acc: 0.9465\n",
      "Epoch 84/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.1393 - acc: 0.9537 - val_loss: 0.1830 - val_acc: 0.9465\n",
      "Epoch 85/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.1438 - acc: 0.9552 - val_loss: 0.1881 - val_acc: 0.9465\n",
      "Epoch 86/100\n",
      "1944/1944 [==============================] - 1s 319us/step - loss: 0.1345 - acc: 0.9573 - val_loss: 0.1837 - val_acc: 0.9465\n",
      "Epoch 87/100\n",
      "1944/1944 [==============================] - 1s 321us/step - loss: 0.1382 - acc: 0.9532 - val_loss: 0.1861 - val_acc: 0.9465\n",
      "Epoch 88/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.1377 - acc: 0.9568 - val_loss: 0.1912 - val_acc: 0.9465\n",
      "Epoch 89/100\n",
      "1944/1944 [==============================] - 1s 321us/step - loss: 0.1403 - acc: 0.9604 - val_loss: 0.1894 - val_acc: 0.9465\n",
      "Epoch 90/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1373 - acc: 0.9552 - val_loss: 0.1895 - val_acc: 0.9465\n",
      "Epoch 91/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.1375 - acc: 0.9609 - val_loss: 0.1955 - val_acc: 0.9444\n",
      "Epoch 92/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.1373 - acc: 0.9568 - val_loss: 0.1864 - val_acc: 0.9465\n",
      "Epoch 93/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.1373 - acc: 0.9604 - val_loss: 0.1895 - val_acc: 0.9465\n",
      "Epoch 94/100\n",
      "1944/1944 [==============================] - 1s 321us/step - loss: 0.1311 - acc: 0.9604 - val_loss: 0.1850 - val_acc: 0.9465\n",
      "Epoch 95/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.1401 - acc: 0.9547 - val_loss: 0.1809 - val_acc: 0.9465\n",
      "Epoch 96/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.1305 - acc: 0.9588 - val_loss: 0.1982 - val_acc: 0.9424\n",
      "Epoch 97/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1385 - acc: 0.9547 - val_loss: 0.1828 - val_acc: 0.9465\n",
      "Epoch 98/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.1347 - acc: 0.9573 - val_loss: 0.1847 - val_acc: 0.9465\n",
      "Epoch 99/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.1374 - acc: 0.9537 - val_loss: 0.1924 - val_acc: 0.9444\n",
      "Epoch 100/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.1288 - acc: 0.9599 - val_loss: 0.1907 - val_acc: 0.9444\n",
      "Test subject 10, class FirstDigitTouch\n",
      "Train subject 10, class BothStartLoadPhase\n",
      "Train on 1944 samples, validate on 486 samples\n",
      "Epoch 1/100\n",
      "1944/1944 [==============================] - 1s 320us/step - loss: 0.5878 - acc: 0.8076 - val_loss: 0.5031 - val_acc: 0.8128\n",
      "Epoch 2/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.3964 - acc: 0.8436 - val_loss: 0.4300 - val_acc: 0.8457\n",
      "Epoch 3/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.3577 - acc: 0.8657 - val_loss: 0.4038 - val_acc: 0.8601\n",
      "Epoch 4/100\n",
      "1944/1944 [==============================] - 1s 319us/step - loss: 0.3267 - acc: 0.8796 - val_loss: 0.3859 - val_acc: 0.8704\n",
      "Epoch 5/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.3146 - acc: 0.8837 - val_loss: 0.3778 - val_acc: 0.8765\n",
      "Epoch 6/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.3008 - acc: 0.8904 - val_loss: 0.3653 - val_acc: 0.8807\n",
      "Epoch 7/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.3052 - acc: 0.8884 - val_loss: 0.3632 - val_acc: 0.8765\n",
      "Epoch 8/100\n",
      "1944/1944 [==============================] - 1s 319us/step - loss: 0.2925 - acc: 0.8951 - val_loss: 0.3522 - val_acc: 0.8827\n",
      "Epoch 9/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.2894 - acc: 0.9028 - val_loss: 0.3492 - val_acc: 0.8889\n",
      "Epoch 10/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.2852 - acc: 0.9038 - val_loss: 0.3332 - val_acc: 0.8930\n",
      "Epoch 11/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.2799 - acc: 0.9059 - val_loss: 0.3331 - val_acc: 0.8889\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.2644 - acc: 0.9084 - val_loss: 0.3360 - val_acc: 0.8868\n",
      "Epoch 13/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.2664 - acc: 0.9141 - val_loss: 0.3249 - val_acc: 0.8889\n",
      "Epoch 14/100\n",
      "1944/1944 [==============================] - 1s 334us/step - loss: 0.2708 - acc: 0.9038 - val_loss: 0.3251 - val_acc: 0.8930\n",
      "Epoch 15/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.2620 - acc: 0.9115 - val_loss: 0.3255 - val_acc: 0.8765\n",
      "Epoch 16/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.2580 - acc: 0.9146 - val_loss: 0.3196 - val_acc: 0.8909\n",
      "Epoch 17/100\n",
      "1944/1944 [==============================] - 1s 321us/step - loss: 0.2563 - acc: 0.9167 - val_loss: 0.3194 - val_acc: 0.8889\n",
      "Epoch 18/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.2524 - acc: 0.9151 - val_loss: 0.3222 - val_acc: 0.8889\n",
      "Epoch 19/100\n",
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.2509 - acc: 0.9141 - val_loss: 0.3251 - val_acc: 0.8848\n",
      "Epoch 20/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.2413 - acc: 0.9228 - val_loss: 0.3146 - val_acc: 0.8909\n",
      "Epoch 21/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.2505 - acc: 0.9198 - val_loss: 0.3153 - val_acc: 0.8909\n",
      "Epoch 22/100\n",
      "1944/1944 [==============================] - 1s 321us/step - loss: 0.2510 - acc: 0.9162 - val_loss: 0.3178 - val_acc: 0.8868\n",
      "Epoch 23/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.2433 - acc: 0.9182 - val_loss: 0.3125 - val_acc: 0.8909\n",
      "Epoch 24/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.2492 - acc: 0.9192 - val_loss: 0.3214 - val_acc: 0.8827\n",
      "Epoch 25/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.2485 - acc: 0.9162 - val_loss: 0.3026 - val_acc: 0.9012\n",
      "Epoch 26/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.2329 - acc: 0.9280 - val_loss: 0.2979 - val_acc: 0.9074\n",
      "Epoch 27/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.2398 - acc: 0.9182 - val_loss: 0.3127 - val_acc: 0.8889\n",
      "Epoch 28/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.2361 - acc: 0.9275 - val_loss: 0.3041 - val_acc: 0.8971\n",
      "Epoch 29/100\n",
      "1944/1944 [==============================] - 1s 320us/step - loss: 0.2398 - acc: 0.9223 - val_loss: 0.3031 - val_acc: 0.9033\n",
      "Epoch 30/100\n",
      "1944/1944 [==============================] - 1s 317us/step - loss: 0.2307 - acc: 0.9275 - val_loss: 0.2959 - val_acc: 0.9095\n",
      "Epoch 31/100\n",
      "1944/1944 [==============================] - 1s 334us/step - loss: 0.2339 - acc: 0.9234 - val_loss: 0.2965 - val_acc: 0.9095\n",
      "Epoch 32/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.2293 - acc: 0.9311 - val_loss: 0.2978 - val_acc: 0.9033\n",
      "Epoch 33/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.2344 - acc: 0.9295 - val_loss: 0.2902 - val_acc: 0.9074\n",
      "Epoch 34/100\n",
      "1944/1944 [==============================] - 1s 319us/step - loss: 0.2305 - acc: 0.9208 - val_loss: 0.3034 - val_acc: 0.8930\n",
      "Epoch 35/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.2250 - acc: 0.9280 - val_loss: 0.2930 - val_acc: 0.9053\n",
      "Epoch 36/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.2256 - acc: 0.9300 - val_loss: 0.2886 - val_acc: 0.9095\n",
      "Epoch 37/100\n",
      "1944/1944 [==============================] - 1s 321us/step - loss: 0.2276 - acc: 0.9223 - val_loss: 0.2908 - val_acc: 0.9095\n",
      "Epoch 38/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.2180 - acc: 0.9321 - val_loss: 0.2986 - val_acc: 0.8971\n",
      "Epoch 39/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.2231 - acc: 0.9280 - val_loss: 0.2900 - val_acc: 0.9095\n",
      "Epoch 40/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.2225 - acc: 0.9280 - val_loss: 0.2914 - val_acc: 0.8992\n",
      "Epoch 41/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.2206 - acc: 0.9331 - val_loss: 0.2859 - val_acc: 0.9074\n",
      "Epoch 42/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.2137 - acc: 0.9357 - val_loss: 0.2824 - val_acc: 0.9115\n",
      "Epoch 43/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.2176 - acc: 0.9378 - val_loss: 0.2908 - val_acc: 0.9053\n",
      "Epoch 44/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.2217 - acc: 0.9264 - val_loss: 0.2846 - val_acc: 0.9074\n",
      "Epoch 45/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.2080 - acc: 0.9336 - val_loss: 0.2802 - val_acc: 0.9136\n",
      "Epoch 46/100\n",
      "1944/1944 [==============================] - 1s 318us/step - loss: 0.2126 - acc: 0.9378 - val_loss: 0.2915 - val_acc: 0.9012\n",
      "Epoch 47/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.2178 - acc: 0.9285 - val_loss: 0.2873 - val_acc: 0.9053\n",
      "Epoch 48/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.2208 - acc: 0.9228 - val_loss: 0.2728 - val_acc: 0.9177\n",
      "Epoch 49/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.2217 - acc: 0.9295 - val_loss: 0.2798 - val_acc: 0.9095\n",
      "Epoch 50/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.2073 - acc: 0.9372 - val_loss: 0.2812 - val_acc: 0.9095\n",
      "Epoch 51/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.2166 - acc: 0.9336 - val_loss: 0.2764 - val_acc: 0.9115\n",
      "Epoch 52/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.2118 - acc: 0.9311 - val_loss: 0.2740 - val_acc: 0.9156\n",
      "Epoch 53/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.2071 - acc: 0.9326 - val_loss: 0.2865 - val_acc: 0.8971\n",
      "Epoch 54/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.2071 - acc: 0.9372 - val_loss: 0.2705 - val_acc: 0.9177\n",
      "Epoch 55/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.2025 - acc: 0.9352 - val_loss: 0.2688 - val_acc: 0.9177\n",
      "Epoch 56/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.1990 - acc: 0.9383 - val_loss: 0.2697 - val_acc: 0.9177\n",
      "Epoch 57/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.2086 - acc: 0.9357 - val_loss: 0.2744 - val_acc: 0.9177\n",
      "Epoch 58/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.2086 - acc: 0.9342 - val_loss: 0.2751 - val_acc: 0.9136\n",
      "Epoch 59/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.2002 - acc: 0.9367 - val_loss: 0.2705 - val_acc: 0.9177\n",
      "Epoch 60/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.2075 - acc: 0.9367 - val_loss: 0.2728 - val_acc: 0.9156\n",
      "Epoch 61/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.1964 - acc: 0.9408 - val_loss: 0.2680 - val_acc: 0.9156\n",
      "Epoch 62/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.2053 - acc: 0.9357 - val_loss: 0.2620 - val_acc: 0.9177\n",
      "Epoch 63/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1928 - acc: 0.9419 - val_loss: 0.2680 - val_acc: 0.9156\n",
      "Epoch 64/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.1940 - acc: 0.9414 - val_loss: 0.2732 - val_acc: 0.9115\n",
      "Epoch 65/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1987 - acc: 0.9408 - val_loss: 0.2583 - val_acc: 0.9177\n",
      "Epoch 66/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.2011 - acc: 0.9393 - val_loss: 0.2653 - val_acc: 0.9156\n",
      "Epoch 67/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.2010 - acc: 0.9362 - val_loss: 0.2655 - val_acc: 0.9115\n",
      "Epoch 68/100\n",
      "1944/1944 [==============================] - 1s 320us/step - loss: 0.1924 - acc: 0.9429 - val_loss: 0.2492 - val_acc: 0.9218\n",
      "Epoch 69/100\n",
      "1944/1944 [==============================] - 1s 337us/step - loss: 0.1967 - acc: 0.9403 - val_loss: 0.2634 - val_acc: 0.9156\n",
      "Epoch 70/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.1913 - acc: 0.9388 - val_loss: 0.2617 - val_acc: 0.9136\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.1951 - acc: 0.9414 - val_loss: 0.2629 - val_acc: 0.9136\n",
      "Epoch 72/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.1936 - acc: 0.9398 - val_loss: 0.2561 - val_acc: 0.9136\n",
      "Epoch 73/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.1993 - acc: 0.9357 - val_loss: 0.2532 - val_acc: 0.9156\n",
      "Epoch 74/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1892 - acc: 0.9352 - val_loss: 0.2608 - val_acc: 0.9095\n",
      "Epoch 75/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1865 - acc: 0.9393 - val_loss: 0.2541 - val_acc: 0.9156\n",
      "Epoch 76/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.1930 - acc: 0.9352 - val_loss: 0.2616 - val_acc: 0.9136\n",
      "Epoch 77/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1856 - acc: 0.9460 - val_loss: 0.2608 - val_acc: 0.9095\n",
      "Epoch 78/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1917 - acc: 0.9398 - val_loss: 0.2569 - val_acc: 0.9136\n",
      "Epoch 79/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.1836 - acc: 0.9455 - val_loss: 0.2449 - val_acc: 0.9177\n",
      "Epoch 80/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1801 - acc: 0.9414 - val_loss: 0.2544 - val_acc: 0.9156\n",
      "Epoch 81/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.1816 - acc: 0.9429 - val_loss: 0.2549 - val_acc: 0.9136\n",
      "Epoch 82/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1863 - acc: 0.9419 - val_loss: 0.2445 - val_acc: 0.9198\n",
      "Epoch 83/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1801 - acc: 0.9444 - val_loss: 0.2486 - val_acc: 0.9198\n",
      "Epoch 84/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.1872 - acc: 0.9419 - val_loss: 0.2507 - val_acc: 0.9156\n",
      "Epoch 85/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.1844 - acc: 0.9388 - val_loss: 0.2516 - val_acc: 0.9156\n",
      "Epoch 86/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.1848 - acc: 0.9398 - val_loss: 0.2473 - val_acc: 0.9218\n",
      "Epoch 87/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.1815 - acc: 0.9429 - val_loss: 0.2457 - val_acc: 0.9198\n",
      "Epoch 88/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1821 - acc: 0.9455 - val_loss: 0.2505 - val_acc: 0.9136\n",
      "Epoch 89/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.1805 - acc: 0.9455 - val_loss: 0.2423 - val_acc: 0.9218\n",
      "Epoch 90/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.1796 - acc: 0.9455 - val_loss: 0.2489 - val_acc: 0.9198\n",
      "Epoch 91/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.1785 - acc: 0.9475 - val_loss: 0.2429 - val_acc: 0.9239\n",
      "Epoch 92/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.1828 - acc: 0.9465 - val_loss: 0.2449 - val_acc: 0.9177\n",
      "Epoch 93/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1738 - acc: 0.9465 - val_loss: 0.2450 - val_acc: 0.9198\n",
      "Epoch 94/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.1772 - acc: 0.9444 - val_loss: 0.2406 - val_acc: 0.9218\n",
      "Epoch 95/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.1777 - acc: 0.9444 - val_loss: 0.2381 - val_acc: 0.9218\n",
      "Epoch 96/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1757 - acc: 0.9486 - val_loss: 0.2416 - val_acc: 0.9198\n",
      "Epoch 97/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1737 - acc: 0.9429 - val_loss: 0.2425 - val_acc: 0.9198\n",
      "Epoch 98/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.1776 - acc: 0.9434 - val_loss: 0.2480 - val_acc: 0.9136\n",
      "Epoch 99/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.1724 - acc: 0.9475 - val_loss: 0.2497 - val_acc: 0.9156\n",
      "Epoch 100/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.1740 - acc: 0.9475 - val_loss: 0.2480 - val_acc: 0.9177\n",
      "Train on 1944 samples, validate on 486 samples\n",
      "Epoch 1/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.2213 - acc: 0.9187 - val_loss: 0.1848 - val_acc: 0.9342\n",
      "Epoch 2/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.2279 - acc: 0.9198 - val_loss: 0.1872 - val_acc: 0.9342\n",
      "Epoch 3/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.2105 - acc: 0.9331 - val_loss: 0.1831 - val_acc: 0.9342\n",
      "Epoch 4/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.2203 - acc: 0.9208 - val_loss: 0.1801 - val_acc: 0.9321\n",
      "Epoch 5/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.2195 - acc: 0.9249 - val_loss: 0.1780 - val_acc: 0.9362\n",
      "Epoch 6/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.2180 - acc: 0.9264 - val_loss: 0.1817 - val_acc: 0.9383\n",
      "Epoch 7/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.2118 - acc: 0.9275 - val_loss: 0.1725 - val_acc: 0.9383\n",
      "Epoch 8/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.2150 - acc: 0.9275 - val_loss: 0.1767 - val_acc: 0.9383\n",
      "Epoch 9/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.2073 - acc: 0.9280 - val_loss: 0.1809 - val_acc: 0.9321\n",
      "Epoch 10/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.2077 - acc: 0.9347 - val_loss: 0.1852 - val_acc: 0.9321\n",
      "Epoch 11/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.2008 - acc: 0.9300 - val_loss: 0.1676 - val_acc: 0.9424\n",
      "Epoch 12/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.2060 - acc: 0.9270 - val_loss: 0.1703 - val_acc: 0.9383\n",
      "Epoch 13/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.2122 - acc: 0.9331 - val_loss: 0.1728 - val_acc: 0.9362\n",
      "Epoch 14/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.2060 - acc: 0.9331 - val_loss: 0.1772 - val_acc: 0.9321\n",
      "Epoch 15/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.2078 - acc: 0.9249 - val_loss: 0.1718 - val_acc: 0.9342\n",
      "Epoch 16/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.2055 - acc: 0.9316 - val_loss: 0.1784 - val_acc: 0.9342\n",
      "Epoch 17/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.2063 - acc: 0.9316 - val_loss: 0.1811 - val_acc: 0.9300\n",
      "Epoch 18/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.2049 - acc: 0.9295 - val_loss: 0.1679 - val_acc: 0.9383\n",
      "Epoch 19/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.1924 - acc: 0.9403 - val_loss: 0.1771 - val_acc: 0.9321\n",
      "Epoch 20/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.2028 - acc: 0.9254 - val_loss: 0.1685 - val_acc: 0.9362\n",
      "Epoch 21/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.1982 - acc: 0.9270 - val_loss: 0.1673 - val_acc: 0.9403\n",
      "Epoch 22/100\n",
      "1944/1944 [==============================] - 1s 334us/step - loss: 0.1962 - acc: 0.9316 - val_loss: 0.1674 - val_acc: 0.9403\n",
      "Epoch 23/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.1952 - acc: 0.9362 - val_loss: 0.1659 - val_acc: 0.9383\n",
      "Epoch 24/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.2003 - acc: 0.9383 - val_loss: 0.1730 - val_acc: 0.9342\n",
      "Epoch 25/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.2000 - acc: 0.9290 - val_loss: 0.1725 - val_acc: 0.9342\n",
      "Epoch 26/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.1939 - acc: 0.9388 - val_loss: 0.1654 - val_acc: 0.9383\n",
      "Epoch 27/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.1937 - acc: 0.9347 - val_loss: 0.1653 - val_acc: 0.9383\n",
      "Epoch 28/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1939 - acc: 0.9290 - val_loss: 0.1579 - val_acc: 0.9424\n",
      "Epoch 29/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.1945 - acc: 0.9378 - val_loss: 0.1645 - val_acc: 0.9362\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.1952 - acc: 0.9372 - val_loss: 0.1699 - val_acc: 0.9342\n",
      "Epoch 31/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.1950 - acc: 0.9372 - val_loss: 0.1635 - val_acc: 0.9383\n",
      "Epoch 32/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.1876 - acc: 0.9408 - val_loss: 0.1637 - val_acc: 0.9383\n",
      "Epoch 33/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1826 - acc: 0.9408 - val_loss: 0.1640 - val_acc: 0.9383\n",
      "Epoch 34/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.1885 - acc: 0.9403 - val_loss: 0.1671 - val_acc: 0.9321\n",
      "Epoch 35/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.1823 - acc: 0.9383 - val_loss: 0.1577 - val_acc: 0.9424\n",
      "Epoch 36/100\n",
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.1849 - acc: 0.9383 - val_loss: 0.1626 - val_acc: 0.9403\n",
      "Epoch 37/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1854 - acc: 0.9388 - val_loss: 0.1645 - val_acc: 0.9362\n",
      "Epoch 38/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.1868 - acc: 0.9383 - val_loss: 0.1562 - val_acc: 0.9403\n",
      "Epoch 39/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.1864 - acc: 0.9403 - val_loss: 0.1625 - val_acc: 0.9362\n",
      "Epoch 40/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.1784 - acc: 0.9424 - val_loss: 0.1616 - val_acc: 0.9362\n",
      "Epoch 41/100\n",
      "1944/1944 [==============================] - 1s 337us/step - loss: 0.1881 - acc: 0.9403 - val_loss: 0.1627 - val_acc: 0.9383\n",
      "Epoch 42/100\n",
      "1944/1944 [==============================] - 1s 356us/step - loss: 0.1806 - acc: 0.9434 - val_loss: 0.1566 - val_acc: 0.9424\n",
      "Epoch 43/100\n",
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.1861 - acc: 0.9347 - val_loss: 0.1641 - val_acc: 0.9383\n",
      "Epoch 44/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.1789 - acc: 0.9439 - val_loss: 0.1576 - val_acc: 0.9424\n",
      "Epoch 45/100\n",
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.1899 - acc: 0.9367 - val_loss: 0.1596 - val_acc: 0.9383\n",
      "Epoch 46/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.1780 - acc: 0.9434 - val_loss: 0.1569 - val_acc: 0.9403\n",
      "Epoch 47/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.1746 - acc: 0.9460 - val_loss: 0.1592 - val_acc: 0.9383\n",
      "Epoch 48/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.1799 - acc: 0.9408 - val_loss: 0.1616 - val_acc: 0.9383\n",
      "Epoch 49/100\n",
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.1796 - acc: 0.9424 - val_loss: 0.1659 - val_acc: 0.9362\n",
      "Epoch 50/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.1788 - acc: 0.9403 - val_loss: 0.1567 - val_acc: 0.9403\n",
      "Epoch 51/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.1780 - acc: 0.9434 - val_loss: 0.1573 - val_acc: 0.9403\n",
      "Epoch 52/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.1754 - acc: 0.9444 - val_loss: 0.1554 - val_acc: 0.9403\n",
      "Epoch 53/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1798 - acc: 0.9393 - val_loss: 0.1589 - val_acc: 0.9362\n",
      "Epoch 54/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.1732 - acc: 0.9439 - val_loss: 0.1657 - val_acc: 0.9362\n",
      "Epoch 55/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1741 - acc: 0.9455 - val_loss: 0.1536 - val_acc: 0.9424\n",
      "Epoch 56/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.1778 - acc: 0.9439 - val_loss: 0.1589 - val_acc: 0.9362\n",
      "Epoch 57/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.1763 - acc: 0.9444 - val_loss: 0.1591 - val_acc: 0.9362\n",
      "Epoch 58/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.1640 - acc: 0.9516 - val_loss: 0.1562 - val_acc: 0.9403\n",
      "Epoch 59/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.1678 - acc: 0.9465 - val_loss: 0.1622 - val_acc: 0.9362\n",
      "Epoch 60/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.1702 - acc: 0.9475 - val_loss: 0.1587 - val_acc: 0.9362\n",
      "Epoch 61/100\n",
      "1944/1944 [==============================] - 1s 353us/step - loss: 0.1720 - acc: 0.9491 - val_loss: 0.1580 - val_acc: 0.9362\n",
      "Epoch 62/100\n",
      "1944/1944 [==============================] - 1s 334us/step - loss: 0.1714 - acc: 0.9455 - val_loss: 0.1601 - val_acc: 0.9362\n",
      "Epoch 63/100\n",
      "1944/1944 [==============================] - 1s 336us/step - loss: 0.1719 - acc: 0.9434 - val_loss: 0.1555 - val_acc: 0.9383\n",
      "Epoch 64/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.1668 - acc: 0.9501 - val_loss: 0.1586 - val_acc: 0.9362\n",
      "Epoch 65/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.1710 - acc: 0.9444 - val_loss: 0.1531 - val_acc: 0.9383\n",
      "Epoch 66/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1698 - acc: 0.9414 - val_loss: 0.1571 - val_acc: 0.9362\n",
      "Epoch 67/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1597 - acc: 0.9511 - val_loss: 0.1569 - val_acc: 0.9383\n",
      "Epoch 68/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.1670 - acc: 0.9414 - val_loss: 0.1518 - val_acc: 0.9465\n",
      "Epoch 69/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1654 - acc: 0.9480 - val_loss: 0.1551 - val_acc: 0.9403\n",
      "Epoch 70/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.1726 - acc: 0.9444 - val_loss: 0.1488 - val_acc: 0.9403\n",
      "Epoch 71/100\n",
      "1944/1944 [==============================] - 1s 319us/step - loss: 0.1623 - acc: 0.9516 - val_loss: 0.1536 - val_acc: 0.9403\n",
      "Epoch 72/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1665 - acc: 0.9506 - val_loss: 0.1581 - val_acc: 0.9362\n",
      "Epoch 73/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1652 - acc: 0.9434 - val_loss: 0.1518 - val_acc: 0.9403\n",
      "Epoch 74/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.1553 - acc: 0.9537 - val_loss: 0.1533 - val_acc: 0.9403\n",
      "Epoch 75/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.1751 - acc: 0.9429 - val_loss: 0.1486 - val_acc: 0.9424\n",
      "Epoch 76/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.1692 - acc: 0.9434 - val_loss: 0.1547 - val_acc: 0.9383\n",
      "Epoch 77/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1691 - acc: 0.9486 - val_loss: 0.1530 - val_acc: 0.9424\n",
      "Epoch 78/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.1629 - acc: 0.9516 - val_loss: 0.1592 - val_acc: 0.9362\n",
      "Epoch 79/100\n",
      "1944/1944 [==============================] - 1s 334us/step - loss: 0.1627 - acc: 0.9511 - val_loss: 0.1588 - val_acc: 0.9383\n",
      "Epoch 80/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.1596 - acc: 0.9450 - val_loss: 0.1497 - val_acc: 0.9403\n",
      "Epoch 81/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.1628 - acc: 0.9506 - val_loss: 0.1508 - val_acc: 0.9383\n",
      "Epoch 82/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.1655 - acc: 0.9522 - val_loss: 0.1522 - val_acc: 0.9383\n",
      "Epoch 83/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.1619 - acc: 0.9486 - val_loss: 0.1536 - val_acc: 0.9424\n",
      "Epoch 84/100\n",
      "1944/1944 [==============================] - 1s 321us/step - loss: 0.1609 - acc: 0.9516 - val_loss: 0.1538 - val_acc: 0.9383\n",
      "Epoch 85/100\n",
      "1944/1944 [==============================] - 1s 337us/step - loss: 0.1600 - acc: 0.9496 - val_loss: 0.1538 - val_acc: 0.9383\n",
      "Epoch 86/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.1604 - acc: 0.9542 - val_loss: 0.1516 - val_acc: 0.9403\n",
      "Epoch 87/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.1575 - acc: 0.9547 - val_loss: 0.1523 - val_acc: 0.9403\n",
      "Epoch 88/100\n",
      "1944/1944 [==============================] - 1s 320us/step - loss: 0.1523 - acc: 0.9511 - val_loss: 0.1503 - val_acc: 0.9403\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.1592 - acc: 0.9532 - val_loss: 0.1539 - val_acc: 0.9424\n",
      "Epoch 90/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1583 - acc: 0.9496 - val_loss: 0.1519 - val_acc: 0.9403\n",
      "Epoch 91/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.1598 - acc: 0.9511 - val_loss: 0.1448 - val_acc: 0.9444\n",
      "Epoch 92/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.1608 - acc: 0.9522 - val_loss: 0.1479 - val_acc: 0.9403\n",
      "Epoch 93/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.1587 - acc: 0.9542 - val_loss: 0.1460 - val_acc: 0.9403\n",
      "Epoch 94/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.1552 - acc: 0.9516 - val_loss: 0.1504 - val_acc: 0.9403\n",
      "Epoch 95/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.1522 - acc: 0.9501 - val_loss: 0.1540 - val_acc: 0.9383\n",
      "Epoch 96/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.1567 - acc: 0.9501 - val_loss: 0.1512 - val_acc: 0.9403\n",
      "Epoch 97/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1513 - acc: 0.9516 - val_loss: 0.1484 - val_acc: 0.9403\n",
      "Epoch 98/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.1601 - acc: 0.9475 - val_loss: 0.1505 - val_acc: 0.9403\n",
      "Epoch 99/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1575 - acc: 0.9506 - val_loss: 0.1539 - val_acc: 0.9383\n",
      "Epoch 100/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.1535 - acc: 0.9527 - val_loss: 0.1527 - val_acc: 0.9403\n",
      "Test subject 10, class BothStartLoadPhase\n",
      "Train subject 10, class LiftOff\n",
      "Train on 1944 samples, validate on 486 samples\n",
      "Epoch 1/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.5405 - acc: 0.7855 - val_loss: 0.3922 - val_acc: 0.8477\n",
      "Epoch 2/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.4292 - acc: 0.8251 - val_loss: 0.3413 - val_acc: 0.8704\n",
      "Epoch 3/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.3825 - acc: 0.8380 - val_loss: 0.3208 - val_acc: 0.8827\n",
      "Epoch 4/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.3738 - acc: 0.8395 - val_loss: 0.3082 - val_acc: 0.8786\n",
      "Epoch 5/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.3510 - acc: 0.8570 - val_loss: 0.2979 - val_acc: 0.8909\n",
      "Epoch 6/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.3426 - acc: 0.8575 - val_loss: 0.2887 - val_acc: 0.8868\n",
      "Epoch 7/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.3285 - acc: 0.8637 - val_loss: 0.2832 - val_acc: 0.8930\n",
      "Epoch 8/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.3249 - acc: 0.8621 - val_loss: 0.2877 - val_acc: 0.8951\n",
      "Epoch 9/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.3320 - acc: 0.8611 - val_loss: 0.2797 - val_acc: 0.8971\n",
      "Epoch 10/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.3022 - acc: 0.8822 - val_loss: 0.2734 - val_acc: 0.9012\n",
      "Epoch 11/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.3103 - acc: 0.8709 - val_loss: 0.2722 - val_acc: 0.9033\n",
      "Epoch 12/100\n",
      "1944/1944 [==============================] - 1s 318us/step - loss: 0.3124 - acc: 0.8709 - val_loss: 0.2734 - val_acc: 0.9033\n",
      "Epoch 13/100\n",
      "1944/1944 [==============================] - 1s 320us/step - loss: 0.3052 - acc: 0.8755 - val_loss: 0.2676 - val_acc: 0.9053\n",
      "Epoch 14/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.3012 - acc: 0.8807 - val_loss: 0.2635 - val_acc: 0.9074\n",
      "Epoch 15/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.2882 - acc: 0.8760 - val_loss: 0.2725 - val_acc: 0.8992\n",
      "Epoch 16/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.2944 - acc: 0.8817 - val_loss: 0.2674 - val_acc: 0.8971\n",
      "Epoch 17/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.2833 - acc: 0.8817 - val_loss: 0.2640 - val_acc: 0.8971\n",
      "Epoch 18/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.2887 - acc: 0.8832 - val_loss: 0.2599 - val_acc: 0.9012\n",
      "Epoch 19/100\n",
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.2849 - acc: 0.8858 - val_loss: 0.2595 - val_acc: 0.9012\n",
      "Epoch 20/100\n",
      "1944/1944 [==============================] - 1s 337us/step - loss: 0.2773 - acc: 0.8920 - val_loss: 0.2534 - val_acc: 0.9074\n",
      "Epoch 21/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.2736 - acc: 0.8920 - val_loss: 0.2540 - val_acc: 0.9033\n",
      "Epoch 22/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.2739 - acc: 0.8904 - val_loss: 0.2527 - val_acc: 0.9095\n",
      "Epoch 23/100\n",
      "1944/1944 [==============================] - 1s 337us/step - loss: 0.2708 - acc: 0.8879 - val_loss: 0.2537 - val_acc: 0.9053\n",
      "Epoch 24/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.2704 - acc: 0.8909 - val_loss: 0.2551 - val_acc: 0.9033\n",
      "Epoch 25/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.2678 - acc: 0.8915 - val_loss: 0.2490 - val_acc: 0.9074\n",
      "Epoch 26/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.2606 - acc: 0.8930 - val_loss: 0.2473 - val_acc: 0.9074\n",
      "Epoch 27/100\n",
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.2611 - acc: 0.8992 - val_loss: 0.2477 - val_acc: 0.9074\n",
      "Epoch 28/100\n",
      "1944/1944 [==============================] - 1s 337us/step - loss: 0.2643 - acc: 0.8920 - val_loss: 0.2443 - val_acc: 0.9095\n",
      "Epoch 29/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.2602 - acc: 0.8992 - val_loss: 0.2466 - val_acc: 0.9074\n",
      "Epoch 30/100\n",
      "1944/1944 [==============================] - 1s 336us/step - loss: 0.2581 - acc: 0.9012 - val_loss: 0.2438 - val_acc: 0.9095\n",
      "Epoch 31/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.2591 - acc: 0.9002 - val_loss: 0.2391 - val_acc: 0.9156\n",
      "Epoch 32/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.2539 - acc: 0.9012 - val_loss: 0.2391 - val_acc: 0.9156\n",
      "Epoch 33/100\n",
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.2504 - acc: 0.9002 - val_loss: 0.2370 - val_acc: 0.9177\n",
      "Epoch 34/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.2566 - acc: 0.9017 - val_loss: 0.2352 - val_acc: 0.9198\n",
      "Epoch 35/100\n",
      "1944/1944 [==============================] - 1s 351us/step - loss: 0.2512 - acc: 0.9033 - val_loss: 0.2431 - val_acc: 0.9115\n",
      "Epoch 36/100\n",
      "1944/1944 [==============================] - 1s 361us/step - loss: 0.2566 - acc: 0.8971 - val_loss: 0.2358 - val_acc: 0.9177\n",
      "Epoch 37/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.2532 - acc: 0.9064 - val_loss: 0.2357 - val_acc: 0.9198\n",
      "Epoch 38/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.2563 - acc: 0.9012 - val_loss: 0.2367 - val_acc: 0.9198\n",
      "Epoch 39/100\n",
      "1944/1944 [==============================] - 1s 337us/step - loss: 0.2480 - acc: 0.9105 - val_loss: 0.2338 - val_acc: 0.9218\n",
      "Epoch 40/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.2441 - acc: 0.9100 - val_loss: 0.2328 - val_acc: 0.9218\n",
      "Epoch 41/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.2486 - acc: 0.9028 - val_loss: 0.2327 - val_acc: 0.9218\n",
      "Epoch 42/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.2483 - acc: 0.9053 - val_loss: 0.2309 - val_acc: 0.9218\n",
      "Epoch 43/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.2372 - acc: 0.9141 - val_loss: 0.2326 - val_acc: 0.9239\n",
      "Epoch 44/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.2414 - acc: 0.9090 - val_loss: 0.2279 - val_acc: 0.9239\n",
      "Epoch 45/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.2390 - acc: 0.9053 - val_loss: 0.2302 - val_acc: 0.9218\n",
      "Epoch 46/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.2331 - acc: 0.9146 - val_loss: 0.2275 - val_acc: 0.9259\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.2345 - acc: 0.9110 - val_loss: 0.2304 - val_acc: 0.9239\n",
      "Epoch 48/100\n",
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.2331 - acc: 0.9156 - val_loss: 0.2224 - val_acc: 0.9259\n",
      "Epoch 49/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.2353 - acc: 0.9095 - val_loss: 0.2244 - val_acc: 0.9239\n",
      "Epoch 50/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.2374 - acc: 0.9105 - val_loss: 0.2247 - val_acc: 0.9239\n",
      "Epoch 51/100\n",
      "1944/1944 [==============================] - 1s 321us/step - loss: 0.2329 - acc: 0.9115 - val_loss: 0.2224 - val_acc: 0.9239\n",
      "Epoch 52/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.2304 - acc: 0.9100 - val_loss: 0.2273 - val_acc: 0.9239\n",
      "Epoch 53/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.2278 - acc: 0.9120 - val_loss: 0.2203 - val_acc: 0.9239\n",
      "Epoch 54/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.2389 - acc: 0.9095 - val_loss: 0.2248 - val_acc: 0.9259\n",
      "Epoch 55/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.2290 - acc: 0.9156 - val_loss: 0.2227 - val_acc: 0.9239\n",
      "Epoch 56/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.2321 - acc: 0.9151 - val_loss: 0.2228 - val_acc: 0.9259\n",
      "Epoch 57/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.2334 - acc: 0.9100 - val_loss: 0.2210 - val_acc: 0.9280\n",
      "Epoch 58/100\n",
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.2260 - acc: 0.9198 - val_loss: 0.2202 - val_acc: 0.9259\n",
      "Epoch 59/100\n",
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.2249 - acc: 0.9136 - val_loss: 0.2236 - val_acc: 0.9280\n",
      "Epoch 60/100\n",
      "1944/1944 [==============================] - 1s 336us/step - loss: 0.2281 - acc: 0.9120 - val_loss: 0.2191 - val_acc: 0.9280\n",
      "Epoch 61/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.2284 - acc: 0.9110 - val_loss: 0.2194 - val_acc: 0.9300\n",
      "Epoch 62/100\n",
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.2236 - acc: 0.9218 - val_loss: 0.2167 - val_acc: 0.9300\n",
      "Epoch 63/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.2170 - acc: 0.9234 - val_loss: 0.2165 - val_acc: 0.9280\n",
      "Epoch 64/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.2207 - acc: 0.9182 - val_loss: 0.2181 - val_acc: 0.9280\n",
      "Epoch 65/100\n",
      "1944/1944 [==============================] - 1s 336us/step - loss: 0.2261 - acc: 0.9131 - val_loss: 0.2191 - val_acc: 0.9300\n",
      "Epoch 66/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.2213 - acc: 0.9167 - val_loss: 0.2144 - val_acc: 0.9321\n",
      "Epoch 67/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.2112 - acc: 0.9234 - val_loss: 0.2170 - val_acc: 0.9280\n",
      "Epoch 68/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.2178 - acc: 0.9244 - val_loss: 0.2139 - val_acc: 0.9321\n",
      "Epoch 69/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.2216 - acc: 0.9228 - val_loss: 0.2166 - val_acc: 0.9321\n",
      "Epoch 70/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.2194 - acc: 0.9270 - val_loss: 0.2123 - val_acc: 0.9342\n",
      "Epoch 71/100\n",
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.2217 - acc: 0.9177 - val_loss: 0.2124 - val_acc: 0.9342\n",
      "Epoch 72/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.2107 - acc: 0.9239 - val_loss: 0.2172 - val_acc: 0.9300\n",
      "Epoch 73/100\n",
      "1944/1944 [==============================] - 1s 318us/step - loss: 0.2260 - acc: 0.9198 - val_loss: 0.2159 - val_acc: 0.9321\n",
      "Epoch 74/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.2212 - acc: 0.9156 - val_loss: 0.2153 - val_acc: 0.9321\n",
      "Epoch 75/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.2238 - acc: 0.9167 - val_loss: 0.2139 - val_acc: 0.9321\n",
      "Epoch 76/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.2130 - acc: 0.9203 - val_loss: 0.2122 - val_acc: 0.9342\n",
      "Epoch 77/100\n",
      "1944/1944 [==============================] - 1s 319us/step - loss: 0.2149 - acc: 0.9182 - val_loss: 0.2144 - val_acc: 0.9321\n",
      "Epoch 78/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.2118 - acc: 0.9208 - val_loss: 0.2167 - val_acc: 0.9259\n",
      "Epoch 79/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.2182 - acc: 0.9192 - val_loss: 0.2109 - val_acc: 0.9342\n",
      "Epoch 80/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.2172 - acc: 0.9192 - val_loss: 0.2112 - val_acc: 0.9342\n",
      "Epoch 81/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.2177 - acc: 0.9228 - val_loss: 0.2159 - val_acc: 0.9239\n",
      "Epoch 82/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.2179 - acc: 0.9187 - val_loss: 0.2095 - val_acc: 0.9321\n",
      "Epoch 83/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.2040 - acc: 0.9228 - val_loss: 0.2131 - val_acc: 0.9321\n",
      "Epoch 84/100\n",
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.2075 - acc: 0.9254 - val_loss: 0.2107 - val_acc: 0.9321\n",
      "Epoch 85/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.2012 - acc: 0.9218 - val_loss: 0.2091 - val_acc: 0.9321\n",
      "Epoch 86/100\n",
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.2093 - acc: 0.9192 - val_loss: 0.2117 - val_acc: 0.9300\n",
      "Epoch 87/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.2119 - acc: 0.9203 - val_loss: 0.2133 - val_acc: 0.9300\n",
      "Epoch 88/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.2090 - acc: 0.9228 - val_loss: 0.2098 - val_acc: 0.9342\n",
      "Epoch 89/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.2094 - acc: 0.9213 - val_loss: 0.2108 - val_acc: 0.9362\n",
      "Epoch 90/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.2043 - acc: 0.9270 - val_loss: 0.2111 - val_acc: 0.9300\n",
      "Epoch 91/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.2036 - acc: 0.9218 - val_loss: 0.2116 - val_acc: 0.9300\n",
      "Epoch 92/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.2060 - acc: 0.9270 - val_loss: 0.2079 - val_acc: 0.9362\n",
      "Epoch 93/100\n",
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.2076 - acc: 0.9218 - val_loss: 0.2055 - val_acc: 0.9342\n",
      "Epoch 94/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.2011 - acc: 0.9300 - val_loss: 0.2102 - val_acc: 0.9280\n",
      "Epoch 95/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.2041 - acc: 0.9218 - val_loss: 0.2080 - val_acc: 0.9342\n",
      "Epoch 96/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.2135 - acc: 0.9254 - val_loss: 0.2065 - val_acc: 0.9342\n",
      "Epoch 97/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.2053 - acc: 0.9218 - val_loss: 0.2079 - val_acc: 0.9342\n",
      "Epoch 98/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.1967 - acc: 0.9275 - val_loss: 0.2063 - val_acc: 0.9342\n",
      "Epoch 99/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.1965 - acc: 0.9270 - val_loss: 0.2060 - val_acc: 0.9342\n",
      "Epoch 100/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.2043 - acc: 0.9264 - val_loss: 0.2041 - val_acc: 0.9362\n",
      "Train on 1944 samples, validate on 486 samples\n",
      "Epoch 1/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.2142 - acc: 0.9213 - val_loss: 0.1608 - val_acc: 0.9465\n",
      "Epoch 2/100\n",
      "1944/1944 [==============================] - 1s 321us/step - loss: 0.2203 - acc: 0.9223 - val_loss: 0.1589 - val_acc: 0.9486\n",
      "Epoch 3/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.2172 - acc: 0.9218 - val_loss: 0.1600 - val_acc: 0.9486\n",
      "Epoch 4/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.2154 - acc: 0.9280 - val_loss: 0.1551 - val_acc: 0.9506\n",
      "Epoch 5/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.2074 - acc: 0.9295 - val_loss: 0.1554 - val_acc: 0.9506\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.2086 - acc: 0.9285 - val_loss: 0.1540 - val_acc: 0.9486\n",
      "Epoch 7/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.2041 - acc: 0.9342 - val_loss: 0.1535 - val_acc: 0.9486\n",
      "Epoch 8/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.2048 - acc: 0.9285 - val_loss: 0.1496 - val_acc: 0.9506\n",
      "Epoch 9/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.2041 - acc: 0.9357 - val_loss: 0.1487 - val_acc: 0.9506\n",
      "Epoch 10/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.2029 - acc: 0.9275 - val_loss: 0.1502 - val_acc: 0.9506\n",
      "Epoch 11/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.1992 - acc: 0.9316 - val_loss: 0.1482 - val_acc: 0.9547\n",
      "Epoch 12/100\n",
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.2050 - acc: 0.9300 - val_loss: 0.1515 - val_acc: 0.9444\n",
      "Epoch 13/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.1964 - acc: 0.9357 - val_loss: 0.1465 - val_acc: 0.9506\n",
      "Epoch 14/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1984 - acc: 0.9342 - val_loss: 0.1503 - val_acc: 0.9486\n",
      "Epoch 15/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.1957 - acc: 0.9352 - val_loss: 0.1453 - val_acc: 0.9527\n",
      "Epoch 16/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.1974 - acc: 0.9306 - val_loss: 0.1451 - val_acc: 0.9506\n",
      "Epoch 17/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.2003 - acc: 0.9336 - val_loss: 0.1453 - val_acc: 0.9506\n",
      "Epoch 18/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.1966 - acc: 0.9372 - val_loss: 0.1439 - val_acc: 0.9547\n",
      "Epoch 19/100\n",
      "1944/1944 [==============================] - 1s 337us/step - loss: 0.2001 - acc: 0.9347 - val_loss: 0.1469 - val_acc: 0.9527\n",
      "Epoch 20/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1954 - acc: 0.9372 - val_loss: 0.1468 - val_acc: 0.9506\n",
      "Epoch 21/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.1929 - acc: 0.9352 - val_loss: 0.1472 - val_acc: 0.9506\n",
      "Epoch 22/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.2004 - acc: 0.9342 - val_loss: 0.1516 - val_acc: 0.9444\n",
      "Epoch 23/100\n",
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.1989 - acc: 0.9352 - val_loss: 0.1433 - val_acc: 0.9568\n",
      "Epoch 24/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.1902 - acc: 0.9383 - val_loss: 0.1455 - val_acc: 0.9506\n",
      "Epoch 25/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1895 - acc: 0.9388 - val_loss: 0.1387 - val_acc: 0.9568\n",
      "Epoch 26/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1924 - acc: 0.9352 - val_loss: 0.1419 - val_acc: 0.9527\n",
      "Epoch 27/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1909 - acc: 0.9372 - val_loss: 0.1424 - val_acc: 0.9506\n",
      "Epoch 28/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1906 - acc: 0.9342 - val_loss: 0.1426 - val_acc: 0.9527\n",
      "Epoch 29/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1875 - acc: 0.9367 - val_loss: 0.1453 - val_acc: 0.9486\n",
      "Epoch 30/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.1890 - acc: 0.9362 - val_loss: 0.1436 - val_acc: 0.9506\n",
      "Epoch 31/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.1923 - acc: 0.9357 - val_loss: 0.1434 - val_acc: 0.9506\n",
      "Epoch 32/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1880 - acc: 0.9398 - val_loss: 0.1438 - val_acc: 0.9486\n",
      "Epoch 33/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.1909 - acc: 0.9372 - val_loss: 0.1388 - val_acc: 0.9547\n",
      "Epoch 34/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.1903 - acc: 0.9393 - val_loss: 0.1428 - val_acc: 0.9506\n",
      "Epoch 35/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1774 - acc: 0.9414 - val_loss: 0.1424 - val_acc: 0.9486\n",
      "Epoch 36/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.1845 - acc: 0.9460 - val_loss: 0.1385 - val_acc: 0.9527\n",
      "Epoch 37/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1827 - acc: 0.9403 - val_loss: 0.1412 - val_acc: 0.9506\n",
      "Epoch 38/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1827 - acc: 0.9414 - val_loss: 0.1373 - val_acc: 0.9547\n",
      "Epoch 39/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1871 - acc: 0.9367 - val_loss: 0.1352 - val_acc: 0.9588\n",
      "Epoch 40/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.1856 - acc: 0.9342 - val_loss: 0.1339 - val_acc: 0.9547\n",
      "Epoch 41/100\n",
      "1944/1944 [==============================] - 1s 321us/step - loss: 0.1816 - acc: 0.9419 - val_loss: 0.1364 - val_acc: 0.9527\n",
      "Epoch 42/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.1847 - acc: 0.9419 - val_loss: 0.1384 - val_acc: 0.9527\n",
      "Epoch 43/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1863 - acc: 0.9424 - val_loss: 0.1367 - val_acc: 0.9547\n",
      "Epoch 44/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1803 - acc: 0.9414 - val_loss: 0.1365 - val_acc: 0.9527\n",
      "Epoch 45/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.1752 - acc: 0.9434 - val_loss: 0.1344 - val_acc: 0.9547\n",
      "Epoch 46/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.1789 - acc: 0.9444 - val_loss: 0.1350 - val_acc: 0.9547\n",
      "Epoch 47/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.1815 - acc: 0.9388 - val_loss: 0.1412 - val_acc: 0.9465\n",
      "Epoch 48/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.1844 - acc: 0.9414 - val_loss: 0.1336 - val_acc: 0.9568\n",
      "Epoch 49/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.1804 - acc: 0.9419 - val_loss: 0.1386 - val_acc: 0.9527\n",
      "Epoch 50/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.1782 - acc: 0.9439 - val_loss: 0.1345 - val_acc: 0.9547\n",
      "Epoch 51/100\n",
      "1944/1944 [==============================] - 1s 321us/step - loss: 0.1872 - acc: 0.9383 - val_loss: 0.1373 - val_acc: 0.9506\n",
      "Epoch 52/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.1766 - acc: 0.9450 - val_loss: 0.1312 - val_acc: 0.9588\n",
      "Epoch 53/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1760 - acc: 0.9414 - val_loss: 0.1319 - val_acc: 0.9547\n",
      "Epoch 54/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.1717 - acc: 0.9460 - val_loss: 0.1346 - val_acc: 0.9547\n",
      "Epoch 55/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1672 - acc: 0.9501 - val_loss: 0.1372 - val_acc: 0.9527\n",
      "Epoch 56/100\n",
      "1944/1944 [==============================] - 1s 321us/step - loss: 0.1691 - acc: 0.9486 - val_loss: 0.1365 - val_acc: 0.9527\n",
      "Epoch 57/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.1703 - acc: 0.9465 - val_loss: 0.1358 - val_acc: 0.9527\n",
      "Epoch 58/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1772 - acc: 0.9465 - val_loss: 0.1283 - val_acc: 0.9547\n",
      "Epoch 59/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1698 - acc: 0.9480 - val_loss: 0.1316 - val_acc: 0.9547\n",
      "Epoch 60/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1784 - acc: 0.9393 - val_loss: 0.1340 - val_acc: 0.9547\n",
      "Epoch 61/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1782 - acc: 0.9414 - val_loss: 0.1292 - val_acc: 0.9568\n",
      "Epoch 62/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.1745 - acc: 0.9434 - val_loss: 0.1304 - val_acc: 0.9547\n",
      "Epoch 63/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1707 - acc: 0.9455 - val_loss: 0.1310 - val_acc: 0.9547\n",
      "Epoch 64/100\n",
      "1944/1944 [==============================] - 1s 320us/step - loss: 0.1757 - acc: 0.9434 - val_loss: 0.1333 - val_acc: 0.9547\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.1739 - acc: 0.9434 - val_loss: 0.1281 - val_acc: 0.9547\n",
      "Epoch 66/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.1721 - acc: 0.9444 - val_loss: 0.1292 - val_acc: 0.9547\n",
      "Epoch 67/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.1744 - acc: 0.9419 - val_loss: 0.1297 - val_acc: 0.9547\n",
      "Epoch 68/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.1724 - acc: 0.9434 - val_loss: 0.1282 - val_acc: 0.9609\n",
      "Epoch 69/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.1698 - acc: 0.9434 - val_loss: 0.1315 - val_acc: 0.9547\n",
      "Epoch 70/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.1658 - acc: 0.9501 - val_loss: 0.1299 - val_acc: 0.9568\n",
      "Epoch 71/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1721 - acc: 0.9424 - val_loss: 0.1359 - val_acc: 0.9527\n",
      "Epoch 72/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.1701 - acc: 0.9506 - val_loss: 0.1298 - val_acc: 0.9568\n",
      "Epoch 73/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.1724 - acc: 0.9408 - val_loss: 0.1287 - val_acc: 0.9568\n",
      "Epoch 74/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.1726 - acc: 0.9434 - val_loss: 0.1298 - val_acc: 0.9568\n",
      "Epoch 75/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1703 - acc: 0.9434 - val_loss: 0.1280 - val_acc: 0.9568\n",
      "Epoch 76/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.1629 - acc: 0.9475 - val_loss: 0.1249 - val_acc: 0.9568\n",
      "Epoch 77/100\n",
      "1944/1944 [==============================] - 1s 320us/step - loss: 0.1668 - acc: 0.9506 - val_loss: 0.1313 - val_acc: 0.9547\n",
      "Epoch 78/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1686 - acc: 0.9480 - val_loss: 0.1266 - val_acc: 0.9547\n",
      "Epoch 79/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.1763 - acc: 0.9372 - val_loss: 0.1260 - val_acc: 0.9588\n",
      "Epoch 80/100\n",
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.1613 - acc: 0.9465 - val_loss: 0.1253 - val_acc: 0.9609\n",
      "Epoch 81/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.1587 - acc: 0.9542 - val_loss: 0.1257 - val_acc: 0.9588\n",
      "Epoch 82/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.1654 - acc: 0.9475 - val_loss: 0.1257 - val_acc: 0.9547\n",
      "Epoch 83/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1701 - acc: 0.9486 - val_loss: 0.1227 - val_acc: 0.9588\n",
      "Epoch 84/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.1669 - acc: 0.9465 - val_loss: 0.1315 - val_acc: 0.9547\n",
      "Epoch 85/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.1698 - acc: 0.9434 - val_loss: 0.1287 - val_acc: 0.9547\n",
      "Epoch 86/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1659 - acc: 0.9470 - val_loss: 0.1305 - val_acc: 0.9547\n",
      "Epoch 87/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.1640 - acc: 0.9480 - val_loss: 0.1257 - val_acc: 0.9568\n",
      "Epoch 88/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1638 - acc: 0.9465 - val_loss: 0.1264 - val_acc: 0.9568\n",
      "Epoch 89/100\n",
      "1944/1944 [==============================] - 1s 321us/step - loss: 0.1662 - acc: 0.9511 - val_loss: 0.1243 - val_acc: 0.9568\n",
      "Epoch 90/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.1579 - acc: 0.9491 - val_loss: 0.1251 - val_acc: 0.9568\n",
      "Epoch 91/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.1607 - acc: 0.9516 - val_loss: 0.1202 - val_acc: 0.9588\n",
      "Epoch 92/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1643 - acc: 0.9398 - val_loss: 0.1196 - val_acc: 0.9609\n",
      "Epoch 93/100\n",
      "1944/1944 [==============================] - 1s 320us/step - loss: 0.1604 - acc: 0.9506 - val_loss: 0.1246 - val_acc: 0.9568\n",
      "Epoch 94/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1694 - acc: 0.9455 - val_loss: 0.1215 - val_acc: 0.9588\n",
      "Epoch 95/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1694 - acc: 0.9455 - val_loss: 0.1227 - val_acc: 0.9588\n",
      "Epoch 96/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.1606 - acc: 0.9532 - val_loss: 0.1190 - val_acc: 0.9609\n",
      "Epoch 97/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.1640 - acc: 0.9491 - val_loss: 0.1248 - val_acc: 0.9568\n",
      "Epoch 98/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1586 - acc: 0.9486 - val_loss: 0.1256 - val_acc: 0.9568\n",
      "Epoch 99/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1645 - acc: 0.9506 - val_loss: 0.1249 - val_acc: 0.9568\n",
      "Epoch 100/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1569 - acc: 0.9511 - val_loss: 0.1198 - val_acc: 0.9609\n",
      "Test subject 10, class LiftOff\n",
      "Train subject 10, class Replace\n",
      "Train on 1943 samples, validate on 486 samples\n",
      "Epoch 1/100\n",
      "1943/1943 [==============================] - 1s 329us/step - loss: 0.5085 - acc: 0.7962 - val_loss: 0.4587 - val_acc: 0.7963\n",
      "Epoch 2/100\n",
      "1943/1943 [==============================] - 1s 325us/step - loss: 0.4094 - acc: 0.8343 - val_loss: 0.4024 - val_acc: 0.8189\n",
      "Epoch 3/100\n",
      "1943/1943 [==============================] - 1s 340us/step - loss: 0.3810 - acc: 0.8430 - val_loss: 0.3957 - val_acc: 0.8333\n",
      "Epoch 4/100\n",
      "1943/1943 [==============================] - 1s 328us/step - loss: 0.3614 - acc: 0.8518 - val_loss: 0.3822 - val_acc: 0.8416\n",
      "Epoch 5/100\n",
      "1943/1943 [==============================] - 1s 326us/step - loss: 0.3605 - acc: 0.8487 - val_loss: 0.3746 - val_acc: 0.8416\n",
      "Epoch 6/100\n",
      "1943/1943 [==============================] - 1s 326us/step - loss: 0.3354 - acc: 0.8554 - val_loss: 0.3632 - val_acc: 0.8539\n",
      "Epoch 7/100\n",
      "1943/1943 [==============================] - 1s 326us/step - loss: 0.3502 - acc: 0.8554 - val_loss: 0.3516 - val_acc: 0.8539\n",
      "Epoch 8/100\n",
      "1943/1943 [==============================] - 1s 334us/step - loss: 0.3268 - acc: 0.8662 - val_loss: 0.3424 - val_acc: 0.8580\n",
      "Epoch 9/100\n",
      "1943/1943 [==============================] - 1s 328us/step - loss: 0.3271 - acc: 0.8559 - val_loss: 0.3441 - val_acc: 0.8580\n",
      "Epoch 10/100\n",
      "1943/1943 [==============================] - 1s 329us/step - loss: 0.3112 - acc: 0.8698 - val_loss: 0.3304 - val_acc: 0.8663\n",
      "Epoch 11/100\n",
      "1943/1943 [==============================] - 1s 338us/step - loss: 0.3101 - acc: 0.8693 - val_loss: 0.3293 - val_acc: 0.8663\n",
      "Epoch 12/100\n",
      "1943/1943 [==============================] - 1s 322us/step - loss: 0.2999 - acc: 0.8796 - val_loss: 0.3274 - val_acc: 0.8683\n",
      "Epoch 13/100\n",
      "1943/1943 [==============================] - 1s 321us/step - loss: 0.3007 - acc: 0.8724 - val_loss: 0.3166 - val_acc: 0.8724\n",
      "Epoch 14/100\n",
      "1943/1943 [==============================] - 1s 321us/step - loss: 0.2866 - acc: 0.8811 - val_loss: 0.3035 - val_acc: 0.8724\n",
      "Epoch 15/100\n",
      "1943/1943 [==============================] - 1s 324us/step - loss: 0.2869 - acc: 0.8749 - val_loss: 0.3014 - val_acc: 0.8724\n",
      "Epoch 16/100\n",
      "1943/1943 [==============================] - 1s 318us/step - loss: 0.2855 - acc: 0.8816 - val_loss: 0.2996 - val_acc: 0.8765\n",
      "Epoch 17/100\n",
      "1943/1943 [==============================] - 1s 324us/step - loss: 0.2775 - acc: 0.8806 - val_loss: 0.2961 - val_acc: 0.8724\n",
      "Epoch 18/100\n",
      "1943/1943 [==============================] - 1s 325us/step - loss: 0.2846 - acc: 0.8780 - val_loss: 0.2896 - val_acc: 0.8765\n",
      "Epoch 19/100\n",
      "1943/1943 [==============================] - 1s 324us/step - loss: 0.2699 - acc: 0.8857 - val_loss: 0.2970 - val_acc: 0.8745\n",
      "Epoch 20/100\n",
      "1943/1943 [==============================] - 1s 327us/step - loss: 0.2667 - acc: 0.8935 - val_loss: 0.2862 - val_acc: 0.8807\n",
      "Epoch 21/100\n",
      "1943/1943 [==============================] - 1s 320us/step - loss: 0.2649 - acc: 0.8868 - val_loss: 0.2739 - val_acc: 0.8807\n",
      "Epoch 22/100\n",
      "1943/1943 [==============================] - 1s 328us/step - loss: 0.2636 - acc: 0.8852 - val_loss: 0.2769 - val_acc: 0.8848\n",
      "Epoch 23/100\n",
      "1943/1943 [==============================] - 1s 329us/step - loss: 0.2531 - acc: 0.8966 - val_loss: 0.2860 - val_acc: 0.8868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "1943/1943 [==============================] - 1s 325us/step - loss: 0.2502 - acc: 0.8955 - val_loss: 0.2775 - val_acc: 0.8868\n",
      "Epoch 25/100\n",
      "1943/1943 [==============================] - 1s 326us/step - loss: 0.2551 - acc: 0.8929 - val_loss: 0.2660 - val_acc: 0.8909\n",
      "Epoch 26/100\n",
      "1943/1943 [==============================] - 1s 328us/step - loss: 0.2552 - acc: 0.8888 - val_loss: 0.2608 - val_acc: 0.8930\n",
      "Epoch 27/100\n",
      "1943/1943 [==============================] - 1s 327us/step - loss: 0.2566 - acc: 0.8919 - val_loss: 0.2635 - val_acc: 0.8971\n",
      "Epoch 28/100\n",
      "1943/1943 [==============================] - 1s 327us/step - loss: 0.2507 - acc: 0.8966 - val_loss: 0.2618 - val_acc: 0.8951\n",
      "Epoch 29/100\n",
      "1943/1943 [==============================] - 1s 329us/step - loss: 0.2449 - acc: 0.9002 - val_loss: 0.2605 - val_acc: 0.8951\n",
      "Epoch 30/100\n",
      "1943/1943 [==============================] - 1s 326us/step - loss: 0.2481 - acc: 0.8976 - val_loss: 0.2502 - val_acc: 0.9053\n",
      "Epoch 31/100\n",
      "1943/1943 [==============================] - 1s 324us/step - loss: 0.2408 - acc: 0.9032 - val_loss: 0.2507 - val_acc: 0.9012\n",
      "Epoch 32/100\n",
      "1943/1943 [==============================] - 1s 327us/step - loss: 0.2317 - acc: 0.9089 - val_loss: 0.2493 - val_acc: 0.9053\n",
      "Epoch 33/100\n",
      "1943/1943 [==============================] - 1s 321us/step - loss: 0.2330 - acc: 0.9094 - val_loss: 0.2517 - val_acc: 0.8992\n",
      "Epoch 34/100\n",
      "1943/1943 [==============================] - 1s 327us/step - loss: 0.2366 - acc: 0.9032 - val_loss: 0.2572 - val_acc: 0.8951\n",
      "Epoch 35/100\n",
      "1943/1943 [==============================] - 1s 327us/step - loss: 0.2310 - acc: 0.9074 - val_loss: 0.2425 - val_acc: 0.9095\n",
      "Epoch 36/100\n",
      "1943/1943 [==============================] - 1s 323us/step - loss: 0.2289 - acc: 0.9048 - val_loss: 0.2525 - val_acc: 0.8992\n",
      "Epoch 37/100\n",
      "1943/1943 [==============================] - 1s 328us/step - loss: 0.2247 - acc: 0.9089 - val_loss: 0.2545 - val_acc: 0.8971\n",
      "Epoch 38/100\n",
      "1943/1943 [==============================] - 1s 329us/step - loss: 0.2256 - acc: 0.9141 - val_loss: 0.2389 - val_acc: 0.9053\n",
      "Epoch 39/100\n",
      "1943/1943 [==============================] - 1s 327us/step - loss: 0.2342 - acc: 0.9084 - val_loss: 0.2441 - val_acc: 0.9033\n",
      "Epoch 40/100\n",
      "1943/1943 [==============================] - 1s 320us/step - loss: 0.2244 - acc: 0.9099 - val_loss: 0.2381 - val_acc: 0.9115\n",
      "Epoch 41/100\n",
      "1943/1943 [==============================] - 1s 324us/step - loss: 0.2207 - acc: 0.9161 - val_loss: 0.2481 - val_acc: 0.8992\n",
      "Epoch 42/100\n",
      "1943/1943 [==============================] - 1s 328us/step - loss: 0.2288 - acc: 0.9079 - val_loss: 0.2441 - val_acc: 0.9033\n",
      "Epoch 43/100\n",
      "1943/1943 [==============================] - 1s 326us/step - loss: 0.2191 - acc: 0.9161 - val_loss: 0.2421 - val_acc: 0.9053\n",
      "Epoch 44/100\n",
      "1943/1943 [==============================] - 1s 322us/step - loss: 0.2149 - acc: 0.9115 - val_loss: 0.2319 - val_acc: 0.9136\n",
      "Epoch 45/100\n",
      "1943/1943 [==============================] - 1s 326us/step - loss: 0.2201 - acc: 0.9089 - val_loss: 0.2336 - val_acc: 0.9115\n",
      "Epoch 46/100\n",
      "1943/1943 [==============================] - 1s 326us/step - loss: 0.2156 - acc: 0.9146 - val_loss: 0.2331 - val_acc: 0.9115\n",
      "Epoch 47/100\n",
      "1943/1943 [==============================] - 1s 323us/step - loss: 0.2127 - acc: 0.9161 - val_loss: 0.2358 - val_acc: 0.9095\n",
      "Epoch 48/100\n",
      "1943/1943 [==============================] - 1s 323us/step - loss: 0.2099 - acc: 0.9187 - val_loss: 0.2315 - val_acc: 0.9115\n",
      "Epoch 49/100\n",
      "1943/1943 [==============================] - 1s 329us/step - loss: 0.2153 - acc: 0.9171 - val_loss: 0.2266 - val_acc: 0.9136\n",
      "Epoch 50/100\n",
      "1943/1943 [==============================] - 1s 319us/step - loss: 0.2039 - acc: 0.9187 - val_loss: 0.2213 - val_acc: 0.9156\n",
      "Epoch 51/100\n",
      "1943/1943 [==============================] - 1s 326us/step - loss: 0.2175 - acc: 0.9120 - val_loss: 0.2259 - val_acc: 0.9136\n",
      "Epoch 52/100\n",
      "1943/1943 [==============================] - 1s 330us/step - loss: 0.2085 - acc: 0.9177 - val_loss: 0.2241 - val_acc: 0.9136\n",
      "Epoch 53/100\n",
      "1943/1943 [==============================] - 1s 326us/step - loss: 0.2029 - acc: 0.9218 - val_loss: 0.2327 - val_acc: 0.9074\n",
      "Epoch 54/100\n",
      "1943/1943 [==============================] - 1s 321us/step - loss: 0.2115 - acc: 0.9192 - val_loss: 0.2302 - val_acc: 0.9095\n",
      "Epoch 55/100\n",
      "1943/1943 [==============================] - 1s 325us/step - loss: 0.2036 - acc: 0.9213 - val_loss: 0.2263 - val_acc: 0.9136\n",
      "Epoch 56/100\n",
      "1943/1943 [==============================] - 1s 329us/step - loss: 0.1999 - acc: 0.9223 - val_loss: 0.2223 - val_acc: 0.9177\n",
      "Epoch 57/100\n",
      "1943/1943 [==============================] - 1s 327us/step - loss: 0.2060 - acc: 0.9223 - val_loss: 0.2138 - val_acc: 0.9198\n",
      "Epoch 58/100\n",
      "1943/1943 [==============================] - 1s 325us/step - loss: 0.1992 - acc: 0.9228 - val_loss: 0.2246 - val_acc: 0.9115\n",
      "Epoch 59/100\n",
      "1943/1943 [==============================] - 1s 326us/step - loss: 0.2044 - acc: 0.9161 - val_loss: 0.2198 - val_acc: 0.9156\n",
      "Epoch 60/100\n",
      "1943/1943 [==============================] - 1s 325us/step - loss: 0.2092 - acc: 0.9233 - val_loss: 0.2185 - val_acc: 0.9156\n",
      "Epoch 61/100\n",
      "1943/1943 [==============================] - 1s 328us/step - loss: 0.1975 - acc: 0.9249 - val_loss: 0.2229 - val_acc: 0.9115\n",
      "Epoch 62/100\n",
      "1943/1943 [==============================] - 1s 325us/step - loss: 0.2057 - acc: 0.9177 - val_loss: 0.2127 - val_acc: 0.9218\n",
      "Epoch 63/100\n",
      "1943/1943 [==============================] - 1s 326us/step - loss: 0.1945 - acc: 0.9295 - val_loss: 0.2156 - val_acc: 0.9177\n",
      "Epoch 64/100\n",
      "1943/1943 [==============================] - 1s 327us/step - loss: 0.1994 - acc: 0.9233 - val_loss: 0.2107 - val_acc: 0.9239\n",
      "Epoch 65/100\n",
      "1943/1943 [==============================] - 1s 325us/step - loss: 0.1997 - acc: 0.9202 - val_loss: 0.2104 - val_acc: 0.9218\n",
      "Epoch 66/100\n",
      "1943/1943 [==============================] - 1s 326us/step - loss: 0.1914 - acc: 0.9254 - val_loss: 0.2061 - val_acc: 0.9239\n",
      "Epoch 67/100\n",
      "1943/1943 [==============================] - 1s 323us/step - loss: 0.1992 - acc: 0.9223 - val_loss: 0.2129 - val_acc: 0.9177\n",
      "Epoch 68/100\n",
      "1943/1943 [==============================] - 1s 321us/step - loss: 0.1889 - acc: 0.9233 - val_loss: 0.2215 - val_acc: 0.9115\n",
      "Epoch 69/100\n",
      "1943/1943 [==============================] - 1s 328us/step - loss: 0.1896 - acc: 0.9290 - val_loss: 0.2092 - val_acc: 0.9198\n",
      "Epoch 70/100\n",
      "1943/1943 [==============================] - 1s 326us/step - loss: 0.1923 - acc: 0.9207 - val_loss: 0.2068 - val_acc: 0.9239\n",
      "Epoch 71/100\n",
      "1943/1943 [==============================] - 1s 329us/step - loss: 0.1897 - acc: 0.9295 - val_loss: 0.2058 - val_acc: 0.9239\n",
      "Epoch 72/100\n",
      "1943/1943 [==============================] - 1s 329us/step - loss: 0.1910 - acc: 0.9223 - val_loss: 0.2042 - val_acc: 0.9239\n",
      "Epoch 73/100\n",
      "1943/1943 [==============================] - 1s 356us/step - loss: 0.1932 - acc: 0.9259 - val_loss: 0.2096 - val_acc: 0.9177\n",
      "Epoch 74/100\n",
      "1943/1943 [==============================] - 1s 402us/step - loss: 0.1888 - acc: 0.9269 - val_loss: 0.2093 - val_acc: 0.9177\n",
      "Epoch 75/100\n",
      "1943/1943 [==============================] - 1s 357us/step - loss: 0.1894 - acc: 0.9274 - val_loss: 0.2020 - val_acc: 0.9239\n",
      "Epoch 76/100\n",
      "1943/1943 [==============================] - 1s 359us/step - loss: 0.1863 - acc: 0.9279 - val_loss: 0.1991 - val_acc: 0.9259\n",
      "Epoch 77/100\n",
      "1943/1943 [==============================] - 1s 346us/step - loss: 0.1866 - acc: 0.9295 - val_loss: 0.2028 - val_acc: 0.9280\n",
      "Epoch 78/100\n",
      "1943/1943 [==============================] - 1s 335us/step - loss: 0.1890 - acc: 0.9279 - val_loss: 0.2084 - val_acc: 0.9218\n",
      "Epoch 79/100\n",
      "1943/1943 [==============================] - 1s 323us/step - loss: 0.1935 - acc: 0.9285 - val_loss: 0.2043 - val_acc: 0.9259\n",
      "Epoch 80/100\n",
      "1943/1943 [==============================] - 1s 325us/step - loss: 0.1835 - acc: 0.9352 - val_loss: 0.2074 - val_acc: 0.9239\n",
      "Epoch 81/100\n",
      "1943/1943 [==============================] - 1s 326us/step - loss: 0.1891 - acc: 0.9310 - val_loss: 0.2090 - val_acc: 0.9198\n",
      "Epoch 82/100\n",
      "1943/1943 [==============================] - 1s 329us/step - loss: 0.1926 - acc: 0.9315 - val_loss: 0.2041 - val_acc: 0.9239\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1943/1943 [==============================] - 1s 330us/step - loss: 0.1782 - acc: 0.9310 - val_loss: 0.2077 - val_acc: 0.9177\n",
      "Epoch 84/100\n",
      "1943/1943 [==============================] - 1s 323us/step - loss: 0.1758 - acc: 0.9305 - val_loss: 0.2036 - val_acc: 0.9239\n",
      "Epoch 85/100\n",
      "1943/1943 [==============================] - 1s 318us/step - loss: 0.1769 - acc: 0.9352 - val_loss: 0.2020 - val_acc: 0.9259\n",
      "Epoch 86/100\n",
      "1943/1943 [==============================] - 1s 324us/step - loss: 0.1790 - acc: 0.9341 - val_loss: 0.2002 - val_acc: 0.9239\n",
      "Epoch 87/100\n",
      "1943/1943 [==============================] - 1s 326us/step - loss: 0.1796 - acc: 0.9336 - val_loss: 0.1954 - val_acc: 0.9300\n",
      "Epoch 88/100\n",
      "1943/1943 [==============================] - 1s 330us/step - loss: 0.1758 - acc: 0.9315 - val_loss: 0.1948 - val_acc: 0.9321\n",
      "Epoch 89/100\n",
      "1943/1943 [==============================] - 1s 320us/step - loss: 0.1804 - acc: 0.9357 - val_loss: 0.2146 - val_acc: 0.9156\n",
      "Epoch 90/100\n",
      "1943/1943 [==============================] - 1s 320us/step - loss: 0.1805 - acc: 0.9321 - val_loss: 0.2090 - val_acc: 0.9198\n",
      "Epoch 91/100\n",
      "1943/1943 [==============================] - 1s 322us/step - loss: 0.1777 - acc: 0.9300 - val_loss: 0.1944 - val_acc: 0.9321\n",
      "Epoch 92/100\n",
      "1943/1943 [==============================] - 1s 320us/step - loss: 0.1755 - acc: 0.9315 - val_loss: 0.1956 - val_acc: 0.9280\n",
      "Epoch 93/100\n",
      "1943/1943 [==============================] - 1s 329us/step - loss: 0.1721 - acc: 0.9310 - val_loss: 0.1931 - val_acc: 0.9321\n",
      "Epoch 94/100\n",
      "1943/1943 [==============================] - 1s 321us/step - loss: 0.1731 - acc: 0.9331 - val_loss: 0.1968 - val_acc: 0.9280\n",
      "Epoch 95/100\n",
      "1943/1943 [==============================] - 1s 319us/step - loss: 0.1819 - acc: 0.9315 - val_loss: 0.2011 - val_acc: 0.9259\n",
      "Epoch 96/100\n",
      "1943/1943 [==============================] - 1s 324us/step - loss: 0.1816 - acc: 0.9388 - val_loss: 0.1967 - val_acc: 0.9300\n",
      "Epoch 97/100\n",
      "1943/1943 [==============================] - 1s 324us/step - loss: 0.1746 - acc: 0.9382 - val_loss: 0.1918 - val_acc: 0.9362\n",
      "Epoch 98/100\n",
      "1943/1943 [==============================] - 1s 328us/step - loss: 0.1699 - acc: 0.9393 - val_loss: 0.1970 - val_acc: 0.9280\n",
      "Epoch 99/100\n",
      "1943/1943 [==============================] - 1s 322us/step - loss: 0.1680 - acc: 0.9372 - val_loss: 0.1998 - val_acc: 0.9259\n",
      "Epoch 100/100\n",
      "1943/1943 [==============================] - 1s 331us/step - loss: 0.1753 - acc: 0.9377 - val_loss: 0.1938 - val_acc: 0.9300\n",
      "Train on 1943 samples, validate on 486 samples\n",
      "Epoch 1/100\n",
      "1943/1943 [==============================] - 1s 331us/step - loss: 0.1839 - acc: 0.9326 - val_loss: 0.1642 - val_acc: 0.9486\n",
      "Epoch 2/100\n",
      "1943/1943 [==============================] - 1s 323us/step - loss: 0.1896 - acc: 0.9326 - val_loss: 0.1611 - val_acc: 0.9527\n",
      "Epoch 3/100\n",
      "1943/1943 [==============================] - 1s 322us/step - loss: 0.1881 - acc: 0.9285 - val_loss: 0.1712 - val_acc: 0.9342\n",
      "Epoch 4/100\n",
      "1943/1943 [==============================] - 1s 319us/step - loss: 0.1844 - acc: 0.9321 - val_loss: 0.1681 - val_acc: 0.9383\n",
      "Epoch 5/100\n",
      "1943/1943 [==============================] - 1s 324us/step - loss: 0.1760 - acc: 0.9372 - val_loss: 0.1650 - val_acc: 0.9465\n",
      "Epoch 6/100\n",
      "1943/1943 [==============================] - 1s 321us/step - loss: 0.1767 - acc: 0.9331 - val_loss: 0.1641 - val_acc: 0.9444\n",
      "Epoch 7/100\n",
      "1943/1943 [==============================] - 1s 322us/step - loss: 0.1745 - acc: 0.9388 - val_loss: 0.1719 - val_acc: 0.9321\n",
      "Epoch 8/100\n",
      "1943/1943 [==============================] - 1s 321us/step - loss: 0.1778 - acc: 0.9285 - val_loss: 0.1666 - val_acc: 0.9403\n",
      "Epoch 9/100\n",
      "1943/1943 [==============================] - 1s 323us/step - loss: 0.1732 - acc: 0.9367 - val_loss: 0.1657 - val_acc: 0.9424\n",
      "Epoch 10/100\n",
      "1943/1943 [==============================] - 1s 325us/step - loss: 0.1778 - acc: 0.9346 - val_loss: 0.1667 - val_acc: 0.9383\n",
      "Epoch 11/100\n",
      "1943/1943 [==============================] - 1s 320us/step - loss: 0.1684 - acc: 0.9418 - val_loss: 0.1682 - val_acc: 0.9383\n",
      "Epoch 12/100\n",
      "1943/1943 [==============================] - 1s 321us/step - loss: 0.1737 - acc: 0.9372 - val_loss: 0.1670 - val_acc: 0.9383\n",
      "Epoch 13/100\n",
      "1943/1943 [==============================] - 1s 326us/step - loss: 0.1780 - acc: 0.9341 - val_loss: 0.1669 - val_acc: 0.9403\n",
      "Epoch 14/100\n",
      "1943/1943 [==============================] - 1s 322us/step - loss: 0.1689 - acc: 0.9372 - val_loss: 0.1630 - val_acc: 0.9465\n",
      "Epoch 15/100\n",
      "1943/1943 [==============================] - 1s 329us/step - loss: 0.1772 - acc: 0.9367 - val_loss: 0.1663 - val_acc: 0.9403\n",
      "Epoch 16/100\n",
      "1943/1943 [==============================] - 1s 323us/step - loss: 0.1741 - acc: 0.9367 - val_loss: 0.1663 - val_acc: 0.9403\n",
      "Epoch 17/100\n",
      "1943/1943 [==============================] - 1s 320us/step - loss: 0.1683 - acc: 0.9372 - val_loss: 0.1683 - val_acc: 0.9383\n",
      "Epoch 18/100\n",
      "1943/1943 [==============================] - 1s 320us/step - loss: 0.1615 - acc: 0.9403 - val_loss: 0.1655 - val_acc: 0.9403\n",
      "Epoch 19/100\n",
      "1943/1943 [==============================] - 1s 323us/step - loss: 0.1779 - acc: 0.9305 - val_loss: 0.1629 - val_acc: 0.9424\n",
      "Epoch 20/100\n",
      "1943/1943 [==============================] - 1s 329us/step - loss: 0.1694 - acc: 0.9382 - val_loss: 0.1672 - val_acc: 0.9403\n",
      "Epoch 21/100\n",
      "1943/1943 [==============================] - 1s 324us/step - loss: 0.1632 - acc: 0.9424 - val_loss: 0.1631 - val_acc: 0.9424\n",
      "Epoch 22/100\n",
      "1943/1943 [==============================] - 1s 359us/step - loss: 0.1662 - acc: 0.9403 - val_loss: 0.1631 - val_acc: 0.9444\n",
      "Epoch 23/100\n",
      "1943/1943 [==============================] - 1s 346us/step - loss: 0.1695 - acc: 0.9418 - val_loss: 0.1644 - val_acc: 0.9444\n",
      "Epoch 24/100\n",
      "1943/1943 [==============================] - 1s 336us/step - loss: 0.1660 - acc: 0.9367 - val_loss: 0.1610 - val_acc: 0.9465\n",
      "Epoch 25/100\n",
      "1943/1943 [==============================] - 1s 321us/step - loss: 0.1635 - acc: 0.9398 - val_loss: 0.1623 - val_acc: 0.9465\n",
      "Epoch 26/100\n",
      "1943/1943 [==============================] - 1s 325us/step - loss: 0.1652 - acc: 0.9377 - val_loss: 0.1599 - val_acc: 0.9465\n",
      "Epoch 27/100\n",
      "1943/1943 [==============================] - 1s 334us/step - loss: 0.1590 - acc: 0.9424 - val_loss: 0.1595 - val_acc: 0.9465\n",
      "Epoch 28/100\n",
      "1943/1943 [==============================] - 1s 331us/step - loss: 0.1618 - acc: 0.9439 - val_loss: 0.1648 - val_acc: 0.9403\n",
      "Epoch 29/100\n",
      "1943/1943 [==============================] - 1s 327us/step - loss: 0.1654 - acc: 0.9413 - val_loss: 0.1611 - val_acc: 0.9444\n",
      "Epoch 30/100\n",
      "1943/1943 [==============================] - 1s 322us/step - loss: 0.1645 - acc: 0.9429 - val_loss: 0.1598 - val_acc: 0.9465\n",
      "Epoch 31/100\n",
      "1943/1943 [==============================] - 1s 325us/step - loss: 0.1565 - acc: 0.9490 - val_loss: 0.1613 - val_acc: 0.9444\n",
      "Epoch 32/100\n",
      "1943/1943 [==============================] - 1s 325us/step - loss: 0.1567 - acc: 0.9434 - val_loss: 0.1632 - val_acc: 0.9424\n",
      "Epoch 33/100\n",
      "1943/1943 [==============================] - 1s 318us/step - loss: 0.1655 - acc: 0.9424 - val_loss: 0.1584 - val_acc: 0.9486\n",
      "Epoch 34/100\n",
      "1943/1943 [==============================] - 1s 327us/step - loss: 0.1622 - acc: 0.9408 - val_loss: 0.1621 - val_acc: 0.9444\n",
      "Epoch 35/100\n",
      "1943/1943 [==============================] - 1s 329us/step - loss: 0.1559 - acc: 0.9424 - val_loss: 0.1601 - val_acc: 0.9444\n",
      "Epoch 36/100\n",
      "1943/1943 [==============================] - 1s 334us/step - loss: 0.1640 - acc: 0.9424 - val_loss: 0.1639 - val_acc: 0.9444\n",
      "Epoch 37/100\n",
      "1943/1943 [==============================] - 1s 323us/step - loss: 0.1599 - acc: 0.9418 - val_loss: 0.1650 - val_acc: 0.9424\n",
      "Epoch 38/100\n",
      "1943/1943 [==============================] - 1s 317us/step - loss: 0.1615 - acc: 0.9418 - val_loss: 0.1605 - val_acc: 0.9444\n",
      "Epoch 39/100\n",
      "1943/1943 [==============================] - 1s 326us/step - loss: 0.1554 - acc: 0.9449 - val_loss: 0.1617 - val_acc: 0.9403\n",
      "Epoch 40/100\n",
      "1943/1943 [==============================] - 1s 322us/step - loss: 0.1598 - acc: 0.9403 - val_loss: 0.1592 - val_acc: 0.9444\n",
      "Epoch 41/100\n",
      "1943/1943 [==============================] - 1s 322us/step - loss: 0.1527 - acc: 0.9506 - val_loss: 0.1627 - val_acc: 0.9403\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1943/1943 [==============================] - 1s 326us/step - loss: 0.1571 - acc: 0.9460 - val_loss: 0.1588 - val_acc: 0.9424\n",
      "Epoch 43/100\n",
      "1943/1943 [==============================] - 1s 319us/step - loss: 0.1604 - acc: 0.9388 - val_loss: 0.1593 - val_acc: 0.9444\n",
      "Epoch 44/100\n",
      "1943/1943 [==============================] - 1s 322us/step - loss: 0.1525 - acc: 0.9449 - val_loss: 0.1573 - val_acc: 0.9486\n",
      "Epoch 45/100\n",
      "1943/1943 [==============================] - 1s 325us/step - loss: 0.1597 - acc: 0.9418 - val_loss: 0.1614 - val_acc: 0.9383\n",
      "Epoch 46/100\n",
      "1943/1943 [==============================] - 1s 321us/step - loss: 0.1621 - acc: 0.9434 - val_loss: 0.1604 - val_acc: 0.9403\n",
      "Epoch 47/100\n",
      "1943/1943 [==============================] - 1s 324us/step - loss: 0.1533 - acc: 0.9470 - val_loss: 0.1626 - val_acc: 0.9383\n",
      "Epoch 48/100\n",
      "1943/1943 [==============================] - 1s 319us/step - loss: 0.1500 - acc: 0.9470 - val_loss: 0.1576 - val_acc: 0.9444\n",
      "Epoch 49/100\n",
      "1943/1943 [==============================] - 1s 316us/step - loss: 0.1594 - acc: 0.9434 - val_loss: 0.1556 - val_acc: 0.9506\n",
      "Epoch 50/100\n",
      "1943/1943 [==============================] - 1s 324us/step - loss: 0.1535 - acc: 0.9460 - val_loss: 0.1554 - val_acc: 0.9506\n",
      "Epoch 51/100\n",
      "1943/1943 [==============================] - 1s 326us/step - loss: 0.1470 - acc: 0.9454 - val_loss: 0.1558 - val_acc: 0.9465\n",
      "Epoch 52/100\n",
      "1943/1943 [==============================] - 1s 323us/step - loss: 0.1511 - acc: 0.9485 - val_loss: 0.1560 - val_acc: 0.9486\n",
      "Epoch 53/100\n",
      "1943/1943 [==============================] - 1s 324us/step - loss: 0.1504 - acc: 0.9475 - val_loss: 0.1583 - val_acc: 0.9424\n",
      "Epoch 54/100\n",
      "1943/1943 [==============================] - 1s 320us/step - loss: 0.1488 - acc: 0.9485 - val_loss: 0.1563 - val_acc: 0.9444\n",
      "Epoch 55/100\n",
      "1943/1943 [==============================] - 1s 320us/step - loss: 0.1470 - acc: 0.9490 - val_loss: 0.1550 - val_acc: 0.9465\n",
      "Epoch 56/100\n",
      "1943/1943 [==============================] - 1s 322us/step - loss: 0.1523 - acc: 0.9444 - val_loss: 0.1545 - val_acc: 0.9465\n",
      "Epoch 57/100\n",
      "1943/1943 [==============================] - 1s 322us/step - loss: 0.1516 - acc: 0.9454 - val_loss: 0.1543 - val_acc: 0.9444\n",
      "Epoch 58/100\n",
      "1943/1943 [==============================] - 1s 322us/step - loss: 0.1561 - acc: 0.9454 - val_loss: 0.1536 - val_acc: 0.9506\n",
      "Epoch 59/100\n",
      "1943/1943 [==============================] - 1s 324us/step - loss: 0.1477 - acc: 0.9465 - val_loss: 0.1539 - val_acc: 0.9444\n",
      "Epoch 60/100\n",
      "1943/1943 [==============================] - 1s 324us/step - loss: 0.1536 - acc: 0.9475 - val_loss: 0.1548 - val_acc: 0.9444\n",
      "Epoch 61/100\n",
      "1943/1943 [==============================] - 1s 324us/step - loss: 0.1508 - acc: 0.9465 - val_loss: 0.1541 - val_acc: 0.9444\n",
      "Epoch 62/100\n",
      "1943/1943 [==============================] - 1s 322us/step - loss: 0.1461 - acc: 0.9475 - val_loss: 0.1563 - val_acc: 0.9403\n",
      "Epoch 63/100\n",
      "1943/1943 [==============================] - 1s 322us/step - loss: 0.1430 - acc: 0.9490 - val_loss: 0.1547 - val_acc: 0.9444\n",
      "Epoch 64/100\n",
      "1943/1943 [==============================] - 1s 319us/step - loss: 0.1439 - acc: 0.9496 - val_loss: 0.1564 - val_acc: 0.9424\n",
      "Epoch 65/100\n",
      "1943/1943 [==============================] - 1s 328us/step - loss: 0.1431 - acc: 0.9557 - val_loss: 0.1512 - val_acc: 0.9444\n",
      "Epoch 66/100\n",
      "1943/1943 [==============================] - 1s 327us/step - loss: 0.1500 - acc: 0.9465 - val_loss: 0.1506 - val_acc: 0.9444\n",
      "Epoch 67/100\n",
      "1943/1943 [==============================] - 1s 325us/step - loss: 0.1454 - acc: 0.9501 - val_loss: 0.1504 - val_acc: 0.9444\n",
      "Epoch 68/100\n",
      "1943/1943 [==============================] - 1s 319us/step - loss: 0.1474 - acc: 0.9470 - val_loss: 0.1517 - val_acc: 0.9444\n",
      "Epoch 69/100\n",
      "1943/1943 [==============================] - 1s 324us/step - loss: 0.1353 - acc: 0.9521 - val_loss: 0.1524 - val_acc: 0.9424\n",
      "Epoch 70/100\n",
      "1943/1943 [==============================] - 1s 320us/step - loss: 0.1475 - acc: 0.9485 - val_loss: 0.1528 - val_acc: 0.9444\n",
      "Epoch 71/100\n",
      "1943/1943 [==============================] - 1s 327us/step - loss: 0.1420 - acc: 0.9521 - val_loss: 0.1515 - val_acc: 0.9444\n",
      "Epoch 72/100\n",
      "1943/1943 [==============================] - 1s 323us/step - loss: 0.1419 - acc: 0.9490 - val_loss: 0.1508 - val_acc: 0.9444\n",
      "Epoch 73/100\n",
      "1943/1943 [==============================] - 1s 321us/step - loss: 0.1413 - acc: 0.9511 - val_loss: 0.1528 - val_acc: 0.9444\n",
      "Epoch 74/100\n",
      "1943/1943 [==============================] - 1s 317us/step - loss: 0.1441 - acc: 0.9506 - val_loss: 0.1480 - val_acc: 0.9486\n",
      "Epoch 75/100\n",
      "1943/1943 [==============================] - 1s 322us/step - loss: 0.1456 - acc: 0.9490 - val_loss: 0.1509 - val_acc: 0.9444\n",
      "Epoch 76/100\n",
      "1943/1943 [==============================] - 1s 335us/step - loss: 0.1428 - acc: 0.9532 - val_loss: 0.1549 - val_acc: 0.9444\n",
      "Epoch 77/100\n",
      "1943/1943 [==============================] - 1s 341us/step - loss: 0.1488 - acc: 0.9480 - val_loss: 0.1570 - val_acc: 0.9424\n",
      "Epoch 78/100\n",
      "1943/1943 [==============================] - 1s 350us/step - loss: 0.1363 - acc: 0.9527 - val_loss: 0.1489 - val_acc: 0.9486\n",
      "Epoch 79/100\n",
      "1943/1943 [==============================] - 1s 334us/step - loss: 0.1459 - acc: 0.9480 - val_loss: 0.1477 - val_acc: 0.9465\n",
      "Epoch 80/100\n",
      "1943/1943 [==============================] - 1s 333us/step - loss: 0.1431 - acc: 0.9485 - val_loss: 0.1479 - val_acc: 0.9486\n",
      "Epoch 81/100\n",
      "1943/1943 [==============================] - 1s 331us/step - loss: 0.1423 - acc: 0.9516 - val_loss: 0.1532 - val_acc: 0.9444\n",
      "Epoch 82/100\n",
      "1943/1943 [==============================] - 1s 323us/step - loss: 0.1411 - acc: 0.9506 - val_loss: 0.1517 - val_acc: 0.9444\n",
      "Epoch 83/100\n",
      "1943/1943 [==============================] - 1s 338us/step - loss: 0.1398 - acc: 0.9470 - val_loss: 0.1528 - val_acc: 0.9465\n",
      "Epoch 84/100\n",
      "1943/1943 [==============================] - 1s 364us/step - loss: 0.1429 - acc: 0.9475 - val_loss: 0.1521 - val_acc: 0.9465\n",
      "Epoch 85/100\n",
      "1943/1943 [==============================] - 1s 369us/step - loss: 0.1433 - acc: 0.9475 - val_loss: 0.1498 - val_acc: 0.9465\n",
      "Epoch 86/100\n",
      "1943/1943 [==============================] - 1s 346us/step - loss: 0.1468 - acc: 0.9496 - val_loss: 0.1517 - val_acc: 0.9465\n",
      "Epoch 87/100\n",
      "1943/1943 [==============================] - 1s 347us/step - loss: 0.1365 - acc: 0.9521 - val_loss: 0.1499 - val_acc: 0.9465\n",
      "Epoch 88/100\n",
      "1943/1943 [==============================] - 1s 335us/step - loss: 0.1375 - acc: 0.9521 - val_loss: 0.1499 - val_acc: 0.9465\n",
      "Epoch 89/100\n",
      "1943/1943 [==============================] - 1s 324us/step - loss: 0.1356 - acc: 0.9521 - val_loss: 0.1492 - val_acc: 0.9465\n",
      "Epoch 90/100\n",
      "1943/1943 [==============================] - 1s 324us/step - loss: 0.1406 - acc: 0.9537 - val_loss: 0.1509 - val_acc: 0.9465\n",
      "Epoch 91/100\n",
      "1943/1943 [==============================] - 1s 345us/step - loss: 0.1339 - acc: 0.9557 - val_loss: 0.1504 - val_acc: 0.9465\n",
      "Epoch 92/100\n",
      "1943/1943 [==============================] - 1s 331us/step - loss: 0.1384 - acc: 0.9501 - val_loss: 0.1509 - val_acc: 0.9465\n",
      "Epoch 93/100\n",
      "1943/1943 [==============================] - 1s 328us/step - loss: 0.1385 - acc: 0.9490 - val_loss: 0.1512 - val_acc: 0.9465\n",
      "Epoch 94/100\n",
      "1943/1943 [==============================] - 1s 326us/step - loss: 0.1373 - acc: 0.9547 - val_loss: 0.1515 - val_acc: 0.9465\n",
      "Epoch 95/100\n",
      "1943/1943 [==============================] - 1s 336us/step - loss: 0.1370 - acc: 0.9496 - val_loss: 0.1472 - val_acc: 0.9486\n",
      "Epoch 96/100\n",
      "1943/1943 [==============================] - 1s 324us/step - loss: 0.1330 - acc: 0.9532 - val_loss: 0.1521 - val_acc: 0.9465\n",
      "Epoch 97/100\n",
      "1943/1943 [==============================] - 1s 323us/step - loss: 0.1354 - acc: 0.9552 - val_loss: 0.1467 - val_acc: 0.9506\n",
      "Epoch 98/100\n",
      "1943/1943 [==============================] - 1s 333us/step - loss: 0.1290 - acc: 0.9547 - val_loss: 0.1480 - val_acc: 0.9465\n",
      "Epoch 99/100\n",
      "1943/1943 [==============================] - 1s 330us/step - loss: 0.1375 - acc: 0.9542 - val_loss: 0.1476 - val_acc: 0.9465\n",
      "Epoch 100/100\n",
      "1943/1943 [==============================] - 1s 333us/step - loss: 0.1376 - acc: 0.9578 - val_loss: 0.1499 - val_acc: 0.9465\n",
      "Test subject 10, class Replace\n",
      "Train subject 10, class BothReleased\n",
      "Train on 1944 samples, validate on 486 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.5854 - acc: 0.7665 - val_loss: 0.5898 - val_acc: 0.7654\n",
      "Epoch 2/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.4726 - acc: 0.7984 - val_loss: 0.5374 - val_acc: 0.7757\n",
      "Epoch 3/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.4295 - acc: 0.8153 - val_loss: 0.4986 - val_acc: 0.7984\n",
      "Epoch 4/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.3762 - acc: 0.8416 - val_loss: 0.4615 - val_acc: 0.8004\n",
      "Epoch 5/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.3636 - acc: 0.8426 - val_loss: 0.4544 - val_acc: 0.8045\n",
      "Epoch 6/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.3535 - acc: 0.8560 - val_loss: 0.4532 - val_acc: 0.8148\n",
      "Epoch 7/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.3388 - acc: 0.8529 - val_loss: 0.4247 - val_acc: 0.8210\n",
      "Epoch 8/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.3241 - acc: 0.8678 - val_loss: 0.4454 - val_acc: 0.8107\n",
      "Epoch 9/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.3085 - acc: 0.8771 - val_loss: 0.4178 - val_acc: 0.8333\n",
      "Epoch 10/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.3058 - acc: 0.8745 - val_loss: 0.4146 - val_acc: 0.8416\n",
      "Epoch 11/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.2968 - acc: 0.8812 - val_loss: 0.4211 - val_acc: 0.8313\n",
      "Epoch 12/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.2852 - acc: 0.8868 - val_loss: 0.4214 - val_acc: 0.8272\n",
      "Epoch 13/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.2989 - acc: 0.8812 - val_loss: 0.3982 - val_acc: 0.8498\n",
      "Epoch 14/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.2814 - acc: 0.8879 - val_loss: 0.3978 - val_acc: 0.8560\n",
      "Epoch 15/100\n",
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.2754 - acc: 0.8930 - val_loss: 0.4031 - val_acc: 0.8539\n",
      "Epoch 16/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.2700 - acc: 0.8971 - val_loss: 0.3875 - val_acc: 0.8580\n",
      "Epoch 17/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.2755 - acc: 0.8956 - val_loss: 0.4017 - val_acc: 0.8580\n",
      "Epoch 18/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.2653 - acc: 0.9017 - val_loss: 0.3929 - val_acc: 0.8539\n",
      "Epoch 19/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.2577 - acc: 0.9002 - val_loss: 0.3768 - val_acc: 0.8580\n",
      "Epoch 20/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.2503 - acc: 0.9043 - val_loss: 0.3864 - val_acc: 0.8560\n",
      "Epoch 21/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.2603 - acc: 0.9033 - val_loss: 0.3736 - val_acc: 0.8601\n",
      "Epoch 22/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.2592 - acc: 0.8935 - val_loss: 0.3769 - val_acc: 0.8621\n",
      "Epoch 23/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.2520 - acc: 0.9028 - val_loss: 0.3758 - val_acc: 0.8621\n",
      "Epoch 24/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.2506 - acc: 0.9048 - val_loss: 0.3822 - val_acc: 0.8580\n",
      "Epoch 25/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.2450 - acc: 0.9069 - val_loss: 0.3640 - val_acc: 0.8621\n",
      "Epoch 26/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.2395 - acc: 0.9120 - val_loss: 0.3601 - val_acc: 0.8642\n",
      "Epoch 27/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.2413 - acc: 0.9141 - val_loss: 0.3644 - val_acc: 0.8642\n",
      "Epoch 28/100\n",
      "1944/1944 [==============================] - ETA: 0s - loss: 0.2345 - acc: 0.906 - 1s 323us/step - loss: 0.2343 - acc: 0.9064 - val_loss: 0.3785 - val_acc: 0.8621\n",
      "Epoch 29/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.2361 - acc: 0.9136 - val_loss: 0.3620 - val_acc: 0.8621\n",
      "Epoch 30/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.2429 - acc: 0.9115 - val_loss: 0.3679 - val_acc: 0.8642\n",
      "Epoch 31/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.2340 - acc: 0.9167 - val_loss: 0.3557 - val_acc: 0.8663\n",
      "Epoch 32/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.2371 - acc: 0.9090 - val_loss: 0.3624 - val_acc: 0.8642\n",
      "Epoch 33/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.2297 - acc: 0.9126 - val_loss: 0.3614 - val_acc: 0.8663\n",
      "Epoch 34/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.2359 - acc: 0.9079 - val_loss: 0.3470 - val_acc: 0.8683\n",
      "Epoch 35/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.2293 - acc: 0.9146 - val_loss: 0.3570 - val_acc: 0.8642\n",
      "Epoch 36/100\n",
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.2320 - acc: 0.9100 - val_loss: 0.3613 - val_acc: 0.8642\n",
      "Epoch 37/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.2226 - acc: 0.9162 - val_loss: 0.3484 - val_acc: 0.8683\n",
      "Epoch 38/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.2297 - acc: 0.9141 - val_loss: 0.3571 - val_acc: 0.8683\n",
      "Epoch 39/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.2208 - acc: 0.9192 - val_loss: 0.3464 - val_acc: 0.8683\n",
      "Epoch 40/100\n",
      "1944/1944 [==============================] - 1s 337us/step - loss: 0.2258 - acc: 0.9192 - val_loss: 0.3516 - val_acc: 0.8704\n",
      "Epoch 41/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.2229 - acc: 0.9213 - val_loss: 0.3570 - val_acc: 0.8683\n",
      "Epoch 42/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.2221 - acc: 0.9203 - val_loss: 0.3466 - val_acc: 0.8683\n",
      "Epoch 43/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.2215 - acc: 0.9203 - val_loss: 0.3432 - val_acc: 0.8704\n",
      "Epoch 44/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.2104 - acc: 0.9244 - val_loss: 0.3385 - val_acc: 0.8745\n",
      "Epoch 45/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.2155 - acc: 0.9228 - val_loss: 0.3388 - val_acc: 0.8724\n",
      "Epoch 46/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.2046 - acc: 0.9234 - val_loss: 0.3416 - val_acc: 0.8724\n",
      "Epoch 47/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.2168 - acc: 0.9162 - val_loss: 0.3418 - val_acc: 0.8724\n",
      "Epoch 48/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.2126 - acc: 0.9213 - val_loss: 0.3412 - val_acc: 0.8724\n",
      "Epoch 49/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.2112 - acc: 0.9234 - val_loss: 0.3426 - val_acc: 0.8765\n",
      "Epoch 50/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.2048 - acc: 0.9239 - val_loss: 0.3356 - val_acc: 0.8765\n",
      "Epoch 51/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.2084 - acc: 0.9259 - val_loss: 0.3285 - val_acc: 0.8765\n",
      "Epoch 52/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.2070 - acc: 0.9280 - val_loss: 0.3341 - val_acc: 0.8765\n",
      "Epoch 53/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.2071 - acc: 0.9228 - val_loss: 0.3326 - val_acc: 0.8786\n",
      "Epoch 54/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.2070 - acc: 0.9254 - val_loss: 0.3259 - val_acc: 0.8807\n",
      "Epoch 55/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.1968 - acc: 0.9275 - val_loss: 0.3228 - val_acc: 0.8889\n",
      "Epoch 56/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.2035 - acc: 0.9259 - val_loss: 0.3278 - val_acc: 0.8786\n",
      "Epoch 57/100\n",
      "1944/1944 [==============================] - 1s 321us/step - loss: 0.2010 - acc: 0.9331 - val_loss: 0.3249 - val_acc: 0.8827\n",
      "Epoch 58/100\n",
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.1913 - acc: 0.9342 - val_loss: 0.3299 - val_acc: 0.8827\n",
      "Epoch 59/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.2010 - acc: 0.9295 - val_loss: 0.3367 - val_acc: 0.8765\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.1936 - acc: 0.9270 - val_loss: 0.3364 - val_acc: 0.8786\n",
      "Epoch 61/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1961 - acc: 0.9306 - val_loss: 0.3340 - val_acc: 0.8807\n",
      "Epoch 62/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1999 - acc: 0.9280 - val_loss: 0.3163 - val_acc: 0.8868\n",
      "Epoch 63/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.1930 - acc: 0.9290 - val_loss: 0.3229 - val_acc: 0.8889\n",
      "Epoch 64/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.1941 - acc: 0.9352 - val_loss: 0.3237 - val_acc: 0.8889\n",
      "Epoch 65/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1974 - acc: 0.9254 - val_loss: 0.3149 - val_acc: 0.8909\n",
      "Epoch 66/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.1894 - acc: 0.9295 - val_loss: 0.3233 - val_acc: 0.8889\n",
      "Epoch 67/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1858 - acc: 0.9352 - val_loss: 0.3181 - val_acc: 0.8889\n",
      "Epoch 68/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.1923 - acc: 0.9321 - val_loss: 0.3120 - val_acc: 0.8909\n",
      "Epoch 69/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.1804 - acc: 0.9347 - val_loss: 0.3174 - val_acc: 0.8930\n",
      "Epoch 70/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.1844 - acc: 0.9295 - val_loss: 0.3149 - val_acc: 0.8930\n",
      "Epoch 71/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.1859 - acc: 0.9388 - val_loss: 0.3175 - val_acc: 0.8930\n",
      "Epoch 72/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1859 - acc: 0.9331 - val_loss: 0.3185 - val_acc: 0.8930\n",
      "Epoch 73/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.1825 - acc: 0.9347 - val_loss: 0.3087 - val_acc: 0.8930\n",
      "Epoch 74/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.1817 - acc: 0.9347 - val_loss: 0.3162 - val_acc: 0.8909\n",
      "Epoch 75/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1882 - acc: 0.9342 - val_loss: 0.3020 - val_acc: 0.8951\n",
      "Epoch 76/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.1900 - acc: 0.9306 - val_loss: 0.3093 - val_acc: 0.8951\n",
      "Epoch 77/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1806 - acc: 0.9306 - val_loss: 0.3049 - val_acc: 0.8951\n",
      "Epoch 78/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.1834 - acc: 0.9362 - val_loss: 0.3053 - val_acc: 0.8951\n",
      "Epoch 79/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1850 - acc: 0.9316 - val_loss: 0.3041 - val_acc: 0.8951\n",
      "Epoch 80/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.1832 - acc: 0.9357 - val_loss: 0.2981 - val_acc: 0.8951\n",
      "Epoch 81/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.1753 - acc: 0.9352 - val_loss: 0.3095 - val_acc: 0.8951\n",
      "Epoch 82/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.1817 - acc: 0.9367 - val_loss: 0.3005 - val_acc: 0.8971\n",
      "Epoch 83/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.1757 - acc: 0.9393 - val_loss: 0.3030 - val_acc: 0.8992\n",
      "Epoch 84/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1738 - acc: 0.9367 - val_loss: 0.2968 - val_acc: 0.9033\n",
      "Epoch 85/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.1734 - acc: 0.9403 - val_loss: 0.2971 - val_acc: 0.9012\n",
      "Epoch 86/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.1779 - acc: 0.9372 - val_loss: 0.3009 - val_acc: 0.8992\n",
      "Epoch 87/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.1813 - acc: 0.9336 - val_loss: 0.3014 - val_acc: 0.9012\n",
      "Epoch 88/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.1677 - acc: 0.9444 - val_loss: 0.2960 - val_acc: 0.9012\n",
      "Epoch 89/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.1675 - acc: 0.9419 - val_loss: 0.2966 - val_acc: 0.8971\n",
      "Epoch 90/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.1831 - acc: 0.9347 - val_loss: 0.3057 - val_acc: 0.9012\n",
      "Epoch 91/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1679 - acc: 0.9408 - val_loss: 0.3076 - val_acc: 0.8992\n",
      "Epoch 92/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.1671 - acc: 0.9393 - val_loss: 0.2929 - val_acc: 0.9012\n",
      "Epoch 93/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1694 - acc: 0.9439 - val_loss: 0.3035 - val_acc: 0.9033\n",
      "Epoch 94/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1660 - acc: 0.9419 - val_loss: 0.2950 - val_acc: 0.8992\n",
      "Epoch 95/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.1673 - acc: 0.9378 - val_loss: 0.3029 - val_acc: 0.9033\n",
      "Epoch 96/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1695 - acc: 0.9403 - val_loss: 0.2969 - val_acc: 0.9033\n",
      "Epoch 97/100\n",
      "1944/1944 [==============================] - 1s 334us/step - loss: 0.1626 - acc: 0.9439 - val_loss: 0.2936 - val_acc: 0.9012\n",
      "Epoch 98/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.1730 - acc: 0.9378 - val_loss: 0.2927 - val_acc: 0.9033\n",
      "Epoch 99/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.1681 - acc: 0.9419 - val_loss: 0.2958 - val_acc: 0.9033\n",
      "Epoch 100/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.1650 - acc: 0.9367 - val_loss: 0.2929 - val_acc: 0.9053\n",
      "Train on 1944 samples, validate on 486 samples\n",
      "Epoch 1/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.2106 - acc: 0.9270 - val_loss: 0.2241 - val_acc: 0.9218\n",
      "Epoch 2/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.2080 - acc: 0.9259 - val_loss: 0.2166 - val_acc: 0.9218\n",
      "Epoch 3/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.2013 - acc: 0.9280 - val_loss: 0.2183 - val_acc: 0.9218\n",
      "Epoch 4/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.2038 - acc: 0.9249 - val_loss: 0.2210 - val_acc: 0.9239\n",
      "Epoch 5/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.2139 - acc: 0.9239 - val_loss: 0.2166 - val_acc: 0.9239\n",
      "Epoch 6/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.1918 - acc: 0.9347 - val_loss: 0.2168 - val_acc: 0.9239\n",
      "Epoch 7/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.1972 - acc: 0.9295 - val_loss: 0.2105 - val_acc: 0.9259\n",
      "Epoch 8/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.1971 - acc: 0.9342 - val_loss: 0.2090 - val_acc: 0.9280\n",
      "Epoch 9/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.1995 - acc: 0.9311 - val_loss: 0.2081 - val_acc: 0.9259\n",
      "Epoch 10/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.1966 - acc: 0.9316 - val_loss: 0.2114 - val_acc: 0.9239\n",
      "Epoch 11/100\n",
      "1944/1944 [==============================] - 1s 334us/step - loss: 0.1937 - acc: 0.9316 - val_loss: 0.2030 - val_acc: 0.9300\n",
      "Epoch 12/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.1859 - acc: 0.9357 - val_loss: 0.2095 - val_acc: 0.9300\n",
      "Epoch 13/100\n",
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.1925 - acc: 0.9321 - val_loss: 0.2087 - val_acc: 0.9300\n",
      "Epoch 14/100\n",
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.2001 - acc: 0.9285 - val_loss: 0.2119 - val_acc: 0.9280\n",
      "Epoch 15/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.2040 - acc: 0.9264 - val_loss: 0.2141 - val_acc: 0.9259\n",
      "Epoch 16/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.1940 - acc: 0.9290 - val_loss: 0.2043 - val_acc: 0.9321\n",
      "Epoch 17/100\n",
      "1944/1944 [==============================] - 1s 337us/step - loss: 0.1850 - acc: 0.9336 - val_loss: 0.2079 - val_acc: 0.9321\n",
      "Epoch 18/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1915 - acc: 0.9311 - val_loss: 0.2085 - val_acc: 0.9321\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.1811 - acc: 0.9316 - val_loss: 0.2068 - val_acc: 0.9342\n",
      "Epoch 20/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.1908 - acc: 0.9311 - val_loss: 0.2095 - val_acc: 0.9300\n",
      "Epoch 21/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.1885 - acc: 0.9331 - val_loss: 0.2062 - val_acc: 0.9300\n",
      "Epoch 22/100\n",
      "1944/1944 [==============================] - 1s 336us/step - loss: 0.1885 - acc: 0.9367 - val_loss: 0.2085 - val_acc: 0.9300\n",
      "Epoch 23/100\n",
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.1839 - acc: 0.9326 - val_loss: 0.2084 - val_acc: 0.9300\n",
      "Epoch 24/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.1868 - acc: 0.9342 - val_loss: 0.2055 - val_acc: 0.9321\n",
      "Epoch 25/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1882 - acc: 0.9300 - val_loss: 0.2073 - val_acc: 0.9300\n",
      "Epoch 26/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.1852 - acc: 0.9321 - val_loss: 0.2063 - val_acc: 0.9300\n",
      "Epoch 27/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1843 - acc: 0.9367 - val_loss: 0.2033 - val_acc: 0.9300\n",
      "Epoch 28/100\n",
      "1944/1944 [==============================] - 1s 334us/step - loss: 0.1827 - acc: 0.9372 - val_loss: 0.2015 - val_acc: 0.9342\n",
      "Epoch 29/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.1823 - acc: 0.9347 - val_loss: 0.2013 - val_acc: 0.9321\n",
      "Epoch 30/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.1805 - acc: 0.9367 - val_loss: 0.2072 - val_acc: 0.9280\n",
      "Epoch 31/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1772 - acc: 0.9383 - val_loss: 0.1970 - val_acc: 0.9342\n",
      "Epoch 32/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.1788 - acc: 0.9342 - val_loss: 0.1988 - val_acc: 0.9342\n",
      "Epoch 33/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1864 - acc: 0.9357 - val_loss: 0.1970 - val_acc: 0.9342\n",
      "Epoch 34/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.1791 - acc: 0.9367 - val_loss: 0.2024 - val_acc: 0.9300\n",
      "Epoch 35/100\n",
      "1944/1944 [==============================] - 1s 337us/step - loss: 0.1723 - acc: 0.9372 - val_loss: 0.1944 - val_acc: 0.9362\n",
      "Epoch 36/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.1822 - acc: 0.9347 - val_loss: 0.2023 - val_acc: 0.9280\n",
      "Epoch 37/100\n",
      "1944/1944 [==============================] - 1s 336us/step - loss: 0.1787 - acc: 0.9372 - val_loss: 0.1933 - val_acc: 0.9383\n",
      "Epoch 38/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1835 - acc: 0.9362 - val_loss: 0.1956 - val_acc: 0.9321\n",
      "Epoch 39/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.1779 - acc: 0.9393 - val_loss: 0.1997 - val_acc: 0.9300\n",
      "Epoch 40/100\n",
      "1944/1944 [==============================] - 1s 337us/step - loss: 0.1708 - acc: 0.9403 - val_loss: 0.1927 - val_acc: 0.9383\n",
      "Epoch 41/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.1803 - acc: 0.9372 - val_loss: 0.1935 - val_acc: 0.9342\n",
      "Epoch 42/100\n",
      "1944/1944 [==============================] - 1s 337us/step - loss: 0.1757 - acc: 0.9419 - val_loss: 0.1987 - val_acc: 0.9300\n",
      "Epoch 43/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.1667 - acc: 0.9424 - val_loss: 0.1942 - val_acc: 0.9342\n",
      "Epoch 44/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1706 - acc: 0.9408 - val_loss: 0.1920 - val_acc: 0.9362\n",
      "Epoch 45/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.1746 - acc: 0.9398 - val_loss: 0.1924 - val_acc: 0.9362\n",
      "Epoch 46/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.1689 - acc: 0.9419 - val_loss: 0.1919 - val_acc: 0.9362\n",
      "Epoch 47/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1691 - acc: 0.9367 - val_loss: 0.1890 - val_acc: 0.9403\n",
      "Epoch 48/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.1794 - acc: 0.9357 - val_loss: 0.1913 - val_acc: 0.9362\n",
      "Epoch 49/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.1762 - acc: 0.9347 - val_loss: 0.1965 - val_acc: 0.9300\n",
      "Epoch 50/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.1746 - acc: 0.9383 - val_loss: 0.1952 - val_acc: 0.9342\n",
      "Epoch 51/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.1643 - acc: 0.9419 - val_loss: 0.1918 - val_acc: 0.9383\n",
      "Epoch 52/100\n",
      "1944/1944 [==============================] - 1s 336us/step - loss: 0.1748 - acc: 0.9372 - val_loss: 0.1974 - val_acc: 0.9321\n",
      "Epoch 53/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1714 - acc: 0.9378 - val_loss: 0.1891 - val_acc: 0.9403\n",
      "Epoch 54/100\n",
      "1944/1944 [==============================] - 1s 334us/step - loss: 0.1771 - acc: 0.9378 - val_loss: 0.1957 - val_acc: 0.9342\n",
      "Epoch 55/100\n",
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.1668 - acc: 0.9419 - val_loss: 0.1854 - val_acc: 0.9424\n",
      "Epoch 56/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.1712 - acc: 0.9357 - val_loss: 0.1915 - val_acc: 0.9362\n",
      "Epoch 57/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.1696 - acc: 0.9383 - val_loss: 0.1893 - val_acc: 0.9403\n",
      "Epoch 58/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.1675 - acc: 0.9398 - val_loss: 0.1908 - val_acc: 0.9383\n",
      "Epoch 59/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1654 - acc: 0.9419 - val_loss: 0.1960 - val_acc: 0.9300\n",
      "Epoch 60/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1607 - acc: 0.9460 - val_loss: 0.1872 - val_acc: 0.9444\n",
      "Epoch 61/100\n",
      "1944/1944 [==============================] - 1s 321us/step - loss: 0.1663 - acc: 0.9419 - val_loss: 0.1890 - val_acc: 0.9383\n",
      "Epoch 62/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.1699 - acc: 0.9414 - val_loss: 0.1891 - val_acc: 0.9383\n",
      "Epoch 63/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.1668 - acc: 0.9429 - val_loss: 0.1895 - val_acc: 0.9383\n",
      "Epoch 64/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.1688 - acc: 0.9414 - val_loss: 0.1928 - val_acc: 0.9321\n",
      "Epoch 65/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1640 - acc: 0.9470 - val_loss: 0.1885 - val_acc: 0.9383\n",
      "Epoch 66/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.1706 - acc: 0.9429 - val_loss: 0.1872 - val_acc: 0.9383\n",
      "Epoch 67/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.1616 - acc: 0.9424 - val_loss: 0.1828 - val_acc: 0.9403\n",
      "Epoch 68/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1604 - acc: 0.9444 - val_loss: 0.1870 - val_acc: 0.9403\n",
      "Epoch 69/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1581 - acc: 0.9419 - val_loss: 0.1859 - val_acc: 0.9403\n",
      "Epoch 70/100\n",
      "1944/1944 [==============================] - 1s 334us/step - loss: 0.1594 - acc: 0.9465 - val_loss: 0.1842 - val_acc: 0.9424\n",
      "Epoch 71/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.1664 - acc: 0.9398 - val_loss: 0.1862 - val_acc: 0.9403\n",
      "Epoch 72/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1619 - acc: 0.9424 - val_loss: 0.1853 - val_acc: 0.9424\n",
      "Epoch 73/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1624 - acc: 0.9444 - val_loss: 0.1848 - val_acc: 0.9424\n",
      "Epoch 74/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.1637 - acc: 0.9414 - val_loss: 0.1886 - val_acc: 0.9403\n",
      "Epoch 75/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.1614 - acc: 0.9414 - val_loss: 0.1823 - val_acc: 0.9424\n",
      "Epoch 76/100\n",
      "1944/1944 [==============================] - 1s 336us/step - loss: 0.1636 - acc: 0.9455 - val_loss: 0.1830 - val_acc: 0.9424\n",
      "Epoch 77/100\n",
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.1608 - acc: 0.9424 - val_loss: 0.1894 - val_acc: 0.9403\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1583 - acc: 0.9419 - val_loss: 0.1902 - val_acc: 0.9362\n",
      "Epoch 79/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1599 - acc: 0.9450 - val_loss: 0.1888 - val_acc: 0.9383\n",
      "Epoch 80/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1580 - acc: 0.9455 - val_loss: 0.1870 - val_acc: 0.9383\n",
      "Epoch 81/100\n",
      "1944/1944 [==============================] - 1s 334us/step - loss: 0.1597 - acc: 0.9414 - val_loss: 0.1836 - val_acc: 0.9424\n",
      "Epoch 82/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1590 - acc: 0.9439 - val_loss: 0.1837 - val_acc: 0.9424\n",
      "Epoch 83/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1529 - acc: 0.9486 - val_loss: 0.1834 - val_acc: 0.9424\n",
      "Epoch 84/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.1510 - acc: 0.9475 - val_loss: 0.1843 - val_acc: 0.9444\n",
      "Epoch 85/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.1517 - acc: 0.9450 - val_loss: 0.1857 - val_acc: 0.9424\n",
      "Epoch 86/100\n",
      "1944/1944 [==============================] - ETA: 0s - loss: 0.1556 - acc: 0.944 - 1s 324us/step - loss: 0.1544 - acc: 0.9450 - val_loss: 0.1887 - val_acc: 0.9403\n",
      "Epoch 87/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.1583 - acc: 0.9460 - val_loss: 0.1849 - val_acc: 0.9424\n",
      "Epoch 88/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.1616 - acc: 0.9465 - val_loss: 0.1833 - val_acc: 0.9424\n",
      "Epoch 89/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.1515 - acc: 0.9439 - val_loss: 0.1826 - val_acc: 0.9424\n",
      "Epoch 90/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.1598 - acc: 0.9429 - val_loss: 0.1867 - val_acc: 0.9424\n",
      "Epoch 91/100\n",
      "1944/1944 [==============================] - 1s 345us/step - loss: 0.1486 - acc: 0.9506 - val_loss: 0.1807 - val_acc: 0.9444\n",
      "Epoch 92/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.1562 - acc: 0.9491 - val_loss: 0.1823 - val_acc: 0.9444\n",
      "Epoch 93/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.1572 - acc: 0.9419 - val_loss: 0.1901 - val_acc: 0.9362\n",
      "Epoch 94/100\n",
      "1944/1944 [==============================] - 1s 336us/step - loss: 0.1541 - acc: 0.9444 - val_loss: 0.1808 - val_acc: 0.9444\n",
      "Epoch 95/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.1514 - acc: 0.9501 - val_loss: 0.1874 - val_acc: 0.9403\n",
      "Epoch 96/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1502 - acc: 0.9465 - val_loss: 0.1856 - val_acc: 0.9424\n",
      "Epoch 97/100\n",
      "1944/1944 [==============================] - 1s 318us/step - loss: 0.1516 - acc: 0.9547 - val_loss: 0.1871 - val_acc: 0.9403\n",
      "Epoch 98/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1471 - acc: 0.9480 - val_loss: 0.1784 - val_acc: 0.9465\n",
      "Epoch 99/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1447 - acc: 0.9532 - val_loss: 0.1836 - val_acc: 0.9424\n",
      "Epoch 100/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1500 - acc: 0.9470 - val_loss: 0.1841 - val_acc: 0.9424\n",
      "Test subject 10, class BothReleased\n",
      "HandStart AUC score = 0.825\n",
      "FirstDigitTouch AUC score = 0.952\n",
      "BothStartLoadPhase AUC score = 0.952\n",
      "LiftOff AUC score = 0.930\n",
      "Replace AUC score = 0.871\n",
      "BothReleased AUC score = 0.879\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50195 50195\n",
      "Train subject 11, class HandStart\n",
      "Train on 1956 samples, validate on 489 samples\n",
      "Epoch 1/100\n",
      "1956/1956 [==============================] - 1s 435us/step - loss: 1.1368 - acc: 0.5138 - val_loss: 0.8226 - val_acc: 0.5174\n",
      "Epoch 2/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.7507 - acc: 0.5486 - val_loss: 0.7114 - val_acc: 0.5767\n",
      "Epoch 3/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.7071 - acc: 0.5588 - val_loss: 0.6866 - val_acc: 0.5808\n",
      "Epoch 4/100\n",
      "1956/1956 [==============================] - 1s 322us/step - loss: 0.6944 - acc: 0.5619 - val_loss: 0.6734 - val_acc: 0.5869\n",
      "Epoch 5/100\n",
      "1956/1956 [==============================] - 1s 318us/step - loss: 0.6857 - acc: 0.5624 - val_loss: 0.6647 - val_acc: 0.6053\n",
      "Epoch 6/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.6759 - acc: 0.5675 - val_loss: 0.6614 - val_acc: 0.6033\n",
      "Epoch 7/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.6567 - acc: 0.6022 - val_loss: 0.6590 - val_acc: 0.6053\n",
      "Epoch 8/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.6534 - acc: 0.6053 - val_loss: 0.6766 - val_acc: 0.5910\n",
      "Epoch 9/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.6517 - acc: 0.6161 - val_loss: 0.6568 - val_acc: 0.6155\n",
      "Epoch 10/100\n",
      "1956/1956 [==============================] - 1s 323us/step - loss: 0.6418 - acc: 0.6171 - val_loss: 0.6810 - val_acc: 0.5767\n",
      "Epoch 11/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.6415 - acc: 0.6273 - val_loss: 0.6534 - val_acc: 0.6176\n",
      "Epoch 12/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.6419 - acc: 0.6171 - val_loss: 0.6537 - val_acc: 0.6053\n",
      "Epoch 13/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.6334 - acc: 0.6293 - val_loss: 0.6388 - val_acc: 0.6360\n",
      "Epoch 14/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.6272 - acc: 0.6391 - val_loss: 0.6662 - val_acc: 0.5849\n",
      "Epoch 15/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.6241 - acc: 0.6442 - val_loss: 0.6478 - val_acc: 0.6135\n",
      "Epoch 16/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.6187 - acc: 0.6396 - val_loss: 0.6314 - val_acc: 0.6503\n",
      "Epoch 17/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.6246 - acc: 0.6365 - val_loss: 0.6363 - val_acc: 0.6401\n",
      "Epoch 18/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.6200 - acc: 0.6375 - val_loss: 0.6442 - val_acc: 0.6217\n",
      "Epoch 19/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.6074 - acc: 0.6610 - val_loss: 0.6357 - val_acc: 0.6237\n",
      "Epoch 20/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.5976 - acc: 0.6585 - val_loss: 0.6231 - val_acc: 0.6667\n",
      "Epoch 21/100\n",
      "1956/1956 [==============================] - 1s 335us/step - loss: 0.6046 - acc: 0.6549 - val_loss: 0.6138 - val_acc: 0.6605\n",
      "Epoch 22/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.5967 - acc: 0.6677 - val_loss: 0.6161 - val_acc: 0.6708\n",
      "Epoch 23/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.5937 - acc: 0.6713 - val_loss: 0.6226 - val_acc: 0.6626\n",
      "Epoch 24/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.5959 - acc: 0.6835 - val_loss: 0.6161 - val_acc: 0.6687\n",
      "Epoch 25/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.5880 - acc: 0.6779 - val_loss: 0.6235 - val_acc: 0.6483\n",
      "Epoch 26/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.5846 - acc: 0.6856 - val_loss: 0.6136 - val_acc: 0.6646\n",
      "Epoch 27/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.5780 - acc: 0.6881 - val_loss: 0.6198 - val_acc: 0.6421\n",
      "Epoch 28/100\n",
      "1956/1956 [==============================] - 1s 324us/step - loss: 0.5792 - acc: 0.6825 - val_loss: 0.6156 - val_acc: 0.6667\n",
      "Epoch 29/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.5843 - acc: 0.6892 - val_loss: 0.6459 - val_acc: 0.6217\n",
      "Epoch 30/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.5788 - acc: 0.6922 - val_loss: 0.6169 - val_acc: 0.6687\n",
      "Epoch 31/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.5720 - acc: 0.6897 - val_loss: 0.6193 - val_acc: 0.6605\n",
      "Epoch 32/100\n",
      "1956/1956 [==============================] - 1s 322us/step - loss: 0.5711 - acc: 0.6968 - val_loss: 0.5962 - val_acc: 0.6830\n",
      "Epoch 33/100\n",
      "1956/1956 [==============================] - 1s 337us/step - loss: 0.5614 - acc: 0.7045 - val_loss: 0.6158 - val_acc: 0.6605\n",
      "Epoch 34/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.5560 - acc: 0.7065 - val_loss: 0.6102 - val_acc: 0.6585\n",
      "Epoch 35/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.5559 - acc: 0.7142 - val_loss: 0.5884 - val_acc: 0.6994\n",
      "Epoch 36/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.5560 - acc: 0.7060 - val_loss: 0.6248 - val_acc: 0.6503\n",
      "Epoch 37/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.5520 - acc: 0.7101 - val_loss: 0.5923 - val_acc: 0.6789\n",
      "Epoch 38/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.5530 - acc: 0.7137 - val_loss: 0.6293 - val_acc: 0.6421\n",
      "Epoch 39/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.5574 - acc: 0.7014 - val_loss: 0.5753 - val_acc: 0.7096\n",
      "Epoch 40/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.5455 - acc: 0.7219 - val_loss: 0.6192 - val_acc: 0.6646\n",
      "Epoch 41/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.5401 - acc: 0.7270 - val_loss: 0.5776 - val_acc: 0.7055\n",
      "Epoch 42/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.5388 - acc: 0.7219 - val_loss: 0.5804 - val_acc: 0.6953\n",
      "Epoch 43/100\n",
      "1956/1956 [==============================] - 1s 335us/step - loss: 0.5340 - acc: 0.7260 - val_loss: 0.5871 - val_acc: 0.6810\n",
      "Epoch 44/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.5315 - acc: 0.7249 - val_loss: 0.5689 - val_acc: 0.7055\n",
      "Epoch 45/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.5317 - acc: 0.7342 - val_loss: 0.5948 - val_acc: 0.6667\n",
      "Epoch 46/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.5281 - acc: 0.7260 - val_loss: 0.5948 - val_acc: 0.6667\n",
      "Epoch 47/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.5217 - acc: 0.7321 - val_loss: 0.5745 - val_acc: 0.6973\n",
      "Epoch 48/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.5163 - acc: 0.7377 - val_loss: 0.5891 - val_acc: 0.6810\n",
      "Epoch 49/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.5225 - acc: 0.7301 - val_loss: 0.6279 - val_acc: 0.6544\n",
      "Epoch 50/100\n",
      "1956/1956 [==============================] - 1s 339us/step - loss: 0.5247 - acc: 0.7388 - val_loss: 0.5640 - val_acc: 0.6912\n",
      "Epoch 51/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.5139 - acc: 0.7423 - val_loss: 0.5651 - val_acc: 0.6912\n",
      "Epoch 52/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.5210 - acc: 0.7418 - val_loss: 0.5788 - val_acc: 0.6830\n",
      "Epoch 53/100\n",
      "1956/1956 [==============================] - 1s 336us/step - loss: 0.5048 - acc: 0.7536 - val_loss: 0.5609 - val_acc: 0.7076\n",
      "Epoch 54/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.5097 - acc: 0.7485 - val_loss: 0.5939 - val_acc: 0.6892\n",
      "Epoch 55/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.4987 - acc: 0.7495 - val_loss: 0.5588 - val_acc: 0.7137\n",
      "Epoch 56/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.5080 - acc: 0.7495 - val_loss: 0.5597 - val_acc: 0.7076\n",
      "Epoch 57/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.4979 - acc: 0.7648 - val_loss: 0.5707 - val_acc: 0.6994\n",
      "Epoch 58/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.4964 - acc: 0.7480 - val_loss: 0.5812 - val_acc: 0.6953\n",
      "Epoch 59/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.4947 - acc: 0.7587 - val_loss: 0.5546 - val_acc: 0.7055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.4903 - acc: 0.7623 - val_loss: 0.5529 - val_acc: 0.7117\n",
      "Epoch 61/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.4919 - acc: 0.7669 - val_loss: 0.5418 - val_acc: 0.7178\n",
      "Epoch 62/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.4925 - acc: 0.7423 - val_loss: 0.6174 - val_acc: 0.6748\n",
      "Epoch 63/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.4861 - acc: 0.7648 - val_loss: 0.5488 - val_acc: 0.7157\n",
      "Epoch 64/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.4749 - acc: 0.7720 - val_loss: 0.5828 - val_acc: 0.6851\n",
      "Epoch 65/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.4791 - acc: 0.7618 - val_loss: 0.5621 - val_acc: 0.7035\n",
      "Epoch 66/100\n",
      "1956/1956 [==============================] - 1s 335us/step - loss: 0.4660 - acc: 0.7827 - val_loss: 0.5436 - val_acc: 0.7239\n",
      "Epoch 67/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.4652 - acc: 0.7812 - val_loss: 0.5345 - val_acc: 0.7342\n",
      "Epoch 68/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.4695 - acc: 0.7797 - val_loss: 0.5330 - val_acc: 0.7403\n",
      "Epoch 69/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.4660 - acc: 0.7822 - val_loss: 0.5434 - val_acc: 0.7239\n",
      "Epoch 70/100\n",
      "1956/1956 [==============================] - 1s 336us/step - loss: 0.4671 - acc: 0.7807 - val_loss: 0.5258 - val_acc: 0.7444\n",
      "Epoch 71/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.4556 - acc: 0.7781 - val_loss: 0.5461 - val_acc: 0.7301\n",
      "Epoch 72/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.4569 - acc: 0.7863 - val_loss: 0.5265 - val_acc: 0.7464\n",
      "Epoch 73/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.4667 - acc: 0.7745 - val_loss: 0.5290 - val_acc: 0.7505\n",
      "Epoch 74/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.4568 - acc: 0.7771 - val_loss: 0.5227 - val_acc: 0.7464\n",
      "Epoch 75/100\n",
      "1956/1956 [==============================] - 1s 335us/step - loss: 0.4570 - acc: 0.7883 - val_loss: 0.5323 - val_acc: 0.7423\n",
      "Epoch 76/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.4485 - acc: 0.7863 - val_loss: 0.5529 - val_acc: 0.7198\n",
      "Epoch 77/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.4596 - acc: 0.7822 - val_loss: 0.5418 - val_acc: 0.7260\n",
      "Epoch 78/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.4468 - acc: 0.8011 - val_loss: 0.5370 - val_acc: 0.7362\n",
      "Epoch 79/100\n",
      "1956/1956 [==============================] - 1s 324us/step - loss: 0.4446 - acc: 0.7935 - val_loss: 0.5108 - val_acc: 0.7566\n",
      "Epoch 80/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.4431 - acc: 0.7883 - val_loss: 0.5563 - val_acc: 0.7239\n",
      "Epoch 81/100\n",
      "1956/1956 [==============================] - 1s 324us/step - loss: 0.4437 - acc: 0.7919 - val_loss: 0.5306 - val_acc: 0.7423\n",
      "Epoch 82/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.4466 - acc: 0.7904 - val_loss: 0.5201 - val_acc: 0.7546\n",
      "Epoch 83/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.4516 - acc: 0.7848 - val_loss: 0.5130 - val_acc: 0.7526\n",
      "Epoch 84/100\n",
      "1956/1956 [==============================] - 1s 323us/step - loss: 0.4406 - acc: 0.7991 - val_loss: 0.5295 - val_acc: 0.7382\n",
      "Epoch 85/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.4363 - acc: 0.7955 - val_loss: 0.5045 - val_acc: 0.7710\n",
      "Epoch 86/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.4357 - acc: 0.7975 - val_loss: 0.5166 - val_acc: 0.7566\n",
      "Epoch 87/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.4201 - acc: 0.8098 - val_loss: 0.5118 - val_acc: 0.7505\n",
      "Epoch 88/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.4206 - acc: 0.8144 - val_loss: 0.5159 - val_acc: 0.7607\n",
      "Epoch 89/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.4268 - acc: 0.8175 - val_loss: 0.5258 - val_acc: 0.7444\n",
      "Epoch 90/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.4362 - acc: 0.7991 - val_loss: 0.5165 - val_acc: 0.7505\n",
      "Epoch 91/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.4286 - acc: 0.8006 - val_loss: 0.5104 - val_acc: 0.7628\n",
      "Epoch 92/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.4152 - acc: 0.8057 - val_loss: 0.5115 - val_acc: 0.7607\n",
      "Epoch 93/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.4221 - acc: 0.8083 - val_loss: 0.4922 - val_acc: 0.7873\n",
      "Epoch 94/100\n",
      "1956/1956 [==============================] - 1s 337us/step - loss: 0.4207 - acc: 0.8113 - val_loss: 0.5103 - val_acc: 0.7648\n",
      "Epoch 95/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.4107 - acc: 0.8083 - val_loss: 0.5275 - val_acc: 0.7382\n",
      "Epoch 96/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.4204 - acc: 0.8083 - val_loss: 0.5290 - val_acc: 0.7423\n",
      "Epoch 97/100\n",
      "1956/1956 [==============================] - 1s 336us/step - loss: 0.4226 - acc: 0.8047 - val_loss: 0.5167 - val_acc: 0.7485\n",
      "Epoch 98/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.4159 - acc: 0.8139 - val_loss: 0.4964 - val_acc: 0.7751\n",
      "Epoch 99/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.4116 - acc: 0.8129 - val_loss: 0.5139 - val_acc: 0.7546\n",
      "Epoch 100/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.4048 - acc: 0.8200 - val_loss: 0.4876 - val_acc: 0.7751\n",
      "Train on 1956 samples, validate on 489 samples\n",
      "Epoch 1/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.4898 - acc: 0.7643 - val_loss: 0.5071 - val_acc: 0.7730\n",
      "Epoch 2/100\n",
      "1956/1956 [==============================] - 1s 324us/step - loss: 0.4716 - acc: 0.7889 - val_loss: 0.4940 - val_acc: 0.7669\n",
      "Epoch 3/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.4527 - acc: 0.7883 - val_loss: 0.5168 - val_acc: 0.7689\n",
      "Epoch 4/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.4631 - acc: 0.7878 - val_loss: 0.4712 - val_acc: 0.7873\n",
      "Epoch 5/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.4483 - acc: 0.7960 - val_loss: 0.4975 - val_acc: 0.7771\n",
      "Epoch 6/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.4450 - acc: 0.7904 - val_loss: 0.4758 - val_acc: 0.7894\n",
      "Epoch 7/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.4493 - acc: 0.7919 - val_loss: 0.5053 - val_acc: 0.7587\n",
      "Epoch 8/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.4435 - acc: 0.8001 - val_loss: 0.5047 - val_acc: 0.7628\n",
      "Epoch 9/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.4466 - acc: 0.7924 - val_loss: 0.5120 - val_acc: 0.7628\n",
      "Epoch 10/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.4388 - acc: 0.7955 - val_loss: 0.4510 - val_acc: 0.7935\n",
      "Epoch 11/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.4269 - acc: 0.8088 - val_loss: 0.4600 - val_acc: 0.7894\n",
      "Epoch 12/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.4379 - acc: 0.7965 - val_loss: 0.4429 - val_acc: 0.7853\n",
      "Epoch 13/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.4304 - acc: 0.8047 - val_loss: 0.4571 - val_acc: 0.7873\n",
      "Epoch 14/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.4291 - acc: 0.8037 - val_loss: 0.4505 - val_acc: 0.7914\n",
      "Epoch 15/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.4361 - acc: 0.8027 - val_loss: 0.4486 - val_acc: 0.7853\n",
      "Epoch 16/100\n",
      "1956/1956 [==============================] - 1s 323us/step - loss: 0.4337 - acc: 0.8124 - val_loss: 0.4596 - val_acc: 0.7935\n",
      "Epoch 17/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.4169 - acc: 0.8124 - val_loss: 0.4495 - val_acc: 0.7894\n",
      "Epoch 18/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.4206 - acc: 0.8154 - val_loss: 0.4650 - val_acc: 0.7914\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.4224 - acc: 0.8083 - val_loss: 0.4566 - val_acc: 0.7894\n",
      "Epoch 20/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.4129 - acc: 0.8149 - val_loss: 0.5386 - val_acc: 0.7526\n",
      "Epoch 21/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.4143 - acc: 0.8124 - val_loss: 0.4333 - val_acc: 0.8057\n",
      "Epoch 22/100\n",
      "1956/1956 [==============================] - 1s 337us/step - loss: 0.4104 - acc: 0.8236 - val_loss: 0.4213 - val_acc: 0.8119\n",
      "Epoch 23/100\n",
      "1956/1956 [==============================] - 1s 348us/step - loss: 0.4106 - acc: 0.8144 - val_loss: 0.4581 - val_acc: 0.7873\n",
      "Epoch 24/100\n",
      "1956/1956 [==============================] - 1s 335us/step - loss: 0.4136 - acc: 0.8144 - val_loss: 0.4263 - val_acc: 0.8139\n",
      "Epoch 25/100\n",
      "1956/1956 [==============================] - 1s 337us/step - loss: 0.4105 - acc: 0.8185 - val_loss: 0.4502 - val_acc: 0.7914\n",
      "Epoch 26/100\n",
      "1956/1956 [==============================] - 1s 347us/step - loss: 0.4056 - acc: 0.8236 - val_loss: 0.4139 - val_acc: 0.8160\n",
      "Epoch 27/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.4018 - acc: 0.8175 - val_loss: 0.4774 - val_acc: 0.7791\n",
      "Epoch 28/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.4121 - acc: 0.8252 - val_loss: 0.4747 - val_acc: 0.7791\n",
      "Epoch 29/100\n",
      "1956/1956 [==============================] - 1s 347us/step - loss: 0.4053 - acc: 0.8236 - val_loss: 0.4387 - val_acc: 0.7996\n",
      "Epoch 30/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.3989 - acc: 0.8185 - val_loss: 0.4317 - val_acc: 0.8139\n",
      "Epoch 31/100\n",
      "1956/1956 [==============================] - 1s 323us/step - loss: 0.4010 - acc: 0.8221 - val_loss: 0.4271 - val_acc: 0.7791\n",
      "Epoch 32/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.4028 - acc: 0.8221 - val_loss: 0.4237 - val_acc: 0.8098\n",
      "Epoch 33/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.3892 - acc: 0.8257 - val_loss: 0.4059 - val_acc: 0.8200\n",
      "Epoch 34/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.3850 - acc: 0.8359 - val_loss: 0.4172 - val_acc: 0.8057\n",
      "Epoch 35/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.3868 - acc: 0.8308 - val_loss: 0.4361 - val_acc: 0.8016\n",
      "Epoch 36/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.3894 - acc: 0.8354 - val_loss: 0.4165 - val_acc: 0.8139\n",
      "Epoch 37/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.3799 - acc: 0.8410 - val_loss: 0.4517 - val_acc: 0.7935\n",
      "Epoch 38/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.3754 - acc: 0.8374 - val_loss: 0.4252 - val_acc: 0.8119\n",
      "Epoch 39/100\n",
      "1956/1956 [==============================] - 1s 321us/step - loss: 0.3870 - acc: 0.8369 - val_loss: 0.4092 - val_acc: 0.8160\n",
      "Epoch 40/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.3761 - acc: 0.8328 - val_loss: 0.3994 - val_acc: 0.8282\n",
      "Epoch 41/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.3691 - acc: 0.8405 - val_loss: 0.4460 - val_acc: 0.7975\n",
      "Epoch 42/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.3744 - acc: 0.8436 - val_loss: 0.4160 - val_acc: 0.8160\n",
      "Epoch 43/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.3809 - acc: 0.8354 - val_loss: 0.4266 - val_acc: 0.8139\n",
      "Epoch 44/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.3808 - acc: 0.8369 - val_loss: 0.4036 - val_acc: 0.8241\n",
      "Epoch 45/100\n",
      "1956/1956 [==============================] - 1s 338us/step - loss: 0.3801 - acc: 0.8333 - val_loss: 0.4022 - val_acc: 0.8282\n",
      "Epoch 46/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.3667 - acc: 0.8492 - val_loss: 0.4063 - val_acc: 0.8282\n",
      "Epoch 47/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.3680 - acc: 0.8492 - val_loss: 0.4109 - val_acc: 0.8303\n",
      "Epoch 48/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.3703 - acc: 0.8415 - val_loss: 0.4185 - val_acc: 0.7812\n",
      "Epoch 49/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.3729 - acc: 0.8461 - val_loss: 0.4519 - val_acc: 0.7894\n",
      "Epoch 50/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.3768 - acc: 0.8400 - val_loss: 0.3998 - val_acc: 0.8384\n",
      "Epoch 51/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.3797 - acc: 0.8384 - val_loss: 0.3961 - val_acc: 0.8344\n",
      "Epoch 52/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.3667 - acc: 0.8384 - val_loss: 0.4214 - val_acc: 0.8078\n",
      "Epoch 53/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.3621 - acc: 0.8436 - val_loss: 0.4275 - val_acc: 0.8098\n",
      "Epoch 54/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.3602 - acc: 0.8522 - val_loss: 0.4041 - val_acc: 0.8323\n",
      "Epoch 55/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.3580 - acc: 0.8482 - val_loss: 0.4178 - val_acc: 0.8241\n",
      "Epoch 56/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.3565 - acc: 0.8579 - val_loss: 0.4087 - val_acc: 0.8241\n",
      "Epoch 57/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.3521 - acc: 0.8609 - val_loss: 0.4112 - val_acc: 0.8200\n",
      "Epoch 58/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.3570 - acc: 0.8543 - val_loss: 0.4377 - val_acc: 0.7955\n",
      "Epoch 59/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.3631 - acc: 0.8507 - val_loss: 0.4003 - val_acc: 0.8323\n",
      "Epoch 60/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.3580 - acc: 0.8584 - val_loss: 0.4445 - val_acc: 0.8057\n",
      "Epoch 61/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.3527 - acc: 0.8528 - val_loss: 0.3978 - val_acc: 0.8200\n",
      "Epoch 62/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.3485 - acc: 0.8528 - val_loss: 0.4074 - val_acc: 0.8221\n",
      "Epoch 63/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.3438 - acc: 0.8722 - val_loss: 0.4026 - val_acc: 0.8282\n",
      "Epoch 64/100\n",
      "1956/1956 [==============================] - 1s 335us/step - loss: 0.3597 - acc: 0.8492 - val_loss: 0.4362 - val_acc: 0.8016\n",
      "Epoch 65/100\n",
      "1956/1956 [==============================] - 1s 335us/step - loss: 0.3489 - acc: 0.8589 - val_loss: 0.3887 - val_acc: 0.8323\n",
      "Epoch 66/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.3524 - acc: 0.8441 - val_loss: 0.3741 - val_acc: 0.8609\n",
      "Epoch 67/100\n",
      "1956/1956 [==============================] - 1s 336us/step - loss: 0.3436 - acc: 0.8640 - val_loss: 0.4111 - val_acc: 0.8241\n",
      "Epoch 68/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.3419 - acc: 0.8645 - val_loss: 0.4484 - val_acc: 0.7914\n",
      "Epoch 69/100\n",
      "1956/1956 [==============================] - 1s 337us/step - loss: 0.3457 - acc: 0.8620 - val_loss: 0.3857 - val_acc: 0.8466\n",
      "Epoch 70/100\n",
      "1956/1956 [==============================] - 1s 337us/step - loss: 0.3332 - acc: 0.8676 - val_loss: 0.4352 - val_acc: 0.8037\n",
      "Epoch 71/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.3401 - acc: 0.8579 - val_loss: 0.4635 - val_acc: 0.7853\n",
      "Epoch 72/100\n",
      "1956/1956 [==============================] - 1s 337us/step - loss: 0.3477 - acc: 0.8666 - val_loss: 0.4318 - val_acc: 0.8016\n",
      "Epoch 73/100\n",
      "1956/1956 [==============================] - 1s 324us/step - loss: 0.3358 - acc: 0.8620 - val_loss: 0.3905 - val_acc: 0.8344\n",
      "Epoch 74/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.3409 - acc: 0.8717 - val_loss: 0.3919 - val_acc: 0.8323\n",
      "Epoch 75/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.3279 - acc: 0.8686 - val_loss: 0.3811 - val_acc: 0.8528\n",
      "Epoch 76/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.3339 - acc: 0.8666 - val_loss: 0.4558 - val_acc: 0.7894\n",
      "Epoch 77/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.3342 - acc: 0.8676 - val_loss: 0.4201 - val_acc: 0.8139\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.3413 - acc: 0.8563 - val_loss: 0.3993 - val_acc: 0.8344\n",
      "Epoch 79/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.3329 - acc: 0.8691 - val_loss: 0.3807 - val_acc: 0.8466\n",
      "Epoch 80/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.3318 - acc: 0.8696 - val_loss: 0.4048 - val_acc: 0.8303\n",
      "Epoch 81/100\n",
      "1956/1956 [==============================] - 1s 342us/step - loss: 0.3379 - acc: 0.8635 - val_loss: 0.3838 - val_acc: 0.8405\n",
      "Epoch 82/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.3296 - acc: 0.8778 - val_loss: 0.4006 - val_acc: 0.8241\n",
      "Epoch 83/100\n",
      "1956/1956 [==============================] - 1s 338us/step - loss: 0.3252 - acc: 0.8691 - val_loss: 0.3555 - val_acc: 0.8569\n",
      "Epoch 84/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.3197 - acc: 0.8686 - val_loss: 0.4180 - val_acc: 0.8180\n",
      "Epoch 85/100\n",
      "1956/1956 [==============================] - 1s 339us/step - loss: 0.3340 - acc: 0.8676 - val_loss: 0.4386 - val_acc: 0.8057\n",
      "Epoch 86/100\n",
      "1956/1956 [==============================] - 1s 346us/step - loss: 0.3246 - acc: 0.8768 - val_loss: 0.3725 - val_acc: 0.8507\n",
      "Epoch 87/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.3231 - acc: 0.8742 - val_loss: 0.3669 - val_acc: 0.8425\n",
      "Epoch 88/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.3253 - acc: 0.8676 - val_loss: 0.4512 - val_acc: 0.7914\n",
      "Epoch 89/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.3262 - acc: 0.8609 - val_loss: 0.3915 - val_acc: 0.8323\n",
      "Epoch 90/100\n",
      "1956/1956 [==============================] - 1s 339us/step - loss: 0.3210 - acc: 0.8717 - val_loss: 0.3776 - val_acc: 0.8507\n",
      "Epoch 91/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.3136 - acc: 0.8768 - val_loss: 0.4140 - val_acc: 0.8241\n",
      "Epoch 92/100\n",
      "1956/1956 [==============================] - 1s 338us/step - loss: 0.3163 - acc: 0.8809 - val_loss: 0.3810 - val_acc: 0.8384\n",
      "Epoch 93/100\n",
      "1956/1956 [==============================] - 1s 335us/step - loss: 0.3036 - acc: 0.8845 - val_loss: 0.4161 - val_acc: 0.8078\n",
      "Epoch 94/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.3154 - acc: 0.8768 - val_loss: 0.3714 - val_acc: 0.8528\n",
      "Epoch 95/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.3132 - acc: 0.8742 - val_loss: 0.3932 - val_acc: 0.8405\n",
      "Epoch 96/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.3159 - acc: 0.8788 - val_loss: 0.4259 - val_acc: 0.8098\n",
      "Epoch 97/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.3245 - acc: 0.8620 - val_loss: 0.3702 - val_acc: 0.8507\n",
      "Epoch 98/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.3156 - acc: 0.8768 - val_loss: 0.4048 - val_acc: 0.8200\n",
      "Epoch 99/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.3094 - acc: 0.8839 - val_loss: 0.3754 - val_acc: 0.8405\n",
      "Epoch 100/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.3127 - acc: 0.8763 - val_loss: 0.4079 - val_acc: 0.8221\n",
      "Test subject 11, class HandStart\n",
      "Train subject 11, class FirstDigitTouch\n",
      "Train on 1956 samples, validate on 489 samples\n",
      "Epoch 1/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 1.1133 - acc: 0.6268 - val_loss: 0.7335 - val_acc: 0.6933\n",
      "Epoch 2/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.6685 - acc: 0.6840 - val_loss: 0.6772 - val_acc: 0.6830\n",
      "Epoch 3/100\n",
      "1956/1956 [==============================] - 1s 335us/step - loss: 0.5946 - acc: 0.7091 - val_loss: 0.5923 - val_acc: 0.7096\n",
      "Epoch 4/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.5664 - acc: 0.7168 - val_loss: 0.6332 - val_acc: 0.6789\n",
      "Epoch 5/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.5350 - acc: 0.7342 - val_loss: 0.5727 - val_acc: 0.7137\n",
      "Epoch 6/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.5166 - acc: 0.7382 - val_loss: 0.5427 - val_acc: 0.7423\n",
      "Epoch 7/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.5114 - acc: 0.7500 - val_loss: 0.4964 - val_acc: 0.7566\n",
      "Epoch 8/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.4895 - acc: 0.7572 - val_loss: 0.5316 - val_acc: 0.7485\n",
      "Epoch 9/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.4884 - acc: 0.7679 - val_loss: 0.5286 - val_acc: 0.7382\n",
      "Epoch 10/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.4909 - acc: 0.7638 - val_loss: 0.5044 - val_acc: 0.7730\n",
      "Epoch 11/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.4806 - acc: 0.7715 - val_loss: 0.4926 - val_acc: 0.7771\n",
      "Epoch 12/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.4794 - acc: 0.7730 - val_loss: 0.4768 - val_acc: 0.7812\n",
      "Epoch 13/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.4558 - acc: 0.7817 - val_loss: 0.4918 - val_acc: 0.7832\n",
      "Epoch 14/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.4552 - acc: 0.7843 - val_loss: 0.4677 - val_acc: 0.7894\n",
      "Epoch 15/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.4440 - acc: 0.7935 - val_loss: 0.4682 - val_acc: 0.7914\n",
      "Epoch 16/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.4427 - acc: 0.7858 - val_loss: 0.4831 - val_acc: 0.7873\n",
      "Epoch 17/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.4232 - acc: 0.8047 - val_loss: 0.4750 - val_acc: 0.7914\n",
      "Epoch 18/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.4264 - acc: 0.8001 - val_loss: 0.4408 - val_acc: 0.8016\n",
      "Epoch 19/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.4235 - acc: 0.7965 - val_loss: 0.4963 - val_acc: 0.7853\n",
      "Epoch 20/100\n",
      "1956/1956 [==============================] - 1s 338us/step - loss: 0.4212 - acc: 0.7970 - val_loss: 0.4399 - val_acc: 0.8119\n",
      "Epoch 21/100\n",
      "1956/1956 [==============================] - 1s 336us/step - loss: 0.4054 - acc: 0.8165 - val_loss: 0.4238 - val_acc: 0.8180\n",
      "Epoch 22/100\n",
      "1956/1956 [==============================] - 1s 341us/step - loss: 0.3961 - acc: 0.8221 - val_loss: 0.4323 - val_acc: 0.8160\n",
      "Epoch 23/100\n",
      "1956/1956 [==============================] - 1s 342us/step - loss: 0.3884 - acc: 0.8246 - val_loss: 0.4547 - val_acc: 0.8057\n",
      "Epoch 24/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.3859 - acc: 0.8226 - val_loss: 0.4333 - val_acc: 0.8221\n",
      "Epoch 25/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.3895 - acc: 0.8252 - val_loss: 0.4306 - val_acc: 0.8139\n",
      "Epoch 26/100\n",
      "1956/1956 [==============================] - 1s 336us/step - loss: 0.3878 - acc: 0.8185 - val_loss: 0.4389 - val_acc: 0.8180\n",
      "Epoch 27/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.3842 - acc: 0.8246 - val_loss: 0.3967 - val_acc: 0.8323\n",
      "Epoch 28/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.3791 - acc: 0.8292 - val_loss: 0.4038 - val_acc: 0.8384\n",
      "Epoch 29/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.3675 - acc: 0.8456 - val_loss: 0.4262 - val_acc: 0.8262\n",
      "Epoch 30/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.3635 - acc: 0.8359 - val_loss: 0.3946 - val_acc: 0.8425\n",
      "Epoch 31/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.3510 - acc: 0.8492 - val_loss: 0.4073 - val_acc: 0.8384\n",
      "Epoch 32/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.3543 - acc: 0.8487 - val_loss: 0.3856 - val_acc: 0.8487\n",
      "Epoch 33/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.3501 - acc: 0.8533 - val_loss: 0.3675 - val_acc: 0.8446\n",
      "Epoch 34/100\n",
      "1956/1956 [==============================] - 1s 345us/step - loss: 0.3464 - acc: 0.8415 - val_loss: 0.3888 - val_acc: 0.8425\n",
      "Epoch 35/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.3440 - acc: 0.8471 - val_loss: 0.4313 - val_acc: 0.8200\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.3432 - acc: 0.8548 - val_loss: 0.4023 - val_acc: 0.8364\n",
      "Epoch 37/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.3353 - acc: 0.8466 - val_loss: 0.3900 - val_acc: 0.8446\n",
      "Epoch 38/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.3240 - acc: 0.8599 - val_loss: 0.3888 - val_acc: 0.8466\n",
      "Epoch 39/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.3240 - acc: 0.8517 - val_loss: 0.3798 - val_acc: 0.8487\n",
      "Epoch 40/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.3269 - acc: 0.8548 - val_loss: 0.3747 - val_acc: 0.8466\n",
      "Epoch 41/100\n",
      "1956/1956 [==============================] - 1s 336us/step - loss: 0.3144 - acc: 0.8615 - val_loss: 0.3688 - val_acc: 0.8466\n",
      "Epoch 42/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.3131 - acc: 0.8661 - val_loss: 0.3605 - val_acc: 0.8548\n",
      "Epoch 43/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.3170 - acc: 0.8604 - val_loss: 0.3463 - val_acc: 0.8609\n",
      "Epoch 44/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.3060 - acc: 0.8707 - val_loss: 0.3974 - val_acc: 0.8405\n",
      "Epoch 45/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.3015 - acc: 0.8671 - val_loss: 0.3720 - val_acc: 0.8507\n",
      "Epoch 46/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.3072 - acc: 0.8732 - val_loss: 0.3799 - val_acc: 0.8446\n",
      "Epoch 47/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.3168 - acc: 0.8609 - val_loss: 0.3641 - val_acc: 0.8548\n",
      "Epoch 48/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.2957 - acc: 0.8819 - val_loss: 0.3962 - val_acc: 0.8384\n",
      "Epoch 49/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.2975 - acc: 0.8701 - val_loss: 0.3339 - val_acc: 0.8630\n",
      "Epoch 50/100\n",
      "1956/1956 [==============================] - 1s 338us/step - loss: 0.3037 - acc: 0.8742 - val_loss: 0.3394 - val_acc: 0.8671\n",
      "Epoch 51/100\n",
      "1956/1956 [==============================] - 1s 341us/step - loss: 0.3101 - acc: 0.8747 - val_loss: 0.3502 - val_acc: 0.8712\n",
      "Epoch 52/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.2848 - acc: 0.8747 - val_loss: 0.3516 - val_acc: 0.8671\n",
      "Epoch 53/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.2927 - acc: 0.8758 - val_loss: 0.3400 - val_acc: 0.8650\n",
      "Epoch 54/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.2820 - acc: 0.8845 - val_loss: 0.3724 - val_acc: 0.8507\n",
      "Epoch 55/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.2797 - acc: 0.8829 - val_loss: 0.3632 - val_acc: 0.8609\n",
      "Epoch 56/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.2750 - acc: 0.8865 - val_loss: 0.3499 - val_acc: 0.8691\n",
      "Epoch 57/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.2933 - acc: 0.8737 - val_loss: 0.3365 - val_acc: 0.8671\n",
      "Epoch 58/100\n",
      "1956/1956 [==============================] - 1s 324us/step - loss: 0.2859 - acc: 0.8809 - val_loss: 0.3275 - val_acc: 0.8855\n",
      "Epoch 59/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.2691 - acc: 0.8901 - val_loss: 0.3584 - val_acc: 0.8671\n",
      "Epoch 60/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.2751 - acc: 0.8824 - val_loss: 0.3378 - val_acc: 0.8732\n",
      "Epoch 61/100\n",
      "1956/1956 [==============================] - 1s 345us/step - loss: 0.2682 - acc: 0.8896 - val_loss: 0.3360 - val_acc: 0.8793\n",
      "Epoch 62/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.2603 - acc: 0.8988 - val_loss: 0.3588 - val_acc: 0.8671\n",
      "Epoch 63/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.2665 - acc: 0.8860 - val_loss: 0.3190 - val_acc: 0.8793\n",
      "Epoch 64/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.2557 - acc: 0.8891 - val_loss: 0.3636 - val_acc: 0.8691\n",
      "Epoch 65/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.2687 - acc: 0.8850 - val_loss: 0.3201 - val_acc: 0.8834\n",
      "Epoch 66/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.2700 - acc: 0.8885 - val_loss: 0.3341 - val_acc: 0.8834\n",
      "Epoch 67/100\n",
      "1956/1956 [==============================] - 1s 337us/step - loss: 0.2550 - acc: 0.8911 - val_loss: 0.3248 - val_acc: 0.8814\n",
      "Epoch 68/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.2627 - acc: 0.8921 - val_loss: 0.3229 - val_acc: 0.8855\n",
      "Epoch 69/100\n",
      "1956/1956 [==============================] - 1s 338us/step - loss: 0.2560 - acc: 0.8896 - val_loss: 0.3016 - val_acc: 0.8875\n",
      "Epoch 70/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.2519 - acc: 0.9003 - val_loss: 0.3217 - val_acc: 0.8855\n",
      "Epoch 71/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.2502 - acc: 0.8931 - val_loss: 0.3001 - val_acc: 0.8957\n",
      "Epoch 72/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.2482 - acc: 0.9018 - val_loss: 0.3170 - val_acc: 0.8896\n",
      "Epoch 73/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.2482 - acc: 0.9034 - val_loss: 0.3192 - val_acc: 0.8916\n",
      "Epoch 74/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.2503 - acc: 0.8952 - val_loss: 0.2962 - val_acc: 0.8916\n",
      "Epoch 75/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.2457 - acc: 0.9024 - val_loss: 0.3109 - val_acc: 0.8896\n",
      "Epoch 76/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.2435 - acc: 0.9029 - val_loss: 0.3307 - val_acc: 0.8793\n",
      "Epoch 77/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.2354 - acc: 0.9059 - val_loss: 0.2871 - val_acc: 0.8896\n",
      "Epoch 78/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.2446 - acc: 0.9018 - val_loss: 0.3278 - val_acc: 0.8896\n",
      "Epoch 79/100\n",
      "1956/1956 [==============================] - 1s 336us/step - loss: 0.2388 - acc: 0.9049 - val_loss: 0.3322 - val_acc: 0.8834\n",
      "Epoch 80/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.2354 - acc: 0.9029 - val_loss: 0.2869 - val_acc: 0.8978\n",
      "Epoch 81/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.2432 - acc: 0.9090 - val_loss: 0.3024 - val_acc: 0.8916\n",
      "Epoch 82/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.2238 - acc: 0.9156 - val_loss: 0.2983 - val_acc: 0.8896\n",
      "Epoch 83/100\n",
      "1956/1956 [==============================] - 1s 335us/step - loss: 0.2317 - acc: 0.9110 - val_loss: 0.3024 - val_acc: 0.8896\n",
      "Epoch 84/100\n",
      "1956/1956 [==============================] - 1s 338us/step - loss: 0.2243 - acc: 0.9141 - val_loss: 0.3289 - val_acc: 0.8855\n",
      "Epoch 85/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.2299 - acc: 0.9126 - val_loss: 0.2982 - val_acc: 0.8957\n",
      "Epoch 86/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.2294 - acc: 0.9059 - val_loss: 0.3145 - val_acc: 0.8834\n",
      "Epoch 87/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.2351 - acc: 0.9100 - val_loss: 0.2671 - val_acc: 0.9141\n",
      "Epoch 88/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.2337 - acc: 0.9116 - val_loss: 0.2801 - val_acc: 0.8937\n",
      "Epoch 89/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.2248 - acc: 0.9156 - val_loss: 0.2787 - val_acc: 0.8998\n",
      "Epoch 90/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.2232 - acc: 0.9172 - val_loss: 0.2843 - val_acc: 0.8937\n",
      "Epoch 91/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.2276 - acc: 0.9070 - val_loss: 0.2961 - val_acc: 0.8937\n",
      "Epoch 92/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.2244 - acc: 0.9090 - val_loss: 0.2936 - val_acc: 0.8978\n",
      "Epoch 93/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.2239 - acc: 0.9162 - val_loss: 0.2697 - val_acc: 0.9059\n",
      "Epoch 94/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.2127 - acc: 0.9269 - val_loss: 0.2739 - val_acc: 0.9121\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.2166 - acc: 0.9223 - val_loss: 0.2762 - val_acc: 0.9018\n",
      "Epoch 96/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.2099 - acc: 0.9218 - val_loss: 0.2958 - val_acc: 0.8978\n",
      "Epoch 97/100\n",
      "1956/1956 [==============================] - 1s 335us/step - loss: 0.2239 - acc: 0.9121 - val_loss: 0.2807 - val_acc: 0.8978\n",
      "Epoch 98/100\n",
      "1956/1956 [==============================] - 1s 341us/step - loss: 0.2162 - acc: 0.9223 - val_loss: 0.2974 - val_acc: 0.8937\n",
      "Epoch 99/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.2073 - acc: 0.9141 - val_loss: 0.2672 - val_acc: 0.9121\n",
      "Epoch 100/100\n",
      "1956/1956 [==============================] - 1s 336us/step - loss: 0.2185 - acc: 0.9167 - val_loss: 0.2680 - val_acc: 0.9039\n",
      "Train on 1956 samples, validate on 489 samples\n",
      "Epoch 1/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.2762 - acc: 0.8926 - val_loss: 0.2930 - val_acc: 0.9162\n",
      "Epoch 2/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.2666 - acc: 0.9013 - val_loss: 0.2806 - val_acc: 0.9243\n",
      "Epoch 3/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.2642 - acc: 0.9013 - val_loss: 0.2620 - val_acc: 0.9243\n",
      "Epoch 4/100\n",
      "1956/1956 [==============================] - 1s 320us/step - loss: 0.2587 - acc: 0.9105 - val_loss: 0.2806 - val_acc: 0.9162\n",
      "Epoch 5/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.2642 - acc: 0.8993 - val_loss: 0.2872 - val_acc: 0.9162\n",
      "Epoch 6/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.2542 - acc: 0.9008 - val_loss: 0.2867 - val_acc: 0.9121\n",
      "Epoch 7/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.2512 - acc: 0.9121 - val_loss: 0.2830 - val_acc: 0.9121\n",
      "Epoch 8/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.2467 - acc: 0.9156 - val_loss: 0.2615 - val_acc: 0.9182\n",
      "Epoch 9/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.2513 - acc: 0.9116 - val_loss: 0.2795 - val_acc: 0.9141\n",
      "Epoch 10/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.2430 - acc: 0.9192 - val_loss: 0.2949 - val_acc: 0.9039\n",
      "Epoch 11/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.2475 - acc: 0.9105 - val_loss: 0.2526 - val_acc: 0.9264\n",
      "Epoch 12/100\n",
      "1956/1956 [==============================] - 1s 337us/step - loss: 0.2480 - acc: 0.9064 - val_loss: 0.2584 - val_acc: 0.9243\n",
      "Epoch 13/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.2532 - acc: 0.9070 - val_loss: 0.2731 - val_acc: 0.9182\n",
      "Epoch 14/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.2432 - acc: 0.9085 - val_loss: 0.2632 - val_acc: 0.9264\n",
      "Epoch 15/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.2430 - acc: 0.9085 - val_loss: 0.2780 - val_acc: 0.9100\n",
      "Epoch 16/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.2418 - acc: 0.9116 - val_loss: 0.2936 - val_acc: 0.9039\n",
      "Epoch 17/100\n",
      "1956/1956 [==============================] - 1s 336us/step - loss: 0.2408 - acc: 0.9131 - val_loss: 0.2691 - val_acc: 0.9162\n",
      "Epoch 18/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.2336 - acc: 0.9156 - val_loss: 0.3025 - val_acc: 0.8998\n",
      "Epoch 19/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.2463 - acc: 0.9126 - val_loss: 0.2772 - val_acc: 0.9100\n",
      "Epoch 20/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.2309 - acc: 0.9182 - val_loss: 0.2540 - val_acc: 0.9284\n",
      "Epoch 21/100\n",
      "1956/1956 [==============================] - 1s 336us/step - loss: 0.2399 - acc: 0.9146 - val_loss: 0.2992 - val_acc: 0.8998\n",
      "Epoch 22/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.2342 - acc: 0.9131 - val_loss: 0.2741 - val_acc: 0.9162\n",
      "Epoch 23/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.2308 - acc: 0.9162 - val_loss: 0.2723 - val_acc: 0.9121\n",
      "Epoch 24/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.2223 - acc: 0.9223 - val_loss: 0.2798 - val_acc: 0.9141\n",
      "Epoch 25/100\n",
      "1956/1956 [==============================] - 1s 337us/step - loss: 0.2218 - acc: 0.9254 - val_loss: 0.2621 - val_acc: 0.9182\n",
      "Epoch 26/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.2326 - acc: 0.9156 - val_loss: 0.2480 - val_acc: 0.9305\n",
      "Epoch 27/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.2279 - acc: 0.9248 - val_loss: 0.2620 - val_acc: 0.9202\n",
      "Epoch 28/100\n",
      "1956/1956 [==============================] - 1s 336us/step - loss: 0.2234 - acc: 0.9248 - val_loss: 0.2614 - val_acc: 0.9182\n",
      "Epoch 29/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.2228 - acc: 0.9167 - val_loss: 0.2548 - val_acc: 0.9264\n",
      "Epoch 30/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.2276 - acc: 0.9208 - val_loss: 0.2772 - val_acc: 0.9121\n",
      "Epoch 31/100\n",
      "1956/1956 [==============================] - 1s 337us/step - loss: 0.2183 - acc: 0.9269 - val_loss: 0.2632 - val_acc: 0.9243\n",
      "Epoch 32/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.2183 - acc: 0.9202 - val_loss: 0.2495 - val_acc: 0.9305\n",
      "Epoch 33/100\n",
      "1956/1956 [==============================] - 1s 324us/step - loss: 0.2222 - acc: 0.9172 - val_loss: 0.2479 - val_acc: 0.9346\n",
      "Epoch 34/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.2188 - acc: 0.9243 - val_loss: 0.2809 - val_acc: 0.9141\n",
      "Epoch 35/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.2229 - acc: 0.9187 - val_loss: 0.2481 - val_acc: 0.9284\n",
      "Epoch 36/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.2092 - acc: 0.9300 - val_loss: 0.2609 - val_acc: 0.9223\n",
      "Epoch 37/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.2241 - acc: 0.9197 - val_loss: 0.2908 - val_acc: 0.9059\n",
      "Epoch 38/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.2144 - acc: 0.9223 - val_loss: 0.2642 - val_acc: 0.9162\n",
      "Epoch 39/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.2083 - acc: 0.9264 - val_loss: 0.2401 - val_acc: 0.9305\n",
      "Epoch 40/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.2102 - acc: 0.9305 - val_loss: 0.2554 - val_acc: 0.9243\n",
      "Epoch 41/100\n",
      "1956/1956 [==============================] - 1s 336us/step - loss: 0.1986 - acc: 0.9361 - val_loss: 0.2954 - val_acc: 0.9080\n",
      "Epoch 42/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.2156 - acc: 0.9238 - val_loss: 0.2849 - val_acc: 0.9080\n",
      "Epoch 43/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.2099 - acc: 0.9310 - val_loss: 0.2697 - val_acc: 0.9141\n",
      "Epoch 44/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.2069 - acc: 0.9305 - val_loss: 0.2596 - val_acc: 0.9182\n",
      "Epoch 45/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.1977 - acc: 0.9356 - val_loss: 0.2366 - val_acc: 0.9387\n",
      "Epoch 46/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.1976 - acc: 0.9305 - val_loss: 0.2766 - val_acc: 0.9121\n",
      "Epoch 47/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.2007 - acc: 0.9320 - val_loss: 0.2562 - val_acc: 0.9284\n",
      "Epoch 48/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.2033 - acc: 0.9315 - val_loss: 0.2883 - val_acc: 0.9121\n",
      "Epoch 49/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.2088 - acc: 0.9325 - val_loss: 0.2820 - val_acc: 0.9100\n",
      "Epoch 50/100\n",
      "1956/1956 [==============================] - 1s 336us/step - loss: 0.2015 - acc: 0.9330 - val_loss: 0.3180 - val_acc: 0.8896\n",
      "Epoch 51/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.1962 - acc: 0.9340 - val_loss: 0.2786 - val_acc: 0.9162\n",
      "Epoch 52/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.1998 - acc: 0.9294 - val_loss: 0.2741 - val_acc: 0.9182\n",
      "Epoch 53/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.1948 - acc: 0.9320 - val_loss: 0.2473 - val_acc: 0.9325\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.2043 - acc: 0.9289 - val_loss: 0.2617 - val_acc: 0.9223\n",
      "Epoch 55/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.2008 - acc: 0.9366 - val_loss: 0.2554 - val_acc: 0.9284\n",
      "Epoch 56/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.1974 - acc: 0.9315 - val_loss: 0.2543 - val_acc: 0.9264\n",
      "Epoch 57/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.2014 - acc: 0.9361 - val_loss: 0.2474 - val_acc: 0.9284\n",
      "Epoch 58/100\n",
      "1956/1956 [==============================] - 1s 336us/step - loss: 0.1885 - acc: 0.9346 - val_loss: 0.2696 - val_acc: 0.9182\n",
      "Epoch 59/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.1924 - acc: 0.9320 - val_loss: 0.2565 - val_acc: 0.9264\n",
      "Epoch 60/100\n",
      "1956/1956 [==============================] - 1s 337us/step - loss: 0.1902 - acc: 0.9340 - val_loss: 0.2438 - val_acc: 0.9325\n",
      "Epoch 61/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.1923 - acc: 0.9346 - val_loss: 0.2512 - val_acc: 0.9305\n",
      "Epoch 62/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.1983 - acc: 0.9346 - val_loss: 0.2420 - val_acc: 0.9284\n",
      "Epoch 63/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.1875 - acc: 0.9376 - val_loss: 0.2591 - val_acc: 0.9243\n",
      "Epoch 64/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.1754 - acc: 0.9489 - val_loss: 0.2546 - val_acc: 0.9284\n",
      "Epoch 65/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.1962 - acc: 0.9335 - val_loss: 0.2572 - val_acc: 0.9243\n",
      "Epoch 66/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.1907 - acc: 0.9402 - val_loss: 0.2600 - val_acc: 0.9264\n",
      "Epoch 67/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.1814 - acc: 0.9325 - val_loss: 0.2604 - val_acc: 0.9264\n",
      "Epoch 68/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.1916 - acc: 0.9397 - val_loss: 0.2498 - val_acc: 0.9325\n",
      "Epoch 69/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.1789 - acc: 0.9412 - val_loss: 0.2522 - val_acc: 0.9305\n",
      "Epoch 70/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.1836 - acc: 0.9361 - val_loss: 0.2529 - val_acc: 0.9243\n",
      "Epoch 71/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.1832 - acc: 0.9366 - val_loss: 0.2627 - val_acc: 0.9223\n",
      "Epoch 72/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.1848 - acc: 0.9320 - val_loss: 0.2520 - val_acc: 0.9264\n",
      "Epoch 73/100\n",
      "1956/1956 [==============================] - 1s 321us/step - loss: 0.1766 - acc: 0.9402 - val_loss: 0.2480 - val_acc: 0.9325\n",
      "Epoch 74/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.1841 - acc: 0.9371 - val_loss: 0.2388 - val_acc: 0.9346\n",
      "Epoch 75/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.1903 - acc: 0.9351 - val_loss: 0.2639 - val_acc: 0.9264\n",
      "Epoch 76/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.1823 - acc: 0.9366 - val_loss: 0.2667 - val_acc: 0.9202\n",
      "Epoch 77/100\n",
      "1956/1956 [==============================] - 1s 336us/step - loss: 0.1797 - acc: 0.9376 - val_loss: 0.2354 - val_acc: 0.9366\n",
      "Epoch 78/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.1830 - acc: 0.9371 - val_loss: 0.2472 - val_acc: 0.9264\n",
      "Epoch 79/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.1777 - acc: 0.9438 - val_loss: 0.2368 - val_acc: 0.9305\n",
      "Epoch 80/100\n",
      "1956/1956 [==============================] - 1s 335us/step - loss: 0.1799 - acc: 0.9381 - val_loss: 0.2634 - val_acc: 0.9243\n",
      "Epoch 81/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.1771 - acc: 0.9346 - val_loss: 0.2528 - val_acc: 0.9243\n",
      "Epoch 82/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.1759 - acc: 0.9392 - val_loss: 0.3671 - val_acc: 0.8732\n",
      "Epoch 83/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.1916 - acc: 0.9366 - val_loss: 0.2440 - val_acc: 0.9305\n",
      "Epoch 84/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.1748 - acc: 0.9381 - val_loss: 0.2544 - val_acc: 0.9284\n",
      "Epoch 85/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.1804 - acc: 0.9351 - val_loss: 0.2364 - val_acc: 0.9346\n",
      "Epoch 86/100\n",
      "1956/1956 [==============================] - 1s 335us/step - loss: 0.1638 - acc: 0.9463 - val_loss: 0.2468 - val_acc: 0.9284\n",
      "Epoch 87/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.1687 - acc: 0.9453 - val_loss: 0.2739 - val_acc: 0.9202\n",
      "Epoch 88/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.1677 - acc: 0.9402 - val_loss: 0.2494 - val_acc: 0.9284\n",
      "Epoch 89/100\n",
      "1956/1956 [==============================] - 1s 323us/step - loss: 0.1679 - acc: 0.9443 - val_loss: 0.2417 - val_acc: 0.9284\n",
      "Epoch 90/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.1744 - acc: 0.9427 - val_loss: 0.2626 - val_acc: 0.9202\n",
      "Epoch 91/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.1705 - acc: 0.9422 - val_loss: 0.2581 - val_acc: 0.9243\n",
      "Epoch 92/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.1642 - acc: 0.9422 - val_loss: 0.2315 - val_acc: 0.9305\n",
      "Epoch 93/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.1683 - acc: 0.9402 - val_loss: 0.2371 - val_acc: 0.9305\n",
      "Epoch 94/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.1779 - acc: 0.9412 - val_loss: 0.2760 - val_acc: 0.9182\n",
      "Epoch 95/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.1682 - acc: 0.9463 - val_loss: 0.2601 - val_acc: 0.9223\n",
      "Epoch 96/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.1680 - acc: 0.9448 - val_loss: 0.2284 - val_acc: 0.9387\n",
      "Epoch 97/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.1719 - acc: 0.9453 - val_loss: 0.2824 - val_acc: 0.9162\n",
      "Epoch 98/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.1661 - acc: 0.9473 - val_loss: 0.2694 - val_acc: 0.9202\n",
      "Epoch 99/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.1688 - acc: 0.9387 - val_loss: 0.2616 - val_acc: 0.9243\n",
      "Epoch 100/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.1575 - acc: 0.9509 - val_loss: 0.2262 - val_acc: 0.9407\n",
      "Test subject 11, class FirstDigitTouch\n",
      "Train subject 11, class BothStartLoadPhase\n",
      "Train on 1956 samples, validate on 489 samples\n",
      "Epoch 1/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 1.0725 - acc: 0.6278 - val_loss: 0.6526 - val_acc: 0.6892\n",
      "Epoch 2/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.6735 - acc: 0.6702 - val_loss: 0.5552 - val_acc: 0.7117\n",
      "Epoch 3/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.5913 - acc: 0.6933 - val_loss: 0.5164 - val_acc: 0.7505\n",
      "Epoch 4/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.5554 - acc: 0.7081 - val_loss: 0.4956 - val_acc: 0.7648\n",
      "Epoch 5/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.5224 - acc: 0.7382 - val_loss: 0.4649 - val_acc: 0.7832\n",
      "Epoch 6/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.5023 - acc: 0.7459 - val_loss: 0.4419 - val_acc: 0.8016\n",
      "Epoch 7/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.4801 - acc: 0.7658 - val_loss: 0.4351 - val_acc: 0.8037\n",
      "Epoch 8/100\n",
      "1956/1956 [==============================] - 1s 335us/step - loss: 0.4784 - acc: 0.7684 - val_loss: 0.4211 - val_acc: 0.8200\n",
      "Epoch 9/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.4663 - acc: 0.7791 - val_loss: 0.4334 - val_acc: 0.8119\n",
      "Epoch 10/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.4479 - acc: 0.7812 - val_loss: 0.4217 - val_acc: 0.8139\n",
      "Epoch 11/100\n",
      "1956/1956 [==============================] - 1s 324us/step - loss: 0.4417 - acc: 0.7873 - val_loss: 0.3958 - val_acc: 0.8303\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956/1956 [==============================] - 1s 324us/step - loss: 0.4252 - acc: 0.8027 - val_loss: 0.3931 - val_acc: 0.8364\n",
      "Epoch 13/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.4240 - acc: 0.8027 - val_loss: 0.3890 - val_acc: 0.8425\n",
      "Epoch 14/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.4198 - acc: 0.8037 - val_loss: 0.3969 - val_acc: 0.8364\n",
      "Epoch 15/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.4035 - acc: 0.8124 - val_loss: 0.3910 - val_acc: 0.8446\n",
      "Epoch 16/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.4028 - acc: 0.8129 - val_loss: 0.3759 - val_acc: 0.8528\n",
      "Epoch 17/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.3916 - acc: 0.8252 - val_loss: 0.3743 - val_acc: 0.8487\n",
      "Epoch 18/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.3970 - acc: 0.8252 - val_loss: 0.3643 - val_acc: 0.8630\n",
      "Epoch 19/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.3863 - acc: 0.8252 - val_loss: 0.3687 - val_acc: 0.8569\n",
      "Epoch 20/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.3815 - acc: 0.8359 - val_loss: 0.3631 - val_acc: 0.8650\n",
      "Epoch 21/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.3818 - acc: 0.8328 - val_loss: 0.3565 - val_acc: 0.8671\n",
      "Epoch 22/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.3695 - acc: 0.8338 - val_loss: 0.3581 - val_acc: 0.8650\n",
      "Epoch 23/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.3668 - acc: 0.8354 - val_loss: 0.3577 - val_acc: 0.8630\n",
      "Epoch 24/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.3595 - acc: 0.8369 - val_loss: 0.3545 - val_acc: 0.8630\n",
      "Epoch 25/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.3513 - acc: 0.8415 - val_loss: 0.3576 - val_acc: 0.8589\n",
      "Epoch 26/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.3558 - acc: 0.8395 - val_loss: 0.3506 - val_acc: 0.8671\n",
      "Epoch 27/100\n",
      "1956/1956 [==============================] - 1s 335us/step - loss: 0.3401 - acc: 0.8579 - val_loss: 0.3417 - val_acc: 0.8732\n",
      "Epoch 28/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.3438 - acc: 0.8563 - val_loss: 0.3462 - val_acc: 0.8712\n",
      "Epoch 29/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.3437 - acc: 0.8543 - val_loss: 0.3309 - val_acc: 0.8814\n",
      "Epoch 30/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.3393 - acc: 0.8584 - val_loss: 0.3403 - val_acc: 0.8753\n",
      "Epoch 31/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.3348 - acc: 0.8574 - val_loss: 0.3464 - val_acc: 0.8650\n",
      "Epoch 32/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.3314 - acc: 0.8625 - val_loss: 0.3305 - val_acc: 0.8814\n",
      "Epoch 33/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.3398 - acc: 0.8553 - val_loss: 0.3305 - val_acc: 0.8773\n",
      "Epoch 34/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.3267 - acc: 0.8691 - val_loss: 0.3356 - val_acc: 0.8753\n",
      "Epoch 35/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.3253 - acc: 0.8686 - val_loss: 0.3231 - val_acc: 0.8916\n",
      "Epoch 36/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.3210 - acc: 0.8681 - val_loss: 0.3203 - val_acc: 0.8896\n",
      "Epoch 37/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.3220 - acc: 0.8609 - val_loss: 0.3193 - val_acc: 0.8875\n",
      "Epoch 38/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.3183 - acc: 0.8696 - val_loss: 0.3233 - val_acc: 0.8753\n",
      "Epoch 39/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.3062 - acc: 0.8763 - val_loss: 0.3199 - val_acc: 0.8834\n",
      "Epoch 40/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.3112 - acc: 0.8701 - val_loss: 0.3184 - val_acc: 0.8814\n",
      "Epoch 41/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.3142 - acc: 0.8722 - val_loss: 0.3119 - val_acc: 0.8957\n",
      "Epoch 42/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.3083 - acc: 0.8799 - val_loss: 0.3137 - val_acc: 0.8916\n",
      "Epoch 43/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.3004 - acc: 0.8737 - val_loss: 0.3111 - val_acc: 0.8896\n",
      "Epoch 44/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.3006 - acc: 0.8839 - val_loss: 0.3145 - val_acc: 0.8937\n",
      "Epoch 45/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.2896 - acc: 0.8870 - val_loss: 0.2997 - val_acc: 0.8957\n",
      "Epoch 46/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.3004 - acc: 0.8834 - val_loss: 0.3002 - val_acc: 0.8957\n",
      "Epoch 47/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.2936 - acc: 0.8829 - val_loss: 0.3109 - val_acc: 0.8896\n",
      "Epoch 48/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.2961 - acc: 0.8824 - val_loss: 0.3025 - val_acc: 0.8957\n",
      "Epoch 49/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.2906 - acc: 0.8896 - val_loss: 0.2939 - val_acc: 0.8998\n",
      "Epoch 50/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.2910 - acc: 0.8839 - val_loss: 0.2962 - val_acc: 0.8998\n",
      "Epoch 51/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.2914 - acc: 0.8804 - val_loss: 0.2892 - val_acc: 0.8957\n",
      "Epoch 52/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.2847 - acc: 0.8865 - val_loss: 0.2996 - val_acc: 0.8937\n",
      "Epoch 53/100\n",
      "1956/1956 [==============================] - 1s 324us/step - loss: 0.2843 - acc: 0.8860 - val_loss: 0.2894 - val_acc: 0.8978\n",
      "Epoch 54/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.2910 - acc: 0.8870 - val_loss: 0.2891 - val_acc: 0.8916\n",
      "Epoch 55/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.2825 - acc: 0.8911 - val_loss: 0.2933 - val_acc: 0.8957\n",
      "Epoch 56/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.2730 - acc: 0.8896 - val_loss: 0.2874 - val_acc: 0.8998\n",
      "Epoch 57/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.2632 - acc: 0.8983 - val_loss: 0.2974 - val_acc: 0.8957\n",
      "Epoch 58/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.2856 - acc: 0.8906 - val_loss: 0.2828 - val_acc: 0.8937\n",
      "Epoch 59/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.2683 - acc: 0.8962 - val_loss: 0.2956 - val_acc: 0.8937\n",
      "Epoch 60/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.2635 - acc: 0.8962 - val_loss: 0.2833 - val_acc: 0.8957\n",
      "Epoch 61/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.2612 - acc: 0.9013 - val_loss: 0.2810 - val_acc: 0.8998\n",
      "Epoch 62/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.2652 - acc: 0.8967 - val_loss: 0.2881 - val_acc: 0.8957\n",
      "Epoch 63/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.2649 - acc: 0.9054 - val_loss: 0.2902 - val_acc: 0.8957\n",
      "Epoch 64/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.2606 - acc: 0.9003 - val_loss: 0.2843 - val_acc: 0.8998\n",
      "Epoch 65/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.2669 - acc: 0.8962 - val_loss: 0.2839 - val_acc: 0.8998\n",
      "Epoch 66/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.2582 - acc: 0.9013 - val_loss: 0.2851 - val_acc: 0.8998\n",
      "Epoch 67/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.2583 - acc: 0.9049 - val_loss: 0.2739 - val_acc: 0.8916\n",
      "Epoch 68/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.2596 - acc: 0.9034 - val_loss: 0.2794 - val_acc: 0.8937\n",
      "Epoch 69/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.2622 - acc: 0.8983 - val_loss: 0.2860 - val_acc: 0.8978\n",
      "Epoch 70/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.2546 - acc: 0.8983 - val_loss: 0.2766 - val_acc: 0.8957\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.2603 - acc: 0.8962 - val_loss: 0.2722 - val_acc: 0.8937\n",
      "Epoch 72/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.2538 - acc: 0.9080 - val_loss: 0.2913 - val_acc: 0.8896\n",
      "Epoch 73/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.2501 - acc: 0.9116 - val_loss: 0.2704 - val_acc: 0.8937\n",
      "Epoch 74/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.2574 - acc: 0.9034 - val_loss: 0.2735 - val_acc: 0.8957\n",
      "Epoch 75/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.2497 - acc: 0.9080 - val_loss: 0.2663 - val_acc: 0.8978\n",
      "Epoch 76/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.2423 - acc: 0.9126 - val_loss: 0.2709 - val_acc: 0.8998\n",
      "Epoch 77/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.2384 - acc: 0.9116 - val_loss: 0.2628 - val_acc: 0.8978\n",
      "Epoch 78/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.2414 - acc: 0.9075 - val_loss: 0.2740 - val_acc: 0.9039\n",
      "Epoch 79/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.2489 - acc: 0.9003 - val_loss: 0.2699 - val_acc: 0.9039\n",
      "Epoch 80/100\n",
      "1956/1956 [==============================] - 1s 323us/step - loss: 0.2416 - acc: 0.9105 - val_loss: 0.2643 - val_acc: 0.8998\n",
      "Epoch 81/100\n",
      "1956/1956 [==============================] - 1s 336us/step - loss: 0.2370 - acc: 0.9121 - val_loss: 0.2692 - val_acc: 0.9018\n",
      "Epoch 82/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.2295 - acc: 0.9172 - val_loss: 0.2713 - val_acc: 0.9039\n",
      "Epoch 83/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.2339 - acc: 0.9080 - val_loss: 0.2695 - val_acc: 0.9039\n",
      "Epoch 84/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.2340 - acc: 0.9100 - val_loss: 0.2681 - val_acc: 0.9018\n",
      "Epoch 85/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.2312 - acc: 0.9116 - val_loss: 0.2639 - val_acc: 0.8937\n",
      "Epoch 86/100\n",
      "1956/1956 [==============================] - 1s 335us/step - loss: 0.2332 - acc: 0.9105 - val_loss: 0.2711 - val_acc: 0.9059\n",
      "Epoch 87/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.2260 - acc: 0.9136 - val_loss: 0.2878 - val_acc: 0.9059\n",
      "Epoch 88/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.2326 - acc: 0.9172 - val_loss: 0.2686 - val_acc: 0.9039\n",
      "Epoch 89/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.2359 - acc: 0.9172 - val_loss: 0.2659 - val_acc: 0.8998\n",
      "Epoch 90/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.2327 - acc: 0.9110 - val_loss: 0.2683 - val_acc: 0.9018\n",
      "Epoch 91/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.2307 - acc: 0.9202 - val_loss: 0.2662 - val_acc: 0.8937\n",
      "Epoch 92/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.2292 - acc: 0.9213 - val_loss: 0.2622 - val_acc: 0.8998\n",
      "Epoch 93/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.2281 - acc: 0.9192 - val_loss: 0.2681 - val_acc: 0.9018\n",
      "Epoch 94/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.2203 - acc: 0.9223 - val_loss: 0.2642 - val_acc: 0.8978\n",
      "Epoch 95/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.2165 - acc: 0.9243 - val_loss: 0.2641 - val_acc: 0.9018\n",
      "Epoch 96/100\n",
      "1956/1956 [==============================] - 1s 323us/step - loss: 0.2317 - acc: 0.9177 - val_loss: 0.2593 - val_acc: 0.8957\n",
      "Epoch 97/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.2224 - acc: 0.9182 - val_loss: 0.2533 - val_acc: 0.8978\n",
      "Epoch 98/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.2161 - acc: 0.9228 - val_loss: 0.2525 - val_acc: 0.8957\n",
      "Epoch 99/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.2186 - acc: 0.9182 - val_loss: 0.2639 - val_acc: 0.9039\n",
      "Epoch 100/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.2223 - acc: 0.9172 - val_loss: 0.2599 - val_acc: 0.9039\n",
      "Train on 1956 samples, validate on 489 samples\n",
      "Epoch 1/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.2637 - acc: 0.9018 - val_loss: 0.3301 - val_acc: 0.8834\n",
      "Epoch 2/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.2577 - acc: 0.8998 - val_loss: 0.3354 - val_acc: 0.8753\n",
      "Epoch 3/100\n",
      "1956/1956 [==============================] - 1s 335us/step - loss: 0.2514 - acc: 0.9049 - val_loss: 0.3187 - val_acc: 0.8896\n",
      "Epoch 4/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.2482 - acc: 0.9064 - val_loss: 0.3168 - val_acc: 0.8875\n",
      "Epoch 5/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.2463 - acc: 0.9110 - val_loss: 0.3430 - val_acc: 0.8814\n",
      "Epoch 6/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.2394 - acc: 0.9100 - val_loss: 0.3348 - val_acc: 0.8855\n",
      "Epoch 7/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.2280 - acc: 0.9202 - val_loss: 0.3341 - val_acc: 0.8793\n",
      "Epoch 8/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.2358 - acc: 0.9141 - val_loss: 0.3228 - val_acc: 0.8896\n",
      "Epoch 9/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.2369 - acc: 0.9146 - val_loss: 0.3199 - val_acc: 0.8896\n",
      "Epoch 10/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.2412 - acc: 0.9121 - val_loss: 0.3148 - val_acc: 0.8916\n",
      "Epoch 11/100\n",
      "1956/1956 [==============================] - 1s 335us/step - loss: 0.2257 - acc: 0.9110 - val_loss: 0.3274 - val_acc: 0.8855\n",
      "Epoch 12/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.2354 - acc: 0.9156 - val_loss: 0.3341 - val_acc: 0.8834\n",
      "Epoch 13/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.2230 - acc: 0.9151 - val_loss: 0.3349 - val_acc: 0.8855\n",
      "Epoch 14/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.2203 - acc: 0.9238 - val_loss: 0.3173 - val_acc: 0.8834\n",
      "Epoch 15/100\n",
      "1956/1956 [==============================] - 1s 341us/step - loss: 0.2199 - acc: 0.9223 - val_loss: 0.3148 - val_acc: 0.8916\n",
      "Epoch 16/100\n",
      "1956/1956 [==============================] - 1s 338us/step - loss: 0.2183 - acc: 0.9238 - val_loss: 0.3184 - val_acc: 0.8937\n",
      "Epoch 17/100\n",
      "1956/1956 [==============================] - 1s 341us/step - loss: 0.2051 - acc: 0.9300 - val_loss: 0.3139 - val_acc: 0.8957\n",
      "Epoch 18/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.2129 - acc: 0.9259 - val_loss: 0.3199 - val_acc: 0.8957\n",
      "Epoch 19/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.2098 - acc: 0.9284 - val_loss: 0.3307 - val_acc: 0.8855\n",
      "Epoch 20/100\n",
      "1956/1956 [==============================] - 1s 336us/step - loss: 0.2130 - acc: 0.9213 - val_loss: 0.3147 - val_acc: 0.8937\n",
      "Epoch 21/100\n",
      "1956/1956 [==============================] - 1s 339us/step - loss: 0.2090 - acc: 0.9233 - val_loss: 0.3255 - val_acc: 0.8875\n",
      "Epoch 22/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.2061 - acc: 0.9325 - val_loss: 0.3324 - val_acc: 0.8875\n",
      "Epoch 23/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.2129 - acc: 0.9172 - val_loss: 0.3405 - val_acc: 0.8814\n",
      "Epoch 24/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.2020 - acc: 0.9310 - val_loss: 0.3312 - val_acc: 0.8896\n",
      "Epoch 25/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.2018 - acc: 0.9269 - val_loss: 0.3225 - val_acc: 0.8875\n",
      "Epoch 26/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.1990 - acc: 0.9305 - val_loss: 0.3340 - val_acc: 0.8875\n",
      "Epoch 27/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.2076 - acc: 0.9238 - val_loss: 0.3423 - val_acc: 0.8855\n",
      "Epoch 28/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.2033 - acc: 0.9305 - val_loss: 0.3463 - val_acc: 0.8814\n",
      "Epoch 29/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.2015 - acc: 0.9289 - val_loss: 0.3287 - val_acc: 0.8834\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.1903 - acc: 0.9315 - val_loss: 0.3303 - val_acc: 0.8875\n",
      "Epoch 31/100\n",
      "1956/1956 [==============================] - 1s 337us/step - loss: 0.1969 - acc: 0.9315 - val_loss: 0.3317 - val_acc: 0.8855\n",
      "Epoch 32/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.1933 - acc: 0.9305 - val_loss: 0.3236 - val_acc: 0.8916\n",
      "Epoch 33/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.1836 - acc: 0.9340 - val_loss: 0.3202 - val_acc: 0.8937\n",
      "Epoch 34/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.1997 - acc: 0.9305 - val_loss: 0.3318 - val_acc: 0.8937\n",
      "Epoch 35/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.1833 - acc: 0.9397 - val_loss: 0.3531 - val_acc: 0.8814\n",
      "Epoch 36/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.1904 - acc: 0.9320 - val_loss: 0.3270 - val_acc: 0.8916\n",
      "Epoch 37/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.1853 - acc: 0.9366 - val_loss: 0.3070 - val_acc: 0.8957\n",
      "Epoch 38/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.1902 - acc: 0.9305 - val_loss: 0.3266 - val_acc: 0.8896\n",
      "Epoch 39/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.1832 - acc: 0.9381 - val_loss: 0.3858 - val_acc: 0.8630\n",
      "Epoch 40/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.1943 - acc: 0.9340 - val_loss: 0.3383 - val_acc: 0.8814\n",
      "Epoch 41/100\n",
      "1956/1956 [==============================] - 1s 343us/step - loss: 0.1895 - acc: 0.9320 - val_loss: 0.3243 - val_acc: 0.8916\n",
      "Epoch 42/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.1875 - acc: 0.9330 - val_loss: 0.3333 - val_acc: 0.8855\n",
      "Epoch 43/100\n",
      "1956/1956 [==============================] - 1s 343us/step - loss: 0.1863 - acc: 0.9335 - val_loss: 0.3150 - val_acc: 0.8937\n",
      "Epoch 44/100\n",
      "1956/1956 [==============================] - 1s 336us/step - loss: 0.1756 - acc: 0.9412 - val_loss: 0.3389 - val_acc: 0.8896\n",
      "Epoch 45/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.1789 - acc: 0.9397 - val_loss: 0.3138 - val_acc: 0.8937\n",
      "Epoch 46/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.1840 - acc: 0.9376 - val_loss: 0.3206 - val_acc: 0.8937\n",
      "Epoch 47/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.1723 - acc: 0.9407 - val_loss: 0.3221 - val_acc: 0.8896\n",
      "Epoch 48/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.1775 - acc: 0.9392 - val_loss: 0.2959 - val_acc: 0.9059\n",
      "Epoch 49/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.1782 - acc: 0.9376 - val_loss: 0.3209 - val_acc: 0.8937\n",
      "Epoch 50/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.1765 - acc: 0.9397 - val_loss: 0.3173 - val_acc: 0.8916\n",
      "Epoch 51/100\n",
      "1956/1956 [==============================] - 1s 340us/step - loss: 0.1715 - acc: 0.9387 - val_loss: 0.3121 - val_acc: 0.8916\n",
      "Epoch 52/100\n",
      "1956/1956 [==============================] - 1s 350us/step - loss: 0.1792 - acc: 0.9315 - val_loss: 0.3263 - val_acc: 0.8916\n",
      "Epoch 53/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.1735 - acc: 0.9417 - val_loss: 0.3272 - val_acc: 0.8916\n",
      "Epoch 54/100\n",
      "1956/1956 [==============================] - 1s 344us/step - loss: 0.1669 - acc: 0.9427 - val_loss: 0.3070 - val_acc: 0.8937\n",
      "Epoch 55/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.1747 - acc: 0.9397 - val_loss: 0.3324 - val_acc: 0.8916\n",
      "Epoch 56/100\n",
      "1956/1956 [==============================] - 1s 339us/step - loss: 0.1714 - acc: 0.9381 - val_loss: 0.3214 - val_acc: 0.8916\n",
      "Epoch 57/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.1701 - acc: 0.9402 - val_loss: 0.3218 - val_acc: 0.8896\n",
      "Epoch 58/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.1621 - acc: 0.9453 - val_loss: 0.3158 - val_acc: 0.8916\n",
      "Epoch 59/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.1607 - acc: 0.9463 - val_loss: 0.3237 - val_acc: 0.8937\n",
      "Epoch 60/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.1639 - acc: 0.9433 - val_loss: 0.3497 - val_acc: 0.8875\n",
      "Epoch 61/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.1583 - acc: 0.9509 - val_loss: 0.3151 - val_acc: 0.8998\n",
      "Epoch 62/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.1679 - acc: 0.9448 - val_loss: 0.3277 - val_acc: 0.8896\n",
      "Epoch 63/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.1691 - acc: 0.9392 - val_loss: 0.3175 - val_acc: 0.8916\n",
      "Epoch 64/100\n",
      "1956/1956 [==============================] - 1s 337us/step - loss: 0.1547 - acc: 0.9473 - val_loss: 0.3586 - val_acc: 0.8814\n",
      "Epoch 65/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.1630 - acc: 0.9458 - val_loss: 0.3174 - val_acc: 0.8937\n",
      "Epoch 66/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.1585 - acc: 0.9473 - val_loss: 0.3120 - val_acc: 0.8998\n",
      "Epoch 67/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.1553 - acc: 0.9458 - val_loss: 0.3224 - val_acc: 0.8957\n",
      "Epoch 68/100\n",
      "1956/1956 [==============================] - 1s 338us/step - loss: 0.1577 - acc: 0.9473 - val_loss: 0.3344 - val_acc: 0.8957\n",
      "Epoch 69/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.1676 - acc: 0.9468 - val_loss: 0.3216 - val_acc: 0.8937\n",
      "Epoch 70/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.1653 - acc: 0.9422 - val_loss: 0.2951 - val_acc: 0.9059\n",
      "Epoch 71/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.1549 - acc: 0.9484 - val_loss: 0.3227 - val_acc: 0.8855\n",
      "Epoch 72/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.1500 - acc: 0.9468 - val_loss: 0.3203 - val_acc: 0.8896\n",
      "Epoch 73/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.1645 - acc: 0.9422 - val_loss: 0.3225 - val_acc: 0.8896\n",
      "Epoch 74/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.1640 - acc: 0.9468 - val_loss: 0.3293 - val_acc: 0.8937\n",
      "Epoch 75/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.1630 - acc: 0.9448 - val_loss: 0.3248 - val_acc: 0.8916\n",
      "Epoch 76/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.1563 - acc: 0.9494 - val_loss: 0.3168 - val_acc: 0.8957\n",
      "Epoch 77/100\n",
      "1956/1956 [==============================] - 1s 321us/step - loss: 0.1664 - acc: 0.9463 - val_loss: 0.3158 - val_acc: 0.8978\n",
      "Epoch 78/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.1617 - acc: 0.9412 - val_loss: 0.3217 - val_acc: 0.8957\n",
      "Epoch 79/100\n",
      "1956/1956 [==============================] - 1s 322us/step - loss: 0.1513 - acc: 0.9504 - val_loss: 0.3106 - val_acc: 0.8875\n",
      "Epoch 80/100\n",
      "1956/1956 [==============================] - 1s 323us/step - loss: 0.1541 - acc: 0.9489 - val_loss: 0.3225 - val_acc: 0.8896\n",
      "Epoch 81/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.1490 - acc: 0.9484 - val_loss: 0.3075 - val_acc: 0.8937\n",
      "Epoch 82/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.1572 - acc: 0.9448 - val_loss: 0.3136 - val_acc: 0.8916\n",
      "Epoch 83/100\n",
      "1956/1956 [==============================] - 1s 337us/step - loss: 0.1426 - acc: 0.9479 - val_loss: 0.2920 - val_acc: 0.8998\n",
      "Epoch 84/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.1489 - acc: 0.9514 - val_loss: 0.3369 - val_acc: 0.8957\n",
      "Epoch 85/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.1466 - acc: 0.9530 - val_loss: 0.3257 - val_acc: 0.8916\n",
      "Epoch 86/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.1445 - acc: 0.9489 - val_loss: 0.3344 - val_acc: 0.8998\n",
      "Epoch 87/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.1492 - acc: 0.9514 - val_loss: 0.3156 - val_acc: 0.8978\n",
      "Epoch 88/100\n",
      "1956/1956 [==============================] - 1s 347us/step - loss: 0.1486 - acc: 0.9509 - val_loss: 0.3149 - val_acc: 0.8957\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956/1956 [==============================] - 1s 336us/step - loss: 0.1378 - acc: 0.9586 - val_loss: 0.3227 - val_acc: 0.8957\n",
      "Epoch 90/100\n",
      "1956/1956 [==============================] - 1s 338us/step - loss: 0.1437 - acc: 0.9514 - val_loss: 0.3398 - val_acc: 0.8937\n",
      "Epoch 91/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.1473 - acc: 0.9489 - val_loss: 0.3009 - val_acc: 0.8957\n",
      "Epoch 92/100\n",
      "1956/1956 [==============================] - 1s 337us/step - loss: 0.1348 - acc: 0.9591 - val_loss: 0.3194 - val_acc: 0.8937\n",
      "Epoch 93/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.1400 - acc: 0.9530 - val_loss: 0.3145 - val_acc: 0.8937\n",
      "Epoch 94/100\n",
      "1956/1956 [==============================] - 1s 346us/step - loss: 0.1323 - acc: 0.9560 - val_loss: 0.3169 - val_acc: 0.8937\n",
      "Epoch 95/100\n",
      "1956/1956 [==============================] - 1s 344us/step - loss: 0.1349 - acc: 0.9560 - val_loss: 0.3171 - val_acc: 0.8957\n",
      "Epoch 96/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.1331 - acc: 0.9560 - val_loss: 0.3112 - val_acc: 0.8978\n",
      "Epoch 97/100\n",
      "1956/1956 [==============================] - 1s 352us/step - loss: 0.1424 - acc: 0.9530 - val_loss: 0.3064 - val_acc: 0.8998\n",
      "Epoch 98/100\n",
      "1956/1956 [==============================] - 1s 339us/step - loss: 0.1378 - acc: 0.9545 - val_loss: 0.3107 - val_acc: 0.8998\n",
      "Epoch 99/100\n",
      "1956/1956 [==============================] - 1s 339us/step - loss: 0.1435 - acc: 0.9479 - val_loss: 0.2873 - val_acc: 0.9080\n",
      "Epoch 100/100\n",
      "1956/1956 [==============================] - 1s 368us/step - loss: 0.1330 - acc: 0.9565 - val_loss: 0.3209 - val_acc: 0.8937\n",
      "Test subject 11, class BothStartLoadPhase\n",
      "Train subject 11, class LiftOff\n",
      "Train on 1955 samples, validate on 489 samples\n",
      "Epoch 1/100\n",
      "1955/1955 [==============================] - 1s 401us/step - loss: 0.9338 - acc: 0.6384 - val_loss: 0.6972 - val_acc: 0.6626\n",
      "Epoch 2/100\n",
      "1955/1955 [==============================] - 1s 321us/step - loss: 0.6749 - acc: 0.6588 - val_loss: 0.5883 - val_acc: 0.6994\n",
      "Epoch 3/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.6176 - acc: 0.6772 - val_loss: 0.5669 - val_acc: 0.7382\n",
      "Epoch 4/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.5721 - acc: 0.7120 - val_loss: 0.5975 - val_acc: 0.7035\n",
      "Epoch 5/100\n",
      "1955/1955 [==============================] - 1s 349us/step - loss: 0.5477 - acc: 0.7269 - val_loss: 0.5350 - val_acc: 0.7546\n",
      "Epoch 6/100\n",
      "1955/1955 [==============================] - 1s 345us/step - loss: 0.5295 - acc: 0.7361 - val_loss: 0.5326 - val_acc: 0.7566\n",
      "Epoch 7/100\n",
      "1955/1955 [==============================] - 1s 350us/step - loss: 0.5090 - acc: 0.7535 - val_loss: 0.4997 - val_acc: 0.7955\n",
      "Epoch 8/100\n",
      "1955/1955 [==============================] - 1s 357us/step - loss: 0.4951 - acc: 0.7693 - val_loss: 0.4903 - val_acc: 0.7832\n",
      "Epoch 9/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.4958 - acc: 0.7560 - val_loss: 0.4656 - val_acc: 0.8057\n",
      "Epoch 10/100\n",
      "1955/1955 [==============================] - 1s 354us/step - loss: 0.4738 - acc: 0.7785 - val_loss: 0.4791 - val_acc: 0.7935\n",
      "Epoch 11/100\n",
      "1955/1955 [==============================] - 1s 340us/step - loss: 0.4606 - acc: 0.7949 - val_loss: 0.4512 - val_acc: 0.8078\n",
      "Epoch 12/100\n",
      "1955/1955 [==============================] - 1s 343us/step - loss: 0.4545 - acc: 0.7872 - val_loss: 0.4467 - val_acc: 0.8119\n",
      "Epoch 13/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.4374 - acc: 0.7964 - val_loss: 0.4339 - val_acc: 0.8016\n",
      "Epoch 14/100\n",
      "1955/1955 [==============================] - 1s 345us/step - loss: 0.4386 - acc: 0.7959 - val_loss: 0.4427 - val_acc: 0.8160\n",
      "Epoch 15/100\n",
      "1955/1955 [==============================] - 1s 338us/step - loss: 0.4216 - acc: 0.8056 - val_loss: 0.4262 - val_acc: 0.8057\n",
      "Epoch 16/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.4270 - acc: 0.8056 - val_loss: 0.4331 - val_acc: 0.8160\n",
      "Epoch 17/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.4095 - acc: 0.8164 - val_loss: 0.4199 - val_acc: 0.8016\n",
      "Epoch 18/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.3996 - acc: 0.8215 - val_loss: 0.4187 - val_acc: 0.8016\n",
      "Epoch 19/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.4037 - acc: 0.8205 - val_loss: 0.4130 - val_acc: 0.8037\n",
      "Epoch 20/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.3956 - acc: 0.8194 - val_loss: 0.4166 - val_acc: 0.8160\n",
      "Epoch 21/100\n",
      "1955/1955 [==============================] - 1s 349us/step - loss: 0.3907 - acc: 0.8215 - val_loss: 0.4180 - val_acc: 0.8200\n",
      "Epoch 22/100\n",
      "1955/1955 [==============================] - 1s 321us/step - loss: 0.3908 - acc: 0.8302 - val_loss: 0.4049 - val_acc: 0.8160\n",
      "Epoch 23/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.3954 - acc: 0.8174 - val_loss: 0.4097 - val_acc: 0.8262\n",
      "Epoch 24/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.3825 - acc: 0.8307 - val_loss: 0.4366 - val_acc: 0.8119\n",
      "Epoch 25/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.3853 - acc: 0.8379 - val_loss: 0.3921 - val_acc: 0.8160\n",
      "Epoch 26/100\n",
      "1955/1955 [==============================] - 1s 336us/step - loss: 0.3859 - acc: 0.8312 - val_loss: 0.3985 - val_acc: 0.8241\n",
      "Epoch 27/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.3671 - acc: 0.8430 - val_loss: 0.4001 - val_acc: 0.8180\n",
      "Epoch 28/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.3686 - acc: 0.8312 - val_loss: 0.4105 - val_acc: 0.8282\n",
      "Epoch 29/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.3706 - acc: 0.8358 - val_loss: 0.3889 - val_acc: 0.8344\n",
      "Epoch 30/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.3637 - acc: 0.8450 - val_loss: 0.3781 - val_acc: 0.8323\n",
      "Epoch 31/100\n",
      "1955/1955 [==============================] - 1s 337us/step - loss: 0.3624 - acc: 0.8419 - val_loss: 0.3898 - val_acc: 0.8384\n",
      "Epoch 32/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.3487 - acc: 0.8455 - val_loss: 0.3726 - val_acc: 0.8344\n",
      "Epoch 33/100\n",
      "1955/1955 [==============================] - 1s 326us/step - loss: 0.3611 - acc: 0.8389 - val_loss: 0.4160 - val_acc: 0.8323\n",
      "Epoch 34/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.3619 - acc: 0.8399 - val_loss: 0.3838 - val_acc: 0.8303\n",
      "Epoch 35/100\n",
      "1955/1955 [==============================] - 1s 326us/step - loss: 0.3506 - acc: 0.8445 - val_loss: 0.3773 - val_acc: 0.8344\n",
      "Epoch 36/100\n",
      "1955/1955 [==============================] - 1s 343us/step - loss: 0.3419 - acc: 0.8542 - val_loss: 0.3647 - val_acc: 0.8446\n",
      "Epoch 37/100\n",
      "1955/1955 [==============================] - 1s 341us/step - loss: 0.3536 - acc: 0.8506 - val_loss: 0.3876 - val_acc: 0.8446\n",
      "Epoch 38/100\n",
      "1955/1955 [==============================] - 1s 344us/step - loss: 0.3486 - acc: 0.8486 - val_loss: 0.3749 - val_acc: 0.8405\n",
      "Epoch 39/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.3414 - acc: 0.8496 - val_loss: 0.3696 - val_acc: 0.8364\n",
      "Epoch 40/100\n",
      "1955/1955 [==============================] - 1s 325us/step - loss: 0.3322 - acc: 0.8563 - val_loss: 0.3716 - val_acc: 0.8384\n",
      "Epoch 41/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.3400 - acc: 0.8593 - val_loss: 0.3717 - val_acc: 0.8425\n",
      "Epoch 42/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.3313 - acc: 0.8588 - val_loss: 0.3711 - val_acc: 0.8384\n",
      "Epoch 43/100\n",
      "1955/1955 [==============================] - 1s 346us/step - loss: 0.3366 - acc: 0.8568 - val_loss: 0.3637 - val_acc: 0.8425\n",
      "Epoch 44/100\n",
      "1955/1955 [==============================] - 1s 343us/step - loss: 0.3271 - acc: 0.8742 - val_loss: 0.3610 - val_acc: 0.8446\n",
      "Epoch 45/100\n",
      "1955/1955 [==============================] - 1s 349us/step - loss: 0.3291 - acc: 0.8588 - val_loss: 0.3874 - val_acc: 0.8405\n",
      "Epoch 46/100\n",
      "1955/1955 [==============================] - 1s 340us/step - loss: 0.3246 - acc: 0.8731 - val_loss: 0.3740 - val_acc: 0.8487\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1955/1955 [==============================] - 1s 338us/step - loss: 0.3180 - acc: 0.8685 - val_loss: 0.3589 - val_acc: 0.8569\n",
      "Epoch 48/100\n",
      "1955/1955 [==============================] - 1s 344us/step - loss: 0.3236 - acc: 0.8670 - val_loss: 0.3665 - val_acc: 0.8548\n",
      "Epoch 49/100\n",
      "1955/1955 [==============================] - 1s 359us/step - loss: 0.3132 - acc: 0.8701 - val_loss: 0.3560 - val_acc: 0.8446\n",
      "Epoch 50/100\n",
      "1955/1955 [==============================] - 1s 345us/step - loss: 0.3188 - acc: 0.8737 - val_loss: 0.3532 - val_acc: 0.8466\n",
      "Epoch 51/100\n",
      "1955/1955 [==============================] - 1s 347us/step - loss: 0.3184 - acc: 0.8762 - val_loss: 0.3485 - val_acc: 0.8487\n",
      "Epoch 52/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.3179 - acc: 0.8624 - val_loss: 0.3690 - val_acc: 0.8589\n",
      "Epoch 53/100\n",
      "1955/1955 [==============================] - 1s 354us/step - loss: 0.3104 - acc: 0.8783 - val_loss: 0.3519 - val_acc: 0.8609\n",
      "Epoch 54/100\n",
      "1955/1955 [==============================] - 1s 356us/step - loss: 0.3111 - acc: 0.8777 - val_loss: 0.3528 - val_acc: 0.8609\n",
      "Epoch 55/100\n",
      "1955/1955 [==============================] - 1s 338us/step - loss: 0.2993 - acc: 0.8859 - val_loss: 0.3404 - val_acc: 0.8609\n",
      "Epoch 56/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.3080 - acc: 0.8772 - val_loss: 0.3529 - val_acc: 0.8630\n",
      "Epoch 57/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.3039 - acc: 0.8752 - val_loss: 0.3798 - val_acc: 0.8569\n",
      "Epoch 58/100\n",
      "1955/1955 [==============================] - 1s 337us/step - loss: 0.2995 - acc: 0.8824 - val_loss: 0.3397 - val_acc: 0.8548\n",
      "Epoch 59/100\n",
      "1955/1955 [==============================] - 1s 345us/step - loss: 0.3033 - acc: 0.8711 - val_loss: 0.3513 - val_acc: 0.8712\n",
      "Epoch 60/100\n",
      "1955/1955 [==============================] - 1s 359us/step - loss: 0.2958 - acc: 0.8818 - val_loss: 0.3664 - val_acc: 0.8589\n",
      "Epoch 61/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.2980 - acc: 0.8859 - val_loss: 0.3360 - val_acc: 0.8671\n",
      "Epoch 62/100\n",
      "1955/1955 [==============================] - 1s 347us/step - loss: 0.2910 - acc: 0.8777 - val_loss: 0.3367 - val_acc: 0.8691\n",
      "Epoch 63/100\n",
      "1955/1955 [==============================] - 1s 345us/step - loss: 0.2955 - acc: 0.8742 - val_loss: 0.3583 - val_acc: 0.8609\n",
      "Epoch 64/100\n",
      "1955/1955 [==============================] - 1s 345us/step - loss: 0.2963 - acc: 0.8839 - val_loss: 0.3431 - val_acc: 0.8630\n",
      "Epoch 65/100\n",
      "1955/1955 [==============================] - 1s 338us/step - loss: 0.2869 - acc: 0.8905 - val_loss: 0.3349 - val_acc: 0.8712\n",
      "Epoch 66/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.2980 - acc: 0.8772 - val_loss: 0.3365 - val_acc: 0.8732\n",
      "Epoch 67/100\n",
      "1955/1955 [==============================] - 1s 340us/step - loss: 0.2886 - acc: 0.8905 - val_loss: 0.3408 - val_acc: 0.8712\n",
      "Epoch 68/100\n",
      "1955/1955 [==============================] - 1s 337us/step - loss: 0.2786 - acc: 0.8936 - val_loss: 0.3343 - val_acc: 0.8753\n",
      "Epoch 69/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.2776 - acc: 0.8900 - val_loss: 0.3360 - val_acc: 0.8793\n",
      "Epoch 70/100\n",
      "1955/1955 [==============================] - 1s 338us/step - loss: 0.2895 - acc: 0.8890 - val_loss: 0.3326 - val_acc: 0.8753\n",
      "Epoch 71/100\n",
      "1955/1955 [==============================] - 1s 339us/step - loss: 0.2773 - acc: 0.8895 - val_loss: 0.3377 - val_acc: 0.8753\n",
      "Epoch 72/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.2770 - acc: 0.8905 - val_loss: 0.3533 - val_acc: 0.8548\n",
      "Epoch 73/100\n",
      "1955/1955 [==============================] - 1s 358us/step - loss: 0.2754 - acc: 0.8916 - val_loss: 0.3472 - val_acc: 0.8712\n",
      "Epoch 74/100\n",
      "1955/1955 [==============================] - 1s 345us/step - loss: 0.2688 - acc: 0.8987 - val_loss: 0.3175 - val_acc: 0.8855\n",
      "Epoch 75/100\n",
      "1955/1955 [==============================] - 1s 339us/step - loss: 0.2708 - acc: 0.8936 - val_loss: 0.3374 - val_acc: 0.8753\n",
      "Epoch 76/100\n",
      "1955/1955 [==============================] - 1s 341us/step - loss: 0.2742 - acc: 0.8992 - val_loss: 0.3243 - val_acc: 0.8896\n",
      "Epoch 77/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.2653 - acc: 0.8941 - val_loss: 0.3201 - val_acc: 0.8814\n",
      "Epoch 78/100\n",
      "1955/1955 [==============================] - 1s 339us/step - loss: 0.2712 - acc: 0.8957 - val_loss: 0.3348 - val_acc: 0.8793\n",
      "Epoch 79/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.2631 - acc: 0.9038 - val_loss: 0.3404 - val_acc: 0.8793\n",
      "Epoch 80/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.2604 - acc: 0.9059 - val_loss: 0.3234 - val_acc: 0.8875\n",
      "Epoch 81/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.2641 - acc: 0.9023 - val_loss: 0.3374 - val_acc: 0.8691\n",
      "Epoch 82/100\n",
      "1955/1955 [==============================] - 1s 345us/step - loss: 0.2640 - acc: 0.8951 - val_loss: 0.3324 - val_acc: 0.8814\n",
      "Epoch 83/100\n",
      "1955/1955 [==============================] - 1s 337us/step - loss: 0.2670 - acc: 0.8972 - val_loss: 0.3189 - val_acc: 0.8875\n",
      "Epoch 84/100\n",
      "1955/1955 [==============================] - 1s 343us/step - loss: 0.2597 - acc: 0.8987 - val_loss: 0.3186 - val_acc: 0.8875\n",
      "Epoch 85/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.2701 - acc: 0.8946 - val_loss: 0.3283 - val_acc: 0.8855\n",
      "Epoch 86/100\n",
      "1955/1955 [==============================] - 1s 338us/step - loss: 0.2561 - acc: 0.9023 - val_loss: 0.3117 - val_acc: 0.8937\n",
      "Epoch 87/100\n",
      "1955/1955 [==============================] - 1s 336us/step - loss: 0.2637 - acc: 0.8972 - val_loss: 0.3153 - val_acc: 0.8937\n",
      "Epoch 88/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.2595 - acc: 0.9008 - val_loss: 0.3050 - val_acc: 0.8875\n",
      "Epoch 89/100\n",
      "1955/1955 [==============================] - 1s 343us/step - loss: 0.2617 - acc: 0.8982 - val_loss: 0.3261 - val_acc: 0.8896\n",
      "Epoch 90/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.2588 - acc: 0.9013 - val_loss: 0.3069 - val_acc: 0.8978\n",
      "Epoch 91/100\n",
      "1955/1955 [==============================] - 1s 336us/step - loss: 0.2584 - acc: 0.9033 - val_loss: 0.3045 - val_acc: 0.8998\n",
      "Epoch 92/100\n",
      "1955/1955 [==============================] - 1s 341us/step - loss: 0.2527 - acc: 0.9043 - val_loss: 0.3110 - val_acc: 0.8916\n",
      "Epoch 93/100\n",
      "1955/1955 [==============================] - 1s 336us/step - loss: 0.2452 - acc: 0.9166 - val_loss: 0.3058 - val_acc: 0.8978\n",
      "Epoch 94/100\n",
      "1955/1955 [==============================] - 1s 336us/step - loss: 0.2443 - acc: 0.9100 - val_loss: 0.2999 - val_acc: 0.9018\n",
      "Epoch 95/100\n",
      "1955/1955 [==============================] - 1s 366us/step - loss: 0.2474 - acc: 0.9105 - val_loss: 0.3169 - val_acc: 0.8957\n",
      "Epoch 96/100\n",
      "1955/1955 [==============================] - 1s 351us/step - loss: 0.2440 - acc: 0.9120 - val_loss: 0.3126 - val_acc: 0.8957\n",
      "Epoch 97/100\n",
      "1955/1955 [==============================] - 1s 342us/step - loss: 0.2419 - acc: 0.9136 - val_loss: 0.3020 - val_acc: 0.9039\n",
      "Epoch 98/100\n",
      "1955/1955 [==============================] - 1s 338us/step - loss: 0.2562 - acc: 0.9049 - val_loss: 0.3000 - val_acc: 0.9039\n",
      "Epoch 99/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.2436 - acc: 0.9059 - val_loss: 0.3002 - val_acc: 0.8896\n",
      "Epoch 100/100\n",
      "1955/1955 [==============================] - 1s 340us/step - loss: 0.2443 - acc: 0.9161 - val_loss: 0.3202 - val_acc: 0.8957\n",
      "Train on 1955 samples, validate on 489 samples\n",
      "Epoch 1/100\n",
      "1955/1955 [==============================] - 1s 340us/step - loss: 0.3058 - acc: 0.8783 - val_loss: 0.2661 - val_acc: 0.8978\n",
      "Epoch 2/100\n",
      "1955/1955 [==============================] - 1s 342us/step - loss: 0.2966 - acc: 0.8808 - val_loss: 0.2702 - val_acc: 0.9039\n",
      "Epoch 3/100\n",
      "1955/1955 [==============================] - 1s 360us/step - loss: 0.2930 - acc: 0.8864 - val_loss: 0.2651 - val_acc: 0.9059\n",
      "Epoch 4/100\n",
      "1955/1955 [==============================] - 1s 347us/step - loss: 0.2871 - acc: 0.8849 - val_loss: 0.2771 - val_acc: 0.8916\n",
      "Epoch 5/100\n",
      "1955/1955 [==============================] - 1s 352us/step - loss: 0.2862 - acc: 0.8870 - val_loss: 0.2639 - val_acc: 0.9059\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1955/1955 [==============================] - 1s 340us/step - loss: 0.2843 - acc: 0.8987 - val_loss: 0.2671 - val_acc: 0.9039\n",
      "Epoch 7/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.2887 - acc: 0.8885 - val_loss: 0.2576 - val_acc: 0.9100\n",
      "Epoch 8/100\n",
      "1955/1955 [==============================] - 1s 346us/step - loss: 0.2839 - acc: 0.8941 - val_loss: 0.2709 - val_acc: 0.9059\n",
      "Epoch 9/100\n",
      "1955/1955 [==============================] - 1s 349us/step - loss: 0.2678 - acc: 0.9049 - val_loss: 0.2830 - val_acc: 0.8834\n",
      "Epoch 10/100\n",
      "1955/1955 [==============================] - 1s 354us/step - loss: 0.2829 - acc: 0.8936 - val_loss: 0.2746 - val_acc: 0.9039\n",
      "Epoch 11/100\n",
      "1955/1955 [==============================] - 1s 338us/step - loss: 0.2769 - acc: 0.8967 - val_loss: 0.2559 - val_acc: 0.8978\n",
      "Epoch 12/100\n",
      "1955/1955 [==============================] - 1s 345us/step - loss: 0.2827 - acc: 0.8921 - val_loss: 0.2663 - val_acc: 0.9100\n",
      "Epoch 13/100\n",
      "1955/1955 [==============================] - 1s 355us/step - loss: 0.2634 - acc: 0.9049 - val_loss: 0.2467 - val_acc: 0.9121\n",
      "Epoch 14/100\n",
      "1955/1955 [==============================] - 1s 341us/step - loss: 0.2716 - acc: 0.8987 - val_loss: 0.2631 - val_acc: 0.9059\n",
      "Epoch 15/100\n",
      "1955/1955 [==============================] - 1s 338us/step - loss: 0.2669 - acc: 0.9008 - val_loss: 0.2619 - val_acc: 0.9080\n",
      "Epoch 16/100\n",
      "1955/1955 [==============================] - 1s 337us/step - loss: 0.2732 - acc: 0.8967 - val_loss: 0.2568 - val_acc: 0.9100\n",
      "Epoch 17/100\n",
      "1955/1955 [==============================] - 1s 338us/step - loss: 0.2594 - acc: 0.9008 - val_loss: 0.2450 - val_acc: 0.9121\n",
      "Epoch 18/100\n",
      "1955/1955 [==============================] - 1s 339us/step - loss: 0.2678 - acc: 0.9013 - val_loss: 0.2698 - val_acc: 0.9018\n",
      "Epoch 19/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.2651 - acc: 0.9003 - val_loss: 0.2473 - val_acc: 0.9141\n",
      "Epoch 20/100\n",
      "1955/1955 [==============================] - 1s 337us/step - loss: 0.2585 - acc: 0.9059 - val_loss: 0.2654 - val_acc: 0.9080\n",
      "Epoch 21/100\n",
      "1955/1955 [==============================] - 1s 338us/step - loss: 0.2570 - acc: 0.9079 - val_loss: 0.2485 - val_acc: 0.9121\n",
      "Epoch 22/100\n",
      "1955/1955 [==============================] - 1s 336us/step - loss: 0.2586 - acc: 0.9095 - val_loss: 0.2556 - val_acc: 0.9141\n",
      "Epoch 23/100\n",
      "1955/1955 [==============================] - 1s 338us/step - loss: 0.2522 - acc: 0.9115 - val_loss: 0.2458 - val_acc: 0.9141\n",
      "Epoch 24/100\n",
      "1955/1955 [==============================] - 1s 324us/step - loss: 0.2531 - acc: 0.9059 - val_loss: 0.2440 - val_acc: 0.9141\n",
      "Epoch 25/100\n",
      "1955/1955 [==============================] - 1s 326us/step - loss: 0.2540 - acc: 0.9125 - val_loss: 0.2449 - val_acc: 0.9182\n",
      "Epoch 26/100\n",
      "1955/1955 [==============================] - 1s 326us/step - loss: 0.2498 - acc: 0.9136 - val_loss: 0.2481 - val_acc: 0.9100\n",
      "Epoch 27/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.2532 - acc: 0.9074 - val_loss: 0.2354 - val_acc: 0.9202\n",
      "Epoch 28/100\n",
      "1955/1955 [==============================] - 1s 323us/step - loss: 0.2521 - acc: 0.9079 - val_loss: 0.2348 - val_acc: 0.9223\n",
      "Epoch 29/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.2451 - acc: 0.9105 - val_loss: 0.2399 - val_acc: 0.9243\n",
      "Epoch 30/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.2468 - acc: 0.9095 - val_loss: 0.2317 - val_acc: 0.9080\n",
      "Epoch 31/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.2451 - acc: 0.9100 - val_loss: 0.2306 - val_acc: 0.9264\n",
      "Epoch 32/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.2402 - acc: 0.9182 - val_loss: 0.2282 - val_acc: 0.9162\n",
      "Epoch 33/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.2403 - acc: 0.9151 - val_loss: 0.2301 - val_acc: 0.9243\n",
      "Epoch 34/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.2365 - acc: 0.9207 - val_loss: 0.2257 - val_acc: 0.9346\n",
      "Epoch 35/100\n",
      "1955/1955 [==============================] - 1s 338us/step - loss: 0.2353 - acc: 0.9166 - val_loss: 0.2296 - val_acc: 0.9243\n",
      "Epoch 36/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.2321 - acc: 0.9120 - val_loss: 0.2332 - val_acc: 0.9264\n",
      "Epoch 37/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.2350 - acc: 0.9110 - val_loss: 0.2473 - val_acc: 0.9162\n",
      "Epoch 38/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.2326 - acc: 0.9202 - val_loss: 0.2257 - val_acc: 0.9202\n",
      "Epoch 39/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.2340 - acc: 0.9228 - val_loss: 0.2350 - val_acc: 0.9264\n",
      "Epoch 40/100\n",
      "1955/1955 [==============================] - 1s 336us/step - loss: 0.2279 - acc: 0.9207 - val_loss: 0.2183 - val_acc: 0.9387\n",
      "Epoch 41/100\n",
      "1955/1955 [==============================] - 1s 365us/step - loss: 0.2386 - acc: 0.9156 - val_loss: 0.2512 - val_acc: 0.9141\n",
      "Epoch 42/100\n",
      "1955/1955 [==============================] - 1s 354us/step - loss: 0.2241 - acc: 0.9258 - val_loss: 0.2257 - val_acc: 0.9325\n",
      "Epoch 43/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.2219 - acc: 0.9269 - val_loss: 0.2451 - val_acc: 0.9121\n",
      "Epoch 44/100\n",
      "1955/1955 [==============================] - 1s 350us/step - loss: 0.2246 - acc: 0.9269 - val_loss: 0.2239 - val_acc: 0.9305\n",
      "Epoch 45/100\n",
      "1955/1955 [==============================] - 1s 346us/step - loss: 0.2262 - acc: 0.9212 - val_loss: 0.2206 - val_acc: 0.9346\n",
      "Epoch 46/100\n",
      "1955/1955 [==============================] - 1s 349us/step - loss: 0.2253 - acc: 0.9269 - val_loss: 0.2248 - val_acc: 0.9284\n",
      "Epoch 47/100\n",
      "1955/1955 [==============================] - 1s 351us/step - loss: 0.2310 - acc: 0.9182 - val_loss: 0.2276 - val_acc: 0.9325\n",
      "Epoch 48/100\n",
      "1955/1955 [==============================] - 1s 338us/step - loss: 0.2292 - acc: 0.9212 - val_loss: 0.2229 - val_acc: 0.9325\n",
      "Epoch 49/100\n",
      "1955/1955 [==============================] - 1s 353us/step - loss: 0.2291 - acc: 0.9176 - val_loss: 0.2411 - val_acc: 0.9182\n",
      "Epoch 50/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.2170 - acc: 0.9243 - val_loss: 0.2182 - val_acc: 0.9325\n",
      "Epoch 51/100\n",
      "1955/1955 [==============================] - 1s 344us/step - loss: 0.2229 - acc: 0.9197 - val_loss: 0.2233 - val_acc: 0.9305\n",
      "Epoch 52/100\n",
      "1955/1955 [==============================] - 1s 339us/step - loss: 0.2199 - acc: 0.9238 - val_loss: 0.2110 - val_acc: 0.9366\n",
      "Epoch 53/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.2230 - acc: 0.9228 - val_loss: 0.2214 - val_acc: 0.9346\n",
      "Epoch 54/100\n",
      "1955/1955 [==============================] - 1s 338us/step - loss: 0.2130 - acc: 0.9269 - val_loss: 0.2115 - val_acc: 0.9407\n",
      "Epoch 55/100\n",
      "1955/1955 [==============================] - 1s 340us/step - loss: 0.2166 - acc: 0.9263 - val_loss: 0.2259 - val_acc: 0.9284\n",
      "Epoch 56/100\n",
      "1955/1955 [==============================] - 1s 350us/step - loss: 0.2138 - acc: 0.9299 - val_loss: 0.2073 - val_acc: 0.9366\n",
      "Epoch 57/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.2177 - acc: 0.9258 - val_loss: 0.2245 - val_acc: 0.9264\n",
      "Epoch 58/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.2085 - acc: 0.9340 - val_loss: 0.2144 - val_acc: 0.9100\n",
      "Epoch 59/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.2082 - acc: 0.9263 - val_loss: 0.2140 - val_acc: 0.9387\n",
      "Epoch 60/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.2210 - acc: 0.9228 - val_loss: 0.2219 - val_acc: 0.9100\n",
      "Epoch 61/100\n",
      "1955/1955 [==============================] - 1s 341us/step - loss: 0.2148 - acc: 0.9274 - val_loss: 0.2126 - val_acc: 0.9346\n",
      "Epoch 62/100\n",
      "1955/1955 [==============================] - 1s 380us/step - loss: 0.2079 - acc: 0.9381 - val_loss: 0.2091 - val_acc: 0.9407\n",
      "Epoch 63/100\n",
      "1955/1955 [==============================] - 1s 347us/step - loss: 0.2038 - acc: 0.9304 - val_loss: 0.2053 - val_acc: 0.9346\n",
      "Epoch 64/100\n",
      "1955/1955 [==============================] - 1s 337us/step - loss: 0.2127 - acc: 0.9274 - val_loss: 0.1998 - val_acc: 0.9305\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1955/1955 [==============================] - 1s 344us/step - loss: 0.1976 - acc: 0.9350 - val_loss: 0.2041 - val_acc: 0.9407\n",
      "Epoch 66/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.2046 - acc: 0.9350 - val_loss: 0.2278 - val_acc: 0.9223\n",
      "Epoch 67/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.2046 - acc: 0.9320 - val_loss: 0.2000 - val_acc: 0.9346\n",
      "Epoch 68/100\n",
      "1955/1955 [==============================] - 1s 341us/step - loss: 0.2069 - acc: 0.9304 - val_loss: 0.2096 - val_acc: 0.9366\n",
      "Epoch 69/100\n",
      "1955/1955 [==============================] - 1s 368us/step - loss: 0.2014 - acc: 0.9335 - val_loss: 0.2090 - val_acc: 0.9407\n",
      "Epoch 70/100\n",
      "1955/1955 [==============================] - 1s 341us/step - loss: 0.2106 - acc: 0.9258 - val_loss: 0.2080 - val_acc: 0.9407\n",
      "Epoch 71/100\n",
      "1955/1955 [==============================] - 1s 325us/step - loss: 0.1960 - acc: 0.9417 - val_loss: 0.2093 - val_acc: 0.9366\n",
      "Epoch 72/100\n",
      "1955/1955 [==============================] - 1s 336us/step - loss: 0.2042 - acc: 0.9258 - val_loss: 0.2039 - val_acc: 0.9325\n",
      "Epoch 73/100\n",
      "1955/1955 [==============================] - 1s 351us/step - loss: 0.1998 - acc: 0.9294 - val_loss: 0.2087 - val_acc: 0.9366\n",
      "Epoch 74/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.2001 - acc: 0.9299 - val_loss: 0.2025 - val_acc: 0.9223\n",
      "Epoch 75/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.2055 - acc: 0.9350 - val_loss: 0.2053 - val_acc: 0.9387\n",
      "Epoch 76/100\n",
      "1955/1955 [==============================] - 1s 349us/step - loss: 0.1941 - acc: 0.9386 - val_loss: 0.2148 - val_acc: 0.9284\n",
      "Epoch 77/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.1992 - acc: 0.9325 - val_loss: 0.1901 - val_acc: 0.9509\n",
      "Epoch 78/100\n",
      "1955/1955 [==============================] - 1s 336us/step - loss: 0.2017 - acc: 0.9350 - val_loss: 0.1935 - val_acc: 0.9468\n",
      "Epoch 79/100\n",
      "1955/1955 [==============================] - 1s 354us/step - loss: 0.2022 - acc: 0.9289 - val_loss: 0.2096 - val_acc: 0.9346\n",
      "Epoch 80/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.1949 - acc: 0.9361 - val_loss: 0.1927 - val_acc: 0.9325\n",
      "Epoch 81/100\n",
      "1955/1955 [==============================] - 1s 339us/step - loss: 0.1918 - acc: 0.9366 - val_loss: 0.2129 - val_acc: 0.9346\n",
      "Epoch 82/100\n",
      "1955/1955 [==============================] - 1s 325us/step - loss: 0.1901 - acc: 0.9412 - val_loss: 0.2007 - val_acc: 0.9387\n",
      "Epoch 83/100\n",
      "1955/1955 [==============================] - 1s 337us/step - loss: 0.1877 - acc: 0.9304 - val_loss: 0.2085 - val_acc: 0.9366\n",
      "Epoch 84/100\n",
      "1955/1955 [==============================] - 1s 336us/step - loss: 0.2062 - acc: 0.9350 - val_loss: 0.2160 - val_acc: 0.9264\n",
      "Epoch 85/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.1970 - acc: 0.9299 - val_loss: 0.1970 - val_acc: 0.9427\n",
      "Epoch 86/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.1824 - acc: 0.9422 - val_loss: 0.1964 - val_acc: 0.9427\n",
      "Epoch 87/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.1943 - acc: 0.9381 - val_loss: 0.1953 - val_acc: 0.9407\n",
      "Epoch 88/100\n",
      "1955/1955 [==============================] - 1s 340us/step - loss: 0.1918 - acc: 0.9355 - val_loss: 0.1976 - val_acc: 0.9407\n",
      "Epoch 89/100\n",
      "1955/1955 [==============================] - 1s 326us/step - loss: 0.1875 - acc: 0.9340 - val_loss: 0.1984 - val_acc: 0.9407\n",
      "Epoch 90/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.1818 - acc: 0.9417 - val_loss: 0.2004 - val_acc: 0.9366\n",
      "Epoch 91/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.1919 - acc: 0.9361 - val_loss: 0.2121 - val_acc: 0.9325\n",
      "Epoch 92/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.1967 - acc: 0.9366 - val_loss: 0.1956 - val_acc: 0.9427\n",
      "Epoch 93/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.1924 - acc: 0.9432 - val_loss: 0.2008 - val_acc: 0.9387\n",
      "Epoch 94/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.1944 - acc: 0.9376 - val_loss: 0.1992 - val_acc: 0.9387\n",
      "Epoch 95/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.1953 - acc: 0.9335 - val_loss: 0.2025 - val_acc: 0.9366\n",
      "Epoch 96/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.1885 - acc: 0.9366 - val_loss: 0.1873 - val_acc: 0.9448\n",
      "Epoch 97/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.1851 - acc: 0.9402 - val_loss: 0.1914 - val_acc: 0.9448\n",
      "Epoch 98/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.1868 - acc: 0.9432 - val_loss: 0.1912 - val_acc: 0.9448\n",
      "Epoch 99/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.1875 - acc: 0.9396 - val_loss: 0.1839 - val_acc: 0.9489\n",
      "Epoch 100/100\n",
      "1955/1955 [==============================] - 1s 326us/step - loss: 0.1833 - acc: 0.9422 - val_loss: 0.1986 - val_acc: 0.9387\n",
      "Test subject 11, class LiftOff\n",
      "Train subject 11, class Replace\n",
      "Train on 1943 samples, validate on 486 samples\n",
      "Epoch 1/100\n",
      "1943/1943 [==============================] - 1s 322us/step - loss: 0.8776 - acc: 0.7638 - val_loss: 0.4616 - val_acc: 0.8025\n",
      "Epoch 2/100\n",
      "1943/1943 [==============================] - 1s 326us/step - loss: 0.4266 - acc: 0.8209 - val_loss: 0.3949 - val_acc: 0.8292\n",
      "Epoch 3/100\n",
      "1943/1943 [==============================] - 1s 323us/step - loss: 0.4088 - acc: 0.8322 - val_loss: 0.3721 - val_acc: 0.8416\n",
      "Epoch 4/100\n",
      "1943/1943 [==============================] - 1s 327us/step - loss: 0.3915 - acc: 0.8353 - val_loss: 0.3630 - val_acc: 0.8560\n",
      "Epoch 5/100\n",
      "1943/1943 [==============================] - 1s 326us/step - loss: 0.3751 - acc: 0.8405 - val_loss: 0.3533 - val_acc: 0.8580\n",
      "Epoch 6/100\n",
      "1943/1943 [==============================] - 1s 332us/step - loss: 0.3700 - acc: 0.8374 - val_loss: 0.3505 - val_acc: 0.8580\n",
      "Epoch 7/100\n",
      "1943/1943 [==============================] - 1s 332us/step - loss: 0.3495 - acc: 0.8471 - val_loss: 0.3434 - val_acc: 0.8601\n",
      "Epoch 8/100\n",
      "1943/1943 [==============================] - 1s 326us/step - loss: 0.3461 - acc: 0.8528 - val_loss: 0.3327 - val_acc: 0.8663\n",
      "Epoch 9/100\n",
      "1943/1943 [==============================] - 1s 329us/step - loss: 0.3288 - acc: 0.8590 - val_loss: 0.3321 - val_acc: 0.8704\n",
      "Epoch 10/100\n",
      "1943/1943 [==============================] - 1s 328us/step - loss: 0.3217 - acc: 0.8682 - val_loss: 0.3255 - val_acc: 0.8704\n",
      "Epoch 11/100\n",
      "1943/1943 [==============================] - 1s 339us/step - loss: 0.3277 - acc: 0.8657 - val_loss: 0.3263 - val_acc: 0.8745\n",
      "Epoch 12/100\n",
      "1943/1943 [==============================] - 1s 343us/step - loss: 0.3215 - acc: 0.8626 - val_loss: 0.3185 - val_acc: 0.8683\n",
      "Epoch 13/100\n",
      "1943/1943 [==============================] - 1s 331us/step - loss: 0.3092 - acc: 0.8734 - val_loss: 0.3144 - val_acc: 0.8704\n",
      "Epoch 14/100\n",
      "1943/1943 [==============================] - 1s 330us/step - loss: 0.3162 - acc: 0.8698 - val_loss: 0.3127 - val_acc: 0.8786\n",
      "Epoch 15/100\n",
      "1943/1943 [==============================] - 1s 328us/step - loss: 0.2874 - acc: 0.8760 - val_loss: 0.3092 - val_acc: 0.8807\n",
      "Epoch 16/100\n",
      "1943/1943 [==============================] - 1s 329us/step - loss: 0.2934 - acc: 0.8791 - val_loss: 0.3086 - val_acc: 0.8786\n",
      "Epoch 17/100\n",
      "1943/1943 [==============================] - 1s 329us/step - loss: 0.2928 - acc: 0.8760 - val_loss: 0.3024 - val_acc: 0.8807\n",
      "Epoch 18/100\n",
      "1943/1943 [==============================] - 1s 325us/step - loss: 0.2901 - acc: 0.8770 - val_loss: 0.3044 - val_acc: 0.8786\n",
      "Epoch 19/100\n",
      "1943/1943 [==============================] - 1s 330us/step - loss: 0.2814 - acc: 0.8883 - val_loss: 0.2998 - val_acc: 0.8786\n",
      "Epoch 20/100\n",
      "1943/1943 [==============================] - 1s 326us/step - loss: 0.2786 - acc: 0.8791 - val_loss: 0.2978 - val_acc: 0.8765\n",
      "Epoch 21/100\n",
      "1943/1943 [==============================] - 1s 332us/step - loss: 0.2752 - acc: 0.8904 - val_loss: 0.2924 - val_acc: 0.8745\n",
      "Epoch 22/100\n",
      "1943/1943 [==============================] - 1s 323us/step - loss: 0.2781 - acc: 0.8929 - val_loss: 0.2928 - val_acc: 0.8765\n",
      "Epoch 23/100\n",
      "1943/1943 [==============================] - 1s 329us/step - loss: 0.2711 - acc: 0.8940 - val_loss: 0.2858 - val_acc: 0.8724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "1943/1943 [==============================] - 1s 327us/step - loss: 0.2712 - acc: 0.8837 - val_loss: 0.2897 - val_acc: 0.8765\n",
      "Epoch 25/100\n",
      "1943/1943 [==============================] - 1s 326us/step - loss: 0.2650 - acc: 0.8893 - val_loss: 0.2877 - val_acc: 0.8765\n",
      "Epoch 26/100\n",
      "1943/1943 [==============================] - 1s 330us/step - loss: 0.2662 - acc: 0.8919 - val_loss: 0.2864 - val_acc: 0.8786\n",
      "Epoch 27/100\n",
      "1943/1943 [==============================] - 1s 332us/step - loss: 0.2654 - acc: 0.8893 - val_loss: 0.2829 - val_acc: 0.8765\n",
      "Epoch 28/100\n",
      "1943/1943 [==============================] - 1s 325us/step - loss: 0.2587 - acc: 0.8971 - val_loss: 0.2792 - val_acc: 0.8786\n",
      "Epoch 29/100\n",
      "1943/1943 [==============================] - 1s 328us/step - loss: 0.2522 - acc: 0.8945 - val_loss: 0.2736 - val_acc: 0.8807\n",
      "Epoch 30/100\n",
      "1943/1943 [==============================] - 1s 318us/step - loss: 0.2572 - acc: 0.8976 - val_loss: 0.2778 - val_acc: 0.8786\n",
      "Epoch 31/100\n",
      "1943/1943 [==============================] - 1s 338us/step - loss: 0.2491 - acc: 0.9007 - val_loss: 0.2737 - val_acc: 0.8745\n",
      "Epoch 32/100\n",
      "1943/1943 [==============================] - 1s 329us/step - loss: 0.2474 - acc: 0.9017 - val_loss: 0.2721 - val_acc: 0.8765\n",
      "Epoch 33/100\n",
      "1943/1943 [==============================] - 1s 333us/step - loss: 0.2502 - acc: 0.9048 - val_loss: 0.2726 - val_acc: 0.8786\n",
      "Epoch 34/100\n",
      "1943/1943 [==============================] - 1s 326us/step - loss: 0.2436 - acc: 0.9084 - val_loss: 0.2712 - val_acc: 0.8765\n",
      "Epoch 35/100\n",
      "1943/1943 [==============================] - 1s 329us/step - loss: 0.2507 - acc: 0.9002 - val_loss: 0.2730 - val_acc: 0.8807\n",
      "Epoch 36/100\n",
      "1943/1943 [==============================] - 1s 323us/step - loss: 0.2393 - acc: 0.9048 - val_loss: 0.2691 - val_acc: 0.8765\n",
      "Epoch 37/100\n",
      "1943/1943 [==============================] - 1s 331us/step - loss: 0.2420 - acc: 0.9048 - val_loss: 0.2675 - val_acc: 0.8786\n",
      "Epoch 38/100\n",
      "1943/1943 [==============================] - 1s 329us/step - loss: 0.2400 - acc: 0.9038 - val_loss: 0.2653 - val_acc: 0.8765\n",
      "Epoch 39/100\n",
      "1943/1943 [==============================] - 1s 323us/step - loss: 0.2414 - acc: 0.9007 - val_loss: 0.2671 - val_acc: 0.8786\n",
      "Epoch 40/100\n",
      "1943/1943 [==============================] - 1s 337us/step - loss: 0.2300 - acc: 0.9094 - val_loss: 0.2640 - val_acc: 0.8807\n",
      "Epoch 41/100\n",
      "1943/1943 [==============================] - 1s 326us/step - loss: 0.2350 - acc: 0.9079 - val_loss: 0.2614 - val_acc: 0.8827\n",
      "Epoch 42/100\n",
      "1943/1943 [==============================] - 1s 326us/step - loss: 0.2311 - acc: 0.9125 - val_loss: 0.2627 - val_acc: 0.8848\n",
      "Epoch 43/100\n",
      "1943/1943 [==============================] - 1s 330us/step - loss: 0.2293 - acc: 0.9084 - val_loss: 0.2560 - val_acc: 0.8807\n",
      "Epoch 44/100\n",
      "1943/1943 [==============================] - 1s 321us/step - loss: 0.2298 - acc: 0.9043 - val_loss: 0.2578 - val_acc: 0.8827\n",
      "Epoch 45/100\n",
      "1943/1943 [==============================] - 1s 329us/step - loss: 0.2277 - acc: 0.9089 - val_loss: 0.2587 - val_acc: 0.8868\n",
      "Epoch 46/100\n",
      "1943/1943 [==============================] - 1s 331us/step - loss: 0.2276 - acc: 0.9104 - val_loss: 0.2552 - val_acc: 0.8868\n",
      "Epoch 47/100\n",
      "1943/1943 [==============================] - 1s 329us/step - loss: 0.2272 - acc: 0.9125 - val_loss: 0.2560 - val_acc: 0.8868\n",
      "Epoch 48/100\n",
      "1943/1943 [==============================] - 1s 329us/step - loss: 0.2272 - acc: 0.9110 - val_loss: 0.2541 - val_acc: 0.8868\n",
      "Epoch 49/100\n",
      "1943/1943 [==============================] - 1s 327us/step - loss: 0.2243 - acc: 0.9115 - val_loss: 0.2542 - val_acc: 0.8868\n",
      "Epoch 50/100\n",
      "1943/1943 [==============================] - 1s 326us/step - loss: 0.2176 - acc: 0.9171 - val_loss: 0.2531 - val_acc: 0.8868\n",
      "Epoch 51/100\n",
      "1943/1943 [==============================] - 1s 334us/step - loss: 0.2225 - acc: 0.9115 - val_loss: 0.2504 - val_acc: 0.8868\n",
      "Epoch 52/100\n",
      "1943/1943 [==============================] - 1s 336us/step - loss: 0.2153 - acc: 0.9197 - val_loss: 0.2488 - val_acc: 0.8868\n",
      "Epoch 53/100\n",
      "1943/1943 [==============================] - 1s 326us/step - loss: 0.2141 - acc: 0.9151 - val_loss: 0.2480 - val_acc: 0.8889\n",
      "Epoch 54/100\n",
      "1943/1943 [==============================] - 1s 336us/step - loss: 0.2209 - acc: 0.9115 - val_loss: 0.2487 - val_acc: 0.8889\n",
      "Epoch 55/100\n",
      "1943/1943 [==============================] - 1s 322us/step - loss: 0.2196 - acc: 0.9120 - val_loss: 0.2469 - val_acc: 0.8930\n",
      "Epoch 56/100\n",
      "1943/1943 [==============================] - 1s 326us/step - loss: 0.2173 - acc: 0.9166 - val_loss: 0.2498 - val_acc: 0.8868\n",
      "Epoch 57/100\n",
      "1943/1943 [==============================] - 1s 326us/step - loss: 0.2107 - acc: 0.9166 - val_loss: 0.2461 - val_acc: 0.8909\n",
      "Epoch 58/100\n",
      "1943/1943 [==============================] - 1s 324us/step - loss: 0.2111 - acc: 0.9156 - val_loss: 0.2470 - val_acc: 0.8889\n",
      "Epoch 59/100\n",
      "1943/1943 [==============================] - 1s 326us/step - loss: 0.2163 - acc: 0.9177 - val_loss: 0.2486 - val_acc: 0.8889\n",
      "Epoch 60/100\n",
      "1943/1943 [==============================] - 1s 331us/step - loss: 0.2098 - acc: 0.9223 - val_loss: 0.2441 - val_acc: 0.8930\n",
      "Epoch 61/100\n",
      "1943/1943 [==============================] - 1s 327us/step - loss: 0.2126 - acc: 0.9141 - val_loss: 0.2442 - val_acc: 0.8930\n",
      "Epoch 62/100\n",
      "1943/1943 [==============================] - 1s 327us/step - loss: 0.2068 - acc: 0.9192 - val_loss: 0.2440 - val_acc: 0.8909\n",
      "Epoch 63/100\n",
      "1943/1943 [==============================] - 1s 327us/step - loss: 0.2061 - acc: 0.9228 - val_loss: 0.2414 - val_acc: 0.8909\n",
      "Epoch 64/100\n",
      "1943/1943 [==============================] - 1s 325us/step - loss: 0.2063 - acc: 0.9249 - val_loss: 0.2422 - val_acc: 0.8909\n",
      "Epoch 65/100\n",
      "1943/1943 [==============================] - 1s 330us/step - loss: 0.2033 - acc: 0.9218 - val_loss: 0.2431 - val_acc: 0.8930\n",
      "Epoch 66/100\n",
      "1943/1943 [==============================] - 1s 327us/step - loss: 0.2039 - acc: 0.9223 - val_loss: 0.2436 - val_acc: 0.8909\n",
      "Epoch 67/100\n",
      "1943/1943 [==============================] - 1s 330us/step - loss: 0.2019 - acc: 0.9192 - val_loss: 0.2436 - val_acc: 0.8930\n",
      "Epoch 68/100\n",
      "1943/1943 [==============================] - 1s 325us/step - loss: 0.2005 - acc: 0.9197 - val_loss: 0.2447 - val_acc: 0.8930\n",
      "Epoch 69/100\n",
      "1943/1943 [==============================] - 1s 325us/step - loss: 0.1981 - acc: 0.9233 - val_loss: 0.2416 - val_acc: 0.8951\n",
      "Epoch 70/100\n",
      "1943/1943 [==============================] - 1s 331us/step - loss: 0.2019 - acc: 0.9295 - val_loss: 0.2443 - val_acc: 0.8909\n",
      "Epoch 71/100\n",
      "1943/1943 [==============================] - 1s 330us/step - loss: 0.2019 - acc: 0.9249 - val_loss: 0.2436 - val_acc: 0.8951\n",
      "Epoch 72/100\n",
      "1943/1943 [==============================] - 1s 325us/step - loss: 0.2040 - acc: 0.9238 - val_loss: 0.2416 - val_acc: 0.8992\n",
      "Epoch 73/100\n",
      "1943/1943 [==============================] - 1s 327us/step - loss: 0.1984 - acc: 0.9269 - val_loss: 0.2399 - val_acc: 0.8951\n",
      "Epoch 74/100\n",
      "1943/1943 [==============================] - 1s 331us/step - loss: 0.1965 - acc: 0.9243 - val_loss: 0.2414 - val_acc: 0.8951\n",
      "Epoch 75/100\n",
      "1943/1943 [==============================] - 1s 323us/step - loss: 0.2041 - acc: 0.9238 - val_loss: 0.2414 - val_acc: 0.8951\n",
      "Epoch 76/100\n",
      "1943/1943 [==============================] - 1s 331us/step - loss: 0.1981 - acc: 0.9207 - val_loss: 0.2387 - val_acc: 0.8971\n",
      "Epoch 77/100\n",
      "1943/1943 [==============================] - 1s 336us/step - loss: 0.1919 - acc: 0.9310 - val_loss: 0.2366 - val_acc: 0.9053\n",
      "Epoch 78/100\n",
      "1943/1943 [==============================] - 1s 339us/step - loss: 0.1900 - acc: 0.9254 - val_loss: 0.2389 - val_acc: 0.9012\n",
      "Epoch 79/100\n",
      "1943/1943 [==============================] - 1s 333us/step - loss: 0.1986 - acc: 0.9279 - val_loss: 0.2369 - val_acc: 0.9012\n",
      "Epoch 80/100\n",
      "1943/1943 [==============================] - 1s 331us/step - loss: 0.1958 - acc: 0.9218 - val_loss: 0.2373 - val_acc: 0.9033\n",
      "Epoch 81/100\n",
      "1943/1943 [==============================] - 1s 331us/step - loss: 0.1967 - acc: 0.9269 - val_loss: 0.2364 - val_acc: 0.9033\n",
      "Epoch 82/100\n",
      "1943/1943 [==============================] - 1s 328us/step - loss: 0.1874 - acc: 0.9341 - val_loss: 0.2378 - val_acc: 0.9012\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1943/1943 [==============================] - 1s 325us/step - loss: 0.1919 - acc: 0.9300 - val_loss: 0.2373 - val_acc: 0.9012\n",
      "Epoch 84/100\n",
      "1943/1943 [==============================] - 1s 331us/step - loss: 0.1893 - acc: 0.9213 - val_loss: 0.2353 - val_acc: 0.9033\n",
      "Epoch 85/100\n",
      "1943/1943 [==============================] - 1s 321us/step - loss: 0.1850 - acc: 0.9279 - val_loss: 0.2341 - val_acc: 0.9012\n",
      "Epoch 86/100\n",
      "1943/1943 [==============================] - 1s 325us/step - loss: 0.1848 - acc: 0.9331 - val_loss: 0.2325 - val_acc: 0.9033\n",
      "Epoch 87/100\n",
      "1943/1943 [==============================] - 1s 331us/step - loss: 0.1977 - acc: 0.9269 - val_loss: 0.2323 - val_acc: 0.8992\n",
      "Epoch 88/100\n",
      "1943/1943 [==============================] - 1s 332us/step - loss: 0.1844 - acc: 0.9233 - val_loss: 0.2302 - val_acc: 0.9074\n",
      "Epoch 89/100\n",
      "1943/1943 [==============================] - 1s 328us/step - loss: 0.1901 - acc: 0.9274 - val_loss: 0.2312 - val_acc: 0.9012\n",
      "Epoch 90/100\n",
      "1943/1943 [==============================] - 1s 326us/step - loss: 0.1879 - acc: 0.9269 - val_loss: 0.2292 - val_acc: 0.9095\n",
      "Epoch 91/100\n",
      "1943/1943 [==============================] - 1s 336us/step - loss: 0.1809 - acc: 0.9305 - val_loss: 0.2320 - val_acc: 0.9012\n",
      "Epoch 92/100\n",
      "1943/1943 [==============================] - 1s 328us/step - loss: 0.1845 - acc: 0.9259 - val_loss: 0.2302 - val_acc: 0.9053\n",
      "Epoch 93/100\n",
      "1943/1943 [==============================] - 1s 329us/step - loss: 0.1904 - acc: 0.9290 - val_loss: 0.2302 - val_acc: 0.9033\n",
      "Epoch 94/100\n",
      "1943/1943 [==============================] - 1s 327us/step - loss: 0.1865 - acc: 0.9295 - val_loss: 0.2303 - val_acc: 0.9033\n",
      "Epoch 95/100\n",
      "1943/1943 [==============================] - 1s 328us/step - loss: 0.1867 - acc: 0.9310 - val_loss: 0.2299 - val_acc: 0.8992\n",
      "Epoch 96/100\n",
      "1943/1943 [==============================] - 1s 327us/step - loss: 0.1770 - acc: 0.9362 - val_loss: 0.2296 - val_acc: 0.9012\n",
      "Epoch 97/100\n",
      "1943/1943 [==============================] - 1s 324us/step - loss: 0.1830 - acc: 0.9310 - val_loss: 0.2298 - val_acc: 0.8992\n",
      "Epoch 98/100\n",
      "1943/1943 [==============================] - 1s 326us/step - loss: 0.1836 - acc: 0.9315 - val_loss: 0.2288 - val_acc: 0.9033\n",
      "Epoch 99/100\n",
      "1943/1943 [==============================] - 1s 332us/step - loss: 0.1812 - acc: 0.9290 - val_loss: 0.2280 - val_acc: 0.9095\n",
      "Epoch 100/100\n",
      "1943/1943 [==============================] - 1s 328us/step - loss: 0.1788 - acc: 0.9290 - val_loss: 0.2284 - val_acc: 0.9095\n",
      "Train on 1943 samples, validate on 486 samples\n",
      "Epoch 1/100\n",
      "1943/1943 [==============================] - 1s 322us/step - loss: 0.2097 - acc: 0.9187 - val_loss: 0.1977 - val_acc: 0.9239\n",
      "Epoch 2/100\n",
      "1943/1943 [==============================] - 1s 330us/step - loss: 0.2032 - acc: 0.9182 - val_loss: 0.1954 - val_acc: 0.9239\n",
      "Epoch 3/100\n",
      "1943/1943 [==============================] - 1s 325us/step - loss: 0.2070 - acc: 0.9125 - val_loss: 0.1897 - val_acc: 0.9259\n",
      "Epoch 4/100\n",
      "1943/1943 [==============================] - 1s 329us/step - loss: 0.2030 - acc: 0.9192 - val_loss: 0.1897 - val_acc: 0.9259\n",
      "Epoch 5/100\n",
      "1943/1943 [==============================] - 1s 331us/step - loss: 0.2069 - acc: 0.9233 - val_loss: 0.1905 - val_acc: 0.9259\n",
      "Epoch 6/100\n",
      "1943/1943 [==============================] - 1s 325us/step - loss: 0.1968 - acc: 0.9274 - val_loss: 0.1893 - val_acc: 0.9259\n",
      "Epoch 7/100\n",
      "1943/1943 [==============================] - 1s 323us/step - loss: 0.1981 - acc: 0.9182 - val_loss: 0.1886 - val_acc: 0.9259\n",
      "Epoch 8/100\n",
      "1943/1943 [==============================] - 1s 329us/step - loss: 0.1948 - acc: 0.9213 - val_loss: 0.1885 - val_acc: 0.9259\n",
      "Epoch 9/100\n",
      "1943/1943 [==============================] - 1s 333us/step - loss: 0.1955 - acc: 0.9259 - val_loss: 0.1887 - val_acc: 0.9259\n",
      "Epoch 10/100\n",
      "1943/1943 [==============================] - 1s 329us/step - loss: 0.1932 - acc: 0.9228 - val_loss: 0.1855 - val_acc: 0.9259\n",
      "Epoch 11/100\n",
      "1943/1943 [==============================] - 1s 328us/step - loss: 0.1881 - acc: 0.9238 - val_loss: 0.1866 - val_acc: 0.9259\n",
      "Epoch 12/100\n",
      "1943/1943 [==============================] - 1s 330us/step - loss: 0.1881 - acc: 0.9233 - val_loss: 0.1825 - val_acc: 0.9259\n",
      "Epoch 13/100\n",
      "1943/1943 [==============================] - 1s 331us/step - loss: 0.1905 - acc: 0.9218 - val_loss: 0.1843 - val_acc: 0.9259\n",
      "Epoch 14/100\n",
      "1943/1943 [==============================] - 1s 335us/step - loss: 0.1843 - acc: 0.9238 - val_loss: 0.1834 - val_acc: 0.9259\n",
      "Epoch 15/100\n",
      "1943/1943 [==============================] - 1s 324us/step - loss: 0.1844 - acc: 0.9218 - val_loss: 0.1812 - val_acc: 0.9259\n",
      "Epoch 16/100\n",
      "1943/1943 [==============================] - 1s 340us/step - loss: 0.1844 - acc: 0.9279 - val_loss: 0.1825 - val_acc: 0.9259\n",
      "Epoch 17/100\n",
      "1943/1943 [==============================] - 1s 325us/step - loss: 0.1868 - acc: 0.9295 - val_loss: 0.1830 - val_acc: 0.9259\n",
      "Epoch 18/100\n",
      "1943/1943 [==============================] - 1s 324us/step - loss: 0.1854 - acc: 0.9279 - val_loss: 0.1820 - val_acc: 0.9259\n",
      "Epoch 19/100\n",
      "1943/1943 [==============================] - 1s 329us/step - loss: 0.1879 - acc: 0.9279 - val_loss: 0.1767 - val_acc: 0.9259\n",
      "Epoch 20/100\n",
      "1943/1943 [==============================] - 1s 322us/step - loss: 0.1829 - acc: 0.9279 - val_loss: 0.1799 - val_acc: 0.9259\n",
      "Epoch 21/100\n",
      "1943/1943 [==============================] - 1s 330us/step - loss: 0.1791 - acc: 0.9300 - val_loss: 0.1811 - val_acc: 0.9259\n",
      "Epoch 22/100\n",
      "1943/1943 [==============================] - 1s 324us/step - loss: 0.1822 - acc: 0.9310 - val_loss: 0.1776 - val_acc: 0.9259\n",
      "Epoch 23/100\n",
      "1943/1943 [==============================] - 1s 320us/step - loss: 0.1785 - acc: 0.9279 - val_loss: 0.1779 - val_acc: 0.9259\n",
      "Epoch 24/100\n",
      "1943/1943 [==============================] - 1s 330us/step - loss: 0.1859 - acc: 0.9290 - val_loss: 0.1766 - val_acc: 0.9259\n",
      "Epoch 25/100\n",
      "1943/1943 [==============================] - 1s 333us/step - loss: 0.1753 - acc: 0.9285 - val_loss: 0.1766 - val_acc: 0.9259\n",
      "Epoch 26/100\n",
      "1943/1943 [==============================] - 1s 327us/step - loss: 0.1857 - acc: 0.9238 - val_loss: 0.1791 - val_acc: 0.9280\n",
      "Epoch 27/100\n",
      "1943/1943 [==============================] - 1s 329us/step - loss: 0.1743 - acc: 0.9315 - val_loss: 0.1770 - val_acc: 0.9300\n",
      "Epoch 28/100\n",
      "1943/1943 [==============================] - 1s 327us/step - loss: 0.1728 - acc: 0.9290 - val_loss: 0.1769 - val_acc: 0.9280\n",
      "Epoch 29/100\n",
      "1943/1943 [==============================] - 1s 332us/step - loss: 0.1773 - acc: 0.9300 - val_loss: 0.1745 - val_acc: 0.9300\n",
      "Epoch 30/100\n",
      "1943/1943 [==============================] - 1s 332us/step - loss: 0.1734 - acc: 0.9341 - val_loss: 0.1729 - val_acc: 0.9342\n",
      "Epoch 31/100\n",
      "1943/1943 [==============================] - 1s 328us/step - loss: 0.1752 - acc: 0.9310 - val_loss: 0.1763 - val_acc: 0.9321\n",
      "Epoch 32/100\n",
      "1943/1943 [==============================] - 1s 345us/step - loss: 0.1675 - acc: 0.9362 - val_loss: 0.1768 - val_acc: 0.9321\n",
      "Epoch 33/100\n",
      "1943/1943 [==============================] - 1s 323us/step - loss: 0.1783 - acc: 0.9305 - val_loss: 0.1754 - val_acc: 0.9321\n",
      "Epoch 34/100\n",
      "1943/1943 [==============================] - 1s 336us/step - loss: 0.1777 - acc: 0.9295 - val_loss: 0.1720 - val_acc: 0.9342\n",
      "Epoch 35/100\n",
      "1943/1943 [==============================] - 1s 329us/step - loss: 0.1716 - acc: 0.9377 - val_loss: 0.1749 - val_acc: 0.9342\n",
      "Epoch 36/100\n",
      "1943/1943 [==============================] - 1s 328us/step - loss: 0.1674 - acc: 0.9346 - val_loss: 0.1700 - val_acc: 0.9342\n",
      "Epoch 37/100\n",
      "1943/1943 [==============================] - 1s 322us/step - loss: 0.1696 - acc: 0.9367 - val_loss: 0.1740 - val_acc: 0.9342\n",
      "Epoch 38/100\n",
      "1943/1943 [==============================] - 1s 327us/step - loss: 0.1738 - acc: 0.9341 - val_loss: 0.1751 - val_acc: 0.9342\n",
      "Epoch 39/100\n",
      "1943/1943 [==============================] - 1s 331us/step - loss: 0.1694 - acc: 0.9352 - val_loss: 0.1715 - val_acc: 0.9342\n",
      "Epoch 40/100\n",
      "1943/1943 [==============================] - 1s 321us/step - loss: 0.1657 - acc: 0.9346 - val_loss: 0.1729 - val_acc: 0.9342\n",
      "Epoch 41/100\n",
      "1943/1943 [==============================] - 1s 327us/step - loss: 0.1720 - acc: 0.9352 - val_loss: 0.1706 - val_acc: 0.9342\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1943/1943 [==============================] - 1s 329us/step - loss: 0.1658 - acc: 0.9367 - val_loss: 0.1693 - val_acc: 0.9342\n",
      "Epoch 43/100\n",
      "1943/1943 [==============================] - 1s 321us/step - loss: 0.1682 - acc: 0.9310 - val_loss: 0.1701 - val_acc: 0.9342\n",
      "Epoch 44/100\n",
      "1943/1943 [==============================] - 1s 329us/step - loss: 0.1697 - acc: 0.9295 - val_loss: 0.1701 - val_acc: 0.9342\n",
      "Epoch 45/100\n",
      "1943/1943 [==============================] - 1s 335us/step - loss: 0.1642 - acc: 0.9408 - val_loss: 0.1680 - val_acc: 0.9342\n",
      "Epoch 46/100\n",
      "1943/1943 [==============================] - 1s 340us/step - loss: 0.1692 - acc: 0.9434 - val_loss: 0.1693 - val_acc: 0.9342\n",
      "Epoch 47/100\n",
      "1943/1943 [==============================] - 1s 327us/step - loss: 0.1646 - acc: 0.9346 - val_loss: 0.1672 - val_acc: 0.9342\n",
      "Epoch 48/100\n",
      "1943/1943 [==============================] - 1s 330us/step - loss: 0.1582 - acc: 0.9408 - val_loss: 0.1644 - val_acc: 0.9342\n",
      "Epoch 49/100\n",
      "1943/1943 [==============================] - 1s 329us/step - loss: 0.1617 - acc: 0.9403 - val_loss: 0.1627 - val_acc: 0.9342\n",
      "Epoch 50/100\n",
      "1943/1943 [==============================] - 1s 325us/step - loss: 0.1627 - acc: 0.9372 - val_loss: 0.1639 - val_acc: 0.9342\n",
      "Epoch 51/100\n",
      "1943/1943 [==============================] - 1s 331us/step - loss: 0.1686 - acc: 0.9315 - val_loss: 0.1682 - val_acc: 0.9362\n",
      "Epoch 52/100\n",
      "1943/1943 [==============================] - 1s 330us/step - loss: 0.1661 - acc: 0.9372 - val_loss: 0.1617 - val_acc: 0.9321\n",
      "Epoch 53/100\n",
      "1943/1943 [==============================] - 1s 325us/step - loss: 0.1612 - acc: 0.9336 - val_loss: 0.1674 - val_acc: 0.9362\n",
      "Epoch 54/100\n",
      "1943/1943 [==============================] - 1s 329us/step - loss: 0.1671 - acc: 0.9362 - val_loss: 0.1666 - val_acc: 0.9362\n",
      "Epoch 55/100\n",
      "1943/1943 [==============================] - 1s 327us/step - loss: 0.1599 - acc: 0.9403 - val_loss: 0.1642 - val_acc: 0.9321\n",
      "Epoch 56/100\n",
      "1943/1943 [==============================] - 1s 322us/step - loss: 0.1547 - acc: 0.9470 - val_loss: 0.1629 - val_acc: 0.9321\n",
      "Epoch 57/100\n",
      "1943/1943 [==============================] - 1s 327us/step - loss: 0.1576 - acc: 0.9403 - val_loss: 0.1603 - val_acc: 0.9321\n",
      "Epoch 58/100\n",
      "1943/1943 [==============================] - 1s 328us/step - loss: 0.1526 - acc: 0.9444 - val_loss: 0.1633 - val_acc: 0.9362\n",
      "Epoch 59/100\n",
      "1943/1943 [==============================] - 1s 322us/step - loss: 0.1506 - acc: 0.9470 - val_loss: 0.1608 - val_acc: 0.9362\n",
      "Epoch 60/100\n",
      "1943/1943 [==============================] - 1s 325us/step - loss: 0.1534 - acc: 0.9434 - val_loss: 0.1627 - val_acc: 0.9362\n",
      "Epoch 61/100\n",
      "1943/1943 [==============================] - 1s 331us/step - loss: 0.1569 - acc: 0.9367 - val_loss: 0.1618 - val_acc: 0.9362\n",
      "Epoch 62/100\n",
      "1943/1943 [==============================] - 1s 324us/step - loss: 0.1595 - acc: 0.9372 - val_loss: 0.1615 - val_acc: 0.9362\n",
      "Epoch 63/100\n",
      "1943/1943 [==============================] - 1s 333us/step - loss: 0.1521 - acc: 0.9429 - val_loss: 0.1601 - val_acc: 0.9362\n",
      "Epoch 64/100\n",
      "1943/1943 [==============================] - 1s 324us/step - loss: 0.1545 - acc: 0.9434 - val_loss: 0.1571 - val_acc: 0.9362\n",
      "Epoch 65/100\n",
      "1943/1943 [==============================] - 1s 333us/step - loss: 0.1624 - acc: 0.9382 - val_loss: 0.1559 - val_acc: 0.9342\n",
      "Epoch 66/100\n",
      "1943/1943 [==============================] - 1s 327us/step - loss: 0.1552 - acc: 0.9439 - val_loss: 0.1575 - val_acc: 0.9342\n",
      "Epoch 67/100\n",
      "1943/1943 [==============================] - 1s 328us/step - loss: 0.1595 - acc: 0.9393 - val_loss: 0.1553 - val_acc: 0.9342\n",
      "Epoch 68/100\n",
      "1943/1943 [==============================] - 1s 330us/step - loss: 0.1534 - acc: 0.9439 - val_loss: 0.1569 - val_acc: 0.9342\n",
      "Epoch 69/100\n",
      "1943/1943 [==============================] - 1s 325us/step - loss: 0.1480 - acc: 0.9454 - val_loss: 0.1588 - val_acc: 0.9362\n",
      "Epoch 70/100\n",
      "1943/1943 [==============================] - 1s 326us/step - loss: 0.1523 - acc: 0.9439 - val_loss: 0.1579 - val_acc: 0.9362\n",
      "Epoch 71/100\n",
      "1943/1943 [==============================] - 1s 333us/step - loss: 0.1561 - acc: 0.9413 - val_loss: 0.1604 - val_acc: 0.9362\n",
      "Epoch 72/100\n",
      "1943/1943 [==============================] - 1s 323us/step - loss: 0.1518 - acc: 0.9449 - val_loss: 0.1608 - val_acc: 0.9362\n",
      "Epoch 73/100\n",
      "1943/1943 [==============================] - 1s 323us/step - loss: 0.1513 - acc: 0.9429 - val_loss: 0.1569 - val_acc: 0.9362\n",
      "Epoch 74/100\n",
      "1943/1943 [==============================] - 1s 322us/step - loss: 0.1513 - acc: 0.9439 - val_loss: 0.1575 - val_acc: 0.9362\n",
      "Epoch 75/100\n",
      "1943/1943 [==============================] - 1s 330us/step - loss: 0.1477 - acc: 0.9449 - val_loss: 0.1563 - val_acc: 0.9362\n",
      "Epoch 76/100\n",
      "1943/1943 [==============================] - 1s 332us/step - loss: 0.1446 - acc: 0.9460 - val_loss: 0.1586 - val_acc: 0.9362\n",
      "Epoch 77/100\n",
      "1943/1943 [==============================] - 1s 333us/step - loss: 0.1426 - acc: 0.9444 - val_loss: 0.1567 - val_acc: 0.9362\n",
      "Epoch 78/100\n",
      "1943/1943 [==============================] - 1s 327us/step - loss: 0.1477 - acc: 0.9434 - val_loss: 0.1563 - val_acc: 0.9362\n",
      "Epoch 79/100\n",
      "1943/1943 [==============================] - 1s 325us/step - loss: 0.1524 - acc: 0.9424 - val_loss: 0.1518 - val_acc: 0.9342\n",
      "Epoch 80/100\n",
      "1943/1943 [==============================] - 1s 325us/step - loss: 0.1483 - acc: 0.9408 - val_loss: 0.1550 - val_acc: 0.9342\n",
      "Epoch 81/100\n",
      "1943/1943 [==============================] - 1s 330us/step - loss: 0.1535 - acc: 0.9460 - val_loss: 0.1560 - val_acc: 0.9362\n",
      "Epoch 82/100\n",
      "1943/1943 [==============================] - 1s 333us/step - loss: 0.1387 - acc: 0.9444 - val_loss: 0.1517 - val_acc: 0.9362\n",
      "Epoch 83/100\n",
      "1943/1943 [==============================] - 1s 325us/step - loss: 0.1463 - acc: 0.9490 - val_loss: 0.1507 - val_acc: 0.9362\n",
      "Epoch 84/100\n",
      "1943/1943 [==============================] - 1s 327us/step - loss: 0.1432 - acc: 0.9449 - val_loss: 0.1517 - val_acc: 0.9362\n",
      "Epoch 85/100\n",
      "1943/1943 [==============================] - 1s 322us/step - loss: 0.1420 - acc: 0.9465 - val_loss: 0.1515 - val_acc: 0.9362\n",
      "Epoch 86/100\n",
      "1943/1943 [==============================] - 1s 330us/step - loss: 0.1560 - acc: 0.9408 - val_loss: 0.1543 - val_acc: 0.9383\n",
      "Epoch 87/100\n",
      "1943/1943 [==============================] - 1s 332us/step - loss: 0.1445 - acc: 0.9506 - val_loss: 0.1528 - val_acc: 0.9383\n",
      "Epoch 88/100\n",
      "1943/1943 [==============================] - 1s 324us/step - loss: 0.1393 - acc: 0.9516 - val_loss: 0.1516 - val_acc: 0.9383\n",
      "Epoch 89/100\n",
      "1943/1943 [==============================] - 1s 321us/step - loss: 0.1413 - acc: 0.9470 - val_loss: 0.1514 - val_acc: 0.9362\n",
      "Epoch 90/100\n",
      "1943/1943 [==============================] - 1s 326us/step - loss: 0.1451 - acc: 0.9444 - val_loss: 0.1553 - val_acc: 0.9383\n",
      "Epoch 91/100\n",
      "1943/1943 [==============================] - 1s 328us/step - loss: 0.1398 - acc: 0.9470 - val_loss: 0.1480 - val_acc: 0.9342\n",
      "Epoch 92/100\n",
      "1943/1943 [==============================] - 1s 330us/step - loss: 0.1404 - acc: 0.9439 - val_loss: 0.1491 - val_acc: 0.9383\n",
      "Epoch 93/100\n",
      "1943/1943 [==============================] - 1s 335us/step - loss: 0.1409 - acc: 0.9506 - val_loss: 0.1516 - val_acc: 0.9383\n",
      "Epoch 94/100\n",
      "1943/1943 [==============================] - 1s 328us/step - loss: 0.1344 - acc: 0.9516 - val_loss: 0.1512 - val_acc: 0.9383\n",
      "Epoch 95/100\n",
      "1943/1943 [==============================] - 1s 328us/step - loss: 0.1331 - acc: 0.9547 - val_loss: 0.1521 - val_acc: 0.9383\n",
      "Epoch 96/100\n",
      "1943/1943 [==============================] - 1s 324us/step - loss: 0.1400 - acc: 0.9475 - val_loss: 0.1509 - val_acc: 0.9383\n",
      "Epoch 97/100\n",
      "1943/1943 [==============================] - 1s 325us/step - loss: 0.1379 - acc: 0.9501 - val_loss: 0.1494 - val_acc: 0.9383\n",
      "Epoch 98/100\n",
      "1943/1943 [==============================] - 1s 329us/step - loss: 0.1352 - acc: 0.9496 - val_loss: 0.1534 - val_acc: 0.9383\n",
      "Epoch 99/100\n",
      "1943/1943 [==============================] - 1s 325us/step - loss: 0.1379 - acc: 0.9537 - val_loss: 0.1505 - val_acc: 0.9383\n",
      "Epoch 100/100\n",
      "1943/1943 [==============================] - 1s 321us/step - loss: 0.1376 - acc: 0.9511 - val_loss: 0.1513 - val_acc: 0.9383\n",
      "Test subject 11, class Replace\n",
      "Train subject 11, class BothReleased\n",
      "Train on 1944 samples, validate on 486 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 331us/step - loss: 1.0709 - acc: 0.6965 - val_loss: 0.6464 - val_acc: 0.7387\n",
      "Epoch 2/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.5007 - acc: 0.7767 - val_loss: 0.5606 - val_acc: 0.7757\n",
      "Epoch 3/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.4291 - acc: 0.8071 - val_loss: 0.5296 - val_acc: 0.7840\n",
      "Epoch 4/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.4114 - acc: 0.8236 - val_loss: 0.4763 - val_acc: 0.7942\n",
      "Epoch 5/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.3874 - acc: 0.8297 - val_loss: 0.4619 - val_acc: 0.8066\n",
      "Epoch 6/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.3674 - acc: 0.8359 - val_loss: 0.4328 - val_acc: 0.8189\n",
      "Epoch 7/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.3378 - acc: 0.8513 - val_loss: 0.4143 - val_acc: 0.8189\n",
      "Epoch 8/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.3210 - acc: 0.8560 - val_loss: 0.4230 - val_acc: 0.8230\n",
      "Epoch 9/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.3306 - acc: 0.8580 - val_loss: 0.3978 - val_acc: 0.8272\n",
      "Epoch 10/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.3212 - acc: 0.8621 - val_loss: 0.4000 - val_acc: 0.8354\n",
      "Epoch 11/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.3090 - acc: 0.8704 - val_loss: 0.3797 - val_acc: 0.8436\n",
      "Epoch 12/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.2976 - acc: 0.8791 - val_loss: 0.3739 - val_acc: 0.8457\n",
      "Epoch 13/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.2847 - acc: 0.8884 - val_loss: 0.3620 - val_acc: 0.8498\n",
      "Epoch 14/100\n",
      "1944/1944 [==============================] - 1s 321us/step - loss: 0.2826 - acc: 0.8879 - val_loss: 0.3516 - val_acc: 0.8498\n",
      "Epoch 15/100\n",
      "1944/1944 [==============================] - 1s 336us/step - loss: 0.2706 - acc: 0.8853 - val_loss: 0.3543 - val_acc: 0.8498\n",
      "Epoch 16/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.2678 - acc: 0.8884 - val_loss: 0.3488 - val_acc: 0.8477\n",
      "Epoch 17/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.2578 - acc: 0.8971 - val_loss: 0.3454 - val_acc: 0.8477\n",
      "Epoch 18/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.2593 - acc: 0.8915 - val_loss: 0.3331 - val_acc: 0.8560\n",
      "Epoch 19/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.2520 - acc: 0.8992 - val_loss: 0.3266 - val_acc: 0.8580\n",
      "Epoch 20/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.2463 - acc: 0.8940 - val_loss: 0.3277 - val_acc: 0.8580\n",
      "Epoch 21/100\n",
      "1944/1944 [==============================] - 1s 334us/step - loss: 0.2494 - acc: 0.9023 - val_loss: 0.3260 - val_acc: 0.8663\n",
      "Epoch 22/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.2414 - acc: 0.9038 - val_loss: 0.3229 - val_acc: 0.8642\n",
      "Epoch 23/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.2451 - acc: 0.8992 - val_loss: 0.3248 - val_acc: 0.8642\n",
      "Epoch 24/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.2398 - acc: 0.9033 - val_loss: 0.3234 - val_acc: 0.8642\n",
      "Epoch 25/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.2369 - acc: 0.9059 - val_loss: 0.3143 - val_acc: 0.8704\n",
      "Epoch 26/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.2249 - acc: 0.9079 - val_loss: 0.3165 - val_acc: 0.8663\n",
      "Epoch 27/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.2316 - acc: 0.9043 - val_loss: 0.3037 - val_acc: 0.8663\n",
      "Epoch 28/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.2241 - acc: 0.9095 - val_loss: 0.2982 - val_acc: 0.8663\n",
      "Epoch 29/100\n",
      "1944/1944 [==============================] - 1s 321us/step - loss: 0.2273 - acc: 0.9131 - val_loss: 0.3019 - val_acc: 0.8704\n",
      "Epoch 30/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.2234 - acc: 0.9105 - val_loss: 0.2980 - val_acc: 0.8724\n",
      "Epoch 31/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.2203 - acc: 0.9110 - val_loss: 0.2945 - val_acc: 0.8765\n",
      "Epoch 32/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.2172 - acc: 0.9172 - val_loss: 0.2884 - val_acc: 0.8765\n",
      "Epoch 33/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.2131 - acc: 0.9172 - val_loss: 0.2886 - val_acc: 0.8745\n",
      "Epoch 34/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.2078 - acc: 0.9223 - val_loss: 0.2834 - val_acc: 0.8765\n",
      "Epoch 35/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.2131 - acc: 0.9187 - val_loss: 0.2942 - val_acc: 0.8683\n",
      "Epoch 36/100\n",
      "1944/1944 [==============================] - 1s 336us/step - loss: 0.2020 - acc: 0.9239 - val_loss: 0.2826 - val_acc: 0.8745\n",
      "Epoch 37/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.2021 - acc: 0.9167 - val_loss: 0.2818 - val_acc: 0.8786\n",
      "Epoch 38/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.2067 - acc: 0.9244 - val_loss: 0.2741 - val_acc: 0.8827\n",
      "Epoch 39/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.2091 - acc: 0.9156 - val_loss: 0.2807 - val_acc: 0.8745\n",
      "Epoch 40/100\n",
      "1944/1944 [==============================] - 1s 321us/step - loss: 0.1968 - acc: 0.9244 - val_loss: 0.2729 - val_acc: 0.8765\n",
      "Epoch 41/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1966 - acc: 0.9239 - val_loss: 0.2692 - val_acc: 0.8786\n",
      "Epoch 42/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.1944 - acc: 0.9275 - val_loss: 0.2651 - val_acc: 0.8848\n",
      "Epoch 43/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.1965 - acc: 0.9290 - val_loss: 0.2729 - val_acc: 0.8786\n",
      "Epoch 44/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.2006 - acc: 0.9198 - val_loss: 0.2631 - val_acc: 0.8889\n",
      "Epoch 45/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.1864 - acc: 0.9290 - val_loss: 0.2629 - val_acc: 0.8827\n",
      "Epoch 46/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.1896 - acc: 0.9311 - val_loss: 0.2601 - val_acc: 0.8868\n",
      "Epoch 47/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.1891 - acc: 0.9280 - val_loss: 0.2628 - val_acc: 0.8827\n",
      "Epoch 48/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.1880 - acc: 0.9331 - val_loss: 0.2596 - val_acc: 0.8848\n",
      "Epoch 49/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.1768 - acc: 0.9342 - val_loss: 0.2622 - val_acc: 0.8827\n",
      "Epoch 50/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.1729 - acc: 0.9367 - val_loss: 0.2524 - val_acc: 0.8868\n",
      "Epoch 51/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.1726 - acc: 0.9388 - val_loss: 0.2476 - val_acc: 0.8889\n",
      "Epoch 52/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.1897 - acc: 0.9285 - val_loss: 0.2565 - val_acc: 0.8827\n",
      "Epoch 53/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.1789 - acc: 0.9326 - val_loss: 0.2489 - val_acc: 0.8868\n",
      "Epoch 54/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.1743 - acc: 0.9383 - val_loss: 0.2571 - val_acc: 0.8848\n",
      "Epoch 55/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.1805 - acc: 0.9367 - val_loss: 0.2525 - val_acc: 0.8827\n",
      "Epoch 56/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.1778 - acc: 0.9331 - val_loss: 0.2497 - val_acc: 0.8827\n",
      "Epoch 57/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.1749 - acc: 0.9388 - val_loss: 0.2470 - val_acc: 0.8848\n",
      "Epoch 58/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1764 - acc: 0.9362 - val_loss: 0.2572 - val_acc: 0.8848\n",
      "Epoch 59/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.1738 - acc: 0.9342 - val_loss: 0.2533 - val_acc: 0.8848\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1737 - acc: 0.9378 - val_loss: 0.2436 - val_acc: 0.8848\n",
      "Epoch 61/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1753 - acc: 0.9372 - val_loss: 0.2548 - val_acc: 0.8827\n",
      "Epoch 62/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1776 - acc: 0.9398 - val_loss: 0.2520 - val_acc: 0.8848\n",
      "Epoch 63/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.1694 - acc: 0.9388 - val_loss: 0.2370 - val_acc: 0.8971\n",
      "Epoch 64/100\n",
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.1702 - acc: 0.9367 - val_loss: 0.2468 - val_acc: 0.8868\n",
      "Epoch 65/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.1814 - acc: 0.9342 - val_loss: 0.2411 - val_acc: 0.8889\n",
      "Epoch 66/100\n",
      "1944/1944 [==============================] - 1s 356us/step - loss: 0.1711 - acc: 0.9372 - val_loss: 0.2465 - val_acc: 0.8868\n",
      "Epoch 67/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1676 - acc: 0.9470 - val_loss: 0.2390 - val_acc: 0.8951\n",
      "Epoch 68/100\n",
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.1637 - acc: 0.9450 - val_loss: 0.2557 - val_acc: 0.8827\n",
      "Epoch 69/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.1598 - acc: 0.9434 - val_loss: 0.2415 - val_acc: 0.8909\n",
      "Epoch 70/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.1608 - acc: 0.9434 - val_loss: 0.2413 - val_acc: 0.8930\n",
      "Epoch 71/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.1594 - acc: 0.9460 - val_loss: 0.2435 - val_acc: 0.8930\n",
      "Epoch 72/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.1621 - acc: 0.9383 - val_loss: 0.2380 - val_acc: 0.8930\n",
      "Epoch 73/100\n",
      "1944/1944 [==============================] - 1s 343us/step - loss: 0.1613 - acc: 0.9408 - val_loss: 0.2446 - val_acc: 0.8909\n",
      "Epoch 74/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.1620 - acc: 0.9424 - val_loss: 0.2399 - val_acc: 0.8930\n",
      "Epoch 75/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1670 - acc: 0.9434 - val_loss: 0.2418 - val_acc: 0.8930\n",
      "Epoch 76/100\n",
      "1944/1944 [==============================] - 1s 334us/step - loss: 0.1536 - acc: 0.9532 - val_loss: 0.2391 - val_acc: 0.8909\n",
      "Epoch 77/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.1518 - acc: 0.9486 - val_loss: 0.2360 - val_acc: 0.8971\n",
      "Epoch 78/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.1481 - acc: 0.9486 - val_loss: 0.2352 - val_acc: 0.8971\n",
      "Epoch 79/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1681 - acc: 0.9393 - val_loss: 0.2332 - val_acc: 0.8992\n",
      "Epoch 80/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1556 - acc: 0.9434 - val_loss: 0.2388 - val_acc: 0.8971\n",
      "Epoch 81/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1545 - acc: 0.9486 - val_loss: 0.2349 - val_acc: 0.9012\n",
      "Epoch 82/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.1604 - acc: 0.9486 - val_loss: 0.2363 - val_acc: 0.8971\n",
      "Epoch 83/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.1557 - acc: 0.9424 - val_loss: 0.2394 - val_acc: 0.8930\n",
      "Epoch 84/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.1498 - acc: 0.9491 - val_loss: 0.2321 - val_acc: 0.8992\n",
      "Epoch 85/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.1543 - acc: 0.9480 - val_loss: 0.2248 - val_acc: 0.9074\n",
      "Epoch 86/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.1550 - acc: 0.9465 - val_loss: 0.2305 - val_acc: 0.8971\n",
      "Epoch 87/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.1543 - acc: 0.9470 - val_loss: 0.2313 - val_acc: 0.9012\n",
      "Epoch 88/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.1557 - acc: 0.9424 - val_loss: 0.2271 - val_acc: 0.9012\n",
      "Epoch 89/100\n",
      "1944/1944 [==============================] - 1s 334us/step - loss: 0.1563 - acc: 0.9439 - val_loss: 0.2249 - val_acc: 0.9033\n",
      "Epoch 90/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.1471 - acc: 0.9558 - val_loss: 0.2247 - val_acc: 0.9012\n",
      "Epoch 91/100\n",
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.1435 - acc: 0.9511 - val_loss: 0.2220 - val_acc: 0.9074\n",
      "Epoch 92/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1530 - acc: 0.9470 - val_loss: 0.2307 - val_acc: 0.8971\n",
      "Epoch 93/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1486 - acc: 0.9501 - val_loss: 0.2269 - val_acc: 0.9012\n",
      "Epoch 94/100\n",
      "1944/1944 [==============================] - 1s 323us/step - loss: 0.1471 - acc: 0.9511 - val_loss: 0.2172 - val_acc: 0.9074\n",
      "Epoch 95/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1380 - acc: 0.9552 - val_loss: 0.2263 - val_acc: 0.9033\n",
      "Epoch 96/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.1462 - acc: 0.9522 - val_loss: 0.2200 - val_acc: 0.9053\n",
      "Epoch 97/100\n",
      "1944/1944 [==============================] - 1s 337us/step - loss: 0.1520 - acc: 0.9527 - val_loss: 0.2229 - val_acc: 0.9033\n",
      "Epoch 98/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1448 - acc: 0.9542 - val_loss: 0.2179 - val_acc: 0.9074\n",
      "Epoch 99/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.1331 - acc: 0.9583 - val_loss: 0.2212 - val_acc: 0.9053\n",
      "Epoch 100/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1433 - acc: 0.9506 - val_loss: 0.2214 - val_acc: 0.9033\n",
      "Train on 1944 samples, validate on 486 samples\n",
      "Epoch 1/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.2148 - acc: 0.9208 - val_loss: 0.2085 - val_acc: 0.9218\n",
      "Epoch 2/100\n",
      "1944/1944 [==============================] - 1s 337us/step - loss: 0.2130 - acc: 0.9234 - val_loss: 0.1993 - val_acc: 0.9239\n",
      "Epoch 3/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.2124 - acc: 0.9198 - val_loss: 0.2069 - val_acc: 0.9239\n",
      "Epoch 4/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1944 - acc: 0.9285 - val_loss: 0.1945 - val_acc: 0.9259\n",
      "Epoch 5/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.2001 - acc: 0.9295 - val_loss: 0.1938 - val_acc: 0.9259\n",
      "Epoch 6/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.1891 - acc: 0.9352 - val_loss: 0.1922 - val_acc: 0.9280\n",
      "Epoch 7/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1880 - acc: 0.9362 - val_loss: 0.1850 - val_acc: 0.9342\n",
      "Epoch 8/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.1909 - acc: 0.9316 - val_loss: 0.1901 - val_acc: 0.9300\n",
      "Epoch 9/100\n",
      "1944/1944 [==============================] - 1s 334us/step - loss: 0.1922 - acc: 0.9300 - val_loss: 0.1877 - val_acc: 0.9300\n",
      "Epoch 10/100\n",
      "1944/1944 [==============================] - 1s 322us/step - loss: 0.1935 - acc: 0.9300 - val_loss: 0.1842 - val_acc: 0.9321\n",
      "Epoch 11/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.1846 - acc: 0.9336 - val_loss: 0.1818 - val_acc: 0.9321\n",
      "Epoch 12/100\n",
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.1895 - acc: 0.9300 - val_loss: 0.1793 - val_acc: 0.9362\n",
      "Epoch 13/100\n",
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.1820 - acc: 0.9331 - val_loss: 0.1791 - val_acc: 0.9362\n",
      "Epoch 14/100\n",
      "1944/1944 [==============================] - 1s 347us/step - loss: 0.1817 - acc: 0.9336 - val_loss: 0.1830 - val_acc: 0.9321\n",
      "Epoch 15/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.1839 - acc: 0.9336 - val_loss: 0.1848 - val_acc: 0.9300\n",
      "Epoch 16/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.1879 - acc: 0.9300 - val_loss: 0.1731 - val_acc: 0.9403\n",
      "Epoch 17/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.1801 - acc: 0.9388 - val_loss: 0.1737 - val_acc: 0.9383\n",
      "Epoch 18/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.1729 - acc: 0.9434 - val_loss: 0.1761 - val_acc: 0.9383\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.1858 - acc: 0.9342 - val_loss: 0.1704 - val_acc: 0.9403\n",
      "Epoch 20/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1760 - acc: 0.9393 - val_loss: 0.1773 - val_acc: 0.9383\n",
      "Epoch 21/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1732 - acc: 0.9388 - val_loss: 0.1750 - val_acc: 0.9383\n",
      "Epoch 22/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.1676 - acc: 0.9434 - val_loss: 0.1768 - val_acc: 0.9362\n",
      "Epoch 23/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.1710 - acc: 0.9393 - val_loss: 0.1751 - val_acc: 0.9403\n",
      "Epoch 24/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.1759 - acc: 0.9398 - val_loss: 0.1755 - val_acc: 0.9383\n",
      "Epoch 25/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1735 - acc: 0.9393 - val_loss: 0.1750 - val_acc: 0.9403\n",
      "Epoch 26/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1733 - acc: 0.9378 - val_loss: 0.1699 - val_acc: 0.9403\n",
      "Epoch 27/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1685 - acc: 0.9434 - val_loss: 0.1729 - val_acc: 0.9403\n",
      "Epoch 28/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.1756 - acc: 0.9352 - val_loss: 0.1694 - val_acc: 0.9403\n",
      "Epoch 29/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.1702 - acc: 0.9388 - val_loss: 0.1777 - val_acc: 0.9383\n",
      "Epoch 30/100\n",
      "1944/1944 [==============================] - 1s 324us/step - loss: 0.1691 - acc: 0.9398 - val_loss: 0.1648 - val_acc: 0.9424\n",
      "Epoch 31/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.1653 - acc: 0.9429 - val_loss: 0.1613 - val_acc: 0.9424\n",
      "Epoch 32/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.1637 - acc: 0.9450 - val_loss: 0.1697 - val_acc: 0.9403\n",
      "Epoch 33/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.1622 - acc: 0.9424 - val_loss: 0.1693 - val_acc: 0.9424\n",
      "Epoch 34/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.1574 - acc: 0.9434 - val_loss: 0.1721 - val_acc: 0.9424\n",
      "Epoch 35/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1663 - acc: 0.9398 - val_loss: 0.1683 - val_acc: 0.9424\n",
      "Epoch 36/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.1624 - acc: 0.9455 - val_loss: 0.1657 - val_acc: 0.9424\n",
      "Epoch 37/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.1598 - acc: 0.9424 - val_loss: 0.1731 - val_acc: 0.9424\n",
      "Epoch 38/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.1604 - acc: 0.9434 - val_loss: 0.1615 - val_acc: 0.9424\n",
      "Epoch 39/100\n",
      "1944/1944 [==============================] - 1s 336us/step - loss: 0.1582 - acc: 0.9491 - val_loss: 0.1638 - val_acc: 0.9424\n",
      "Epoch 40/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.1568 - acc: 0.9444 - val_loss: 0.1658 - val_acc: 0.9424\n",
      "Epoch 41/100\n",
      "1944/1944 [==============================] - 1s 339us/step - loss: 0.1530 - acc: 0.9480 - val_loss: 0.1660 - val_acc: 0.9424\n",
      "Epoch 42/100\n",
      "1944/1944 [==============================] - 1s 332us/step - loss: 0.1580 - acc: 0.9460 - val_loss: 0.1561 - val_acc: 0.9465\n",
      "Epoch 43/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.1610 - acc: 0.9444 - val_loss: 0.1615 - val_acc: 0.9465\n",
      "Epoch 44/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.1561 - acc: 0.9444 - val_loss: 0.1581 - val_acc: 0.9465\n",
      "Epoch 45/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.1534 - acc: 0.9475 - val_loss: 0.1605 - val_acc: 0.9465\n",
      "Epoch 46/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.1582 - acc: 0.9444 - val_loss: 0.1601 - val_acc: 0.9465\n",
      "Epoch 47/100\n",
      "1944/1944 [==============================] - 1s 337us/step - loss: 0.1564 - acc: 0.9470 - val_loss: 0.1603 - val_acc: 0.9465\n",
      "Epoch 48/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.1589 - acc: 0.9403 - val_loss: 0.1662 - val_acc: 0.9444\n",
      "Epoch 49/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.1615 - acc: 0.9434 - val_loss: 0.1556 - val_acc: 0.9486\n",
      "Epoch 50/100\n",
      "1944/1944 [==============================] - 1s 357us/step - loss: 0.1535 - acc: 0.9491 - val_loss: 0.1653 - val_acc: 0.9444\n",
      "Epoch 51/100\n",
      "1944/1944 [==============================] - 1s 354us/step - loss: 0.1494 - acc: 0.9491 - val_loss: 0.1600 - val_acc: 0.9465\n",
      "Epoch 52/100\n",
      "1944/1944 [==============================] - 1s 349us/step - loss: 0.1531 - acc: 0.9501 - val_loss: 0.1642 - val_acc: 0.9465\n",
      "Epoch 53/100\n",
      "1944/1944 [==============================] - 1s 346us/step - loss: 0.1574 - acc: 0.9444 - val_loss: 0.1551 - val_acc: 0.9486\n",
      "Epoch 54/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.1514 - acc: 0.9480 - val_loss: 0.1586 - val_acc: 0.9465\n",
      "Epoch 55/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.1563 - acc: 0.9486 - val_loss: 0.1563 - val_acc: 0.9486\n",
      "Epoch 56/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.1506 - acc: 0.9465 - val_loss: 0.1575 - val_acc: 0.9465\n",
      "Epoch 57/100\n",
      "1944/1944 [==============================] - 1s 340us/step - loss: 0.1544 - acc: 0.9475 - val_loss: 0.1526 - val_acc: 0.9486\n",
      "Epoch 58/100\n",
      "1944/1944 [==============================] - 1s 352us/step - loss: 0.1518 - acc: 0.9444 - val_loss: 0.1569 - val_acc: 0.9465\n",
      "Epoch 59/100\n",
      "1944/1944 [==============================] - 1s 362us/step - loss: 0.1430 - acc: 0.9496 - val_loss: 0.1551 - val_acc: 0.9465\n",
      "Epoch 60/100\n",
      "1944/1944 [==============================] - 1s 359us/step - loss: 0.1477 - acc: 0.9465 - val_loss: 0.1574 - val_acc: 0.9465\n",
      "Epoch 61/100\n",
      "1944/1944 [==============================] - 1s 358us/step - loss: 0.1530 - acc: 0.9475 - val_loss: 0.1580 - val_acc: 0.9465\n",
      "Epoch 62/100\n",
      "1944/1944 [==============================] - 1s 350us/step - loss: 0.1547 - acc: 0.9439 - val_loss: 0.1614 - val_acc: 0.9444\n",
      "Epoch 63/100\n",
      "1944/1944 [==============================] - 1s 348us/step - loss: 0.1525 - acc: 0.9475 - val_loss: 0.1520 - val_acc: 0.9465\n",
      "Epoch 64/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.1438 - acc: 0.9501 - val_loss: 0.1610 - val_acc: 0.9444\n",
      "Epoch 65/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.1494 - acc: 0.9460 - val_loss: 0.1537 - val_acc: 0.9486\n",
      "Epoch 66/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.1444 - acc: 0.9516 - val_loss: 0.1545 - val_acc: 0.9465\n",
      "Epoch 67/100\n",
      "1944/1944 [==============================] - 1s 338us/step - loss: 0.1449 - acc: 0.9460 - val_loss: 0.1575 - val_acc: 0.9465\n",
      "Epoch 68/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.1455 - acc: 0.9460 - val_loss: 0.1474 - val_acc: 0.9486\n",
      "Epoch 69/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.1423 - acc: 0.9486 - val_loss: 0.1512 - val_acc: 0.9486\n",
      "Epoch 70/100\n",
      "1944/1944 [==============================] - 1s 342us/step - loss: 0.1442 - acc: 0.9532 - val_loss: 0.1516 - val_acc: 0.9486\n",
      "Epoch 71/100\n",
      "1944/1944 [==============================] - 1s 327us/step - loss: 0.1389 - acc: 0.9527 - val_loss: 0.1519 - val_acc: 0.9465\n",
      "Epoch 72/100\n",
      "1944/1944 [==============================] - 1s 334us/step - loss: 0.1410 - acc: 0.9470 - val_loss: 0.1485 - val_acc: 0.9486\n",
      "Epoch 73/100\n",
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.1396 - acc: 0.9506 - val_loss: 0.1500 - val_acc: 0.9486\n",
      "Epoch 74/100\n",
      "1944/1944 [==============================] - 1s 341us/step - loss: 0.1380 - acc: 0.9506 - val_loss: 0.1506 - val_acc: 0.9465\n",
      "Epoch 75/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1474 - acc: 0.9465 - val_loss: 0.1487 - val_acc: 0.9486\n",
      "Epoch 76/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1468 - acc: 0.9532 - val_loss: 0.1541 - val_acc: 0.9465\n",
      "Epoch 77/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.1430 - acc: 0.9542 - val_loss: 0.1574 - val_acc: 0.9465\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1944/1944 [==============================] - 1s 331us/step - loss: 0.1424 - acc: 0.9511 - val_loss: 0.1564 - val_acc: 0.9465\n",
      "Epoch 79/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.1400 - acc: 0.9496 - val_loss: 0.1548 - val_acc: 0.9465\n",
      "Epoch 80/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.1375 - acc: 0.9537 - val_loss: 0.1521 - val_acc: 0.9465\n",
      "Epoch 81/100\n",
      "1944/1944 [==============================] - 1s 337us/step - loss: 0.1395 - acc: 0.9522 - val_loss: 0.1488 - val_acc: 0.9486\n",
      "Epoch 82/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.1417 - acc: 0.9491 - val_loss: 0.1506 - val_acc: 0.9486\n",
      "Epoch 83/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.1402 - acc: 0.9542 - val_loss: 0.1568 - val_acc: 0.9465\n",
      "Epoch 84/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.1376 - acc: 0.9516 - val_loss: 0.1466 - val_acc: 0.9465\n",
      "Epoch 85/100\n",
      "1944/1944 [==============================] - 1s 321us/step - loss: 0.1363 - acc: 0.9547 - val_loss: 0.1474 - val_acc: 0.9486\n",
      "Epoch 86/100\n",
      "1944/1944 [==============================] - 1s 344us/step - loss: 0.1408 - acc: 0.9527 - val_loss: 0.1515 - val_acc: 0.9465\n",
      "Epoch 87/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1323 - acc: 0.9573 - val_loss: 0.1471 - val_acc: 0.9465\n",
      "Epoch 88/100\n",
      "1944/1944 [==============================] - 1s 328us/step - loss: 0.1379 - acc: 0.9522 - val_loss: 0.1524 - val_acc: 0.9444\n",
      "Epoch 89/100\n",
      "1944/1944 [==============================] - 1s 326us/step - loss: 0.1261 - acc: 0.9583 - val_loss: 0.1447 - val_acc: 0.9486\n",
      "Epoch 90/100\n",
      "1944/1944 [==============================] - 1s 325us/step - loss: 0.1363 - acc: 0.9516 - val_loss: 0.1458 - val_acc: 0.9486\n",
      "Epoch 91/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.1283 - acc: 0.9583 - val_loss: 0.1472 - val_acc: 0.9486\n",
      "Epoch 92/100\n",
      "1944/1944 [==============================] - 1s 333us/step - loss: 0.1389 - acc: 0.9532 - val_loss: 0.1472 - val_acc: 0.9465\n",
      "Epoch 93/100\n",
      "1944/1944 [==============================] - 1s 330us/step - loss: 0.1359 - acc: 0.9491 - val_loss: 0.1474 - val_acc: 0.9465\n",
      "Epoch 94/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.1402 - acc: 0.9532 - val_loss: 0.1493 - val_acc: 0.9465\n",
      "Epoch 95/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.1362 - acc: 0.9537 - val_loss: 0.1450 - val_acc: 0.9486\n",
      "Epoch 96/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.1355 - acc: 0.9563 - val_loss: 0.1490 - val_acc: 0.9465\n",
      "Epoch 97/100\n",
      "1944/1944 [==============================] - 1s 336us/step - loss: 0.1310 - acc: 0.9609 - val_loss: 0.1501 - val_acc: 0.9444\n",
      "Epoch 98/100\n",
      "1944/1944 [==============================] - 1s 337us/step - loss: 0.1349 - acc: 0.9501 - val_loss: 0.1542 - val_acc: 0.9444\n",
      "Epoch 99/100\n",
      "1944/1944 [==============================] - 1s 329us/step - loss: 0.1336 - acc: 0.9563 - val_loss: 0.1450 - val_acc: 0.9486\n",
      "Epoch 100/100\n",
      "1944/1944 [==============================] - 1s 335us/step - loss: 0.1253 - acc: 0.9599 - val_loss: 0.1427 - val_acc: 0.9506\n",
      "Test subject 11, class BothReleased\n",
      "HandStart AUC score = 0.627\n",
      "FirstDigitTouch AUC score = 0.868\n",
      "BothStartLoadPhase AUC score = 0.761\n",
      "LiftOff AUC score = 0.842\n",
      "Replace AUC score = 0.914\n",
      "BothReleased AUC score = 0.900\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53062 53062\n",
      "Train subject 12, class HandStart\n",
      "Train on 1955 samples, validate on 489 samples\n",
      "Epoch 1/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.8164 - acc: 0.5647 - val_loss: 0.7030 - val_acc: 0.5992\n",
      "Epoch 2/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.6949 - acc: 0.5882 - val_loss: 0.7094 - val_acc: 0.5828\n",
      "Epoch 3/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.6736 - acc: 0.6235 - val_loss: 0.6998 - val_acc: 0.5992\n",
      "Epoch 4/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.6589 - acc: 0.6092 - val_loss: 0.7160 - val_acc: 0.5706\n",
      "Epoch 5/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.6473 - acc: 0.6153 - val_loss: 0.6308 - val_acc: 0.6339\n",
      "Epoch 6/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.6387 - acc: 0.6389 - val_loss: 0.6571 - val_acc: 0.6155\n",
      "Epoch 7/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.6404 - acc: 0.6302 - val_loss: 0.6520 - val_acc: 0.6462\n",
      "Epoch 8/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.6283 - acc: 0.6404 - val_loss: 0.7029 - val_acc: 0.5930\n",
      "Epoch 9/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.6179 - acc: 0.6506 - val_loss: 0.6088 - val_acc: 0.6605\n",
      "Epoch 10/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.6132 - acc: 0.6573 - val_loss: 0.6022 - val_acc: 0.6708\n",
      "Epoch 11/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.6080 - acc: 0.6496 - val_loss: 0.5927 - val_acc: 0.6708\n",
      "Epoch 12/100\n",
      "1955/1955 [==============================] - 1s 336us/step - loss: 0.6101 - acc: 0.6634 - val_loss: 0.5830 - val_acc: 0.6953\n",
      "Epoch 13/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.5970 - acc: 0.6629 - val_loss: 0.5740 - val_acc: 0.6933\n",
      "Epoch 14/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.5932 - acc: 0.6829 - val_loss: 0.5948 - val_acc: 0.6748\n",
      "Epoch 15/100\n",
      "1955/1955 [==============================] - 1s 338us/step - loss: 0.5836 - acc: 0.6813 - val_loss: 0.5985 - val_acc: 0.6687\n",
      "Epoch 16/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.5812 - acc: 0.6808 - val_loss: 0.5681 - val_acc: 0.6933\n",
      "Epoch 17/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.5761 - acc: 0.6859 - val_loss: 0.6068 - val_acc: 0.6892\n",
      "Epoch 18/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.5690 - acc: 0.7008 - val_loss: 0.5990 - val_acc: 0.6830\n",
      "Epoch 19/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.5805 - acc: 0.6916 - val_loss: 0.6265 - val_acc: 0.6585\n",
      "Epoch 20/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.5706 - acc: 0.7018 - val_loss: 0.5524 - val_acc: 0.7157\n",
      "Epoch 21/100\n",
      "1955/1955 [==============================] - 1s 336us/step - loss: 0.5711 - acc: 0.6880 - val_loss: 0.5702 - val_acc: 0.7035\n",
      "Epoch 22/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.5541 - acc: 0.6941 - val_loss: 0.5792 - val_acc: 0.6933\n",
      "Epoch 23/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.5504 - acc: 0.7141 - val_loss: 0.6143 - val_acc: 0.6789\n",
      "Epoch 24/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.5577 - acc: 0.7059 - val_loss: 0.5489 - val_acc: 0.7178\n",
      "Epoch 25/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.5460 - acc: 0.7146 - val_loss: 0.5342 - val_acc: 0.7035\n",
      "Epoch 26/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.5393 - acc: 0.7258 - val_loss: 0.5484 - val_acc: 0.6933\n",
      "Epoch 27/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.5438 - acc: 0.7105 - val_loss: 0.5646 - val_acc: 0.6830\n",
      "Epoch 28/100\n",
      "1955/1955 [==============================] - 1s 336us/step - loss: 0.5349 - acc: 0.7197 - val_loss: 0.5202 - val_acc: 0.7382\n",
      "Epoch 29/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.5255 - acc: 0.7263 - val_loss: 0.5275 - val_acc: 0.7423\n",
      "Epoch 30/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.5332 - acc: 0.7233 - val_loss: 0.5419 - val_acc: 0.7198\n",
      "Epoch 31/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.5286 - acc: 0.7253 - val_loss: 0.5212 - val_acc: 0.7178\n",
      "Epoch 32/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.5268 - acc: 0.7269 - val_loss: 0.5436 - val_acc: 0.7342\n",
      "Epoch 33/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.5151 - acc: 0.7407 - val_loss: 0.5163 - val_acc: 0.7423\n",
      "Epoch 34/100\n",
      "1955/1955 [==============================] - 1s 341us/step - loss: 0.5180 - acc: 0.7407 - val_loss: 0.5198 - val_acc: 0.7342\n",
      "Epoch 35/100\n",
      "1955/1955 [==============================] - 1s 342us/step - loss: 0.5148 - acc: 0.7381 - val_loss: 0.5291 - val_acc: 0.7280\n",
      "Epoch 36/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.5136 - acc: 0.7366 - val_loss: 0.5304 - val_acc: 0.7382\n",
      "Epoch 37/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.5124 - acc: 0.7355 - val_loss: 0.5059 - val_acc: 0.7464\n",
      "Epoch 38/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.5079 - acc: 0.7488 - val_loss: 0.5243 - val_acc: 0.7239\n",
      "Epoch 39/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.4984 - acc: 0.7550 - val_loss: 0.5525 - val_acc: 0.7096\n",
      "Epoch 40/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.4938 - acc: 0.7555 - val_loss: 0.5293 - val_acc: 0.7178\n",
      "Epoch 41/100\n",
      "1955/1955 [==============================] - 1s 336us/step - loss: 0.4976 - acc: 0.7483 - val_loss: 0.5289 - val_acc: 0.7219\n",
      "Epoch 42/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.4955 - acc: 0.7509 - val_loss: 0.5188 - val_acc: 0.7301\n",
      "Epoch 43/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.4889 - acc: 0.7596 - val_loss: 0.5116 - val_acc: 0.7423\n",
      "Epoch 44/100\n",
      "1955/1955 [==============================] - 1s 336us/step - loss: 0.4826 - acc: 0.7673 - val_loss: 0.5021 - val_acc: 0.7403\n",
      "Epoch 45/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.4858 - acc: 0.7514 - val_loss: 0.4970 - val_acc: 0.7485\n",
      "Epoch 46/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.4800 - acc: 0.7688 - val_loss: 0.5025 - val_acc: 0.7464\n",
      "Epoch 47/100\n",
      "1955/1955 [==============================] - 1s 326us/step - loss: 0.4798 - acc: 0.7739 - val_loss: 0.4916 - val_acc: 0.7648\n",
      "Epoch 48/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.4736 - acc: 0.7591 - val_loss: 0.4982 - val_acc: 0.7628\n",
      "Epoch 49/100\n",
      "1955/1955 [==============================] - 1s 337us/step - loss: 0.4803 - acc: 0.7698 - val_loss: 0.5050 - val_acc: 0.7464\n",
      "Epoch 50/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.4677 - acc: 0.7657 - val_loss: 0.4800 - val_acc: 0.7689\n",
      "Epoch 51/100\n",
      "1955/1955 [==============================] - 1s 342us/step - loss: 0.4557 - acc: 0.7775 - val_loss: 0.5215 - val_acc: 0.7485\n",
      "Epoch 52/100\n",
      "1955/1955 [==============================] - 1s 346us/step - loss: 0.4635 - acc: 0.7729 - val_loss: 0.5178 - val_acc: 0.7444\n",
      "Epoch 53/100\n",
      "1955/1955 [==============================] - 1s 343us/step - loss: 0.4594 - acc: 0.7790 - val_loss: 0.5280 - val_acc: 0.7321\n",
      "Epoch 54/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.4625 - acc: 0.7698 - val_loss: 0.4949 - val_acc: 0.7505\n",
      "Epoch 55/100\n",
      "1955/1955 [==============================] - 1s 338us/step - loss: 0.4444 - acc: 0.7898 - val_loss: 0.5118 - val_acc: 0.7485\n",
      "Epoch 56/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.4424 - acc: 0.7923 - val_loss: 0.5017 - val_acc: 0.7464\n",
      "Epoch 57/100\n",
      "1955/1955 [==============================] - 1s 326us/step - loss: 0.4536 - acc: 0.7877 - val_loss: 0.5378 - val_acc: 0.7239\n",
      "Epoch 58/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.4370 - acc: 0.7939 - val_loss: 0.5059 - val_acc: 0.7587\n",
      "Epoch 59/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.4445 - acc: 0.7893 - val_loss: 0.5066 - val_acc: 0.7566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.4466 - acc: 0.7898 - val_loss: 0.5076 - val_acc: 0.7382\n",
      "Epoch 61/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.4503 - acc: 0.7872 - val_loss: 0.4764 - val_acc: 0.7669\n",
      "Epoch 62/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.4368 - acc: 0.8031 - val_loss: 0.4829 - val_acc: 0.7628\n",
      "Epoch 63/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.4333 - acc: 0.7964 - val_loss: 0.4737 - val_acc: 0.7485\n",
      "Epoch 64/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.4401 - acc: 0.8046 - val_loss: 0.4730 - val_acc: 0.7873\n",
      "Epoch 65/100\n",
      "1955/1955 [==============================] - 1s 325us/step - loss: 0.4431 - acc: 0.7903 - val_loss: 0.4965 - val_acc: 0.7485\n",
      "Epoch 66/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.4336 - acc: 0.8118 - val_loss: 0.4973 - val_acc: 0.7444\n",
      "Epoch 67/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.4268 - acc: 0.7903 - val_loss: 0.4684 - val_acc: 0.7791\n",
      "Epoch 68/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.4295 - acc: 0.7934 - val_loss: 0.4917 - val_acc: 0.7566\n",
      "Epoch 69/100\n",
      "1955/1955 [==============================] - 1s 324us/step - loss: 0.4252 - acc: 0.8036 - val_loss: 0.5538 - val_acc: 0.7198\n",
      "Epoch 70/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.4283 - acc: 0.7974 - val_loss: 0.4844 - val_acc: 0.7628\n",
      "Epoch 71/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.4156 - acc: 0.8082 - val_loss: 0.4786 - val_acc: 0.7812\n",
      "Epoch 72/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.4295 - acc: 0.8051 - val_loss: 0.4607 - val_acc: 0.7730\n",
      "Epoch 73/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.4200 - acc: 0.8031 - val_loss: 0.4742 - val_acc: 0.7894\n",
      "Epoch 74/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.4176 - acc: 0.8107 - val_loss: 0.4594 - val_acc: 0.7955\n",
      "Epoch 75/100\n",
      "1955/1955 [==============================] - 1s 325us/step - loss: 0.4139 - acc: 0.8082 - val_loss: 0.4659 - val_acc: 0.7791\n",
      "Epoch 76/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.4040 - acc: 0.8174 - val_loss: 0.4704 - val_acc: 0.7751\n",
      "Epoch 77/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.4251 - acc: 0.7980 - val_loss: 0.5099 - val_acc: 0.7382\n",
      "Epoch 78/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.4017 - acc: 0.8159 - val_loss: 0.4606 - val_acc: 0.7751\n",
      "Epoch 79/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.4042 - acc: 0.8210 - val_loss: 0.4457 - val_acc: 0.7873\n",
      "Epoch 80/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.4149 - acc: 0.8123 - val_loss: 0.5024 - val_acc: 0.7505\n",
      "Epoch 81/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.4031 - acc: 0.8184 - val_loss: 0.4637 - val_acc: 0.7894\n",
      "Epoch 82/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.4076 - acc: 0.8194 - val_loss: 0.4517 - val_acc: 0.7914\n",
      "Epoch 83/100\n",
      "1955/1955 [==============================] - 1s 337us/step - loss: 0.3935 - acc: 0.8210 - val_loss: 0.4614 - val_acc: 0.7935\n",
      "Epoch 84/100\n",
      "1955/1955 [==============================] - 1s 339us/step - loss: 0.3893 - acc: 0.8251 - val_loss: 0.4523 - val_acc: 0.7935\n",
      "Epoch 85/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.4021 - acc: 0.8281 - val_loss: 0.4383 - val_acc: 0.8016\n",
      "Epoch 86/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.3981 - acc: 0.8240 - val_loss: 0.4473 - val_acc: 0.7873\n",
      "Epoch 87/100\n",
      "1955/1955 [==============================] - 1s 323us/step - loss: 0.3921 - acc: 0.8235 - val_loss: 0.4561 - val_acc: 0.7955\n",
      "Epoch 88/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.3933 - acc: 0.8271 - val_loss: 0.4725 - val_acc: 0.7689\n",
      "Epoch 89/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.3899 - acc: 0.8353 - val_loss: 0.4561 - val_acc: 0.7975\n",
      "Epoch 90/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.3846 - acc: 0.8327 - val_loss: 0.4590 - val_acc: 0.7853\n",
      "Epoch 91/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.3876 - acc: 0.8322 - val_loss: 0.4751 - val_acc: 0.7730\n",
      "Epoch 92/100\n",
      "1955/1955 [==============================] - 1s 325us/step - loss: 0.3801 - acc: 0.8348 - val_loss: 0.4481 - val_acc: 0.7996\n",
      "Epoch 93/100\n",
      "1955/1955 [==============================] - 1s 337us/step - loss: 0.3953 - acc: 0.8230 - val_loss: 0.4393 - val_acc: 0.8037\n",
      "Epoch 94/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.3946 - acc: 0.8251 - val_loss: 0.4733 - val_acc: 0.7812\n",
      "Epoch 95/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.3851 - acc: 0.8348 - val_loss: 0.4569 - val_acc: 0.7894\n",
      "Epoch 96/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.3703 - acc: 0.8379 - val_loss: 0.4263 - val_acc: 0.8037\n",
      "Epoch 97/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.3790 - acc: 0.8322 - val_loss: 0.4755 - val_acc: 0.7689\n",
      "Epoch 98/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.3868 - acc: 0.8353 - val_loss: 0.4219 - val_acc: 0.7996\n",
      "Epoch 99/100\n",
      "1955/1955 [==============================] - 1s 324us/step - loss: 0.3718 - acc: 0.8373 - val_loss: 0.5691 - val_acc: 0.7014\n",
      "Epoch 100/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.3927 - acc: 0.8251 - val_loss: 0.4498 - val_acc: 0.7894\n",
      "Train on 1955 samples, validate on 489 samples\n",
      "Epoch 1/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.4537 - acc: 0.7928 - val_loss: 0.4025 - val_acc: 0.8200\n",
      "Epoch 2/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.4486 - acc: 0.7821 - val_loss: 0.4117 - val_acc: 0.8323\n",
      "Epoch 3/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.4403 - acc: 0.8005 - val_loss: 0.4217 - val_acc: 0.8180\n",
      "Epoch 4/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.4370 - acc: 0.7964 - val_loss: 0.4089 - val_acc: 0.8303\n",
      "Epoch 5/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.4433 - acc: 0.7954 - val_loss: 0.4750 - val_acc: 0.7873\n",
      "Epoch 6/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.4341 - acc: 0.8020 - val_loss: 0.4253 - val_acc: 0.8160\n",
      "Epoch 7/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.4362 - acc: 0.8036 - val_loss: 0.3868 - val_acc: 0.8344\n",
      "Epoch 8/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.4212 - acc: 0.8118 - val_loss: 0.4027 - val_acc: 0.8016\n",
      "Epoch 9/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.4202 - acc: 0.8113 - val_loss: 0.4025 - val_acc: 0.8221\n",
      "Epoch 10/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.4185 - acc: 0.8118 - val_loss: 0.4187 - val_acc: 0.8180\n",
      "Epoch 11/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.4079 - acc: 0.8148 - val_loss: 0.4275 - val_acc: 0.8139\n",
      "Epoch 12/100\n",
      "1955/1955 [==============================] - 1s 336us/step - loss: 0.4192 - acc: 0.8189 - val_loss: 0.4547 - val_acc: 0.7955\n",
      "Epoch 13/100\n",
      "1955/1955 [==============================] - 1s 326us/step - loss: 0.4085 - acc: 0.8153 - val_loss: 0.4280 - val_acc: 0.8160\n",
      "Epoch 14/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.4232 - acc: 0.8072 - val_loss: 0.4221 - val_acc: 0.8160\n",
      "Epoch 15/100\n",
      "1955/1955 [==============================] - 1s 339us/step - loss: 0.4125 - acc: 0.8128 - val_loss: 0.4015 - val_acc: 0.8323\n",
      "Epoch 16/100\n",
      "1955/1955 [==============================] - 1s 339us/step - loss: 0.4028 - acc: 0.8184 - val_loss: 0.3844 - val_acc: 0.8425\n",
      "Epoch 17/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.4017 - acc: 0.8205 - val_loss: 0.3866 - val_acc: 0.8344\n",
      "Epoch 18/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.3949 - acc: 0.8205 - val_loss: 0.4074 - val_acc: 0.8323\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.4053 - acc: 0.8210 - val_loss: 0.4151 - val_acc: 0.8119\n",
      "Epoch 20/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.3913 - acc: 0.8266 - val_loss: 0.3857 - val_acc: 0.8384\n",
      "Epoch 21/100\n",
      "1955/1955 [==============================] - 1s 341us/step - loss: 0.4026 - acc: 0.8189 - val_loss: 0.3924 - val_acc: 0.8282\n",
      "Epoch 22/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.3909 - acc: 0.8363 - val_loss: 0.3770 - val_acc: 0.8528\n",
      "Epoch 23/100\n",
      "1955/1955 [==============================] - 1s 324us/step - loss: 0.3896 - acc: 0.8297 - val_loss: 0.3797 - val_acc: 0.8487\n",
      "Epoch 24/100\n",
      "1955/1955 [==============================] - 1s 325us/step - loss: 0.3985 - acc: 0.8251 - val_loss: 0.3870 - val_acc: 0.8384\n",
      "Epoch 25/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.3909 - acc: 0.8220 - val_loss: 0.4115 - val_acc: 0.8303\n",
      "Epoch 26/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.3901 - acc: 0.8343 - val_loss: 0.3922 - val_acc: 0.8303\n",
      "Epoch 27/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.3834 - acc: 0.8338 - val_loss: 0.4173 - val_acc: 0.8139\n",
      "Epoch 28/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.3693 - acc: 0.8394 - val_loss: 0.4089 - val_acc: 0.8303\n",
      "Epoch 29/100\n",
      "1955/1955 [==============================] - 1s 323us/step - loss: 0.3831 - acc: 0.8343 - val_loss: 0.3613 - val_acc: 0.8528\n",
      "Epoch 30/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.3764 - acc: 0.8425 - val_loss: 0.3805 - val_acc: 0.8384\n",
      "Epoch 31/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.3831 - acc: 0.8389 - val_loss: 0.4090 - val_acc: 0.8221\n",
      "Epoch 32/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.3793 - acc: 0.8353 - val_loss: 0.3711 - val_acc: 0.8569\n",
      "Epoch 33/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.3776 - acc: 0.8399 - val_loss: 0.3944 - val_acc: 0.8282\n",
      "Epoch 34/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.3789 - acc: 0.8363 - val_loss: 0.3596 - val_acc: 0.8528\n",
      "Epoch 35/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.3718 - acc: 0.8414 - val_loss: 0.3822 - val_acc: 0.8384\n",
      "Epoch 36/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.3809 - acc: 0.8358 - val_loss: 0.3830 - val_acc: 0.8384\n",
      "Epoch 37/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.3666 - acc: 0.8414 - val_loss: 0.3809 - val_acc: 0.8323\n",
      "Epoch 38/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.3725 - acc: 0.8358 - val_loss: 0.3646 - val_acc: 0.8466\n",
      "Epoch 39/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.3719 - acc: 0.8368 - val_loss: 0.4110 - val_acc: 0.8160\n",
      "Epoch 40/100\n",
      "1955/1955 [==============================] - 1s 323us/step - loss: 0.3750 - acc: 0.8312 - val_loss: 0.3862 - val_acc: 0.8364\n",
      "Epoch 41/100\n",
      "1955/1955 [==============================] - 1s 343us/step - loss: 0.3808 - acc: 0.8302 - val_loss: 0.3972 - val_acc: 0.8241\n",
      "Epoch 42/100\n",
      "1955/1955 [==============================] - 1s 341us/step - loss: 0.3623 - acc: 0.8430 - val_loss: 0.3756 - val_acc: 0.8364\n",
      "Epoch 43/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.3717 - acc: 0.8419 - val_loss: 0.3716 - val_acc: 0.8364\n",
      "Epoch 44/100\n",
      "1955/1955 [==============================] - 1s 326us/step - loss: 0.3552 - acc: 0.8491 - val_loss: 0.3470 - val_acc: 0.8405\n",
      "Epoch 45/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.3558 - acc: 0.8465 - val_loss: 0.3553 - val_acc: 0.8589\n",
      "Epoch 46/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.3640 - acc: 0.8414 - val_loss: 0.3648 - val_acc: 0.8405\n",
      "Epoch 47/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.3542 - acc: 0.8491 - val_loss: 0.4077 - val_acc: 0.8221\n",
      "Epoch 48/100\n",
      "1955/1955 [==============================] - 1s 326us/step - loss: 0.3537 - acc: 0.8476 - val_loss: 0.3720 - val_acc: 0.8446\n",
      "Epoch 49/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.3571 - acc: 0.8506 - val_loss: 0.3585 - val_acc: 0.8405\n",
      "Epoch 50/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.3651 - acc: 0.8384 - val_loss: 0.3598 - val_acc: 0.8466\n",
      "Epoch 51/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.3610 - acc: 0.8496 - val_loss: 0.3871 - val_acc: 0.8344\n",
      "Epoch 52/100\n",
      "1955/1955 [==============================] - 1s 326us/step - loss: 0.3608 - acc: 0.8501 - val_loss: 0.4005 - val_acc: 0.8139\n",
      "Epoch 53/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.3495 - acc: 0.8563 - val_loss: 0.3818 - val_acc: 0.8262\n",
      "Epoch 54/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.3503 - acc: 0.8486 - val_loss: 0.3470 - val_acc: 0.8528\n",
      "Epoch 55/100\n",
      "1955/1955 [==============================] - 1s 336us/step - loss: 0.3489 - acc: 0.8537 - val_loss: 0.3622 - val_acc: 0.8364\n",
      "Epoch 56/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.3477 - acc: 0.8552 - val_loss: 0.3632 - val_acc: 0.8405\n",
      "Epoch 57/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.3410 - acc: 0.8588 - val_loss: 0.3446 - val_acc: 0.8609\n",
      "Epoch 58/100\n",
      "1955/1955 [==============================] - 1s 339us/step - loss: 0.3584 - acc: 0.8476 - val_loss: 0.3717 - val_acc: 0.8344\n",
      "Epoch 59/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.3482 - acc: 0.8537 - val_loss: 0.3798 - val_acc: 0.8221\n",
      "Epoch 60/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.3522 - acc: 0.8598 - val_loss: 0.3838 - val_acc: 0.8180\n",
      "Epoch 61/100\n",
      "1955/1955 [==============================] - 1s 338us/step - loss: 0.3505 - acc: 0.8506 - val_loss: 0.3864 - val_acc: 0.8180\n",
      "Epoch 62/100\n",
      "1955/1955 [==============================] - 1s 337us/step - loss: 0.3497 - acc: 0.8588 - val_loss: 0.3948 - val_acc: 0.8200\n",
      "Epoch 63/100\n",
      "1955/1955 [==============================] - 1s 325us/step - loss: 0.3378 - acc: 0.8639 - val_loss: 0.3464 - val_acc: 0.8609\n",
      "Epoch 64/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.3381 - acc: 0.8629 - val_loss: 0.3693 - val_acc: 0.8303\n",
      "Epoch 65/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.3389 - acc: 0.8614 - val_loss: 0.3350 - val_acc: 0.8569\n",
      "Epoch 66/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.3564 - acc: 0.8506 - val_loss: 0.3651 - val_acc: 0.8344\n",
      "Epoch 67/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.3369 - acc: 0.8573 - val_loss: 0.3517 - val_acc: 0.8487\n",
      "Epoch 68/100\n",
      "1955/1955 [==============================] - 1s 336us/step - loss: 0.3414 - acc: 0.8609 - val_loss: 0.3440 - val_acc: 0.8548\n",
      "Epoch 69/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.3341 - acc: 0.8598 - val_loss: 0.3316 - val_acc: 0.8691\n",
      "Epoch 70/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.3385 - acc: 0.8588 - val_loss: 0.3540 - val_acc: 0.8466\n",
      "Epoch 71/100\n",
      "1955/1955 [==============================] - 1s 326us/step - loss: 0.3249 - acc: 0.8665 - val_loss: 0.3469 - val_acc: 0.8425\n",
      "Epoch 72/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.3310 - acc: 0.8650 - val_loss: 0.3561 - val_acc: 0.8528\n",
      "Epoch 73/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.3231 - acc: 0.8670 - val_loss: 0.3532 - val_acc: 0.8405\n",
      "Epoch 74/100\n",
      "1955/1955 [==============================] - 1s 336us/step - loss: 0.3355 - acc: 0.8588 - val_loss: 0.3664 - val_acc: 0.8384\n",
      "Epoch 75/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.3362 - acc: 0.8476 - val_loss: 0.3350 - val_acc: 0.8507\n",
      "Epoch 76/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.3268 - acc: 0.8645 - val_loss: 0.3490 - val_acc: 0.8569\n",
      "Epoch 77/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.3383 - acc: 0.8609 - val_loss: 0.3480 - val_acc: 0.8487\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.3286 - acc: 0.8634 - val_loss: 0.3472 - val_acc: 0.8487\n",
      "Epoch 79/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.3305 - acc: 0.8619 - val_loss: 0.3457 - val_acc: 0.8507\n",
      "Epoch 80/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.3319 - acc: 0.8634 - val_loss: 0.3651 - val_acc: 0.8384\n",
      "Epoch 81/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.3290 - acc: 0.8650 - val_loss: 0.3434 - val_acc: 0.8507\n",
      "Epoch 82/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.3285 - acc: 0.8568 - val_loss: 0.3617 - val_acc: 0.8384\n",
      "Epoch 83/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.3166 - acc: 0.8742 - val_loss: 0.3260 - val_acc: 0.8671\n",
      "Epoch 84/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.3252 - acc: 0.8624 - val_loss: 0.3453 - val_acc: 0.8507\n",
      "Epoch 85/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.3228 - acc: 0.8696 - val_loss: 0.3609 - val_acc: 0.8405\n",
      "Epoch 86/100\n",
      "1955/1955 [==============================] - 1s 324us/step - loss: 0.3131 - acc: 0.8711 - val_loss: 0.3318 - val_acc: 0.8466\n",
      "Epoch 87/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.3246 - acc: 0.8619 - val_loss: 0.3706 - val_acc: 0.8364\n",
      "Epoch 88/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.3162 - acc: 0.8726 - val_loss: 0.3280 - val_acc: 0.8630\n",
      "Epoch 89/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.3197 - acc: 0.8685 - val_loss: 0.3532 - val_acc: 0.8405\n",
      "Epoch 90/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.3284 - acc: 0.8685 - val_loss: 0.3433 - val_acc: 0.8528\n",
      "Epoch 91/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.3161 - acc: 0.8670 - val_loss: 0.3218 - val_acc: 0.8691\n",
      "Epoch 92/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.3265 - acc: 0.8696 - val_loss: 0.3305 - val_acc: 0.8569\n",
      "Epoch 93/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.3181 - acc: 0.8747 - val_loss: 0.3348 - val_acc: 0.8507\n",
      "Epoch 94/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.3053 - acc: 0.8839 - val_loss: 0.3448 - val_acc: 0.8507\n",
      "Epoch 95/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.3154 - acc: 0.8788 - val_loss: 0.3507 - val_acc: 0.8548\n",
      "Epoch 96/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.3096 - acc: 0.8824 - val_loss: 0.4007 - val_acc: 0.8160\n",
      "Epoch 97/100\n",
      "1955/1955 [==============================] - 1s 323us/step - loss: 0.3194 - acc: 0.8680 - val_loss: 0.3220 - val_acc: 0.8589\n",
      "Epoch 98/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.3146 - acc: 0.8716 - val_loss: 0.3337 - val_acc: 0.8548\n",
      "Epoch 99/100\n",
      "1955/1955 [==============================] - 1s 324us/step - loss: 0.3047 - acc: 0.8726 - val_loss: 0.3618 - val_acc: 0.8405\n",
      "Epoch 100/100\n",
      "1955/1955 [==============================] - 1s 336us/step - loss: 0.3185 - acc: 0.8701 - val_loss: 0.3597 - val_acc: 0.8405\n",
      "Test subject 12, class HandStart\n",
      "Train subject 12, class FirstDigitTouch\n",
      "Train on 1955 samples, validate on 489 samples\n",
      "Epoch 1/100\n",
      "1955/1955 [==============================] - 1s 326us/step - loss: 0.8060 - acc: 0.7136 - val_loss: 0.5697 - val_acc: 0.7648\n",
      "Epoch 2/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.5926 - acc: 0.7366 - val_loss: 0.5124 - val_acc: 0.7669\n",
      "Epoch 3/100\n",
      "1955/1955 [==============================] - 1s 326us/step - loss: 0.5443 - acc: 0.7611 - val_loss: 0.4779 - val_acc: 0.7669\n",
      "Epoch 4/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.5036 - acc: 0.7744 - val_loss: 0.4444 - val_acc: 0.7832\n",
      "Epoch 5/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.4909 - acc: 0.7826 - val_loss: 0.4199 - val_acc: 0.8037\n",
      "Epoch 6/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.4570 - acc: 0.7903 - val_loss: 0.4010 - val_acc: 0.8221\n",
      "Epoch 7/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.4656 - acc: 0.7923 - val_loss: 0.3916 - val_acc: 0.8180\n",
      "Epoch 8/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.4300 - acc: 0.8082 - val_loss: 0.3695 - val_acc: 0.8487\n",
      "Epoch 9/100\n",
      "1955/1955 [==============================] - 1s 342us/step - loss: 0.4283 - acc: 0.8026 - val_loss: 0.3941 - val_acc: 0.8241\n",
      "Epoch 10/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.4088 - acc: 0.8164 - val_loss: 0.3562 - val_acc: 0.8344\n",
      "Epoch 11/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.4080 - acc: 0.8205 - val_loss: 0.3434 - val_acc: 0.8569\n",
      "Epoch 12/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.3923 - acc: 0.8281 - val_loss: 0.3352 - val_acc: 0.8630\n",
      "Epoch 13/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.3850 - acc: 0.8389 - val_loss: 0.3232 - val_acc: 0.8630\n",
      "Epoch 14/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.3740 - acc: 0.8394 - val_loss: 0.3130 - val_acc: 0.8691\n",
      "Epoch 15/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.3543 - acc: 0.8455 - val_loss: 0.3150 - val_acc: 0.8630\n",
      "Epoch 16/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.3615 - acc: 0.8430 - val_loss: 0.3021 - val_acc: 0.8671\n",
      "Epoch 17/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.3444 - acc: 0.8578 - val_loss: 0.3053 - val_acc: 0.8630\n",
      "Epoch 18/100\n",
      "1955/1955 [==============================] - 1s 341us/step - loss: 0.3414 - acc: 0.8476 - val_loss: 0.3006 - val_acc: 0.8671\n",
      "Epoch 19/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.3347 - acc: 0.8629 - val_loss: 0.2849 - val_acc: 0.8671\n",
      "Epoch 20/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.3428 - acc: 0.8604 - val_loss: 0.2880 - val_acc: 0.8671\n",
      "Epoch 21/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.3181 - acc: 0.8696 - val_loss: 0.2786 - val_acc: 0.8671\n",
      "Epoch 22/100\n",
      "1955/1955 [==============================] - 1s 343us/step - loss: 0.3118 - acc: 0.8680 - val_loss: 0.2777 - val_acc: 0.8834\n",
      "Epoch 23/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.3078 - acc: 0.8624 - val_loss: 0.2627 - val_acc: 0.8896\n",
      "Epoch 24/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.3188 - acc: 0.8650 - val_loss: 0.2642 - val_acc: 0.8834\n",
      "Epoch 25/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.3098 - acc: 0.8691 - val_loss: 0.2498 - val_acc: 0.8875\n",
      "Epoch 26/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.3008 - acc: 0.8798 - val_loss: 0.2542 - val_acc: 0.8916\n",
      "Epoch 27/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.2845 - acc: 0.8757 - val_loss: 0.2469 - val_acc: 0.8937\n",
      "Epoch 28/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.2831 - acc: 0.8885 - val_loss: 0.2443 - val_acc: 0.8957\n",
      "Epoch 29/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.2815 - acc: 0.8798 - val_loss: 0.2333 - val_acc: 0.8978\n",
      "Epoch 30/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.2795 - acc: 0.8936 - val_loss: 0.2552 - val_acc: 0.8937\n",
      "Epoch 31/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.2805 - acc: 0.8803 - val_loss: 0.2384 - val_acc: 0.8978\n",
      "Epoch 32/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.2767 - acc: 0.8885 - val_loss: 0.2264 - val_acc: 0.9121\n",
      "Epoch 33/100\n",
      "1955/1955 [==============================] - 1s 323us/step - loss: 0.2772 - acc: 0.8813 - val_loss: 0.2407 - val_acc: 0.8916\n",
      "Epoch 34/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.2793 - acc: 0.8793 - val_loss: 0.2245 - val_acc: 0.9141\n",
      "Epoch 35/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.2655 - acc: 0.8921 - val_loss: 0.2215 - val_acc: 0.9080\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.2611 - acc: 0.8921 - val_loss: 0.2169 - val_acc: 0.9100\n",
      "Epoch 37/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.2628 - acc: 0.8885 - val_loss: 0.2243 - val_acc: 0.9059\n",
      "Epoch 38/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.2627 - acc: 0.8977 - val_loss: 0.2164 - val_acc: 0.9162\n",
      "Epoch 39/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.2491 - acc: 0.9023 - val_loss: 0.2106 - val_acc: 0.9121\n",
      "Epoch 40/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.2598 - acc: 0.8926 - val_loss: 0.2080 - val_acc: 0.9182\n",
      "Epoch 41/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.2474 - acc: 0.8972 - val_loss: 0.2090 - val_acc: 0.9141\n",
      "Epoch 42/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.2469 - acc: 0.9033 - val_loss: 0.2059 - val_acc: 0.9223\n",
      "Epoch 43/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.2526 - acc: 0.9043 - val_loss: 0.2137 - val_acc: 0.9141\n",
      "Epoch 44/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.2398 - acc: 0.9013 - val_loss: 0.2051 - val_acc: 0.9202\n",
      "Epoch 45/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.2446 - acc: 0.9054 - val_loss: 0.2012 - val_acc: 0.9243\n",
      "Epoch 46/100\n",
      "1955/1955 [==============================] - 1s 338us/step - loss: 0.2378 - acc: 0.9049 - val_loss: 0.1983 - val_acc: 0.9305\n",
      "Epoch 47/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.2370 - acc: 0.9084 - val_loss: 0.1970 - val_acc: 0.9243\n",
      "Epoch 48/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.2448 - acc: 0.9054 - val_loss: 0.1945 - val_acc: 0.9223\n",
      "Epoch 49/100\n",
      "1955/1955 [==============================] - 1s 325us/step - loss: 0.2343 - acc: 0.9074 - val_loss: 0.1934 - val_acc: 0.9284\n",
      "Epoch 50/100\n",
      "1955/1955 [==============================] - 1s 339us/step - loss: 0.2359 - acc: 0.9074 - val_loss: 0.2037 - val_acc: 0.9243\n",
      "Epoch 51/100\n",
      "1955/1955 [==============================] - 1s 338us/step - loss: 0.2270 - acc: 0.9120 - val_loss: 0.1932 - val_acc: 0.9243\n",
      "Epoch 52/100\n",
      "1955/1955 [==============================] - 1s 340us/step - loss: 0.2362 - acc: 0.9033 - val_loss: 0.1915 - val_acc: 0.9284\n",
      "Epoch 53/100\n",
      "1955/1955 [==============================] - 1s 342us/step - loss: 0.2303 - acc: 0.9059 - val_loss: 0.1909 - val_acc: 0.9243\n",
      "Epoch 54/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.2319 - acc: 0.9095 - val_loss: 0.1858 - val_acc: 0.9284\n",
      "Epoch 55/100\n",
      "1955/1955 [==============================] - 1s 336us/step - loss: 0.2222 - acc: 0.9166 - val_loss: 0.1896 - val_acc: 0.9223\n",
      "Epoch 56/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.2318 - acc: 0.9110 - val_loss: 0.1884 - val_acc: 0.9182\n",
      "Epoch 57/100\n",
      "1955/1955 [==============================] - 1s 345us/step - loss: 0.2276 - acc: 0.9064 - val_loss: 0.1792 - val_acc: 0.9305\n",
      "Epoch 58/100\n",
      "1955/1955 [==============================] - 1s 343us/step - loss: 0.2131 - acc: 0.9187 - val_loss: 0.1808 - val_acc: 0.9305\n",
      "Epoch 59/100\n",
      "1955/1955 [==============================] - 1s 342us/step - loss: 0.2150 - acc: 0.9146 - val_loss: 0.1757 - val_acc: 0.9284\n",
      "Epoch 60/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.2202 - acc: 0.9136 - val_loss: 0.1764 - val_acc: 0.9387\n",
      "Epoch 61/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.2162 - acc: 0.9110 - val_loss: 0.1765 - val_acc: 0.9346\n",
      "Epoch 62/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.2313 - acc: 0.9028 - val_loss: 0.1775 - val_acc: 0.9325\n",
      "Epoch 63/100\n",
      "1955/1955 [==============================] - 1s 351us/step - loss: 0.2057 - acc: 0.9217 - val_loss: 0.1747 - val_acc: 0.9284\n",
      "Epoch 64/100\n",
      "1955/1955 [==============================] - 1s 341us/step - loss: 0.2107 - acc: 0.9197 - val_loss: 0.1760 - val_acc: 0.9366\n",
      "Epoch 65/100\n",
      "1955/1955 [==============================] - 1s 341us/step - loss: 0.2163 - acc: 0.9146 - val_loss: 0.1766 - val_acc: 0.9366\n",
      "Epoch 66/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.2212 - acc: 0.9141 - val_loss: 0.1769 - val_acc: 0.9427\n",
      "Epoch 67/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.2006 - acc: 0.9299 - val_loss: 0.1713 - val_acc: 0.9448\n",
      "Epoch 68/100\n",
      "1955/1955 [==============================] - 1s 336us/step - loss: 0.2070 - acc: 0.9228 - val_loss: 0.1694 - val_acc: 0.9427\n",
      "Epoch 69/100\n",
      "1955/1955 [==============================] - 1s 336us/step - loss: 0.2037 - acc: 0.9202 - val_loss: 0.1675 - val_acc: 0.9387\n",
      "Epoch 70/100\n",
      "1955/1955 [==============================] - 1s 344us/step - loss: 0.2073 - acc: 0.9243 - val_loss: 0.1661 - val_acc: 0.9387\n",
      "Epoch 71/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.2048 - acc: 0.9223 - val_loss: 0.1651 - val_acc: 0.9346\n",
      "Epoch 72/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.2010 - acc: 0.9223 - val_loss: 0.1647 - val_acc: 0.9346\n",
      "Epoch 73/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.1951 - acc: 0.9299 - val_loss: 0.1653 - val_acc: 0.9468\n",
      "Epoch 74/100\n",
      "1955/1955 [==============================] - 1s 341us/step - loss: 0.1996 - acc: 0.9289 - val_loss: 0.1700 - val_acc: 0.9468\n",
      "Epoch 75/100\n",
      "1955/1955 [==============================] - 1s 354us/step - loss: 0.2020 - acc: 0.9217 - val_loss: 0.1667 - val_acc: 0.9427\n",
      "Epoch 76/100\n",
      "1955/1955 [==============================] - 1s 344us/step - loss: 0.1914 - acc: 0.9248 - val_loss: 0.1636 - val_acc: 0.9489\n",
      "Epoch 77/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.1920 - acc: 0.9279 - val_loss: 0.1626 - val_acc: 0.9427\n",
      "Epoch 78/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.1945 - acc: 0.9269 - val_loss: 0.1636 - val_acc: 0.9325\n",
      "Epoch 79/100\n",
      "1955/1955 [==============================] - 1s 358us/step - loss: 0.1986 - acc: 0.9258 - val_loss: 0.1622 - val_acc: 0.9468\n",
      "Epoch 80/100\n",
      "1955/1955 [==============================] - 1s 342us/step - loss: 0.1860 - acc: 0.9299 - val_loss: 0.1786 - val_acc: 0.9325\n",
      "Epoch 81/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.1894 - acc: 0.9299 - val_loss: 0.1584 - val_acc: 0.9427\n",
      "Epoch 82/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.1863 - acc: 0.9315 - val_loss: 0.1556 - val_acc: 0.9427\n",
      "Epoch 83/100\n",
      "1955/1955 [==============================] - 1s 337us/step - loss: 0.1804 - acc: 0.9320 - val_loss: 0.1524 - val_acc: 0.9366\n",
      "Epoch 84/100\n",
      "1955/1955 [==============================] - 1s 338us/step - loss: 0.1810 - acc: 0.9294 - val_loss: 0.1528 - val_acc: 0.9387\n",
      "Epoch 85/100\n",
      "1955/1955 [==============================] - 1s 354us/step - loss: 0.1814 - acc: 0.9340 - val_loss: 0.1543 - val_acc: 0.9448\n",
      "Epoch 86/100\n",
      "1955/1955 [==============================] - 1s 339us/step - loss: 0.1830 - acc: 0.9335 - val_loss: 0.1531 - val_acc: 0.9407\n",
      "Epoch 87/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.1872 - acc: 0.9304 - val_loss: 0.1504 - val_acc: 0.9468\n",
      "Epoch 88/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.1793 - acc: 0.9355 - val_loss: 0.1510 - val_acc: 0.9448\n",
      "Epoch 89/100\n",
      "1955/1955 [==============================] - 1s 339us/step - loss: 0.1795 - acc: 0.9330 - val_loss: 0.1500 - val_acc: 0.9427\n",
      "Epoch 90/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.1776 - acc: 0.9340 - val_loss: 0.1489 - val_acc: 0.9387\n",
      "Epoch 91/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.1798 - acc: 0.9289 - val_loss: 0.1557 - val_acc: 0.9448\n",
      "Epoch 92/100\n",
      "1955/1955 [==============================] - 1s 342us/step - loss: 0.1796 - acc: 0.9350 - val_loss: 0.1459 - val_acc: 0.9468\n",
      "Epoch 93/100\n",
      "1955/1955 [==============================] - 1s 336us/step - loss: 0.1807 - acc: 0.9325 - val_loss: 0.1533 - val_acc: 0.9427\n",
      "Epoch 94/100\n",
      "1955/1955 [==============================] - 1s 341us/step - loss: 0.1855 - acc: 0.9330 - val_loss: 0.1471 - val_acc: 0.9448\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1955/1955 [==============================] - 1s 338us/step - loss: 0.1651 - acc: 0.9407 - val_loss: 0.1438 - val_acc: 0.9530\n",
      "Epoch 96/100\n",
      "1955/1955 [==============================] - 1s 344us/step - loss: 0.1743 - acc: 0.9345 - val_loss: 0.1481 - val_acc: 0.9468\n",
      "Epoch 97/100\n",
      "1955/1955 [==============================] - 1s 337us/step - loss: 0.1768 - acc: 0.9345 - val_loss: 0.1444 - val_acc: 0.9509\n",
      "Epoch 98/100\n",
      "1955/1955 [==============================] - 1s 354us/step - loss: 0.1729 - acc: 0.9458 - val_loss: 0.1472 - val_acc: 0.9509\n",
      "Epoch 99/100\n",
      "1955/1955 [==============================] - 1s 346us/step - loss: 0.1765 - acc: 0.9355 - val_loss: 0.1471 - val_acc: 0.9509\n",
      "Epoch 100/100\n",
      "1955/1955 [==============================] - 1s 337us/step - loss: 0.1628 - acc: 0.9427 - val_loss: 0.1427 - val_acc: 0.9530\n",
      "Train on 1955 samples, validate on 489 samples\n",
      "Epoch 1/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.1941 - acc: 0.9269 - val_loss: 0.2303 - val_acc: 0.9162\n",
      "Epoch 2/100\n",
      "1955/1955 [==============================] - 1s 336us/step - loss: 0.1969 - acc: 0.9243 - val_loss: 0.2536 - val_acc: 0.9080\n",
      "Epoch 3/100\n",
      "1955/1955 [==============================] - 1s 341us/step - loss: 0.2035 - acc: 0.9192 - val_loss: 0.2511 - val_acc: 0.9141\n",
      "Epoch 4/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.1940 - acc: 0.9284 - val_loss: 0.2368 - val_acc: 0.9141\n",
      "Epoch 5/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.1894 - acc: 0.9320 - val_loss: 0.2610 - val_acc: 0.9059\n",
      "Epoch 6/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.1930 - acc: 0.9269 - val_loss: 0.2585 - val_acc: 0.9121\n",
      "Epoch 7/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.1839 - acc: 0.9366 - val_loss: 0.2469 - val_acc: 0.9121\n",
      "Epoch 8/100\n",
      "1955/1955 [==============================] - 1s 325us/step - loss: 0.1865 - acc: 0.9258 - val_loss: 0.2538 - val_acc: 0.9121\n",
      "Epoch 9/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.1851 - acc: 0.9289 - val_loss: 0.2405 - val_acc: 0.9162\n",
      "Epoch 10/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.1786 - acc: 0.9325 - val_loss: 0.2486 - val_acc: 0.9121\n",
      "Epoch 11/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.1798 - acc: 0.9361 - val_loss: 0.2535 - val_acc: 0.9141\n",
      "Epoch 12/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.1763 - acc: 0.9402 - val_loss: 0.2355 - val_acc: 0.9243\n",
      "Epoch 13/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.1859 - acc: 0.9340 - val_loss: 0.2412 - val_acc: 0.9182\n",
      "Epoch 14/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.1760 - acc: 0.9391 - val_loss: 0.2607 - val_acc: 0.9141\n",
      "Epoch 15/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.1718 - acc: 0.9402 - val_loss: 0.2509 - val_acc: 0.9121\n",
      "Epoch 16/100\n",
      "1955/1955 [==============================] - 1s 342us/step - loss: 0.1723 - acc: 0.9350 - val_loss: 0.2392 - val_acc: 0.9182\n",
      "Epoch 17/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.1745 - acc: 0.9350 - val_loss: 0.2515 - val_acc: 0.9162\n",
      "Epoch 18/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.1653 - acc: 0.9412 - val_loss: 0.2527 - val_acc: 0.9162\n",
      "Epoch 19/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.1701 - acc: 0.9386 - val_loss: 0.2920 - val_acc: 0.8957\n",
      "Epoch 20/100\n",
      "1955/1955 [==============================] - 1s 338us/step - loss: 0.1734 - acc: 0.9340 - val_loss: 0.2478 - val_acc: 0.9141\n",
      "Epoch 21/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.1660 - acc: 0.9417 - val_loss: 0.2405 - val_acc: 0.9223\n",
      "Epoch 22/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.1574 - acc: 0.9427 - val_loss: 0.2333 - val_acc: 0.9305\n",
      "Epoch 23/100\n",
      "1955/1955 [==============================] - 1s 355us/step - loss: 0.1638 - acc: 0.9422 - val_loss: 0.2629 - val_acc: 0.9100\n",
      "Epoch 24/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.1639 - acc: 0.9478 - val_loss: 0.2626 - val_acc: 0.9141\n",
      "Epoch 25/100\n",
      "1955/1955 [==============================] - 1s 337us/step - loss: 0.1561 - acc: 0.9463 - val_loss: 0.2489 - val_acc: 0.9202\n",
      "Epoch 26/100\n",
      "1955/1955 [==============================] - 1s 338us/step - loss: 0.1611 - acc: 0.9407 - val_loss: 0.2495 - val_acc: 0.9202\n",
      "Epoch 27/100\n",
      "1955/1955 [==============================] - 1s 336us/step - loss: 0.1552 - acc: 0.9453 - val_loss: 0.2464 - val_acc: 0.9202\n",
      "Epoch 28/100\n",
      "1955/1955 [==============================] - 1s 338us/step - loss: 0.1683 - acc: 0.9355 - val_loss: 0.2620 - val_acc: 0.9141\n",
      "Epoch 29/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.1573 - acc: 0.9448 - val_loss: 0.2471 - val_acc: 0.9243\n",
      "Epoch 30/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.1546 - acc: 0.9442 - val_loss: 0.2580 - val_acc: 0.9162\n",
      "Epoch 31/100\n",
      "1955/1955 [==============================] - 1s 347us/step - loss: 0.1539 - acc: 0.9458 - val_loss: 0.2470 - val_acc: 0.9162\n",
      "Epoch 32/100\n",
      "1955/1955 [==============================] - 1s 336us/step - loss: 0.1457 - acc: 0.9509 - val_loss: 0.2490 - val_acc: 0.9243\n",
      "Epoch 33/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.1602 - acc: 0.9463 - val_loss: 0.2456 - val_acc: 0.9182\n",
      "Epoch 34/100\n",
      "1955/1955 [==============================] - 1s 341us/step - loss: 0.1543 - acc: 0.9473 - val_loss: 0.2506 - val_acc: 0.9182\n",
      "Epoch 35/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.1513 - acc: 0.9468 - val_loss: 0.2565 - val_acc: 0.9182\n",
      "Epoch 36/100\n",
      "1955/1955 [==============================] - 1s 345us/step - loss: 0.1547 - acc: 0.9468 - val_loss: 0.2440 - val_acc: 0.9202\n",
      "Epoch 37/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.1480 - acc: 0.9463 - val_loss: 0.2783 - val_acc: 0.9039\n",
      "Epoch 38/100\n",
      "1955/1955 [==============================] - 1s 323us/step - loss: 0.1492 - acc: 0.9478 - val_loss: 0.2434 - val_acc: 0.9121\n",
      "Epoch 39/100\n",
      "1955/1955 [==============================] - 1s 341us/step - loss: 0.1600 - acc: 0.9427 - val_loss: 0.2610 - val_acc: 0.9162\n",
      "Epoch 40/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.1476 - acc: 0.9499 - val_loss: 0.2524 - val_acc: 0.9182\n",
      "Epoch 41/100\n",
      "1955/1955 [==============================] - 1s 336us/step - loss: 0.1564 - acc: 0.9468 - val_loss: 0.2614 - val_acc: 0.9202\n",
      "Epoch 42/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.1400 - acc: 0.9535 - val_loss: 0.2402 - val_acc: 0.9100\n",
      "Epoch 43/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.1449 - acc: 0.9468 - val_loss: 0.2526 - val_acc: 0.9182\n",
      "Epoch 44/100\n",
      "1955/1955 [==============================] - 1s 326us/step - loss: 0.1463 - acc: 0.9488 - val_loss: 0.2596 - val_acc: 0.9182\n",
      "Epoch 45/100\n",
      "1955/1955 [==============================] - 1s 337us/step - loss: 0.1487 - acc: 0.9473 - val_loss: 0.2451 - val_acc: 0.9243\n",
      "Epoch 46/100\n",
      "1955/1955 [==============================] - 1s 336us/step - loss: 0.1427 - acc: 0.9524 - val_loss: 0.2321 - val_acc: 0.9305\n",
      "Epoch 47/100\n",
      "1955/1955 [==============================] - 1s 337us/step - loss: 0.1418 - acc: 0.9499 - val_loss: 0.2417 - val_acc: 0.9202\n",
      "Epoch 48/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.1476 - acc: 0.9483 - val_loss: 0.2553 - val_acc: 0.9182\n",
      "Epoch 49/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.1354 - acc: 0.9524 - val_loss: 0.2580 - val_acc: 0.9121\n",
      "Epoch 50/100\n",
      "1955/1955 [==============================] - 1s 346us/step - loss: 0.1331 - acc: 0.9575 - val_loss: 0.2640 - val_acc: 0.9141\n",
      "Epoch 51/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.1411 - acc: 0.9499 - val_loss: 0.2657 - val_acc: 0.9100\n",
      "Epoch 52/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.1430 - acc: 0.9509 - val_loss: 0.2536 - val_acc: 0.9162\n",
      "Epoch 53/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.1334 - acc: 0.9570 - val_loss: 0.2438 - val_acc: 0.9182\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.1402 - acc: 0.9468 - val_loss: 0.2489 - val_acc: 0.9202\n",
      "Epoch 55/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.1309 - acc: 0.9529 - val_loss: 0.2574 - val_acc: 0.9182\n",
      "Epoch 56/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.1324 - acc: 0.9560 - val_loss: 0.2582 - val_acc: 0.9202\n",
      "Epoch 57/100\n",
      "1955/1955 [==============================] - 1s 340us/step - loss: 0.1448 - acc: 0.9499 - val_loss: 0.2645 - val_acc: 0.9202\n",
      "Epoch 58/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.1367 - acc: 0.9545 - val_loss: 0.2637 - val_acc: 0.9182\n",
      "Epoch 59/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.1370 - acc: 0.9529 - val_loss: 0.2442 - val_acc: 0.9202\n",
      "Epoch 60/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.1311 - acc: 0.9535 - val_loss: 0.2463 - val_acc: 0.9243\n",
      "Epoch 61/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.1343 - acc: 0.9514 - val_loss: 0.2445 - val_acc: 0.9223\n",
      "Epoch 62/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.1368 - acc: 0.9581 - val_loss: 0.2448 - val_acc: 0.9243\n",
      "Epoch 63/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.1357 - acc: 0.9524 - val_loss: 0.2525 - val_acc: 0.9202\n",
      "Epoch 64/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.1328 - acc: 0.9565 - val_loss: 0.2572 - val_acc: 0.9182\n",
      "Epoch 65/100\n",
      "1955/1955 [==============================] - 1s 325us/step - loss: 0.1366 - acc: 0.9535 - val_loss: 0.2468 - val_acc: 0.9264\n",
      "Epoch 66/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.1354 - acc: 0.9545 - val_loss: 0.2468 - val_acc: 0.9223\n",
      "Epoch 67/100\n",
      "1955/1955 [==============================] - 1s 341us/step - loss: 0.1327 - acc: 0.9560 - val_loss: 0.2794 - val_acc: 0.9141\n",
      "Epoch 68/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.1267 - acc: 0.9565 - val_loss: 0.2423 - val_acc: 0.9223\n",
      "Epoch 69/100\n",
      "1955/1955 [==============================] - 1s 343us/step - loss: 0.1274 - acc: 0.9591 - val_loss: 0.2467 - val_acc: 0.9243\n",
      "Epoch 70/100\n",
      "1955/1955 [==============================] - 1s 343us/step - loss: 0.1328 - acc: 0.9565 - val_loss: 0.2652 - val_acc: 0.9182\n",
      "Epoch 71/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.1258 - acc: 0.9575 - val_loss: 0.2683 - val_acc: 0.9182\n",
      "Epoch 72/100\n",
      "1955/1955 [==============================] - 1s 349us/step - loss: 0.1286 - acc: 0.9591 - val_loss: 0.2440 - val_acc: 0.9243\n",
      "Epoch 73/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.1313 - acc: 0.9509 - val_loss: 0.2608 - val_acc: 0.9202\n",
      "Epoch 74/100\n",
      "1955/1955 [==============================] - 1s 337us/step - loss: 0.1277 - acc: 0.9565 - val_loss: 0.2509 - val_acc: 0.9243\n",
      "Epoch 75/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.1178 - acc: 0.9662 - val_loss: 0.2610 - val_acc: 0.9223\n",
      "Epoch 76/100\n",
      "1955/1955 [==============================] - 1s 337us/step - loss: 0.1298 - acc: 0.9596 - val_loss: 0.2658 - val_acc: 0.9182\n",
      "Epoch 77/100\n",
      "1955/1955 [==============================] - 1s 342us/step - loss: 0.1257 - acc: 0.9575 - val_loss: 0.2658 - val_acc: 0.9202\n",
      "Epoch 78/100\n",
      "1955/1955 [==============================] - 1s 346us/step - loss: 0.1405 - acc: 0.9529 - val_loss: 0.2755 - val_acc: 0.9121\n",
      "Epoch 79/100\n",
      "1955/1955 [==============================] - 1s 355us/step - loss: 0.1274 - acc: 0.9575 - val_loss: 0.2244 - val_acc: 0.9264\n",
      "Epoch 80/100\n",
      "1955/1955 [==============================] - 1s 344us/step - loss: 0.1232 - acc: 0.9581 - val_loss: 0.2548 - val_acc: 0.9202\n",
      "Epoch 81/100\n",
      "1955/1955 [==============================] - 1s 358us/step - loss: 0.1338 - acc: 0.9555 - val_loss: 0.2510 - val_acc: 0.9243\n",
      "Epoch 82/100\n",
      "1955/1955 [==============================] - 1s 342us/step - loss: 0.1201 - acc: 0.9642 - val_loss: 0.2618 - val_acc: 0.9182\n",
      "Epoch 83/100\n",
      "1955/1955 [==============================] - 1s 359us/step - loss: 0.1301 - acc: 0.9560 - val_loss: 0.2607 - val_acc: 0.9182\n",
      "Epoch 84/100\n",
      "1955/1955 [==============================] - 1s 338us/step - loss: 0.1287 - acc: 0.9586 - val_loss: 0.2550 - val_acc: 0.9223\n",
      "Epoch 85/100\n",
      "1955/1955 [==============================] - 1s 351us/step - loss: 0.1195 - acc: 0.9611 - val_loss: 0.2441 - val_acc: 0.9202\n",
      "Epoch 86/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.1275 - acc: 0.9570 - val_loss: 0.2509 - val_acc: 0.9223\n",
      "Epoch 87/100\n",
      "1955/1955 [==============================] - 1s 343us/step - loss: 0.1286 - acc: 0.9581 - val_loss: 0.2487 - val_acc: 0.9223\n",
      "Epoch 88/100\n",
      "1955/1955 [==============================] - 1s 340us/step - loss: 0.1307 - acc: 0.9555 - val_loss: 0.2615 - val_acc: 0.9182\n",
      "Epoch 89/100\n",
      "1955/1955 [==============================] - 1s 340us/step - loss: 0.1194 - acc: 0.9596 - val_loss: 0.2577 - val_acc: 0.9223\n",
      "Epoch 90/100\n",
      "1955/1955 [==============================] - 1s 338us/step - loss: 0.1245 - acc: 0.9565 - val_loss: 0.2475 - val_acc: 0.9223\n",
      "Epoch 91/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.1178 - acc: 0.9662 - val_loss: 0.2446 - val_acc: 0.9223\n",
      "Epoch 92/100\n",
      "1955/1955 [==============================] - 1s 337us/step - loss: 0.1215 - acc: 0.9586 - val_loss: 0.2503 - val_acc: 0.9243\n",
      "Epoch 93/100\n",
      "1955/1955 [==============================] - 1s 360us/step - loss: 0.1190 - acc: 0.9611 - val_loss: 0.2551 - val_acc: 0.9202\n",
      "Epoch 94/100\n",
      "1955/1955 [==============================] - 1s 342us/step - loss: 0.1211 - acc: 0.9627 - val_loss: 0.2546 - val_acc: 0.9223\n",
      "Epoch 95/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.1170 - acc: 0.9616 - val_loss: 0.2507 - val_acc: 0.9223\n",
      "Epoch 96/100\n",
      "1955/1955 [==============================] - 1s 340us/step - loss: 0.1196 - acc: 0.9616 - val_loss: 0.2506 - val_acc: 0.9223\n",
      "Epoch 97/100\n",
      "1955/1955 [==============================] - 1s 346us/step - loss: 0.1134 - acc: 0.9647 - val_loss: 0.2615 - val_acc: 0.9202\n",
      "Epoch 98/100\n",
      "1955/1955 [==============================] - 1s 366us/step - loss: 0.1243 - acc: 0.9586 - val_loss: 0.2346 - val_acc: 0.9243\n",
      "Epoch 99/100\n",
      "1955/1955 [==============================] - 1s 366us/step - loss: 0.1104 - acc: 0.9632 - val_loss: 0.2197 - val_acc: 0.9346\n",
      "Epoch 100/100\n",
      "1955/1955 [==============================] - 1s 355us/step - loss: 0.1142 - acc: 0.9601 - val_loss: 0.2473 - val_acc: 0.9264\n",
      "Test subject 12, class FirstDigitTouch\n",
      "Train subject 12, class BothStartLoadPhase\n",
      "Train on 1955 samples, validate on 489 samples\n",
      "Epoch 1/100\n",
      "1955/1955 [==============================] - 1s 343us/step - loss: 0.7496 - acc: 0.7156 - val_loss: 0.5796 - val_acc: 0.7526\n",
      "Epoch 2/100\n",
      "1955/1955 [==============================] - 1s 349us/step - loss: 0.5794 - acc: 0.7407 - val_loss: 0.5430 - val_acc: 0.7587\n",
      "Epoch 3/100\n",
      "1955/1955 [==============================] - 1s 337us/step - loss: 0.5397 - acc: 0.7453 - val_loss: 0.4831 - val_acc: 0.7812\n",
      "Epoch 4/100\n",
      "1955/1955 [==============================] - 1s 338us/step - loss: 0.4940 - acc: 0.7683 - val_loss: 0.4544 - val_acc: 0.8037\n",
      "Epoch 5/100\n",
      "1955/1955 [==============================] - 1s 352us/step - loss: 0.4721 - acc: 0.7775 - val_loss: 0.4508 - val_acc: 0.8037\n",
      "Epoch 6/100\n",
      "1955/1955 [==============================] - 1s 343us/step - loss: 0.4537 - acc: 0.7862 - val_loss: 0.4407 - val_acc: 0.8078\n",
      "Epoch 7/100\n",
      "1955/1955 [==============================] - 1s 344us/step - loss: 0.4432 - acc: 0.7867 - val_loss: 0.4300 - val_acc: 0.8119\n",
      "Epoch 8/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.4328 - acc: 0.7990 - val_loss: 0.4095 - val_acc: 0.8262\n",
      "Epoch 9/100\n",
      "1955/1955 [==============================] - 1s 336us/step - loss: 0.4132 - acc: 0.8010 - val_loss: 0.4213 - val_acc: 0.8119\n",
      "Epoch 10/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.3995 - acc: 0.8199 - val_loss: 0.3985 - val_acc: 0.8344\n",
      "Epoch 11/100\n",
      "1955/1955 [==============================] - 1s 336us/step - loss: 0.4133 - acc: 0.8087 - val_loss: 0.3919 - val_acc: 0.8303\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1955/1955 [==============================] - 1s 339us/step - loss: 0.3960 - acc: 0.8199 - val_loss: 0.3913 - val_acc: 0.8303\n",
      "Epoch 13/100\n",
      "1955/1955 [==============================] - 1s 338us/step - loss: 0.3889 - acc: 0.8189 - val_loss: 0.3894 - val_acc: 0.8282\n",
      "Epoch 14/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.3671 - acc: 0.8389 - val_loss: 0.3865 - val_acc: 0.8364\n",
      "Epoch 15/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.3725 - acc: 0.8322 - val_loss: 0.3898 - val_acc: 0.8323\n",
      "Epoch 16/100\n",
      "1955/1955 [==============================] - 1s 340us/step - loss: 0.3608 - acc: 0.8338 - val_loss: 0.3723 - val_acc: 0.8446\n",
      "Epoch 17/100\n",
      "1955/1955 [==============================] - 1s 345us/step - loss: 0.3600 - acc: 0.8358 - val_loss: 0.3701 - val_acc: 0.8487\n",
      "Epoch 18/100\n",
      "1955/1955 [==============================] - 1s 344us/step - loss: 0.3450 - acc: 0.8450 - val_loss: 0.3791 - val_acc: 0.8446\n",
      "Epoch 19/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.3453 - acc: 0.8455 - val_loss: 0.3583 - val_acc: 0.8569\n",
      "Epoch 20/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.3452 - acc: 0.8481 - val_loss: 0.3492 - val_acc: 0.8630\n",
      "Epoch 21/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.3406 - acc: 0.8512 - val_loss: 0.3491 - val_acc: 0.8650\n",
      "Epoch 22/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.3248 - acc: 0.8583 - val_loss: 0.3502 - val_acc: 0.8671\n",
      "Epoch 23/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.3160 - acc: 0.8634 - val_loss: 0.3461 - val_acc: 0.8650\n",
      "Epoch 24/100\n",
      "1955/1955 [==============================] - 1s 351us/step - loss: 0.3181 - acc: 0.8639 - val_loss: 0.3432 - val_acc: 0.8671\n",
      "Epoch 25/100\n",
      "1955/1955 [==============================] - 1s 351us/step - loss: 0.3129 - acc: 0.8696 - val_loss: 0.3337 - val_acc: 0.8671\n",
      "Epoch 26/100\n",
      "1955/1955 [==============================] - 1s 384us/step - loss: 0.3017 - acc: 0.8680 - val_loss: 0.3360 - val_acc: 0.8773\n",
      "Epoch 27/100\n",
      "1955/1955 [==============================] - 1s 372us/step - loss: 0.3043 - acc: 0.8655 - val_loss: 0.3320 - val_acc: 0.8753\n",
      "Epoch 28/100\n",
      "1955/1955 [==============================] - 1s 353us/step - loss: 0.2920 - acc: 0.8762 - val_loss: 0.3257 - val_acc: 0.8773\n",
      "Epoch 29/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.2912 - acc: 0.8824 - val_loss: 0.3275 - val_acc: 0.8732\n",
      "Epoch 30/100\n",
      "1955/1955 [==============================] - 1s 340us/step - loss: 0.3028 - acc: 0.8691 - val_loss: 0.3200 - val_acc: 0.8773\n",
      "Epoch 31/100\n",
      "1955/1955 [==============================] - 1s 337us/step - loss: 0.2910 - acc: 0.8798 - val_loss: 0.3120 - val_acc: 0.8814\n",
      "Epoch 32/100\n",
      "1955/1955 [==============================] - 1s 339us/step - loss: 0.2826 - acc: 0.8813 - val_loss: 0.3037 - val_acc: 0.8875\n",
      "Epoch 33/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.2810 - acc: 0.8864 - val_loss: 0.3031 - val_acc: 0.8916\n",
      "Epoch 34/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.2756 - acc: 0.8864 - val_loss: 0.3031 - val_acc: 0.8875\n",
      "Epoch 35/100\n",
      "1955/1955 [==============================] - 1s 345us/step - loss: 0.2709 - acc: 0.8916 - val_loss: 0.2999 - val_acc: 0.8834\n",
      "Epoch 36/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.2675 - acc: 0.8926 - val_loss: 0.3014 - val_acc: 0.8855\n",
      "Epoch 37/100\n",
      "1955/1955 [==============================] - 1s 347us/step - loss: 0.2705 - acc: 0.8859 - val_loss: 0.2904 - val_acc: 0.8896\n",
      "Epoch 38/100\n",
      "1955/1955 [==============================] - 1s 346us/step - loss: 0.2685 - acc: 0.8854 - val_loss: 0.3147 - val_acc: 0.8855\n",
      "Epoch 39/100\n",
      "1955/1955 [==============================] - 1s 350us/step - loss: 0.2667 - acc: 0.8921 - val_loss: 0.2856 - val_acc: 0.8998\n",
      "Epoch 40/100\n",
      "1955/1955 [==============================] - 1s 376us/step - loss: 0.2667 - acc: 0.8941 - val_loss: 0.2918 - val_acc: 0.8957\n",
      "Epoch 41/100\n",
      "1955/1955 [==============================] - 1s 362us/step - loss: 0.2666 - acc: 0.8864 - val_loss: 0.2842 - val_acc: 0.8978\n",
      "Epoch 42/100\n",
      "1955/1955 [==============================] - 1s 344us/step - loss: 0.2425 - acc: 0.9049 - val_loss: 0.2834 - val_acc: 0.9059\n",
      "Epoch 43/100\n",
      "1955/1955 [==============================] - 1s 325us/step - loss: 0.2467 - acc: 0.8997 - val_loss: 0.2889 - val_acc: 0.9039\n",
      "Epoch 44/100\n",
      "1955/1955 [==============================] - ETA: 0s - loss: 0.2489 - acc: 0.905 - 1s 327us/step - loss: 0.2489 - acc: 0.9054 - val_loss: 0.2721 - val_acc: 0.8978\n",
      "Epoch 45/100\n",
      "1955/1955 [==============================] - 1s 355us/step - loss: 0.2491 - acc: 0.8987 - val_loss: 0.2778 - val_acc: 0.9018\n",
      "Epoch 46/100\n",
      "1955/1955 [==============================] - 1s 347us/step - loss: 0.2374 - acc: 0.9013 - val_loss: 0.2757 - val_acc: 0.9080\n",
      "Epoch 47/100\n",
      "1955/1955 [==============================] - 1s 347us/step - loss: 0.2446 - acc: 0.9023 - val_loss: 0.2832 - val_acc: 0.9039\n",
      "Epoch 48/100\n",
      "1955/1955 [==============================] - 1s 355us/step - loss: 0.2346 - acc: 0.9095 - val_loss: 0.2729 - val_acc: 0.9059\n",
      "Epoch 49/100\n",
      "1955/1955 [==============================] - 1s 343us/step - loss: 0.2339 - acc: 0.9038 - val_loss: 0.2710 - val_acc: 0.9018\n",
      "Epoch 50/100\n",
      "1955/1955 [==============================] - 1s 341us/step - loss: 0.2283 - acc: 0.9120 - val_loss: 0.2654 - val_acc: 0.9039\n",
      "Epoch 51/100\n",
      "1955/1955 [==============================] - 1s 351us/step - loss: 0.2310 - acc: 0.9054 - val_loss: 0.2698 - val_acc: 0.9018\n",
      "Epoch 52/100\n",
      "1955/1955 [==============================] - 1s 350us/step - loss: 0.2212 - acc: 0.9130 - val_loss: 0.2680 - val_acc: 0.9080\n",
      "Epoch 53/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.2344 - acc: 0.9120 - val_loss: 0.2657 - val_acc: 0.9080\n",
      "Epoch 54/100\n",
      "1955/1955 [==============================] - 1s 336us/step - loss: 0.2229 - acc: 0.9146 - val_loss: 0.2685 - val_acc: 0.9080\n",
      "Epoch 55/100\n",
      "1955/1955 [==============================] - 1s 346us/step - loss: 0.2392 - acc: 0.9043 - val_loss: 0.2645 - val_acc: 0.9100\n",
      "Epoch 56/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.2148 - acc: 0.9207 - val_loss: 0.2555 - val_acc: 0.9100\n",
      "Epoch 57/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.2188 - acc: 0.9136 - val_loss: 0.2615 - val_acc: 0.9121\n",
      "Epoch 58/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.2293 - acc: 0.9074 - val_loss: 0.2563 - val_acc: 0.9059\n",
      "Epoch 59/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.2187 - acc: 0.9182 - val_loss: 0.2490 - val_acc: 0.9121\n",
      "Epoch 60/100\n",
      "1955/1955 [==============================] - 1s 337us/step - loss: 0.2089 - acc: 0.9197 - val_loss: 0.2540 - val_acc: 0.9141\n",
      "Epoch 61/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.2229 - acc: 0.9161 - val_loss: 0.2498 - val_acc: 0.9121\n",
      "Epoch 62/100\n",
      "1955/1955 [==============================] - 1s 325us/step - loss: 0.2050 - acc: 0.9207 - val_loss: 0.2631 - val_acc: 0.9100\n",
      "Epoch 63/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.2192 - acc: 0.9120 - val_loss: 0.2635 - val_acc: 0.9100\n",
      "Epoch 64/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.2084 - acc: 0.9187 - val_loss: 0.2437 - val_acc: 0.9202\n",
      "Epoch 65/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.2043 - acc: 0.9171 - val_loss: 0.2448 - val_acc: 0.9182\n",
      "Epoch 66/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.2020 - acc: 0.9253 - val_loss: 0.2433 - val_acc: 0.9223\n",
      "Epoch 67/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.2067 - acc: 0.9243 - val_loss: 0.2524 - val_acc: 0.9162\n",
      "Epoch 68/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.1978 - acc: 0.9253 - val_loss: 0.2421 - val_acc: 0.9223\n",
      "Epoch 69/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.1962 - acc: 0.9248 - val_loss: 0.2462 - val_acc: 0.9223\n",
      "Epoch 70/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.1965 - acc: 0.9274 - val_loss: 0.2409 - val_acc: 0.9243\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.2024 - acc: 0.9263 - val_loss: 0.2444 - val_acc: 0.9223\n",
      "Epoch 72/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.1945 - acc: 0.9269 - val_loss: 0.2418 - val_acc: 0.9243\n",
      "Epoch 73/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.1838 - acc: 0.9355 - val_loss: 0.2398 - val_acc: 0.9243\n",
      "Epoch 74/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.1925 - acc: 0.9228 - val_loss: 0.2355 - val_acc: 0.9223\n",
      "Epoch 75/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.1930 - acc: 0.9289 - val_loss: 0.2382 - val_acc: 0.9264\n",
      "Epoch 76/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.1889 - acc: 0.9320 - val_loss: 0.2334 - val_acc: 0.9264\n",
      "Epoch 77/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.1819 - acc: 0.9345 - val_loss: 0.2312 - val_acc: 0.9243\n",
      "Epoch 78/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.1826 - acc: 0.9350 - val_loss: 0.2445 - val_acc: 0.9264\n",
      "Epoch 79/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.1885 - acc: 0.9371 - val_loss: 0.2382 - val_acc: 0.9243\n",
      "Epoch 80/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.1844 - acc: 0.9309 - val_loss: 0.2350 - val_acc: 0.9284\n",
      "Epoch 81/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.1898 - acc: 0.9355 - val_loss: 0.2316 - val_acc: 0.9305\n",
      "Epoch 82/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.1817 - acc: 0.9335 - val_loss: 0.2328 - val_acc: 0.9284\n",
      "Epoch 83/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.1794 - acc: 0.9355 - val_loss: 0.2299 - val_acc: 0.9284\n",
      "Epoch 84/100\n",
      "1955/1955 [==============================] - 1s 336us/step - loss: 0.1835 - acc: 0.9335 - val_loss: 0.2408 - val_acc: 0.9182\n",
      "Epoch 85/100\n",
      "1955/1955 [==============================] - 1s 326us/step - loss: 0.1782 - acc: 0.9330 - val_loss: 0.2313 - val_acc: 0.9284\n",
      "Epoch 86/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.1693 - acc: 0.9355 - val_loss: 0.2311 - val_acc: 0.9284\n",
      "Epoch 87/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.1695 - acc: 0.9381 - val_loss: 0.2264 - val_acc: 0.9284\n",
      "Epoch 88/100\n",
      "1955/1955 [==============================] - 1s 337us/step - loss: 0.1679 - acc: 0.9396 - val_loss: 0.2386 - val_acc: 0.9264\n",
      "Epoch 89/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.1793 - acc: 0.9320 - val_loss: 0.2283 - val_acc: 0.9284\n",
      "Epoch 90/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.1827 - acc: 0.9340 - val_loss: 0.2530 - val_acc: 0.9162\n",
      "Epoch 91/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.1831 - acc: 0.9294 - val_loss: 0.2296 - val_acc: 0.9305\n",
      "Epoch 92/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.1669 - acc: 0.9386 - val_loss: 0.2274 - val_acc: 0.9284\n",
      "Epoch 93/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.1710 - acc: 0.9386 - val_loss: 0.2263 - val_acc: 0.9284\n",
      "Epoch 94/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.1746 - acc: 0.9325 - val_loss: 0.2295 - val_acc: 0.9305\n",
      "Epoch 95/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.1710 - acc: 0.9371 - val_loss: 0.2295 - val_acc: 0.9325\n",
      "Epoch 96/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.1658 - acc: 0.9432 - val_loss: 0.2310 - val_acc: 0.9284\n",
      "Epoch 97/100\n",
      "1955/1955 [==============================] - 1s 340us/step - loss: 0.1696 - acc: 0.9386 - val_loss: 0.2275 - val_acc: 0.9305\n",
      "Epoch 98/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.1701 - acc: 0.9427 - val_loss: 0.2281 - val_acc: 0.9305\n",
      "Epoch 99/100\n",
      "1955/1955 [==============================] - 1s 336us/step - loss: 0.1716 - acc: 0.9325 - val_loss: 0.2285 - val_acc: 0.9325\n",
      "Epoch 100/100\n",
      "1955/1955 [==============================] - 1s 339us/step - loss: 0.1625 - acc: 0.9437 - val_loss: 0.2280 - val_acc: 0.9325\n",
      "Train on 1955 samples, validate on 489 samples\n",
      "Epoch 1/100\n",
      "1955/1955 [==============================] - 1s 352us/step - loss: 0.2270 - acc: 0.9151 - val_loss: 0.2377 - val_acc: 0.9202\n",
      "Epoch 2/100\n",
      "1955/1955 [==============================] - 1s 345us/step - loss: 0.2383 - acc: 0.9120 - val_loss: 0.2347 - val_acc: 0.9162\n",
      "Epoch 3/100\n",
      "1955/1955 [==============================] - 1s 336us/step - loss: 0.2318 - acc: 0.9166 - val_loss: 0.2396 - val_acc: 0.9100\n",
      "Epoch 4/100\n",
      "1955/1955 [==============================] - 1s 342us/step - loss: 0.2248 - acc: 0.9161 - val_loss: 0.2406 - val_acc: 0.9059\n",
      "Epoch 5/100\n",
      "1955/1955 [==============================] - 1s 352us/step - loss: 0.2238 - acc: 0.9212 - val_loss: 0.2318 - val_acc: 0.9121\n",
      "Epoch 6/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.2138 - acc: 0.9253 - val_loss: 0.2403 - val_acc: 0.9080\n",
      "Epoch 7/100\n",
      "1955/1955 [==============================] - 1s 358us/step - loss: 0.2085 - acc: 0.9269 - val_loss: 0.2333 - val_acc: 0.9121\n",
      "Epoch 8/100\n",
      "1955/1955 [==============================] - 1s 373us/step - loss: 0.2075 - acc: 0.9228 - val_loss: 0.2383 - val_acc: 0.9100\n",
      "Epoch 9/100\n",
      "1955/1955 [==============================] - 1s 349us/step - loss: 0.2112 - acc: 0.9238 - val_loss: 0.2301 - val_acc: 0.9100\n",
      "Epoch 10/100\n",
      "1955/1955 [==============================] - 1s 350us/step - loss: 0.2070 - acc: 0.9263 - val_loss: 0.2257 - val_acc: 0.9121\n",
      "Epoch 11/100\n",
      "1955/1955 [==============================] - 1s 349us/step - loss: 0.2018 - acc: 0.9279 - val_loss: 0.2278 - val_acc: 0.9121\n",
      "Epoch 12/100\n",
      "1955/1955 [==============================] - 1s 343us/step - loss: 0.2127 - acc: 0.9223 - val_loss: 0.2287 - val_acc: 0.9202\n",
      "Epoch 13/100\n",
      "1955/1955 [==============================] - 1s 349us/step - loss: 0.2048 - acc: 0.9263 - val_loss: 0.2320 - val_acc: 0.9121\n",
      "Epoch 14/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.2040 - acc: 0.9355 - val_loss: 0.2187 - val_acc: 0.9243\n",
      "Epoch 15/100\n",
      "1955/1955 [==============================] - 1s 340us/step - loss: 0.2114 - acc: 0.9228 - val_loss: 0.2303 - val_acc: 0.9162\n",
      "Epoch 16/100\n",
      "1955/1955 [==============================] - 1s 337us/step - loss: 0.1990 - acc: 0.9361 - val_loss: 0.2298 - val_acc: 0.9182\n",
      "Epoch 17/100\n",
      "1955/1955 [==============================] - 1s 351us/step - loss: 0.1977 - acc: 0.9320 - val_loss: 0.2228 - val_acc: 0.9162\n",
      "Epoch 18/100\n",
      "1955/1955 [==============================] - 1s 346us/step - loss: 0.1910 - acc: 0.9320 - val_loss: 0.2265 - val_acc: 0.9182\n",
      "Epoch 19/100\n",
      "1955/1955 [==============================] - 1s 345us/step - loss: 0.1927 - acc: 0.9330 - val_loss: 0.2280 - val_acc: 0.9121\n",
      "Epoch 20/100\n",
      "1955/1955 [==============================] - 1s 339us/step - loss: 0.1862 - acc: 0.9361 - val_loss: 0.2162 - val_acc: 0.9121\n",
      "Epoch 21/100\n",
      "1955/1955 [==============================] - 1s 336us/step - loss: 0.1918 - acc: 0.9315 - val_loss: 0.2193 - val_acc: 0.9182\n",
      "Epoch 22/100\n",
      "1955/1955 [==============================] - 1s 341us/step - loss: 0.1997 - acc: 0.9233 - val_loss: 0.2173 - val_acc: 0.9182\n",
      "Epoch 23/100\n",
      "1955/1955 [==============================] - 1s 347us/step - loss: 0.1794 - acc: 0.9402 - val_loss: 0.2165 - val_acc: 0.9182\n",
      "Epoch 24/100\n",
      "1955/1955 [==============================] - 1s 346us/step - loss: 0.1777 - acc: 0.9463 - val_loss: 0.2166 - val_acc: 0.9223\n",
      "Epoch 25/100\n",
      "1955/1955 [==============================] - 1s 351us/step - loss: 0.1847 - acc: 0.9381 - val_loss: 0.2365 - val_acc: 0.9080\n",
      "Epoch 26/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.1950 - acc: 0.9345 - val_loss: 0.2252 - val_acc: 0.9182\n",
      "Epoch 27/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.1823 - acc: 0.9391 - val_loss: 0.2290 - val_acc: 0.9121\n",
      "Epoch 28/100\n",
      "1955/1955 [==============================] - 1s 353us/step - loss: 0.1835 - acc: 0.9345 - val_loss: 0.2118 - val_acc: 0.9202\n",
      "Epoch 29/100\n",
      "1955/1955 [==============================] - 1s 343us/step - loss: 0.1868 - acc: 0.9355 - val_loss: 0.2121 - val_acc: 0.9202\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.1869 - acc: 0.9361 - val_loss: 0.2251 - val_acc: 0.9182\n",
      "Epoch 31/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.1847 - acc: 0.9340 - val_loss: 0.2091 - val_acc: 0.9202\n",
      "Epoch 32/100\n",
      "1955/1955 [==============================] - 1s 353us/step - loss: 0.1826 - acc: 0.9350 - val_loss: 0.2108 - val_acc: 0.9182\n",
      "Epoch 33/100\n",
      "1955/1955 [==============================] - 1s 362us/step - loss: 0.1784 - acc: 0.9381 - val_loss: 0.2119 - val_acc: 0.9182\n",
      "Epoch 34/100\n",
      "1955/1955 [==============================] - 1s 392us/step - loss: 0.1859 - acc: 0.9345 - val_loss: 0.2183 - val_acc: 0.9141\n",
      "Epoch 35/100\n",
      "1955/1955 [==============================] - 1s 395us/step - loss: 0.1779 - acc: 0.9407 - val_loss: 0.2053 - val_acc: 0.9264\n",
      "Epoch 36/100\n",
      "1955/1955 [==============================] - 1s 354us/step - loss: 0.1841 - acc: 0.9361 - val_loss: 0.2077 - val_acc: 0.9243\n",
      "Epoch 37/100\n",
      "1955/1955 [==============================] - 1s 367us/step - loss: 0.1862 - acc: 0.9299 - val_loss: 0.2101 - val_acc: 0.9182\n",
      "Epoch 38/100\n",
      "1955/1955 [==============================] - 1s 386us/step - loss: 0.1762 - acc: 0.9396 - val_loss: 0.2102 - val_acc: 0.9202\n",
      "Epoch 39/100\n",
      "1955/1955 [==============================] - 1s 383us/step - loss: 0.1773 - acc: 0.9371 - val_loss: 0.2103 - val_acc: 0.9223\n",
      "Epoch 40/100\n",
      "1955/1955 [==============================] - 1s 396us/step - loss: 0.1782 - acc: 0.9412 - val_loss: 0.2163 - val_acc: 0.9162\n",
      "Epoch 41/100\n",
      "1955/1955 [==============================] - 1s 384us/step - loss: 0.1721 - acc: 0.9427 - val_loss: 0.2066 - val_acc: 0.9223\n",
      "Epoch 42/100\n",
      "1955/1955 [==============================] - 1s 392us/step - loss: 0.1708 - acc: 0.9412 - val_loss: 0.2063 - val_acc: 0.9223\n",
      "Epoch 43/100\n",
      "1955/1955 [==============================] - 1s 354us/step - loss: 0.1670 - acc: 0.9453 - val_loss: 0.2132 - val_acc: 0.9223\n",
      "Epoch 44/100\n",
      "1955/1955 [==============================] - 1s 350us/step - loss: 0.1726 - acc: 0.9473 - val_loss: 0.2158 - val_acc: 0.9202\n",
      "Epoch 45/100\n",
      "1955/1955 [==============================] - 1s 344us/step - loss: 0.1758 - acc: 0.9442 - val_loss: 0.2010 - val_acc: 0.9264\n",
      "Epoch 46/100\n",
      "1955/1955 [==============================] - 1s 345us/step - loss: 0.1734 - acc: 0.9402 - val_loss: 0.2058 - val_acc: 0.9223\n",
      "Epoch 47/100\n",
      "1955/1955 [==============================] - 1s 352us/step - loss: 0.1731 - acc: 0.9391 - val_loss: 0.2046 - val_acc: 0.9243\n",
      "Epoch 48/100\n",
      "1955/1955 [==============================] - 1s 346us/step - loss: 0.1701 - acc: 0.9432 - val_loss: 0.2105 - val_acc: 0.9243\n",
      "Epoch 49/100\n",
      "1955/1955 [==============================] - 1s 345us/step - loss: 0.1681 - acc: 0.9458 - val_loss: 0.2089 - val_acc: 0.9223\n",
      "Epoch 50/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.1622 - acc: 0.9458 - val_loss: 0.2060 - val_acc: 0.9264\n",
      "Epoch 51/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.1570 - acc: 0.9463 - val_loss: 0.2009 - val_acc: 0.9264\n",
      "Epoch 52/100\n",
      "1955/1955 [==============================] - 1s 358us/step - loss: 0.1631 - acc: 0.9412 - val_loss: 0.2088 - val_acc: 0.9264\n",
      "Epoch 53/100\n",
      "1955/1955 [==============================] - 1s 348us/step - loss: 0.1644 - acc: 0.9458 - val_loss: 0.2097 - val_acc: 0.9243\n",
      "Epoch 54/100\n",
      "1955/1955 [==============================] - 1s 344us/step - loss: 0.1644 - acc: 0.9427 - val_loss: 0.2028 - val_acc: 0.9264\n",
      "Epoch 55/100\n",
      "1955/1955 [==============================] - 1s 345us/step - loss: 0.1687 - acc: 0.9432 - val_loss: 0.2102 - val_acc: 0.9223\n",
      "Epoch 56/100\n",
      "1955/1955 [==============================] - 1s 343us/step - loss: 0.1556 - acc: 0.9483 - val_loss: 0.1920 - val_acc: 0.9284\n",
      "Epoch 57/100\n",
      "1955/1955 [==============================] - 1s 360us/step - loss: 0.1634 - acc: 0.9524 - val_loss: 0.2047 - val_acc: 0.9264\n",
      "Epoch 58/100\n",
      "1955/1955 [==============================] - 1s 341us/step - loss: 0.1592 - acc: 0.9463 - val_loss: 0.1911 - val_acc: 0.9346\n",
      "Epoch 59/100\n",
      "1955/1955 [==============================] - 1s 336us/step - loss: 0.1629 - acc: 0.9448 - val_loss: 0.1976 - val_acc: 0.9325\n",
      "Epoch 60/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.1593 - acc: 0.9499 - val_loss: 0.1983 - val_acc: 0.9305\n",
      "Epoch 61/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.1585 - acc: 0.9432 - val_loss: 0.1984 - val_acc: 0.9325\n",
      "Epoch 62/100\n",
      "1955/1955 [==============================] - 1s 338us/step - loss: 0.1536 - acc: 0.9499 - val_loss: 0.2000 - val_acc: 0.9305\n",
      "Epoch 63/100\n",
      "1955/1955 [==============================] - 1s 339us/step - loss: 0.1586 - acc: 0.9468 - val_loss: 0.2030 - val_acc: 0.9264\n",
      "Epoch 64/100\n",
      "1955/1955 [==============================] - 1s 336us/step - loss: 0.1620 - acc: 0.9473 - val_loss: 0.2025 - val_acc: 0.9264\n",
      "Epoch 65/100\n",
      "1955/1955 [==============================] - 1s 351us/step - loss: 0.1596 - acc: 0.9453 - val_loss: 0.2014 - val_acc: 0.9305\n",
      "Epoch 66/100\n",
      "1955/1955 [==============================] - 1s 338us/step - loss: 0.1593 - acc: 0.9473 - val_loss: 0.2041 - val_acc: 0.9264\n",
      "Epoch 67/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.1525 - acc: 0.9555 - val_loss: 0.1937 - val_acc: 0.9325\n",
      "Epoch 68/100\n",
      "1955/1955 [==============================] - 1s 340us/step - loss: 0.1553 - acc: 0.9478 - val_loss: 0.2020 - val_acc: 0.9325\n",
      "Epoch 69/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.1534 - acc: 0.9545 - val_loss: 0.1956 - val_acc: 0.9325\n",
      "Epoch 70/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.1600 - acc: 0.9442 - val_loss: 0.1960 - val_acc: 0.9325\n",
      "Epoch 71/100\n",
      "1955/1955 [==============================] - 1s 339us/step - loss: 0.1499 - acc: 0.9519 - val_loss: 0.1978 - val_acc: 0.9325\n",
      "Epoch 72/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.1519 - acc: 0.9494 - val_loss: 0.1990 - val_acc: 0.9325\n",
      "Epoch 73/100\n",
      "1955/1955 [==============================] - 1s 349us/step - loss: 0.1560 - acc: 0.9504 - val_loss: 0.1994 - val_acc: 0.9305\n",
      "Epoch 74/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.1484 - acc: 0.9509 - val_loss: 0.1883 - val_acc: 0.9346\n",
      "Epoch 75/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.1494 - acc: 0.9519 - val_loss: 0.1923 - val_acc: 0.9366\n",
      "Epoch 76/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.1504 - acc: 0.9540 - val_loss: 0.2008 - val_acc: 0.9325\n",
      "Epoch 77/100\n",
      "1955/1955 [==============================] - 1s 367us/step - loss: 0.1537 - acc: 0.9509 - val_loss: 0.2033 - val_acc: 0.9305\n",
      "Epoch 78/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.1438 - acc: 0.9570 - val_loss: 0.1858 - val_acc: 0.9346\n",
      "Epoch 79/100\n",
      "1955/1955 [==============================] - 1s 343us/step - loss: 0.1538 - acc: 0.9504 - val_loss: 0.1988 - val_acc: 0.9346\n",
      "Epoch 80/100\n",
      "1955/1955 [==============================] - 1s 343us/step - loss: 0.1434 - acc: 0.9524 - val_loss: 0.1926 - val_acc: 0.9366\n",
      "Epoch 81/100\n",
      "1955/1955 [==============================] - 1s 339us/step - loss: 0.1443 - acc: 0.9565 - val_loss: 0.1790 - val_acc: 0.9366\n",
      "Epoch 82/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.1568 - acc: 0.9509 - val_loss: 0.1984 - val_acc: 0.9346\n",
      "Epoch 83/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.1529 - acc: 0.9494 - val_loss: 0.1874 - val_acc: 0.9366\n",
      "Epoch 84/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.1471 - acc: 0.9519 - val_loss: 0.1866 - val_acc: 0.9366\n",
      "Epoch 85/100\n",
      "1955/1955 [==============================] - 1s 340us/step - loss: 0.1424 - acc: 0.9560 - val_loss: 0.1906 - val_acc: 0.9366\n",
      "Epoch 86/100\n",
      "1955/1955 [==============================] - 1s 338us/step - loss: 0.1534 - acc: 0.9453 - val_loss: 0.1932 - val_acc: 0.9346\n",
      "Epoch 87/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.1448 - acc: 0.9555 - val_loss: 0.2071 - val_acc: 0.9305\n",
      "Epoch 88/100\n",
      "1955/1955 [==============================] - 1s 346us/step - loss: 0.1525 - acc: 0.9483 - val_loss: 0.1996 - val_acc: 0.9346\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.1376 - acc: 0.9560 - val_loss: 0.1939 - val_acc: 0.9366\n",
      "Epoch 90/100\n",
      "1955/1955 [==============================] - 1s 342us/step - loss: 0.1520 - acc: 0.9504 - val_loss: 0.1988 - val_acc: 0.9346\n",
      "Epoch 91/100\n",
      "1955/1955 [==============================] - 1s 343us/step - loss: 0.1465 - acc: 0.9519 - val_loss: 0.1885 - val_acc: 0.9366\n",
      "Epoch 92/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.1514 - acc: 0.9488 - val_loss: 0.1923 - val_acc: 0.9366\n",
      "Epoch 93/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.1391 - acc: 0.9555 - val_loss: 0.1932 - val_acc: 0.9366\n",
      "Epoch 94/100\n",
      "1955/1955 [==============================] - 1s 339us/step - loss: 0.1483 - acc: 0.9535 - val_loss: 0.1906 - val_acc: 0.9387\n",
      "Epoch 95/100\n",
      "1955/1955 [==============================] - 1s 356us/step - loss: 0.1456 - acc: 0.9529 - val_loss: 0.1972 - val_acc: 0.9387\n",
      "Epoch 96/100\n",
      "1955/1955 [==============================] - 1s 345us/step - loss: 0.1427 - acc: 0.9535 - val_loss: 0.1913 - val_acc: 0.9387\n",
      "Epoch 97/100\n",
      "1955/1955 [==============================] - 1s 370us/step - loss: 0.1354 - acc: 0.9570 - val_loss: 0.1969 - val_acc: 0.9366\n",
      "Epoch 98/100\n",
      "1955/1955 [==============================] - 1s 360us/step - loss: 0.1336 - acc: 0.9540 - val_loss: 0.1913 - val_acc: 0.9346\n",
      "Epoch 99/100\n",
      "1955/1955 [==============================] - 1s 362us/step - loss: 0.1383 - acc: 0.9570 - val_loss: 0.1963 - val_acc: 0.9387\n",
      "Epoch 100/100\n",
      "1955/1955 [==============================] - 1s 350us/step - loss: 0.1410 - acc: 0.9555 - val_loss: 0.1947 - val_acc: 0.9366\n",
      "Test subject 12, class BothStartLoadPhase\n",
      "Train subject 12, class LiftOff\n",
      "Train on 1956 samples, validate on 489 samples\n",
      "Epoch 1/100\n",
      "1956/1956 [==============================] - 1s 357us/step - loss: 0.8361 - acc: 0.6902 - val_loss: 0.6167 - val_acc: 0.7055\n",
      "Epoch 2/100\n",
      "1956/1956 [==============================] - 1s 348us/step - loss: 0.5967 - acc: 0.7239 - val_loss: 0.5957 - val_acc: 0.7157\n",
      "Epoch 3/100\n",
      "1956/1956 [==============================] - 1s 363us/step - loss: 0.5390 - acc: 0.7398 - val_loss: 0.5373 - val_acc: 0.7321\n",
      "Epoch 4/100\n",
      "1956/1956 [==============================] - 1s 373us/step - loss: 0.5251 - acc: 0.7490 - val_loss: 0.5124 - val_acc: 0.7689\n",
      "Epoch 5/100\n",
      "1956/1956 [==============================] - 1s 371us/step - loss: 0.5054 - acc: 0.7704 - val_loss: 0.5092 - val_acc: 0.7444\n",
      "Epoch 6/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.4856 - acc: 0.7745 - val_loss: 0.4967 - val_acc: 0.7566\n",
      "Epoch 7/100\n",
      "1956/1956 [==============================] - 1s 345us/step - loss: 0.4688 - acc: 0.7832 - val_loss: 0.4671 - val_acc: 0.7894\n",
      "Epoch 8/100\n",
      "1956/1956 [==============================] - 1s 353us/step - loss: 0.4452 - acc: 0.7935 - val_loss: 0.4531 - val_acc: 0.7935\n",
      "Epoch 9/100\n",
      "1956/1956 [==============================] - 1s 360us/step - loss: 0.4365 - acc: 0.7986 - val_loss: 0.4487 - val_acc: 0.7975\n",
      "Epoch 10/100\n",
      "1956/1956 [==============================] - 1s 362us/step - loss: 0.4233 - acc: 0.8088 - val_loss: 0.4068 - val_acc: 0.8282\n",
      "Epoch 11/100\n",
      "1956/1956 [==============================] - 1s 356us/step - loss: 0.4149 - acc: 0.8175 - val_loss: 0.4448 - val_acc: 0.7975\n",
      "Epoch 12/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.4054 - acc: 0.8144 - val_loss: 0.4429 - val_acc: 0.7996\n",
      "Epoch 13/100\n",
      "1956/1956 [==============================] - 1s 371us/step - loss: 0.4003 - acc: 0.8267 - val_loss: 0.4093 - val_acc: 0.8262\n",
      "Epoch 14/100\n",
      "1956/1956 [==============================] - 1s 376us/step - loss: 0.3990 - acc: 0.8272 - val_loss: 0.4277 - val_acc: 0.8119\n",
      "Epoch 15/100\n",
      "1956/1956 [==============================] - 1s 386us/step - loss: 0.3842 - acc: 0.8338 - val_loss: 0.3959 - val_acc: 0.8384\n",
      "Epoch 16/100\n",
      "1956/1956 [==============================] - 1s 377us/step - loss: 0.3824 - acc: 0.8313 - val_loss: 0.3917 - val_acc: 0.8323\n",
      "Epoch 17/100\n",
      "1956/1956 [==============================] - 1s 354us/step - loss: 0.3797 - acc: 0.8369 - val_loss: 0.4098 - val_acc: 0.8262\n",
      "Epoch 18/100\n",
      "1956/1956 [==============================] - 1s 347us/step - loss: 0.3685 - acc: 0.8517 - val_loss: 0.3909 - val_acc: 0.8384\n",
      "Epoch 19/100\n",
      "1956/1956 [==============================] - 1s 338us/step - loss: 0.3539 - acc: 0.8400 - val_loss: 0.3765 - val_acc: 0.8487\n",
      "Epoch 20/100\n",
      "1956/1956 [==============================] - 1s 343us/step - loss: 0.3554 - acc: 0.8517 - val_loss: 0.4056 - val_acc: 0.8282\n",
      "Epoch 21/100\n",
      "1956/1956 [==============================] - 1s 358us/step - loss: 0.3545 - acc: 0.8584 - val_loss: 0.3779 - val_acc: 0.8487\n",
      "Epoch 22/100\n",
      "1956/1956 [==============================] - 1s 342us/step - loss: 0.3367 - acc: 0.8538 - val_loss: 0.3543 - val_acc: 0.8528\n",
      "Epoch 23/100\n",
      "1956/1956 [==============================] - 1s 341us/step - loss: 0.3378 - acc: 0.8569 - val_loss: 0.3711 - val_acc: 0.8569\n",
      "Epoch 24/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.3349 - acc: 0.8645 - val_loss: 0.3614 - val_acc: 0.8528\n",
      "Epoch 25/100\n",
      "1956/1956 [==============================] - ETA: 0s - loss: 0.3182 - acc: 0.868 - 1s 350us/step - loss: 0.3189 - acc: 0.8676 - val_loss: 0.3460 - val_acc: 0.8569\n",
      "Epoch 26/100\n",
      "1956/1956 [==============================] - 1s 402us/step - loss: 0.3219 - acc: 0.8707 - val_loss: 0.3600 - val_acc: 0.8548\n",
      "Epoch 27/100\n",
      "1956/1956 [==============================] - 1s 379us/step - loss: 0.3265 - acc: 0.8676 - val_loss: 0.3679 - val_acc: 0.8487\n",
      "Epoch 28/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.3215 - acc: 0.8666 - val_loss: 0.3462 - val_acc: 0.8650\n",
      "Epoch 29/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.3008 - acc: 0.8819 - val_loss: 0.3506 - val_acc: 0.8609\n",
      "Epoch 30/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.3148 - acc: 0.8691 - val_loss: 0.3446 - val_acc: 0.8589\n",
      "Epoch 31/100\n",
      "1956/1956 [==============================] - 1s 341us/step - loss: 0.3053 - acc: 0.8773 - val_loss: 0.3601 - val_acc: 0.8569\n",
      "Epoch 32/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.2857 - acc: 0.8926 - val_loss: 0.3365 - val_acc: 0.8691\n",
      "Epoch 33/100\n",
      "1956/1956 [==============================] - 1s 337us/step - loss: 0.3034 - acc: 0.8747 - val_loss: 0.3413 - val_acc: 0.8671\n",
      "Epoch 34/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.3034 - acc: 0.8753 - val_loss: 0.3154 - val_acc: 0.8834\n",
      "Epoch 35/100\n",
      "1956/1956 [==============================] - 1s 345us/step - loss: 0.2925 - acc: 0.8875 - val_loss: 0.3595 - val_acc: 0.8548\n",
      "Epoch 36/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.2879 - acc: 0.8901 - val_loss: 0.3368 - val_acc: 0.8732\n",
      "Epoch 37/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.2893 - acc: 0.8860 - val_loss: 0.3247 - val_acc: 0.8855\n",
      "Epoch 38/100\n",
      "1956/1956 [==============================] - 1s 335us/step - loss: 0.2959 - acc: 0.8829 - val_loss: 0.3164 - val_acc: 0.8814\n",
      "Epoch 39/100\n",
      "1956/1956 [==============================] - 1s 338us/step - loss: 0.2823 - acc: 0.8931 - val_loss: 0.3199 - val_acc: 0.8834\n",
      "Epoch 40/100\n",
      "1956/1956 [==============================] - 1s 342us/step - loss: 0.2772 - acc: 0.8947 - val_loss: 0.2981 - val_acc: 0.8855\n",
      "Epoch 41/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.2796 - acc: 0.8916 - val_loss: 0.2935 - val_acc: 0.8896\n",
      "Epoch 42/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.2780 - acc: 0.8931 - val_loss: 0.3081 - val_acc: 0.8916\n",
      "Epoch 43/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.2690 - acc: 0.8967 - val_loss: 0.3079 - val_acc: 0.8896\n",
      "Epoch 44/100\n",
      "1956/1956 [==============================] - 1s 324us/step - loss: 0.2698 - acc: 0.8926 - val_loss: 0.3117 - val_acc: 0.8875\n",
      "Epoch 45/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.2736 - acc: 0.8865 - val_loss: 0.3122 - val_acc: 0.8875\n",
      "Epoch 46/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.2666 - acc: 0.8998 - val_loss: 0.2970 - val_acc: 0.8998\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.2586 - acc: 0.8983 - val_loss: 0.3030 - val_acc: 0.8875\n",
      "Epoch 48/100\n",
      "1956/1956 [==============================] - 1s 342us/step - loss: 0.2615 - acc: 0.8978 - val_loss: 0.2982 - val_acc: 0.8978\n",
      "Epoch 49/100\n",
      "1956/1956 [==============================] - 1s 339us/step - loss: 0.2681 - acc: 0.8916 - val_loss: 0.3018 - val_acc: 0.8916\n",
      "Epoch 50/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.2539 - acc: 0.9044 - val_loss: 0.3034 - val_acc: 0.8916\n",
      "Epoch 51/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.2608 - acc: 0.9008 - val_loss: 0.3014 - val_acc: 0.8937\n",
      "Epoch 52/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.2508 - acc: 0.8983 - val_loss: 0.2912 - val_acc: 0.8978\n",
      "Epoch 53/100\n",
      "1956/1956 [==============================] - 1s 339us/step - loss: 0.2407 - acc: 0.9064 - val_loss: 0.2739 - val_acc: 0.9039\n",
      "Epoch 54/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.2533 - acc: 0.9085 - val_loss: 0.2935 - val_acc: 0.8978\n",
      "Epoch 55/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.2363 - acc: 0.9090 - val_loss: 0.2796 - val_acc: 0.9141\n",
      "Epoch 56/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.2452 - acc: 0.9070 - val_loss: 0.2872 - val_acc: 0.8978\n",
      "Epoch 57/100\n",
      "1956/1956 [==============================] - 1s 324us/step - loss: 0.2583 - acc: 0.8988 - val_loss: 0.2759 - val_acc: 0.9100\n",
      "Epoch 58/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.2407 - acc: 0.9100 - val_loss: 0.2758 - val_acc: 0.9100\n",
      "Epoch 59/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.2345 - acc: 0.9136 - val_loss: 0.2740 - val_acc: 0.9059\n",
      "Epoch 60/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.2502 - acc: 0.9090 - val_loss: 0.2685 - val_acc: 0.9100\n",
      "Epoch 61/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.2429 - acc: 0.9146 - val_loss: 0.2765 - val_acc: 0.9141\n",
      "Epoch 62/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.2408 - acc: 0.9085 - val_loss: 0.2613 - val_acc: 0.9141\n",
      "Epoch 63/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.2396 - acc: 0.9126 - val_loss: 0.2754 - val_acc: 0.9039\n",
      "Epoch 64/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.2397 - acc: 0.9070 - val_loss: 0.2722 - val_acc: 0.9059\n",
      "Epoch 65/100\n",
      "1956/1956 [==============================] - 1s 323us/step - loss: 0.2376 - acc: 0.9116 - val_loss: 0.2738 - val_acc: 0.9059\n",
      "Epoch 66/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.2320 - acc: 0.9167 - val_loss: 0.2731 - val_acc: 0.9100\n",
      "Epoch 67/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.2253 - acc: 0.9167 - val_loss: 0.2846 - val_acc: 0.8998\n",
      "Epoch 68/100\n",
      "1956/1956 [==============================] - 1s 336us/step - loss: 0.2438 - acc: 0.9095 - val_loss: 0.2564 - val_acc: 0.9202\n",
      "Epoch 69/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.2393 - acc: 0.9095 - val_loss: 0.2613 - val_acc: 0.9141\n",
      "Epoch 70/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.2193 - acc: 0.9177 - val_loss: 0.2593 - val_acc: 0.9162\n",
      "Epoch 71/100\n",
      "1956/1956 [==============================] - 1s 323us/step - loss: 0.2308 - acc: 0.9105 - val_loss: 0.2666 - val_acc: 0.9121\n",
      "Epoch 72/100\n",
      "1956/1956 [==============================] - 1s 339us/step - loss: 0.2300 - acc: 0.9202 - val_loss: 0.2650 - val_acc: 0.9100\n",
      "Epoch 73/100\n",
      "1956/1956 [==============================] - 1s 335us/step - loss: 0.2196 - acc: 0.9202 - val_loss: 0.2570 - val_acc: 0.9162\n",
      "Epoch 74/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.2198 - acc: 0.9208 - val_loss: 0.2475 - val_acc: 0.9162\n",
      "Epoch 75/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.2221 - acc: 0.9177 - val_loss: 0.2682 - val_acc: 0.9018\n",
      "Epoch 76/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.2251 - acc: 0.9141 - val_loss: 0.2611 - val_acc: 0.9059\n",
      "Epoch 77/100\n",
      "1956/1956 [==============================] - 1s 343us/step - loss: 0.2263 - acc: 0.9177 - val_loss: 0.2557 - val_acc: 0.9162\n",
      "Epoch 78/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.2140 - acc: 0.9197 - val_loss: 0.2672 - val_acc: 0.9059\n",
      "Epoch 79/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.2161 - acc: 0.9197 - val_loss: 0.2723 - val_acc: 0.9018\n",
      "Epoch 80/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.2129 - acc: 0.9243 - val_loss: 0.2622 - val_acc: 0.9121\n",
      "Epoch 81/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.2234 - acc: 0.9146 - val_loss: 0.2545 - val_acc: 0.9141\n",
      "Epoch 82/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.2083 - acc: 0.9208 - val_loss: 0.2542 - val_acc: 0.9141\n",
      "Epoch 83/100\n",
      "1956/1956 [==============================] - 1s 335us/step - loss: 0.2106 - acc: 0.9264 - val_loss: 0.2662 - val_acc: 0.8978\n",
      "Epoch 84/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.2099 - acc: 0.9238 - val_loss: 0.2521 - val_acc: 0.9141\n",
      "Epoch 85/100\n",
      "1956/1956 [==============================] - 1s 341us/step - loss: 0.2120 - acc: 0.9228 - val_loss: 0.2503 - val_acc: 0.9162\n",
      "Epoch 86/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.2055 - acc: 0.9305 - val_loss: 0.2423 - val_acc: 0.9182\n",
      "Epoch 87/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.2067 - acc: 0.9213 - val_loss: 0.2557 - val_acc: 0.9121\n",
      "Epoch 88/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.2054 - acc: 0.9284 - val_loss: 0.2340 - val_acc: 0.9182\n",
      "Epoch 89/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.2099 - acc: 0.9202 - val_loss: 0.2527 - val_acc: 0.9141\n",
      "Epoch 90/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.2075 - acc: 0.9274 - val_loss: 0.2369 - val_acc: 0.9243\n",
      "Epoch 91/100\n",
      "1956/1956 [==============================] - 1s 322us/step - loss: 0.2068 - acc: 0.9279 - val_loss: 0.2570 - val_acc: 0.9100\n",
      "Epoch 92/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.1955 - acc: 0.9330 - val_loss: 0.2518 - val_acc: 0.9141\n",
      "Epoch 93/100\n",
      "1956/1956 [==============================] - 1s 324us/step - loss: 0.2054 - acc: 0.9254 - val_loss: 0.2386 - val_acc: 0.9141\n",
      "Epoch 94/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.2047 - acc: 0.9243 - val_loss: 0.2542 - val_acc: 0.9100\n",
      "Epoch 95/100\n",
      "1956/1956 [==============================] - 1s 323us/step - loss: 0.2116 - acc: 0.9162 - val_loss: 0.2323 - val_acc: 0.9182\n",
      "Epoch 96/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.1970 - acc: 0.9330 - val_loss: 0.2345 - val_acc: 0.9182\n",
      "Epoch 97/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.2031 - acc: 0.9259 - val_loss: 0.2305 - val_acc: 0.9223\n",
      "Epoch 98/100\n",
      "1956/1956 [==============================] - 1s 346us/step - loss: 0.2035 - acc: 0.9233 - val_loss: 0.2629 - val_acc: 0.8978\n",
      "Epoch 99/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.2015 - acc: 0.9284 - val_loss: 0.2437 - val_acc: 0.9121\n",
      "Epoch 100/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.2011 - acc: 0.9335 - val_loss: 0.2432 - val_acc: 0.9100\n",
      "Train on 1956 samples, validate on 489 samples\n",
      "Epoch 1/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.2688 - acc: 0.9008 - val_loss: 0.2376 - val_acc: 0.9141\n",
      "Epoch 2/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.2688 - acc: 0.8967 - val_loss: 0.2462 - val_acc: 0.9100\n",
      "Epoch 3/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.2623 - acc: 0.8962 - val_loss: 0.2494 - val_acc: 0.9059\n",
      "Epoch 4/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.2696 - acc: 0.9044 - val_loss: 0.2387 - val_acc: 0.9141\n",
      "Epoch 5/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.2559 - acc: 0.9029 - val_loss: 0.2333 - val_acc: 0.9202\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.2489 - acc: 0.9105 - val_loss: 0.2242 - val_acc: 0.9202\n",
      "Epoch 7/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.2593 - acc: 0.9054 - val_loss: 0.2339 - val_acc: 0.9121\n",
      "Epoch 8/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.2478 - acc: 0.9049 - val_loss: 0.2264 - val_acc: 0.9182\n",
      "Epoch 9/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.2501 - acc: 0.9116 - val_loss: 0.2227 - val_acc: 0.9243\n",
      "Epoch 10/100\n",
      "1956/1956 [==============================] - 1s 343us/step - loss: 0.2486 - acc: 0.9059 - val_loss: 0.2265 - val_acc: 0.9162\n",
      "Epoch 11/100\n",
      "1956/1956 [==============================] - 1s 324us/step - loss: 0.2397 - acc: 0.9100 - val_loss: 0.2311 - val_acc: 0.9141\n",
      "Epoch 12/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.2458 - acc: 0.9116 - val_loss: 0.2240 - val_acc: 0.9202\n",
      "Epoch 13/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.2440 - acc: 0.9136 - val_loss: 0.2238 - val_acc: 0.9202\n",
      "Epoch 14/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.2428 - acc: 0.9116 - val_loss: 0.2196 - val_acc: 0.9264\n",
      "Epoch 15/100\n",
      "1956/1956 [==============================] - 1s 335us/step - loss: 0.2247 - acc: 0.9223 - val_loss: 0.2307 - val_acc: 0.9141\n",
      "Epoch 16/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.2494 - acc: 0.9090 - val_loss: 0.2227 - val_acc: 0.9223\n",
      "Epoch 17/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.2330 - acc: 0.9136 - val_loss: 0.2353 - val_acc: 0.9162\n",
      "Epoch 18/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.2305 - acc: 0.9177 - val_loss: 0.2289 - val_acc: 0.9202\n",
      "Epoch 19/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.2334 - acc: 0.9151 - val_loss: 0.2141 - val_acc: 0.9284\n",
      "Epoch 20/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.2328 - acc: 0.9192 - val_loss: 0.2187 - val_acc: 0.9243\n",
      "Epoch 21/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.2356 - acc: 0.9187 - val_loss: 0.2290 - val_acc: 0.9182\n",
      "Epoch 22/100\n",
      "1956/1956 [==============================] - 1s 338us/step - loss: 0.2317 - acc: 0.9167 - val_loss: 0.2303 - val_acc: 0.9182\n",
      "Epoch 23/100\n",
      "1956/1956 [==============================] - 1s 340us/step - loss: 0.2198 - acc: 0.9213 - val_loss: 0.2226 - val_acc: 0.9264\n",
      "Epoch 24/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.2316 - acc: 0.9156 - val_loss: 0.2143 - val_acc: 0.9284\n",
      "Epoch 25/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.2282 - acc: 0.9208 - val_loss: 0.2270 - val_acc: 0.9202\n",
      "Epoch 26/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.2213 - acc: 0.9218 - val_loss: 0.2276 - val_acc: 0.9182\n",
      "Epoch 27/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.2205 - acc: 0.9248 - val_loss: 0.2138 - val_acc: 0.9264\n",
      "Epoch 28/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.2202 - acc: 0.9228 - val_loss: 0.2086 - val_acc: 0.9325\n",
      "Epoch 29/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.2186 - acc: 0.9218 - val_loss: 0.2165 - val_acc: 0.9243\n",
      "Epoch 30/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.2308 - acc: 0.9172 - val_loss: 0.2316 - val_acc: 0.9162\n",
      "Epoch 31/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.2260 - acc: 0.9192 - val_loss: 0.2149 - val_acc: 0.9264\n",
      "Epoch 32/100\n",
      "1956/1956 [==============================] - 1s 324us/step - loss: 0.2161 - acc: 0.9259 - val_loss: 0.2265 - val_acc: 0.9162\n",
      "Epoch 33/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.2188 - acc: 0.9238 - val_loss: 0.2023 - val_acc: 0.9387\n",
      "Epoch 34/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.2079 - acc: 0.9300 - val_loss: 0.2164 - val_acc: 0.9284\n",
      "Epoch 35/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.2223 - acc: 0.9254 - val_loss: 0.2116 - val_acc: 0.9284\n",
      "Epoch 36/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.2090 - acc: 0.9320 - val_loss: 0.2143 - val_acc: 0.9243\n",
      "Epoch 37/100\n",
      "1956/1956 [==============================] - 1s 323us/step - loss: 0.2204 - acc: 0.9279 - val_loss: 0.2091 - val_acc: 0.9305\n",
      "Epoch 38/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.2216 - acc: 0.9264 - val_loss: 0.2085 - val_acc: 0.9346\n",
      "Epoch 39/100\n",
      "1956/1956 [==============================] - 1s 340us/step - loss: 0.2138 - acc: 0.9248 - val_loss: 0.2008 - val_acc: 0.9305\n",
      "Epoch 40/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.2152 - acc: 0.9233 - val_loss: 0.2045 - val_acc: 0.9284\n",
      "Epoch 41/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.2082 - acc: 0.9325 - val_loss: 0.2067 - val_acc: 0.9305\n",
      "Epoch 42/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.2102 - acc: 0.9269 - val_loss: 0.2078 - val_acc: 0.9284\n",
      "Epoch 43/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.2085 - acc: 0.9284 - val_loss: 0.2100 - val_acc: 0.9284\n",
      "Epoch 44/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.2173 - acc: 0.9223 - val_loss: 0.2090 - val_acc: 0.9284\n",
      "Epoch 45/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.2066 - acc: 0.9320 - val_loss: 0.2059 - val_acc: 0.9325\n",
      "Epoch 46/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.2077 - acc: 0.9279 - val_loss: 0.2154 - val_acc: 0.9264\n",
      "Epoch 47/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.2036 - acc: 0.9330 - val_loss: 0.2127 - val_acc: 0.9284\n",
      "Epoch 48/100\n",
      "1956/1956 [==============================] - 1s 323us/step - loss: 0.2087 - acc: 0.9279 - val_loss: 0.2182 - val_acc: 0.9223\n",
      "Epoch 49/100\n",
      "1956/1956 [==============================] - 1s 322us/step - loss: 0.2071 - acc: 0.9315 - val_loss: 0.2134 - val_acc: 0.9284\n",
      "Epoch 50/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.2034 - acc: 0.9284 - val_loss: 0.2155 - val_acc: 0.9243\n",
      "Epoch 51/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.2122 - acc: 0.9284 - val_loss: 0.2022 - val_acc: 0.9325\n",
      "Epoch 52/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.2176 - acc: 0.9218 - val_loss: 0.2119 - val_acc: 0.9264\n",
      "Epoch 53/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.1942 - acc: 0.9361 - val_loss: 0.2061 - val_acc: 0.9325\n",
      "Epoch 54/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.2017 - acc: 0.9310 - val_loss: 0.2113 - val_acc: 0.9284\n",
      "Epoch 55/100\n",
      "1956/1956 [==============================] - 1s 341us/step - loss: 0.2109 - acc: 0.9325 - val_loss: 0.2051 - val_acc: 0.9305\n",
      "Epoch 56/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.1987 - acc: 0.9320 - val_loss: 0.1995 - val_acc: 0.9325\n",
      "Epoch 57/100\n",
      "1956/1956 [==============================] - 1s 335us/step - loss: 0.2002 - acc: 0.9325 - val_loss: 0.2150 - val_acc: 0.9264\n",
      "Epoch 58/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.2007 - acc: 0.9325 - val_loss: 0.1985 - val_acc: 0.9346\n",
      "Epoch 59/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.1959 - acc: 0.9361 - val_loss: 0.2124 - val_acc: 0.9284\n",
      "Epoch 60/100\n",
      "1956/1956 [==============================] - 1s 335us/step - loss: 0.2056 - acc: 0.9254 - val_loss: 0.2092 - val_acc: 0.9284\n",
      "Epoch 61/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.2030 - acc: 0.9274 - val_loss: 0.1991 - val_acc: 0.9346\n",
      "Epoch 62/100\n",
      "1956/1956 [==============================] - 1s 336us/step - loss: 0.1999 - acc: 0.9366 - val_loss: 0.2044 - val_acc: 0.9325\n",
      "Epoch 63/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.2084 - acc: 0.9264 - val_loss: 0.2018 - val_acc: 0.9366\n",
      "Epoch 64/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.2031 - acc: 0.9310 - val_loss: 0.2064 - val_acc: 0.9325\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.2003 - acc: 0.9315 - val_loss: 0.2169 - val_acc: 0.9264\n",
      "Epoch 66/100\n",
      "1956/1956 [==============================] - 1s 336us/step - loss: 0.1958 - acc: 0.9366 - val_loss: 0.2026 - val_acc: 0.9325\n",
      "Epoch 67/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.1947 - acc: 0.9356 - val_loss: 0.2050 - val_acc: 0.9305\n",
      "Epoch 68/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.1933 - acc: 0.9402 - val_loss: 0.1992 - val_acc: 0.9346\n",
      "Epoch 69/100\n",
      "1956/1956 [==============================] - 1s 339us/step - loss: 0.1967 - acc: 0.9361 - val_loss: 0.2082 - val_acc: 0.9284\n",
      "Epoch 70/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.1875 - acc: 0.9351 - val_loss: 0.2021 - val_acc: 0.9305\n",
      "Epoch 71/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.2049 - acc: 0.9315 - val_loss: 0.2053 - val_acc: 0.9305\n",
      "Epoch 72/100\n",
      "1956/1956 [==============================] - 1s 335us/step - loss: 0.1968 - acc: 0.9310 - val_loss: 0.2134 - val_acc: 0.9264\n",
      "Epoch 73/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.2006 - acc: 0.9315 - val_loss: 0.2064 - val_acc: 0.9305\n",
      "Epoch 74/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.1958 - acc: 0.9305 - val_loss: 0.2002 - val_acc: 0.9346\n",
      "Epoch 75/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.1929 - acc: 0.9361 - val_loss: 0.1967 - val_acc: 0.9325\n",
      "Epoch 76/100\n",
      "1956/1956 [==============================] - 1s 340us/step - loss: 0.1911 - acc: 0.9387 - val_loss: 0.2281 - val_acc: 0.9182\n",
      "Epoch 77/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.1889 - acc: 0.9407 - val_loss: 0.2093 - val_acc: 0.9264\n",
      "Epoch 78/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.1875 - acc: 0.9381 - val_loss: 0.2087 - val_acc: 0.9243\n",
      "Epoch 79/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.1896 - acc: 0.9346 - val_loss: 0.2019 - val_acc: 0.9325\n",
      "Epoch 80/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.1810 - acc: 0.9366 - val_loss: 0.2004 - val_acc: 0.9346\n",
      "Epoch 81/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.1842 - acc: 0.9417 - val_loss: 0.1936 - val_acc: 0.9366\n",
      "Epoch 82/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.1887 - acc: 0.9340 - val_loss: 0.1860 - val_acc: 0.9448\n",
      "Epoch 83/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.1830 - acc: 0.9427 - val_loss: 0.1971 - val_acc: 0.9346\n",
      "Epoch 84/100\n",
      "1956/1956 [==============================] - 1s 336us/step - loss: 0.1850 - acc: 0.9412 - val_loss: 0.1987 - val_acc: 0.9264\n",
      "Epoch 85/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.1872 - acc: 0.9376 - val_loss: 0.1923 - val_acc: 0.9346\n",
      "Epoch 86/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.1896 - acc: 0.9387 - val_loss: 0.1990 - val_acc: 0.9325\n",
      "Epoch 87/100\n",
      "1956/1956 [==============================] - 1s 336us/step - loss: 0.1786 - acc: 0.9433 - val_loss: 0.1850 - val_acc: 0.9346\n",
      "Epoch 88/100\n",
      "1956/1956 [==============================] - 1s 336us/step - loss: 0.1849 - acc: 0.9340 - val_loss: 0.2025 - val_acc: 0.9325\n",
      "Epoch 89/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.1862 - acc: 0.9397 - val_loss: 0.2139 - val_acc: 0.9264\n",
      "Epoch 90/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.1774 - acc: 0.9397 - val_loss: 0.1775 - val_acc: 0.9346\n",
      "Epoch 91/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.1772 - acc: 0.9443 - val_loss: 0.1960 - val_acc: 0.9366\n",
      "Epoch 92/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.1829 - acc: 0.9397 - val_loss: 0.2031 - val_acc: 0.9325\n",
      "Epoch 93/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.1794 - acc: 0.9397 - val_loss: 0.1954 - val_acc: 0.9346\n",
      "Epoch 94/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.1820 - acc: 0.9458 - val_loss: 0.1984 - val_acc: 0.9346\n",
      "Epoch 95/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.1825 - acc: 0.9387 - val_loss: 0.1941 - val_acc: 0.9305\n",
      "Epoch 96/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.1715 - acc: 0.9473 - val_loss: 0.2025 - val_acc: 0.9264\n",
      "Epoch 97/100\n",
      "1956/1956 [==============================] - 1s 324us/step - loss: 0.1815 - acc: 0.9468 - val_loss: 0.1916 - val_acc: 0.9305\n",
      "Epoch 98/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.1806 - acc: 0.9412 - val_loss: 0.1948 - val_acc: 0.9366\n",
      "Epoch 99/100\n",
      "1956/1956 [==============================] - 1s 323us/step - loss: 0.1802 - acc: 0.9422 - val_loss: 0.2030 - val_acc: 0.9305\n",
      "Epoch 100/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.1811 - acc: 0.9387 - val_loss: 0.2016 - val_acc: 0.9243\n",
      "Test subject 12, class LiftOff\n",
      "Train subject 12, class Replace\n",
      "Train on 1956 samples, validate on 489 samples\n",
      "Epoch 1/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.6666 - acc: 0.8001 - val_loss: 0.5747 - val_acc: 0.7914\n",
      "Epoch 2/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.4770 - acc: 0.8241 - val_loss: 0.4856 - val_acc: 0.8057\n",
      "Epoch 3/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.3900 - acc: 0.8430 - val_loss: 0.4850 - val_acc: 0.7955\n",
      "Epoch 4/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.3713 - acc: 0.8430 - val_loss: 0.4115 - val_acc: 0.8098\n",
      "Epoch 5/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.3620 - acc: 0.8599 - val_loss: 0.3846 - val_acc: 0.8160\n",
      "Epoch 6/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.3436 - acc: 0.8538 - val_loss: 0.3489 - val_acc: 0.8303\n",
      "Epoch 7/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.3294 - acc: 0.8635 - val_loss: 0.3441 - val_acc: 0.8425\n",
      "Epoch 8/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.3142 - acc: 0.8691 - val_loss: 0.3269 - val_acc: 0.8446\n",
      "Epoch 9/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.2978 - acc: 0.8783 - val_loss: 0.3444 - val_acc: 0.8487\n",
      "Epoch 10/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.3047 - acc: 0.8742 - val_loss: 0.3254 - val_acc: 0.8507\n",
      "Epoch 11/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.2938 - acc: 0.8742 - val_loss: 0.3057 - val_acc: 0.8569\n",
      "Epoch 12/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.2859 - acc: 0.8896 - val_loss: 0.3531 - val_acc: 0.8364\n",
      "Epoch 13/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.2766 - acc: 0.8937 - val_loss: 0.2794 - val_acc: 0.8773\n",
      "Epoch 14/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.2687 - acc: 0.9013 - val_loss: 0.2954 - val_acc: 0.8753\n",
      "Epoch 15/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.2752 - acc: 0.8911 - val_loss: 0.2739 - val_acc: 0.8834\n",
      "Epoch 16/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.2760 - acc: 0.8845 - val_loss: 0.2860 - val_acc: 0.8814\n",
      "Epoch 17/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.2582 - acc: 0.8993 - val_loss: 0.2799 - val_acc: 0.8793\n",
      "Epoch 18/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.2596 - acc: 0.8983 - val_loss: 0.2659 - val_acc: 0.8814\n",
      "Epoch 19/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.2487 - acc: 0.9039 - val_loss: 0.2646 - val_acc: 0.8855\n",
      "Epoch 20/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.2604 - acc: 0.8947 - val_loss: 0.2561 - val_acc: 0.8896\n",
      "Epoch 21/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.2529 - acc: 0.9003 - val_loss: 0.2647 - val_acc: 0.8875\n",
      "Epoch 22/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.2413 - acc: 0.9003 - val_loss: 0.2502 - val_acc: 0.8937\n",
      "Epoch 23/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.2445 - acc: 0.9039 - val_loss: 0.2559 - val_acc: 0.8916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.2426 - acc: 0.9029 - val_loss: 0.2625 - val_acc: 0.8896\n",
      "Epoch 25/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.2430 - acc: 0.9029 - val_loss: 0.2354 - val_acc: 0.9059\n",
      "Epoch 26/100\n",
      "1956/1956 [==============================] - 1s 323us/step - loss: 0.2433 - acc: 0.9044 - val_loss: 0.2438 - val_acc: 0.8978\n",
      "Epoch 27/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.2355 - acc: 0.9095 - val_loss: 0.2532 - val_acc: 0.8896\n",
      "Epoch 28/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.2299 - acc: 0.9187 - val_loss: 0.2635 - val_acc: 0.8814\n",
      "Epoch 29/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.2284 - acc: 0.9121 - val_loss: 0.2319 - val_acc: 0.9080\n",
      "Epoch 30/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.2249 - acc: 0.9167 - val_loss: 0.2286 - val_acc: 0.9080\n",
      "Epoch 31/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.2263 - acc: 0.9116 - val_loss: 0.2361 - val_acc: 0.8957\n",
      "Epoch 32/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.2245 - acc: 0.9131 - val_loss: 0.2329 - val_acc: 0.8978\n",
      "Epoch 33/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.2208 - acc: 0.9100 - val_loss: 0.2384 - val_acc: 0.8916\n",
      "Epoch 34/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.2170 - acc: 0.9172 - val_loss: 0.2332 - val_acc: 0.8937\n",
      "Epoch 35/100\n",
      "1956/1956 [==============================] - 1s 324us/step - loss: 0.2235 - acc: 0.9146 - val_loss: 0.2361 - val_acc: 0.8916\n",
      "Epoch 36/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.2162 - acc: 0.9151 - val_loss: 0.2164 - val_acc: 0.9182\n",
      "Epoch 37/100\n",
      "1956/1956 [==============================] - 1s 324us/step - loss: 0.2140 - acc: 0.9151 - val_loss: 0.2202 - val_acc: 0.9141\n",
      "Epoch 38/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.2268 - acc: 0.9100 - val_loss: 0.2213 - val_acc: 0.9121\n",
      "Epoch 39/100\n",
      "1956/1956 [==============================] - 1s 322us/step - loss: 0.2084 - acc: 0.9172 - val_loss: 0.2210 - val_acc: 0.9121\n",
      "Epoch 40/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.2035 - acc: 0.9269 - val_loss: 0.2054 - val_acc: 0.9243\n",
      "Epoch 41/100\n",
      "1956/1956 [==============================] - 1s 323us/step - loss: 0.2120 - acc: 0.9187 - val_loss: 0.2407 - val_acc: 0.8896\n",
      "Epoch 42/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.2062 - acc: 0.9259 - val_loss: 0.2168 - val_acc: 0.9100\n",
      "Epoch 43/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.2016 - acc: 0.9243 - val_loss: 0.2023 - val_acc: 0.9264\n",
      "Epoch 44/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.2138 - acc: 0.9197 - val_loss: 0.2026 - val_acc: 0.9264\n",
      "Epoch 45/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.2126 - acc: 0.9182 - val_loss: 0.2239 - val_acc: 0.9100\n",
      "Epoch 46/100\n",
      "1956/1956 [==============================] - 1s 324us/step - loss: 0.2078 - acc: 0.9208 - val_loss: 0.2238 - val_acc: 0.9100\n",
      "Epoch 47/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.2086 - acc: 0.9177 - val_loss: 0.2121 - val_acc: 0.9162\n",
      "Epoch 48/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.1974 - acc: 0.9294 - val_loss: 0.2097 - val_acc: 0.9202\n",
      "Epoch 49/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.2041 - acc: 0.9243 - val_loss: 0.2106 - val_acc: 0.9223\n",
      "Epoch 50/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.1975 - acc: 0.9254 - val_loss: 0.2110 - val_acc: 0.9162\n",
      "Epoch 51/100\n",
      "1956/1956 [==============================] - 1s 338us/step - loss: 0.1927 - acc: 0.9284 - val_loss: 0.2055 - val_acc: 0.9182\n",
      "Epoch 52/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.2035 - acc: 0.9248 - val_loss: 0.2060 - val_acc: 0.9162\n",
      "Epoch 53/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.1967 - acc: 0.9202 - val_loss: 0.2026 - val_acc: 0.9182\n",
      "Epoch 54/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.1907 - acc: 0.9305 - val_loss: 0.2053 - val_acc: 0.9182\n",
      "Epoch 55/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.1959 - acc: 0.9259 - val_loss: 0.1982 - val_acc: 0.9223\n",
      "Epoch 56/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.1966 - acc: 0.9254 - val_loss: 0.1989 - val_acc: 0.9243\n",
      "Epoch 57/100\n",
      "1956/1956 [==============================] - 1s 323us/step - loss: 0.1906 - acc: 0.9294 - val_loss: 0.1977 - val_acc: 0.9243\n",
      "Epoch 58/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.1894 - acc: 0.9300 - val_loss: 0.1991 - val_acc: 0.9223\n",
      "Epoch 59/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.1860 - acc: 0.9351 - val_loss: 0.1960 - val_acc: 0.9243\n",
      "Epoch 60/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.1922 - acc: 0.9289 - val_loss: 0.1965 - val_acc: 0.9284\n",
      "Epoch 61/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.1908 - acc: 0.9320 - val_loss: 0.1962 - val_acc: 0.9284\n",
      "Epoch 62/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.1865 - acc: 0.9279 - val_loss: 0.2043 - val_acc: 0.9182\n",
      "Epoch 63/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.1878 - acc: 0.9284 - val_loss: 0.2003 - val_acc: 0.9202\n",
      "Epoch 64/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.1808 - acc: 0.9387 - val_loss: 0.1914 - val_acc: 0.9264\n",
      "Epoch 65/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.1817 - acc: 0.9310 - val_loss: 0.1890 - val_acc: 0.9305\n",
      "Epoch 66/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.1840 - acc: 0.9310 - val_loss: 0.1925 - val_acc: 0.9243\n",
      "Epoch 67/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.1853 - acc: 0.9315 - val_loss: 0.1876 - val_acc: 0.9325\n",
      "Epoch 68/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.1783 - acc: 0.9335 - val_loss: 0.1878 - val_acc: 0.9305\n",
      "Epoch 69/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.1841 - acc: 0.9294 - val_loss: 0.1968 - val_acc: 0.9202\n",
      "Epoch 70/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.1786 - acc: 0.9346 - val_loss: 0.1907 - val_acc: 0.9243\n",
      "Epoch 71/100\n",
      "1956/1956 [==============================] - 1s 342us/step - loss: 0.1752 - acc: 0.9346 - val_loss: 0.1902 - val_acc: 0.9243\n",
      "Epoch 72/100\n",
      "1956/1956 [==============================] - 1s 337us/step - loss: 0.1808 - acc: 0.9366 - val_loss: 0.1757 - val_acc: 0.9407\n",
      "Epoch 73/100\n",
      "1956/1956 [==============================] - 1s 346us/step - loss: 0.1801 - acc: 0.9371 - val_loss: 0.1884 - val_acc: 0.9264\n",
      "Epoch 74/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.1719 - acc: 0.9376 - val_loss: 0.1917 - val_acc: 0.9223\n",
      "Epoch 75/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.1680 - acc: 0.9458 - val_loss: 0.1877 - val_acc: 0.9223\n",
      "Epoch 76/100\n",
      "1956/1956 [==============================] - 1s 339us/step - loss: 0.1783 - acc: 0.9366 - val_loss: 0.1894 - val_acc: 0.9243\n",
      "Epoch 77/100\n",
      "1956/1956 [==============================] - 1s 359us/step - loss: 0.1821 - acc: 0.9335 - val_loss: 0.1862 - val_acc: 0.9264\n",
      "Epoch 78/100\n",
      "1956/1956 [==============================] - 1s 355us/step - loss: 0.1769 - acc: 0.9371 - val_loss: 0.1867 - val_acc: 0.9305\n",
      "Epoch 79/100\n",
      "1956/1956 [==============================] - 1s 365us/step - loss: 0.1695 - acc: 0.9402 - val_loss: 0.2130 - val_acc: 0.9100\n",
      "Epoch 80/100\n",
      "1956/1956 [==============================] - 1s 341us/step - loss: 0.1772 - acc: 0.9340 - val_loss: 0.1826 - val_acc: 0.9264\n",
      "Epoch 81/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.1817 - acc: 0.9397 - val_loss: 0.1810 - val_acc: 0.9305\n",
      "Epoch 82/100\n",
      "1956/1956 [==============================] - 1s 343us/step - loss: 0.1694 - acc: 0.9402 - val_loss: 0.1874 - val_acc: 0.9284\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956/1956 [==============================] - 1s 343us/step - loss: 0.1704 - acc: 0.9371 - val_loss: 0.1870 - val_acc: 0.9243\n",
      "Epoch 84/100\n",
      "1956/1956 [==============================] - 1s 324us/step - loss: 0.1697 - acc: 0.9387 - val_loss: 0.1807 - val_acc: 0.9325\n",
      "Epoch 85/100\n",
      "1956/1956 [==============================] - 1s 338us/step - loss: 0.1706 - acc: 0.9387 - val_loss: 0.1849 - val_acc: 0.9305\n",
      "Epoch 86/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.1755 - acc: 0.9356 - val_loss: 0.1861 - val_acc: 0.9264\n",
      "Epoch 87/100\n",
      "1956/1956 [==============================] - 1s 344us/step - loss: 0.1723 - acc: 0.9340 - val_loss: 0.1834 - val_acc: 0.9305\n",
      "Epoch 88/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.1709 - acc: 0.9392 - val_loss: 0.1916 - val_acc: 0.9264\n",
      "Epoch 89/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.1629 - acc: 0.9453 - val_loss: 0.1793 - val_acc: 0.9305\n",
      "Epoch 90/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.1640 - acc: 0.9392 - val_loss: 0.1889 - val_acc: 0.9264\n",
      "Epoch 91/100\n",
      "1956/1956 [==============================] - 1s 324us/step - loss: 0.1713 - acc: 0.9371 - val_loss: 0.1757 - val_acc: 0.9346\n",
      "Epoch 92/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.1710 - acc: 0.9402 - val_loss: 0.1828 - val_acc: 0.9284\n",
      "Epoch 93/100\n",
      "1956/1956 [==============================] - 1s 322us/step - loss: 0.1698 - acc: 0.9402 - val_loss: 0.1749 - val_acc: 0.9346\n",
      "Epoch 94/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.1569 - acc: 0.9473 - val_loss: 0.1773 - val_acc: 0.9346\n",
      "Epoch 95/100\n",
      "1956/1956 [==============================] - 1s 336us/step - loss: 0.1661 - acc: 0.9422 - val_loss: 0.1805 - val_acc: 0.9305\n",
      "Epoch 96/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.1624 - acc: 0.9427 - val_loss: 0.1696 - val_acc: 0.9448\n",
      "Epoch 97/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.1649 - acc: 0.9438 - val_loss: 0.1736 - val_acc: 0.9346\n",
      "Epoch 98/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.1667 - acc: 0.9417 - val_loss: 0.1756 - val_acc: 0.9346\n",
      "Epoch 99/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.1599 - acc: 0.9448 - val_loss: 0.1734 - val_acc: 0.9346\n",
      "Epoch 100/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.1643 - acc: 0.9448 - val_loss: 0.1762 - val_acc: 0.9305\n",
      "Train on 1956 samples, validate on 489 samples\n",
      "Epoch 1/100\n",
      "1956/1956 [==============================] - 1s 324us/step - loss: 0.1889 - acc: 0.9361 - val_loss: 0.1945 - val_acc: 0.9387\n",
      "Epoch 2/100\n",
      "1956/1956 [==============================] - 1s 335us/step - loss: 0.1868 - acc: 0.9279 - val_loss: 0.1863 - val_acc: 0.9427\n",
      "Epoch 3/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.1848 - acc: 0.9340 - val_loss: 0.1818 - val_acc: 0.9489\n",
      "Epoch 4/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.1864 - acc: 0.9305 - val_loss: 0.1940 - val_acc: 0.9387\n",
      "Epoch 5/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.1908 - acc: 0.9289 - val_loss: 0.1888 - val_acc: 0.9448\n",
      "Epoch 6/100\n",
      "1956/1956 [==============================] - 1s 323us/step - loss: 0.1805 - acc: 0.9356 - val_loss: 0.2002 - val_acc: 0.9264\n",
      "Epoch 7/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.1709 - acc: 0.9387 - val_loss: 0.1889 - val_acc: 0.9427\n",
      "Epoch 8/100\n",
      "1956/1956 [==============================] - 1s 322us/step - loss: 0.1784 - acc: 0.9356 - val_loss: 0.1857 - val_acc: 0.9468\n",
      "Epoch 9/100\n",
      "1956/1956 [==============================] - 1s 349us/step - loss: 0.1725 - acc: 0.9376 - val_loss: 0.1739 - val_acc: 0.9591\n",
      "Epoch 10/100\n",
      "1956/1956 [==============================] - 1s 346us/step - loss: 0.1789 - acc: 0.9351 - val_loss: 0.1914 - val_acc: 0.9346\n",
      "Epoch 11/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.1711 - acc: 0.9397 - val_loss: 0.1887 - val_acc: 0.9366\n",
      "Epoch 12/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.1733 - acc: 0.9438 - val_loss: 0.1891 - val_acc: 0.9387\n",
      "Epoch 13/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.1706 - acc: 0.9376 - val_loss: 0.1892 - val_acc: 0.9346\n",
      "Epoch 14/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.1755 - acc: 0.9356 - val_loss: 0.1848 - val_acc: 0.9468\n",
      "Epoch 15/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.1703 - acc: 0.9376 - val_loss: 0.1887 - val_acc: 0.9407\n",
      "Epoch 16/100\n",
      "1956/1956 [==============================] - 1s 324us/step - loss: 0.1700 - acc: 0.9392 - val_loss: 0.1832 - val_acc: 0.9468\n",
      "Epoch 17/100\n",
      "1956/1956 [==============================] - 1s 321us/step - loss: 0.1681 - acc: 0.9356 - val_loss: 0.1820 - val_acc: 0.9468\n",
      "Epoch 18/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.1727 - acc: 0.9366 - val_loss: 0.1790 - val_acc: 0.9509\n",
      "Epoch 19/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.1702 - acc: 0.9412 - val_loss: 0.1847 - val_acc: 0.9448\n",
      "Epoch 20/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.1610 - acc: 0.9448 - val_loss: 0.1786 - val_acc: 0.9509\n",
      "Epoch 21/100\n",
      "1956/1956 [==============================] - 1s 322us/step - loss: 0.1645 - acc: 0.9427 - val_loss: 0.1809 - val_acc: 0.9468\n",
      "Epoch 22/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.1578 - acc: 0.9489 - val_loss: 0.1784 - val_acc: 0.9489\n",
      "Epoch 23/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.1707 - acc: 0.9392 - val_loss: 0.1867 - val_acc: 0.9407\n",
      "Epoch 24/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.1622 - acc: 0.9458 - val_loss: 0.1865 - val_acc: 0.9407\n",
      "Epoch 25/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.1658 - acc: 0.9397 - val_loss: 0.1918 - val_acc: 0.9366\n",
      "Epoch 26/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.1710 - acc: 0.9402 - val_loss: 0.1845 - val_acc: 0.9448\n",
      "Epoch 27/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.1624 - acc: 0.9438 - val_loss: 0.1843 - val_acc: 0.9448\n",
      "Epoch 28/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.1644 - acc: 0.9361 - val_loss: 0.1803 - val_acc: 0.9468\n",
      "Epoch 29/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.1619 - acc: 0.9407 - val_loss: 0.1857 - val_acc: 0.9387\n",
      "Epoch 30/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.1615 - acc: 0.9448 - val_loss: 0.1849 - val_acc: 0.9387\n",
      "Epoch 31/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.1633 - acc: 0.9417 - val_loss: 0.1793 - val_acc: 0.9448\n",
      "Epoch 32/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.1599 - acc: 0.9438 - val_loss: 0.1612 - val_acc: 0.9591\n",
      "Epoch 33/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.1595 - acc: 0.9438 - val_loss: 0.1809 - val_acc: 0.9448\n",
      "Epoch 34/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.1603 - acc: 0.9422 - val_loss: 0.1810 - val_acc: 0.9468\n",
      "Epoch 35/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.1573 - acc: 0.9489 - val_loss: 0.1825 - val_acc: 0.9468\n",
      "Epoch 36/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.1593 - acc: 0.9433 - val_loss: 0.1859 - val_acc: 0.9407\n",
      "Epoch 37/100\n",
      "1956/1956 [==============================] - 1s 322us/step - loss: 0.1632 - acc: 0.9448 - val_loss: 0.1833 - val_acc: 0.9448\n",
      "Epoch 38/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.1597 - acc: 0.9453 - val_loss: 0.1812 - val_acc: 0.9448\n",
      "Epoch 39/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.1624 - acc: 0.9438 - val_loss: 0.1817 - val_acc: 0.9448\n",
      "Epoch 40/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.1490 - acc: 0.9535 - val_loss: 0.1670 - val_acc: 0.9571\n",
      "Epoch 41/100\n",
      "1956/1956 [==============================] - 1s 342us/step - loss: 0.1584 - acc: 0.9443 - val_loss: 0.2209 - val_acc: 0.9284\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.1599 - acc: 0.9458 - val_loss: 0.1708 - val_acc: 0.9550\n",
      "Epoch 43/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.1601 - acc: 0.9448 - val_loss: 0.1784 - val_acc: 0.9468\n",
      "Epoch 44/100\n",
      "1956/1956 [==============================] - 1s 324us/step - loss: 0.1506 - acc: 0.9484 - val_loss: 0.1828 - val_acc: 0.9468\n",
      "Epoch 45/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.1530 - acc: 0.9489 - val_loss: 0.1835 - val_acc: 0.9427\n",
      "Epoch 46/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.1570 - acc: 0.9458 - val_loss: 0.1842 - val_acc: 0.9427\n",
      "Epoch 47/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.1564 - acc: 0.9438 - val_loss: 0.1879 - val_acc: 0.9407\n",
      "Epoch 48/100\n",
      "1956/1956 [==============================] - 1s 344us/step - loss: 0.1495 - acc: 0.9509 - val_loss: 0.1762 - val_acc: 0.9489\n",
      "Epoch 49/100\n",
      "1956/1956 [==============================] - 1s 344us/step - loss: 0.1483 - acc: 0.9519 - val_loss: 0.1831 - val_acc: 0.9427\n",
      "Epoch 50/100\n",
      "1956/1956 [==============================] - 1s 323us/step - loss: 0.1474 - acc: 0.9509 - val_loss: 0.1886 - val_acc: 0.9407\n",
      "Epoch 51/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.1472 - acc: 0.9545 - val_loss: 0.1779 - val_acc: 0.9489\n",
      "Epoch 52/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.1423 - acc: 0.9540 - val_loss: 0.1809 - val_acc: 0.9489\n",
      "Epoch 53/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.1411 - acc: 0.9509 - val_loss: 0.1822 - val_acc: 0.9427\n",
      "Epoch 54/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.1487 - acc: 0.9473 - val_loss: 0.1823 - val_acc: 0.9427\n",
      "Epoch 55/100\n",
      "1956/1956 [==============================] - 1s 335us/step - loss: 0.1483 - acc: 0.9499 - val_loss: 0.1904 - val_acc: 0.9366\n",
      "Epoch 56/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.1519 - acc: 0.9499 - val_loss: 0.1846 - val_acc: 0.9427\n",
      "Epoch 57/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.1519 - acc: 0.9473 - val_loss: 0.1872 - val_acc: 0.9407\n",
      "Epoch 58/100\n",
      "1956/1956 [==============================] - 1s 326us/step - loss: 0.1479 - acc: 0.9463 - val_loss: 0.1739 - val_acc: 0.9509\n",
      "Epoch 59/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.1441 - acc: 0.9504 - val_loss: 0.1780 - val_acc: 0.9468\n",
      "Epoch 60/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.1470 - acc: 0.9484 - val_loss: 0.1810 - val_acc: 0.9448\n",
      "Epoch 61/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.1412 - acc: 0.9525 - val_loss: 0.1768 - val_acc: 0.9489\n",
      "Epoch 62/100\n",
      "1956/1956 [==============================] - 1s 336us/step - loss: 0.1446 - acc: 0.9530 - val_loss: 0.1717 - val_acc: 0.9530\n",
      "Epoch 63/100\n",
      "1956/1956 [==============================] - 1s 338us/step - loss: 0.1445 - acc: 0.9494 - val_loss: 0.1683 - val_acc: 0.9591\n",
      "Epoch 64/100\n",
      "1956/1956 [==============================] - 1s 342us/step - loss: 0.1481 - acc: 0.9489 - val_loss: 0.1764 - val_acc: 0.9489\n",
      "Epoch 65/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.1423 - acc: 0.9514 - val_loss: 0.1676 - val_acc: 0.9591\n",
      "Epoch 66/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.1419 - acc: 0.9540 - val_loss: 0.1737 - val_acc: 0.9509\n",
      "Epoch 67/100\n",
      "1956/1956 [==============================] - 1s 345us/step - loss: 0.1431 - acc: 0.9530 - val_loss: 0.1746 - val_acc: 0.9509\n",
      "Epoch 68/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.1469 - acc: 0.9535 - val_loss: 0.1811 - val_acc: 0.9448\n",
      "Epoch 69/100\n",
      "1956/1956 [==============================] - 1s 339us/step - loss: 0.1392 - acc: 0.9519 - val_loss: 0.1776 - val_acc: 0.9468\n",
      "Epoch 70/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.1382 - acc: 0.9550 - val_loss: 0.1854 - val_acc: 0.9427\n",
      "Epoch 71/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.1383 - acc: 0.9504 - val_loss: 0.1824 - val_acc: 0.9448\n",
      "Epoch 72/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.1391 - acc: 0.9560 - val_loss: 0.1744 - val_acc: 0.9468\n",
      "Epoch 73/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.1399 - acc: 0.9530 - val_loss: 0.1739 - val_acc: 0.9509\n",
      "Epoch 74/100\n",
      "1956/1956 [==============================] - 1s 327us/step - loss: 0.1415 - acc: 0.9591 - val_loss: 0.1808 - val_acc: 0.9448\n",
      "Epoch 75/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.1373 - acc: 0.9499 - val_loss: 0.1715 - val_acc: 0.9489\n",
      "Epoch 76/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.1335 - acc: 0.9581 - val_loss: 0.1690 - val_acc: 0.9550\n",
      "Epoch 77/100\n",
      "1956/1956 [==============================] - 1s 334us/step - loss: 0.1395 - acc: 0.9525 - val_loss: 0.1779 - val_acc: 0.9468\n",
      "Epoch 78/100\n",
      "1956/1956 [==============================] - 1s 332us/step - loss: 0.1404 - acc: 0.9519 - val_loss: 0.1783 - val_acc: 0.9427\n",
      "Epoch 79/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.1369 - acc: 0.9545 - val_loss: 0.1905 - val_acc: 0.9407\n",
      "Epoch 80/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.1438 - acc: 0.9540 - val_loss: 0.1854 - val_acc: 0.9407\n",
      "Epoch 81/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.1346 - acc: 0.9565 - val_loss: 0.1787 - val_acc: 0.9448\n",
      "Epoch 82/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.1325 - acc: 0.9576 - val_loss: 0.1762 - val_acc: 0.9468\n",
      "Epoch 83/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.1381 - acc: 0.9555 - val_loss: 0.1769 - val_acc: 0.9468\n",
      "Epoch 84/100\n",
      "1956/1956 [==============================] - 1s 335us/step - loss: 0.1298 - acc: 0.9591 - val_loss: 0.1769 - val_acc: 0.9468\n",
      "Epoch 85/100\n",
      "1956/1956 [==============================] - 1s 336us/step - loss: 0.1354 - acc: 0.9571 - val_loss: 0.1761 - val_acc: 0.9468\n",
      "Epoch 86/100\n",
      "1956/1956 [==============================] - 1s 339us/step - loss: 0.1337 - acc: 0.9555 - val_loss: 0.1719 - val_acc: 0.9509\n",
      "Epoch 87/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.1297 - acc: 0.9571 - val_loss: 0.1741 - val_acc: 0.9468\n",
      "Epoch 88/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.1340 - acc: 0.9560 - val_loss: 0.1757 - val_acc: 0.9468\n",
      "Epoch 89/100\n",
      "1956/1956 [==============================] - 1s 325us/step - loss: 0.1368 - acc: 0.9514 - val_loss: 0.1850 - val_acc: 0.9407\n",
      "Epoch 90/100\n",
      "1956/1956 [==============================] - 1s 324us/step - loss: 0.1300 - acc: 0.9576 - val_loss: 0.1771 - val_acc: 0.9448\n",
      "Epoch 91/100\n",
      "1956/1956 [==============================] - 1s 321us/step - loss: 0.1286 - acc: 0.9591 - val_loss: 0.1727 - val_acc: 0.9468\n",
      "Epoch 92/100\n",
      "1956/1956 [==============================] - 1s 323us/step - loss: 0.1340 - acc: 0.9494 - val_loss: 0.1717 - val_acc: 0.9509\n",
      "Epoch 93/100\n",
      "1956/1956 [==============================] - 1s 333us/step - loss: 0.1211 - acc: 0.9622 - val_loss: 0.1741 - val_acc: 0.9509\n",
      "Epoch 94/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.1287 - acc: 0.9519 - val_loss: 0.1724 - val_acc: 0.9530\n",
      "Epoch 95/100\n",
      "1956/1956 [==============================] - 1s 330us/step - loss: 0.1303 - acc: 0.9586 - val_loss: 0.1741 - val_acc: 0.9468\n",
      "Epoch 96/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.1334 - acc: 0.9571 - val_loss: 0.1742 - val_acc: 0.9509\n",
      "Epoch 97/100\n",
      "1956/1956 [==============================] - 1s 324us/step - loss: 0.1278 - acc: 0.9560 - val_loss: 0.1742 - val_acc: 0.9489\n",
      "Epoch 98/100\n",
      "1956/1956 [==============================] - 1s 331us/step - loss: 0.1304 - acc: 0.9601 - val_loss: 0.1804 - val_acc: 0.9427\n",
      "Epoch 99/100\n",
      "1956/1956 [==============================] - 1s 329us/step - loss: 0.1262 - acc: 0.9571 - val_loss: 0.1778 - val_acc: 0.9468\n",
      "Epoch 100/100\n",
      "1956/1956 [==============================] - 1s 328us/step - loss: 0.1338 - acc: 0.9550 - val_loss: 0.1762 - val_acc: 0.9468\n",
      "Test subject 12, class Replace\n",
      "Train subject 12, class BothReleased\n",
      "Train on 1955 samples, validate on 489 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.7101 - acc: 0.7872 - val_loss: 0.4577 - val_acc: 0.8098\n",
      "Epoch 2/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.4448 - acc: 0.8205 - val_loss: 0.4415 - val_acc: 0.8098\n",
      "Epoch 3/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.4083 - acc: 0.8322 - val_loss: 0.3940 - val_acc: 0.8221\n",
      "Epoch 4/100\n",
      "1955/1955 [==============================] - 1s 325us/step - loss: 0.4033 - acc: 0.8281 - val_loss: 0.3849 - val_acc: 0.8262\n",
      "Epoch 5/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.3861 - acc: 0.8404 - val_loss: 0.3830 - val_acc: 0.8241\n",
      "Epoch 6/100\n",
      "1955/1955 [==============================] - 1s 326us/step - loss: 0.3671 - acc: 0.8460 - val_loss: 0.3683 - val_acc: 0.8405\n",
      "Epoch 7/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.3617 - acc: 0.8522 - val_loss: 0.3675 - val_acc: 0.8344\n",
      "Epoch 8/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.3509 - acc: 0.8517 - val_loss: 0.3527 - val_acc: 0.8466\n",
      "Epoch 9/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.3386 - acc: 0.8537 - val_loss: 0.3344 - val_acc: 0.8569\n",
      "Epoch 10/100\n",
      "1955/1955 [==============================] - 1s 338us/step - loss: 0.3529 - acc: 0.8573 - val_loss: 0.3580 - val_acc: 0.8507\n",
      "Epoch 11/100\n",
      "1955/1955 [==============================] - 1s 322us/step - loss: 0.3265 - acc: 0.8645 - val_loss: 0.3284 - val_acc: 0.8650\n",
      "Epoch 12/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.3337 - acc: 0.8614 - val_loss: 0.3182 - val_acc: 0.8773\n",
      "Epoch 13/100\n",
      "1955/1955 [==============================] - 1s 323us/step - loss: 0.3176 - acc: 0.8701 - val_loss: 0.3287 - val_acc: 0.8548\n",
      "Epoch 14/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.3224 - acc: 0.8696 - val_loss: 0.3017 - val_acc: 0.8834\n",
      "Epoch 15/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.3072 - acc: 0.8660 - val_loss: 0.3146 - val_acc: 0.8609\n",
      "Epoch 16/100\n",
      "1955/1955 [==============================] - 1s 323us/step - loss: 0.2983 - acc: 0.8788 - val_loss: 0.3087 - val_acc: 0.8630\n",
      "Epoch 17/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.3077 - acc: 0.8711 - val_loss: 0.2995 - val_acc: 0.8793\n",
      "Epoch 18/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.2973 - acc: 0.8829 - val_loss: 0.2953 - val_acc: 0.8814\n",
      "Epoch 19/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.2942 - acc: 0.8772 - val_loss: 0.2947 - val_acc: 0.8753\n",
      "Epoch 20/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.2988 - acc: 0.8793 - val_loss: 0.2883 - val_acc: 0.8855\n",
      "Epoch 21/100\n",
      "1955/1955 [==============================] - 1s 337us/step - loss: 0.2898 - acc: 0.8849 - val_loss: 0.2767 - val_acc: 0.8937\n",
      "Epoch 22/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.2871 - acc: 0.8895 - val_loss: 0.2936 - val_acc: 0.8753\n",
      "Epoch 23/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.2950 - acc: 0.8803 - val_loss: 0.2779 - val_acc: 0.8773\n",
      "Epoch 24/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.2834 - acc: 0.8854 - val_loss: 0.2851 - val_acc: 0.8753\n",
      "Epoch 25/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.2897 - acc: 0.8824 - val_loss: 0.2680 - val_acc: 0.8978\n",
      "Epoch 26/100\n",
      "1955/1955 [==============================] - 1s 326us/step - loss: 0.2831 - acc: 0.8900 - val_loss: 0.2748 - val_acc: 0.8814\n",
      "Epoch 27/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.2737 - acc: 0.8880 - val_loss: 0.2711 - val_acc: 0.8875\n",
      "Epoch 28/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.2801 - acc: 0.8916 - val_loss: 0.2694 - val_acc: 0.8896\n",
      "Epoch 29/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.2646 - acc: 0.9043 - val_loss: 0.2705 - val_acc: 0.8855\n",
      "Epoch 30/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.2656 - acc: 0.9013 - val_loss: 0.2730 - val_acc: 0.8814\n",
      "Epoch 31/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.2573 - acc: 0.9069 - val_loss: 0.2688 - val_acc: 0.8855\n",
      "Epoch 32/100\n",
      "1955/1955 [==============================] - 1s 325us/step - loss: 0.2650 - acc: 0.8931 - val_loss: 0.2572 - val_acc: 0.9018\n",
      "Epoch 33/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.2675 - acc: 0.8962 - val_loss: 0.2734 - val_acc: 0.8834\n",
      "Epoch 34/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.2598 - acc: 0.9033 - val_loss: 0.2666 - val_acc: 0.8937\n",
      "Epoch 35/100\n",
      "1955/1955 [==============================] - 1s 325us/step - loss: 0.2493 - acc: 0.9028 - val_loss: 0.2529 - val_acc: 0.8998\n",
      "Epoch 36/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.2459 - acc: 0.9084 - val_loss: 0.2687 - val_acc: 0.8896\n",
      "Epoch 37/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.2578 - acc: 0.9023 - val_loss: 0.2598 - val_acc: 0.8978\n",
      "Epoch 38/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.2467 - acc: 0.9105 - val_loss: 0.2560 - val_acc: 0.8957\n",
      "Epoch 39/100\n",
      "1955/1955 [==============================] - 1s 325us/step - loss: 0.2487 - acc: 0.9054 - val_loss: 0.2479 - val_acc: 0.9100\n",
      "Epoch 40/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.2609 - acc: 0.9008 - val_loss: 0.2530 - val_acc: 0.8937\n",
      "Epoch 41/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.2543 - acc: 0.9074 - val_loss: 0.2545 - val_acc: 0.8937\n",
      "Epoch 42/100\n",
      "1955/1955 [==============================] - 1s 343us/step - loss: 0.2444 - acc: 0.9090 - val_loss: 0.2490 - val_acc: 0.8998\n",
      "Epoch 43/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.2428 - acc: 0.9141 - val_loss: 0.2607 - val_acc: 0.8896\n",
      "Epoch 44/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.2510 - acc: 0.9023 - val_loss: 0.2530 - val_acc: 0.8957\n",
      "Epoch 45/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.2427 - acc: 0.9110 - val_loss: 0.2558 - val_acc: 0.8937\n",
      "Epoch 46/100\n",
      "1955/1955 [==============================] - 1s 326us/step - loss: 0.2484 - acc: 0.9033 - val_loss: 0.2534 - val_acc: 0.8937\n",
      "Epoch 47/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.2443 - acc: 0.9049 - val_loss: 0.2753 - val_acc: 0.8875\n",
      "Epoch 48/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.2352 - acc: 0.9115 - val_loss: 0.2523 - val_acc: 0.8998\n",
      "Epoch 49/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.2477 - acc: 0.9100 - val_loss: 0.2486 - val_acc: 0.8957\n",
      "Epoch 50/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.2436 - acc: 0.9136 - val_loss: 0.2443 - val_acc: 0.9018\n",
      "Epoch 51/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.2390 - acc: 0.9115 - val_loss: 0.2365 - val_acc: 0.9080\n",
      "Epoch 52/100\n",
      "1955/1955 [==============================] - 1s 339us/step - loss: 0.2298 - acc: 0.9176 - val_loss: 0.2452 - val_acc: 0.9018\n",
      "Epoch 53/100\n",
      "1955/1955 [==============================] - 1s 324us/step - loss: 0.2291 - acc: 0.9187 - val_loss: 0.2496 - val_acc: 0.8998\n",
      "Epoch 54/100\n",
      "1955/1955 [==============================] - 1s 326us/step - loss: 0.2253 - acc: 0.9197 - val_loss: 0.2386 - val_acc: 0.9059\n",
      "Epoch 55/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.2282 - acc: 0.9187 - val_loss: 0.2359 - val_acc: 0.9059\n",
      "Epoch 56/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.2291 - acc: 0.9176 - val_loss: 0.2295 - val_acc: 0.9080\n",
      "Epoch 57/100\n",
      "1955/1955 [==============================] - 1s 325us/step - loss: 0.2236 - acc: 0.9197 - val_loss: 0.2310 - val_acc: 0.9059\n",
      "Epoch 58/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.2279 - acc: 0.9233 - val_loss: 0.2281 - val_acc: 0.9080\n",
      "Epoch 59/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.2291 - acc: 0.9207 - val_loss: 0.2398 - val_acc: 0.9018\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1955/1955 [==============================] - 1s 325us/step - loss: 0.2254 - acc: 0.9202 - val_loss: 0.2414 - val_acc: 0.9018\n",
      "Epoch 61/100\n",
      "1955/1955 [==============================] - 1s 325us/step - loss: 0.2321 - acc: 0.9146 - val_loss: 0.2293 - val_acc: 0.9100\n",
      "Epoch 62/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.2307 - acc: 0.9141 - val_loss: 0.2450 - val_acc: 0.9018\n",
      "Epoch 63/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.2339 - acc: 0.9151 - val_loss: 0.2296 - val_acc: 0.9059\n",
      "Epoch 64/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.2298 - acc: 0.9141 - val_loss: 0.2372 - val_acc: 0.9018\n",
      "Epoch 65/100\n",
      "1955/1955 [==============================] - 1s 326us/step - loss: 0.2229 - acc: 0.9156 - val_loss: 0.2322 - val_acc: 0.9080\n",
      "Epoch 66/100\n",
      "1955/1955 [==============================] - 1s 326us/step - loss: 0.2184 - acc: 0.9202 - val_loss: 0.2250 - val_acc: 0.9080\n",
      "Epoch 67/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.2144 - acc: 0.9202 - val_loss: 0.2176 - val_acc: 0.9141\n",
      "Epoch 68/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.2140 - acc: 0.9238 - val_loss: 0.2261 - val_acc: 0.9121\n",
      "Epoch 69/100\n",
      "1955/1955 [==============================] - 1s 325us/step - loss: 0.2229 - acc: 0.9202 - val_loss: 0.2262 - val_acc: 0.9100\n",
      "Epoch 70/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.2218 - acc: 0.9192 - val_loss: 0.2348 - val_acc: 0.9039\n",
      "Epoch 71/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.2224 - acc: 0.9182 - val_loss: 0.2380 - val_acc: 0.9039\n",
      "Epoch 72/100\n",
      "1955/1955 [==============================] - 1s 321us/step - loss: 0.2173 - acc: 0.9253 - val_loss: 0.2177 - val_acc: 0.9121\n",
      "Epoch 73/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.2119 - acc: 0.9212 - val_loss: 0.2283 - val_acc: 0.9059\n",
      "Epoch 74/100\n",
      "1955/1955 [==============================] - 1s 323us/step - loss: 0.2105 - acc: 0.9269 - val_loss: 0.2308 - val_acc: 0.9059\n",
      "Epoch 75/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.2101 - acc: 0.9299 - val_loss: 0.2354 - val_acc: 0.9059\n",
      "Epoch 76/100\n",
      "1955/1955 [==============================] - 1s 325us/step - loss: 0.2061 - acc: 0.9299 - val_loss: 0.2262 - val_acc: 0.9121\n",
      "Epoch 77/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.2167 - acc: 0.9187 - val_loss: 0.2292 - val_acc: 0.9080\n",
      "Epoch 78/100\n",
      "1955/1955 [==============================] - 1s 321us/step - loss: 0.2091 - acc: 0.9284 - val_loss: 0.2197 - val_acc: 0.9100\n",
      "Epoch 79/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.2128 - acc: 0.9238 - val_loss: 0.2217 - val_acc: 0.9100\n",
      "Epoch 80/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.2123 - acc: 0.9238 - val_loss: 0.2186 - val_acc: 0.9121\n",
      "Epoch 81/100\n",
      "1955/1955 [==============================] - 1s 324us/step - loss: 0.2054 - acc: 0.9223 - val_loss: 0.2169 - val_acc: 0.9121\n",
      "Epoch 82/100\n",
      "1955/1955 [==============================] - 1s 324us/step - loss: 0.2112 - acc: 0.9309 - val_loss: 0.2067 - val_acc: 0.9223\n",
      "Epoch 83/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.2039 - acc: 0.9243 - val_loss: 0.2108 - val_acc: 0.9162\n",
      "Epoch 84/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.2097 - acc: 0.9294 - val_loss: 0.2169 - val_acc: 0.9141\n",
      "Epoch 85/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.2104 - acc: 0.9269 - val_loss: 0.2132 - val_acc: 0.9141\n",
      "Epoch 86/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.2069 - acc: 0.9269 - val_loss: 0.2140 - val_acc: 0.9121\n",
      "Epoch 87/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.2128 - acc: 0.9253 - val_loss: 0.2002 - val_acc: 0.9264\n",
      "Epoch 88/100\n",
      "1955/1955 [==============================] - 1s 325us/step - loss: 0.2164 - acc: 0.9233 - val_loss: 0.2192 - val_acc: 0.9121\n",
      "Epoch 89/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.2058 - acc: 0.9294 - val_loss: 0.2194 - val_acc: 0.9121\n",
      "Epoch 90/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.1950 - acc: 0.9381 - val_loss: 0.2268 - val_acc: 0.9080\n",
      "Epoch 91/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.1926 - acc: 0.9386 - val_loss: 0.2153 - val_acc: 0.9141\n",
      "Epoch 92/100\n",
      "1955/1955 [==============================] - 1s 326us/step - loss: 0.2062 - acc: 0.9243 - val_loss: 0.2114 - val_acc: 0.9162\n",
      "Epoch 93/100\n",
      "1955/1955 [==============================] - 1s 336us/step - loss: 0.1959 - acc: 0.9309 - val_loss: 0.2128 - val_acc: 0.9162\n",
      "Epoch 94/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.2014 - acc: 0.9294 - val_loss: 0.2102 - val_acc: 0.9182\n",
      "Epoch 95/100\n",
      "1955/1955 [==============================] - ETA: 0s - loss: 0.1963 - acc: 0.930 - 1s 322us/step - loss: 0.1972 - acc: 0.9304 - val_loss: 0.2013 - val_acc: 0.9243\n",
      "Epoch 96/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.1992 - acc: 0.9299 - val_loss: 0.2228 - val_acc: 0.9121\n",
      "Epoch 97/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.2011 - acc: 0.9294 - val_loss: 0.2248 - val_acc: 0.9121\n",
      "Epoch 98/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.2007 - acc: 0.9294 - val_loss: 0.2228 - val_acc: 0.9121\n",
      "Epoch 99/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.1972 - acc: 0.9269 - val_loss: 0.2073 - val_acc: 0.9223\n",
      "Epoch 100/100\n",
      "1955/1955 [==============================] - 1s 326us/step - loss: 0.1978 - acc: 0.9274 - val_loss: 0.2077 - val_acc: 0.9182\n",
      "Train on 1955 samples, validate on 489 samples\n",
      "Epoch 1/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.2200 - acc: 0.9243 - val_loss: 0.2033 - val_acc: 0.9264\n",
      "Epoch 2/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.2149 - acc: 0.9233 - val_loss: 0.2106 - val_acc: 0.9243\n",
      "Epoch 3/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.2202 - acc: 0.9228 - val_loss: 0.2000 - val_acc: 0.9243\n",
      "Epoch 4/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.2248 - acc: 0.9207 - val_loss: 0.2063 - val_acc: 0.9264\n",
      "Epoch 5/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.2123 - acc: 0.9243 - val_loss: 0.2022 - val_acc: 0.9243\n",
      "Epoch 6/100\n",
      "1955/1955 [==============================] - 1s 326us/step - loss: 0.2105 - acc: 0.9228 - val_loss: 0.2073 - val_acc: 0.9243\n",
      "Epoch 7/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.2111 - acc: 0.9217 - val_loss: 0.1972 - val_acc: 0.9264\n",
      "Epoch 8/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.2114 - acc: 0.9207 - val_loss: 0.2004 - val_acc: 0.9264\n",
      "Epoch 9/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.2112 - acc: 0.9217 - val_loss: 0.2177 - val_acc: 0.9202\n",
      "Epoch 10/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.2072 - acc: 0.9274 - val_loss: 0.1967 - val_acc: 0.9243\n",
      "Epoch 11/100\n",
      "1955/1955 [==============================] - 1s 324us/step - loss: 0.2032 - acc: 0.9248 - val_loss: 0.1917 - val_acc: 0.9243\n",
      "Epoch 12/100\n",
      "1955/1955 [==============================] - 1s 325us/step - loss: 0.1986 - acc: 0.9309 - val_loss: 0.1909 - val_acc: 0.9243\n",
      "Epoch 13/100\n",
      "1955/1955 [==============================] - 1s 325us/step - loss: 0.2091 - acc: 0.9233 - val_loss: 0.1833 - val_acc: 0.9325\n",
      "Epoch 14/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.2083 - acc: 0.9238 - val_loss: 0.1958 - val_acc: 0.9264\n",
      "Epoch 15/100\n",
      "1955/1955 [==============================] - 1s 324us/step - loss: 0.2066 - acc: 0.9248 - val_loss: 0.2058 - val_acc: 0.9223\n",
      "Epoch 16/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.2018 - acc: 0.9253 - val_loss: 0.1966 - val_acc: 0.9223\n",
      "Epoch 17/100\n",
      "1955/1955 [==============================] - 1s 326us/step - loss: 0.2026 - acc: 0.9248 - val_loss: 0.1942 - val_acc: 0.9264\n",
      "Epoch 18/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.1976 - acc: 0.9325 - val_loss: 0.1826 - val_acc: 0.9366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.1938 - acc: 0.9304 - val_loss: 0.2018 - val_acc: 0.9284\n",
      "Epoch 20/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.1931 - acc: 0.9330 - val_loss: 0.1961 - val_acc: 0.9243\n",
      "Epoch 21/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.1977 - acc: 0.9345 - val_loss: 0.1865 - val_acc: 0.9305\n",
      "Epoch 22/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.1947 - acc: 0.9355 - val_loss: 0.1994 - val_acc: 0.9264\n",
      "Epoch 23/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.1913 - acc: 0.9350 - val_loss: 0.1871 - val_acc: 0.9325\n",
      "Epoch 24/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.1965 - acc: 0.9381 - val_loss: 0.1864 - val_acc: 0.9325\n",
      "Epoch 25/100\n",
      "1955/1955 [==============================] - 1s 346us/step - loss: 0.1968 - acc: 0.9391 - val_loss: 0.1919 - val_acc: 0.9284\n",
      "Epoch 26/100\n",
      "1955/1955 [==============================] - 1s 350us/step - loss: 0.1977 - acc: 0.9315 - val_loss: 0.1879 - val_acc: 0.9305\n",
      "Epoch 27/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.1951 - acc: 0.9340 - val_loss: 0.1865 - val_acc: 0.9325\n",
      "Epoch 28/100\n",
      "1955/1955 [==============================] - 1s 342us/step - loss: 0.1890 - acc: 0.9269 - val_loss: 0.1809 - val_acc: 0.9325\n",
      "Epoch 29/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.1913 - acc: 0.9299 - val_loss: 0.1853 - val_acc: 0.9305\n",
      "Epoch 30/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.1803 - acc: 0.9325 - val_loss: 0.1909 - val_acc: 0.9325\n",
      "Epoch 31/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.1857 - acc: 0.9407 - val_loss: 0.1919 - val_acc: 0.9284\n",
      "Epoch 32/100\n",
      "1955/1955 [==============================] - 1s 351us/step - loss: 0.1862 - acc: 0.9386 - val_loss: 0.1844 - val_acc: 0.9264\n",
      "Epoch 33/100\n",
      "1955/1955 [==============================] - 1s 346us/step - loss: 0.1906 - acc: 0.9304 - val_loss: 0.1931 - val_acc: 0.9284\n",
      "Epoch 34/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.1921 - acc: 0.9320 - val_loss: 0.1806 - val_acc: 0.9346\n",
      "Epoch 35/100\n",
      "1955/1955 [==============================] - 1s 324us/step - loss: 0.1870 - acc: 0.9366 - val_loss: 0.1865 - val_acc: 0.9284\n",
      "Epoch 36/100\n",
      "1955/1955 [==============================] - 1s 323us/step - loss: 0.1813 - acc: 0.9350 - val_loss: 0.1807 - val_acc: 0.9346\n",
      "Epoch 37/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.1837 - acc: 0.9386 - val_loss: 0.1855 - val_acc: 0.9284\n",
      "Epoch 38/100\n",
      "1955/1955 [==============================] - 1s 325us/step - loss: 0.1876 - acc: 0.9366 - val_loss: 0.1905 - val_acc: 0.9305\n",
      "Epoch 39/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.1834 - acc: 0.9381 - val_loss: 0.1829 - val_acc: 0.9325\n",
      "Epoch 40/100\n",
      "1955/1955 [==============================] - 1s 335us/step - loss: 0.1849 - acc: 0.9345 - val_loss: 0.1954 - val_acc: 0.9305\n",
      "Epoch 41/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.1877 - acc: 0.9294 - val_loss: 0.1884 - val_acc: 0.9284\n",
      "Epoch 42/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.1700 - acc: 0.9407 - val_loss: 0.1965 - val_acc: 0.9284\n",
      "Epoch 43/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.1803 - acc: 0.9355 - val_loss: 0.1847 - val_acc: 0.9305\n",
      "Epoch 44/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.1770 - acc: 0.9396 - val_loss: 0.1929 - val_acc: 0.9284\n",
      "Epoch 45/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.1791 - acc: 0.9320 - val_loss: 0.1903 - val_acc: 0.9305\n",
      "Epoch 46/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.1742 - acc: 0.9422 - val_loss: 0.1793 - val_acc: 0.9346\n",
      "Epoch 47/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.1771 - acc: 0.9386 - val_loss: 0.1894 - val_acc: 0.9346\n",
      "Epoch 48/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.1841 - acc: 0.9381 - val_loss: 0.1844 - val_acc: 0.9284\n",
      "Epoch 49/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.1787 - acc: 0.9412 - val_loss: 0.1772 - val_acc: 0.9346\n",
      "Epoch 50/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.1799 - acc: 0.9366 - val_loss: 0.1906 - val_acc: 0.9305\n",
      "Epoch 51/100\n",
      "1955/1955 [==============================] - 1s 325us/step - loss: 0.1695 - acc: 0.9412 - val_loss: 0.1858 - val_acc: 0.9325\n",
      "Epoch 52/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.1732 - acc: 0.9442 - val_loss: 0.1795 - val_acc: 0.9305\n",
      "Epoch 53/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.1770 - acc: 0.9407 - val_loss: 0.1838 - val_acc: 0.9325\n",
      "Epoch 54/100\n",
      "1955/1955 [==============================] - 1s 322us/step - loss: 0.1824 - acc: 0.9376 - val_loss: 0.1872 - val_acc: 0.9346\n",
      "Epoch 55/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.1775 - acc: 0.9371 - val_loss: 0.1817 - val_acc: 0.9325\n",
      "Epoch 56/100\n",
      "1955/1955 [==============================] - 1s 326us/step - loss: 0.1714 - acc: 0.9432 - val_loss: 0.1770 - val_acc: 0.9305\n",
      "Epoch 57/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.1765 - acc: 0.9417 - val_loss: 0.1849 - val_acc: 0.9325\n",
      "Epoch 58/100\n",
      "1955/1955 [==============================] - 1s 324us/step - loss: 0.1744 - acc: 0.9412 - val_loss: 0.1997 - val_acc: 0.9264\n",
      "Epoch 59/100\n",
      "1955/1955 [==============================] - 1s 326us/step - loss: 0.1673 - acc: 0.9427 - val_loss: 0.1750 - val_acc: 0.9325\n",
      "Epoch 60/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.1698 - acc: 0.9442 - val_loss: 0.1781 - val_acc: 0.9325\n",
      "Epoch 61/100\n",
      "1955/1955 [==============================] - 1s 337us/step - loss: 0.1707 - acc: 0.9432 - val_loss: 0.1890 - val_acc: 0.9284\n",
      "Epoch 62/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.1665 - acc: 0.9412 - val_loss: 0.1757 - val_acc: 0.9325\n",
      "Epoch 63/100\n",
      "1955/1955 [==============================] - 1s 324us/step - loss: 0.1752 - acc: 0.9361 - val_loss: 0.1728 - val_acc: 0.9366\n",
      "Epoch 64/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.1743 - acc: 0.9427 - val_loss: 0.1863 - val_acc: 0.9346\n",
      "Epoch 65/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.1687 - acc: 0.9376 - val_loss: 0.1768 - val_acc: 0.9366\n",
      "Epoch 66/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.1677 - acc: 0.9427 - val_loss: 0.1711 - val_acc: 0.9366\n",
      "Epoch 67/100\n",
      "1955/1955 [==============================] - 1s 324us/step - loss: 0.1645 - acc: 0.9463 - val_loss: 0.1874 - val_acc: 0.9325\n",
      "Epoch 68/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.1705 - acc: 0.9458 - val_loss: 0.1862 - val_acc: 0.9346\n",
      "Epoch 69/100\n",
      "1955/1955 [==============================] - 1s 325us/step - loss: 0.1632 - acc: 0.9509 - val_loss: 0.1829 - val_acc: 0.9325\n",
      "Epoch 70/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.1771 - acc: 0.9361 - val_loss: 0.1788 - val_acc: 0.9346\n",
      "Epoch 71/100\n",
      "1955/1955 [==============================] - 1s 346us/step - loss: 0.1632 - acc: 0.9442 - val_loss: 0.1823 - val_acc: 0.9346\n",
      "Epoch 72/100\n",
      "1955/1955 [==============================] - 1s 340us/step - loss: 0.1681 - acc: 0.9402 - val_loss: 0.1803 - val_acc: 0.9346\n",
      "Epoch 73/100\n",
      "1955/1955 [==============================] - 1s 343us/step - loss: 0.1724 - acc: 0.9391 - val_loss: 0.1800 - val_acc: 0.9346\n",
      "Epoch 74/100\n",
      "1955/1955 [==============================] - 1s 326us/step - loss: 0.1635 - acc: 0.9453 - val_loss: 0.1810 - val_acc: 0.9325\n",
      "Epoch 75/100\n",
      "1955/1955 [==============================] - 1s 329us/step - loss: 0.1599 - acc: 0.9458 - val_loss: 0.1769 - val_acc: 0.9346\n",
      "Epoch 76/100\n",
      "1955/1955 [==============================] - 1s 334us/step - loss: 0.1675 - acc: 0.9427 - val_loss: 0.1802 - val_acc: 0.9346\n",
      "Epoch 77/100\n",
      "1955/1955 [==============================] - 1s 333us/step - loss: 0.1602 - acc: 0.9448 - val_loss: 0.1792 - val_acc: 0.9366\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1955/1955 [==============================] - 1s 338us/step - loss: 0.1670 - acc: 0.9458 - val_loss: 0.1827 - val_acc: 0.9346\n",
      "Epoch 79/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.1637 - acc: 0.9422 - val_loss: 0.1787 - val_acc: 0.9325\n",
      "Epoch 80/100\n",
      "1955/1955 [==============================] - 1s 324us/step - loss: 0.1652 - acc: 0.9463 - val_loss: 0.1853 - val_acc: 0.9346\n",
      "Epoch 81/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.1651 - acc: 0.9442 - val_loss: 0.1771 - val_acc: 0.9366\n",
      "Epoch 82/100\n",
      "1955/1955 [==============================] - 1s 325us/step - loss: 0.1633 - acc: 0.9442 - val_loss: 0.1821 - val_acc: 0.9346\n",
      "Epoch 83/100\n",
      "1955/1955 [==============================] - 1s 323us/step - loss: 0.1678 - acc: 0.9463 - val_loss: 0.1748 - val_acc: 0.9325\n",
      "Epoch 84/100\n",
      "1955/1955 [==============================] - 1s 330us/step - loss: 0.1601 - acc: 0.9468 - val_loss: 0.1732 - val_acc: 0.9346\n",
      "Epoch 85/100\n",
      "1955/1955 [==============================] - 1s 343us/step - loss: 0.1588 - acc: 0.9473 - val_loss: 0.1836 - val_acc: 0.9325\n",
      "Epoch 86/100\n",
      "1955/1955 [==============================] - 1s 339us/step - loss: 0.1557 - acc: 0.9453 - val_loss: 0.1787 - val_acc: 0.9325\n",
      "Epoch 87/100\n",
      "1955/1955 [==============================] - 1s 339us/step - loss: 0.1596 - acc: 0.9463 - val_loss: 0.1730 - val_acc: 0.9346\n",
      "Epoch 88/100\n",
      "1955/1955 [==============================] - 1s 336us/step - loss: 0.1619 - acc: 0.9519 - val_loss: 0.1777 - val_acc: 0.9325\n",
      "Epoch 89/100\n",
      "1955/1955 [==============================] - 1s 323us/step - loss: 0.1617 - acc: 0.9458 - val_loss: 0.1804 - val_acc: 0.9325\n",
      "Epoch 90/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.1562 - acc: 0.9514 - val_loss: 0.1764 - val_acc: 0.9346\n",
      "Epoch 91/100\n",
      "1955/1955 [==============================] - 1s 342us/step - loss: 0.1643 - acc: 0.9458 - val_loss: 0.1795 - val_acc: 0.9325\n",
      "Epoch 92/100\n",
      "1955/1955 [==============================] - 1s 332us/step - loss: 0.1598 - acc: 0.9494 - val_loss: 0.1735 - val_acc: 0.9325\n",
      "Epoch 93/100\n",
      "1955/1955 [==============================] - 1s 339us/step - loss: 0.1681 - acc: 0.9422 - val_loss: 0.1649 - val_acc: 0.9407\n",
      "Epoch 94/100\n",
      "1955/1955 [==============================] - 1s 325us/step - loss: 0.1574 - acc: 0.9494 - val_loss: 0.1806 - val_acc: 0.9305\n",
      "Epoch 95/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.1486 - acc: 0.9540 - val_loss: 0.1700 - val_acc: 0.9325\n",
      "Epoch 96/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.1582 - acc: 0.9437 - val_loss: 0.1840 - val_acc: 0.9325\n",
      "Epoch 97/100\n",
      "1955/1955 [==============================] - 1s 323us/step - loss: 0.1565 - acc: 0.9494 - val_loss: 0.1649 - val_acc: 0.9489\n",
      "Epoch 98/100\n",
      "1955/1955 [==============================] - 1s 328us/step - loss: 0.1504 - acc: 0.9550 - val_loss: 0.1718 - val_acc: 0.9305\n",
      "Epoch 99/100\n",
      "1955/1955 [==============================] - 1s 331us/step - loss: 0.1584 - acc: 0.9504 - val_loss: 0.1685 - val_acc: 0.9407\n",
      "Epoch 100/100\n",
      "1955/1955 [==============================] - 1s 327us/step - loss: 0.1527 - acc: 0.9494 - val_loss: 0.1725 - val_acc: 0.9325\n",
      "Test subject 12, class BothReleased\n",
      "HandStart AUC score = 0.658\n",
      "FirstDigitTouch AUC score = 0.807\n",
      "BothStartLoadPhase AUC score = 0.872\n",
      "LiftOff AUC score = 0.823\n",
      "Replace AUC score = 0.874\n",
      "BothReleased AUC score = 0.868\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "models = []\n",
    "# for i in range(N_LABELS):\n",
    "#     models.append(init_cnn(WINDOW_SIZE))\n",
    "    \n",
    "models.append(load_model('general_model_HandStart_subject_8.h5'))    \n",
    "models.append(load_model('general_model_FirstDigitTouch_subject_8.h5'))    \n",
    "models.append(load_model('general_model_BothStartLoadPhase_subject_8.h5'))    \n",
    "models.append(load_model('general_model_LiftOff_subject_8.h5'))    \n",
    "models.append(load_model('general_model_Replace_subject_8.h5'))    \n",
    "models.append(load_model('general_model_BothReleased_subject_8.h5'))    \n",
    "\n",
    "\n",
    "\n",
    "for subject in TRAIN_SUBJECTS:\n",
    "    prediction_total = []\n",
    "    test_data_total = []\n",
    "    train_data_paths = glob(TRAIN_DATA_PATH % (subject))\n",
    "\n",
    "    \n",
    "    x_raw, y_raw = read_training_data(train_data_paths)\n",
    "    \n",
    "    x_raw, _ = preprocess_data(x_raw, WINDOW_SIZE, SUBSAMPLE)\n",
    "#     y_train = y_raw[::SUBSAMPLE]\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_raw, y_raw[::SUBSAMPLE], test_size=0.33, shuffle=False)\n",
    "    x_train, _, y_train, _ = train_test_split(x_train, y_train, test_size=0.0001, shuffle=True)\n",
    "    print(len(x_test), len(y_test))\n",
    "    \n",
    "    for i in range(N_LABELS):\n",
    "        model = models[i]\n",
    "        \n",
    "        balanced_x_train, balanced_y_train = remove_imbalance(x_train, y_train[:,i])\n",
    "        \n",
    "\n",
    "            \n",
    "        train_labels = to_categorical(balanced_y_train, num_classes = None)\n",
    "                \n",
    "        print('Train subject %d, class %s' % (subject, COLUMNS[i]))\n",
    "        \n",
    "        x = [balanced_x_train[j::2] for j in range(2)]\n",
    "        y = [train_labels[j::2] for j in range(2)]\n",
    "        result = np.array([])\n",
    "        for sample_x, sample_y in zip(x, y):\n",
    "            model.fit(np.array(sample_x), np.array(sample_y), verbose=1, validation_split=0.2, epochs=EPOCHS)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         test_labels = to_categorical(y_test[:,i], num_classes = None)\n",
    "                \n",
    "        print('Test subject %d, class %s' % (subject, COLUMNS[i]))                \n",
    "        predictions = predict_on_sub(x_test, model, SPLIT_SIZE, BATCH_SIZE)\n",
    "        \n",
    "        test_data_total.append(y_test[:,i][1000::BATCH_SIZE])\n",
    "        prediction_total.append(predictions)\n",
    "        \n",
    "    multiple_metric_auc_score(prediction_total, test_data_total, True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HandStart AUC score = 0.658\n",
      "FirstDigitTouch AUC score = 0.807\n",
      "BothStartLoadPhase AUC score = 0.872\n",
      "LiftOff AUC score = 0.823\n",
      "Replace AUC score = 0.874\n",
      "BothReleased AUC score = 0.868\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAIABJREFUeJzsnXlcVWX+x98Pm4BgCCKouGAqroCKa+ZopZmVaZlL5tLMtI5lzVTjVGPmTyezRs2askbFLFeacTQ1M819SXFXXHBBRUVQUEB2eH5/HO7pcLkXLstlfd6v133JOec55zz3Cud7n+/y+QopJQqFQqFQADhU9gQUCoVCUXVQRkGhUCgUOsooKBQKhUJHGQWFQqFQ6CijoFAoFAodZRQUCoVCoaOMgkKhUCh0lFFQVHuEEDFCiHQhRKoQIk4IsVgI4WE2prcQ4hchRIoQ4o4Q4gchRHuzMfWEEHOFEJfzr3Uuf7uBlfsKIcRrQogTQoi7QohYIUSEEKKTPd+vQmFPlFFQ1BQel1J6AKFAZ+BvpgNCiF7AJmAN0BgIBI4Cu4UQLfPHuABbgA7AIKAe0Bu4BXS3cs9PgUnAa4A30Ab4H/BoSScvhHAq6TkKhV2QUqqXelXrFxADPGTYngWsN2zvBL6wcN6PwJL8n/8I3AA8bLxnayAX6F7EmG3AHw3bE4Bdhm0J/AmIBi4C84FPzK6xBvhz/s+Ngf8ACfnjXzOM6w5EAsn572N2Zf+/qFf1fKmVgqJGIYQIAB4BzuVvu6N944+wMHwVMCD/54eAjVLKVBtv9SAQK6XcX7YZMxToAbQHlgEjhRACQAhRHxgIrBBCOAA/oK1wmuTf/3UhxMP51/kU+FRKWQ+4N/+9KRQlRhkFRU3hf0KIFOAKEA+8n7/fG+33/LqFc64DpniBj5Ux1ijpeGt8KKVMlFKmo61oJHB//rHhwF4p5TWgG+ArpZwmpcySUl4A/g2Myh+bDbQSQjSQUqZKKfeVw9wUtRBlFBQ1haFSSk+gH9CW3x72SUAe0MjCOY2Am/k/37IyxholHW+NK6YfpJQSWAGMzt/1DLA0/+fmQGMhxG3TC3gH8Ms//ge0mMZpIcQBIcRj5TA3RS1EGQVFjUJKuR1YDHySv30X2As8bWH4CLTgMsBm4GEhRF0bb7UFCBBChBUx5i7gbtj2tzRls+3lwHAhRHM0t9J/8vdfAS5KKb0ML08p5WAAKWW0lHI00BD4CPi+BO9FodBRRkFRE5kLDBBChOZvTwbG56ePegoh6gshpgO9gA/yx3yL9uD9jxCirRDCQQjhI4R4Rwgx2PwGUspo4AtguRCinxDCRQjhKoQYJYSYnD/sCPCkEMJdCNEK7dt8kUgpD6MFkhcAP0kpb+cf2g8kCyH+KoRwE0I4CiE6CiG6AQghnhVC+Eop8wDTObkl+dAUClBGQVEDkVImAEuAv+dv7wIeBp5EiwNcQktb7ZP/cEdKmYkWbD4N/IyWxbMfzQ31q5VbvQZ8DvwL7UF8HhiGFhAGmANkoWUDfcNvrqDiWJ4/l2WG95QLPI6WcnsRze21ALgnf8gg4KQQIhUt6DxKSplh4/0UCh2huTEVCoVCoVArBYVCoVAYUEZBoVAoFDrKKCgUCoVCRxkFhUKhUOhUOxGuBg0ayBYtWlT2NBQKhaJacfDgwZtSSt/ixlU7o9CiRQsiIyMrexoKhUJRrRBCXLJlnHIfKRQKhUJHGQWFQqFQ6CijoFAoFAodZRQUCoVCoaOMgkKhUCh07GYUhBCLhBDxQogTVo4LIcS8/Obox4QQXew1F4VCoVDYhj1XCovRlBut8Qhan9vWwAvAl3aci0KhUChswG51ClLKHUKIFkUMeQKtaboE9gkhvIQQjaSU5dHiUKFQ1BIizkaw4cKGyp5GYVLi4G6C1cP1L7vhdd2NPCnxSJXUTSusWJ3jeA+5jp76tpOjExOXLrTLdE1UZkyhCYZWhEBs/r5CCCFeEEJECiEiExKsf8gKhaL2seHCBs4knqnsaRTmbgJk3bV62Ou6G67JTkgJddMkLtmFx+Q6eiIdXOw4ycJUZkWzsLDPYnMHKeXXwNcAYWFhqgGEQqEAtFVC5I1IwvzCCB8UXqJzj23eyKnd2ywfTImD1DJ+Ac3yABc/aNTJ4uGrd8+ThzOdopK5N/ka3sEdaf7tEk7uvMrZ/TcAuBmbSoMAD4b9peJCrpVpFGKBpobtAOBaJc1FoVDYQJEPUhtISEsgMSOxROfUvZOFe6qFr9FAbl4uL9IQV6d4vlk81LYL5mZBbjY3nesA0CA7s/CYvBztX4eyPCKdwVHC7dMF9mbn5pGdm4dznqRNfALNElNIaRtMfJenOPTPQ1yL1rqpNm7tRYMAD9p09yvDHEpOZRqFtcBEIcQKtAbld1Q8QaGoepgMQUJaApkx2jfYu/7OJb5O3TtZ1EnOwBtwdHC0+TzXdK3VdIZb4XMchQPOUuKck4XW+dQG8h/4DbKhWVYaLTPTrEzYF+r62zxPc26kZHIrubDBSc5/P/XcnKnfMBD/SU/RbuQIVv/zEDdjU2nc2os23f3ocL9Fb7rdsZtREEIsB/oBDYQQscD7gDOAlHI+sAEYDJwD0oDn7DUXhUJhGVuCtIE/3sY1MYcEj3Twhty2DUgKcivxvUZ9dpKGV9PIbdUUX7dixTp/ww3qPfYY9UeOKHws/FGIOw7+ll00lnGBTsMhzD6PHJP7J+p6MmmZObjXKfyYbeDhgounK1eBq7FAvkGoaFeRJapdj+awsDCpVFIVtRWjvxkgOT6S1FvHSn29tOw08mQeDsJ6zonISkK61Cc34CG83XxK9kAHchISyLl1i7y0NBzc3XFt29a2E4vJ3gG0QK5L3RIaBfticv9cc87DvY4T7RvVs/lce64QhBAHpZRhxY2rdtLZCkVNxPxhbw3TAyfFJw5x5xxOCfsByHNtWKr7mgyCu7O79UHO7nj4BFPP28aHeT66MUhJBsDBsx5OPj62X8CUveNS1/oYl7qam6cSiE/J4GZqYZdVsmMup1xycWt7D0+ENmFYj2aVMLvSo4yCQlEFOLv/BjdjU5E+6SSm37I6LqVeCtENDlI3OJvAH2/jBFzt7UFSUGlX/ILBLR/h6TZPl/J861waO46M06dxbdvWuvvHEpHhcPx7yMp3Cz23vtznVlaW/XqZD1cfByfoEehtdrQOo0Kb8Ew1MwYmlFFQKCoJ89RD6ZPOZ03fBCDMz/oq/+mWg3m6zdOs/HUyeMNfJs2skPmWBte2bWn+7ZKSnXT8+9/iBJ2G22diZWTNkasA/GNYp2r78LeGMgoKRQVjMgbmqYd76u4CYEqvKRa/uZuygPJ+PchKDpIQcxHfFoF2m2fSylUkr1tX6vNNq4QSERkOl3ZB8z5VaoWw7NfLuiEAiLqeTI9A7xpnEEAZBYWiVFjL2ql/Jh2vCxby3g243a6PQ64TeY455LhmcOtyOgCO2Wk87dyKvBjtoW9ObJSmLRnQviMAvi0CaXdfvzK+E+skr1tXugd7Pia3kc1EhsO617Wfq8AKwWgIfr2o1VaYXEXtG9XjidDKSRm1N8ooKBQ2YjQEkTe0DDhzN4/XhUxcE3PI8P7tT8s5ww2nDFd922QQ0r2SCpzr7uyOt6u5f/o3Atp3pN19/Qh+qCidydJjvjIwGYQSu39Ky/HvtX8fm2u3dNGiMF8NGA1Bj0BvnqjGcYKSoIyColZSGhG15AOnaXmtLp4ungTSCm9Xb3xjCma+JCSn4dsqiJHv/+bnX23IQTdRmcVJlkhauYq4998HwL1bN6CE3/RNweGyEHdccxtVgkEALU4QdT1ZTyGtTYbAiDIKilqJSUQtyDuo2LEml1DdOC2dMqC99XOsuXQqoiipLDGAtAMHAPD/4IPCWUK2PPAvafEQmvcp1f21m1dcYNl8VQDoBmHli70qZA5VFWUUFLUOW0XUTIFdoy/f3H1jqb7g/FE4f/SQvm2+SrAXNscALBSFuTd1pV57D+qnfQPh3xQcb8sDv3kfu1YJlxZLD38oHCOAmh0nKAnKKChqPOauIlM8YHDLwUWed2r3NhJiLhZpDIwZRNbwqpOOz4kdXBo7tyxvo1hsjgGEPwpxt2yvAq6iD3xLFBUXMFJbXUO2oIyCokZSVFA4zC+Mwfm5/uYYVUBNKZ/G+IAJU7GZUbzMmvvG5Joh31dvL0oUA6iiRWFlRcUFyo4yCooaiTFmYDICQZc99Qe+KdffHKOryDw+UJzOvTX3jXu3biWr6C0PiooDlFhArupiqX5AxQXKhjIKihpLkHcQ4YPCtW//y7fxs1mev5G7t7NIT8nC1bMFHj7BuHhoqwpjfMCSzr1xdVDmFM7yyOAxUVQcoApXCpeEZb9e5p3Vx4HaUT9QUSijoKgRmMcNjJlF5rGBzOOZnIsq2CYx3dEfnMA7Nw4SISOxYGMUAG+gSc4Fmh85q+04AnH5riH3bt1KXqxljlHeoaxUozhAaanJUhOViZLOVlQrwpfO4Mr+3/7/TV25cvO0xiXG5i3ODs44OzhzR+Zyj3Ckn7PmZ96V3ZtUjwDqieQC126Sc4HmOWdLPKdSib1ZIq7qCsBVBZSrqGwo6WxFtcf07d8oHVE3Lpu6/Nb5yz01G5fMPLLqOOpGACBTuJEu3EhHawae7dyCPS6tAEh198a7vuDpmc/Yb/LWHv61wK1TXhSXSaRcRfZBGQVFpWOt7++ZxDP4Zafhe0t70N/1dwY3Seu7kpBETwDO3W1CfEBvvM2Cu9eib+OA5VRRVyj/vrfmRsDaw78WuHVKiq21BCqTqGJQRkFR6Zh8/ibFT1Nz97TsNNyd3QloH0S7+/rR9FayLsVAtwYAxAf0JqVOQ1zNrlnhfW7N4wHq4W8z5mmkJpQRqByUUVBUKsc2byQ26gQB7Tsy8v2ZRJyN4Ku904CC9QQnd15l4+bt5IVOwqVFIE6+muZQamwqvhXV11bFA+yGig1UHZRRUFQKpnhBm9WZuAAxCe7MfHcZKdkpDGEizeu1wPemL5yE1RzS0kEd/fH2RDcIgJ4aajeMhkDFA2zCmjvIGpZWCYrKQxkFRaVgKi5rn9EWnD2Q92hBYE9nz0LN4XMSEvC6fRG/G5F0fWkg9UdWwKrAhNEtpFxCFrFVWsIaKmBctVBGQVHhhC+dQbNf7tA+py0OmXdw9WjEX2YUzAQyFoUVqeBZVoorGFNuoWJR0hI1C2UUFDZjLUuoJCSkJZAZc4N6gIOzMy4ejbi3632FxhklI+wqE1FcwZhyC1nFtEJQ9QI1C2UUFIBtD3zzdpDFYcoiMpKSlQLe0NztEZo06a8HiCu165daCZQYc4kJ5f6pOSijoAAKp4VaoiTtIE/uvMoPG7eT45qOu5Obvt8H8HbzQdzS9pmMQZpBLgJK0d9XYVesxQ2UxETNQxkFhY41mWhrGPWGGsS0xudKC/2Y5y1/PPEHnziCvC00fQnQCsiSv55LxunT5e8islVcrgYphtoTFTeoPSijUMOw1AmsKJLjI0m9dYystDiEqw8z311m87kp2Sk0pieezp543vLX9vnE6f/eahpD9wdaM6xNwWwh3VV0xE5uoshwWPe69nNx7SFVzMAqxtWBihvUHpRRqGHs3n6C9DhJ+j2JxQ8GHOP2IbKSkC71Sa/jQ2Z2Cp7OnjadWyB91NvUjP6BYs8zBpHLzU1kqZ7gsbkqfbQMGFcHKm209qCMQjXHfGWQHie5VfcqV+7fZdP5gT9qPQIuPiKB6wxu2dliR7LyptxXB6qeoNxQWUW1G2UUqiFGQ2Bs/JKQnkC8+yWyAm8V2ZDeyMpfJwMwZZDtsYSSYi2zqMwYVweqnqDcMBoEtTqofSijUA0x9QduEOChC79F+e3hs3zNoCm9phR7DVMKanEZR+WBeZtKm1xGtgSKjbITKjZQLiz79TK/XkykR6C3WiHUUuxqFIQQg4BPAUdggZRyptnxZsA3gFf+mMlSyg2FLqQohKk/cMTZCD658BmRe7XGM1N6TbHq/jHWIhhrDox9iO2FTe4iW3WGTCg3UbljCiyrFULtxW5GQQjhCPwLGADEAgeEEGullFGGYe8Bq6SUXwoh2gMbgBb2mlN1xlLTePhNQ8ioKGoN48qgJDUHFYaKC1QJegR6q1TTWow9VwrdgXNSygsAQogVwBOA0ShIwCSPeA9wzY7zqdYYXUYmZdCIsxFE3ogkzC/M5hhCSWsRyoIpllBsDMG0QlBxgUrF6DpS1F7saRSaAFcM27FAD7MxU4FNQohXgbrAQ5YuJIR4AXgBoFmz2vUNxrRCMBkEkyxExNkIpuXHEAa3HFzsdYx9CyqCpJWr9IY4psK0QpiMgdFVpOIClYJRtkK5jmo39jQKwsI+abY9GlgspfynEKIX8K0QoqOUMq/ASVJ+DXwNEBYWZn6NGonJGBizi0x9A4wGoagYghFTLKEi4geAnm1UpLKpaXWgXEUVQlF9DpRshcKEPY1CLNDUsB1AYffQH4BBAFLKvUIIV6ABEG/HeVULTKsDY1vJiLMRfLJxA5E3ig8qmzBmGQW071ihMQT3bt2sG4TIcG2F0LyPchdVENbaXoKSrVD8hj2NwgGgtRAiELgKjAKeMRtzGXgQWCyEaIfWUz3BjnOq8lhzF0HJgsqgGYSf//05UHFZRqC5jtIOHNDF7Syml5pcRspdVKGoYjRFcdjNKEgpc4QQE4Gf0NJNF0kpTwohpgGRUsq1wF+Afwsh3kBzLU2QUtYK95ARa8VoltpMBnkH2RRUNhqEAc9PLPMKwbwAzSIpcXA3gbQrGQDU874I4Y9aTi9VLqMKwZJ+kUJRFHatU8ivOdhgtm+K4ecooHCHlVqCpbiB0V1UFkwxhPIwCFC4AM0idxMg6y7uTetSr70H9UPzH0DKAFQ4JmNgbI2pKpQVtqAqmisRS3EDaxjTT22lvGIIRneQxQI0PaX0lkoprSKY4gcqVqAoKcooVBInd17lWvRtGrf2KhA3sIapb4G19FPzzmllla+w1CPZalqpUaZaxQgqHSVVoSgLyihUEqYYgqW4gTnGVYIxuGxNtgK0IrWyBJZt6pFsNAhKprrSsNYVTbmKFKVBGYVKpHFrr2JdRhsu/JaCar5KKE/ZilL1SDZlFCmDUGmY90o2/atcRorSooxCJWB0HRVFUSmoxgrlsshWlLpHsrHOQBmESsO0QlBFZ4ryQhmFCsQ828gW15GlFFRjumlZaw9MbqIS9Ug2uo1UDKFSMDbCUQJ2ivJEGYUKpKzZRqYYgil+UF7ppqWWtVZuowrFGDswppqq2IGiPFFGoQIoqkrZEtbE7oxyFRUue61krSsEW/SJegR6q7iBwm4oo2AnSlKlbMRc7C7osicrl2stM01B5YqSvlbtLisepU+kqGxsMgpCCBegmZTynJ3nU2Ow1DLTlirlDRc20OayB/1T25MXc5CfDammZU0zLRHm9Qeq3WW5Y2lVYDIIqr5AUVkUaxSEEI8CswEXIFAIEQq8L6UcZu/JVXdscRVZIuSmPySnQgtfu7qKCgnXGVHppuWKJQNgdAeZUFIUisrGlpXCNLTmOFsBpJRHhBCt7Dqrao6tKafmHNu8kcAfb+OamINvqyC7uYnM01ALpJ4au6CpdNNywVItgeln5Q5SVDVsMQrZUsrbQhTomVPrlExtoTQppyZMaaZ1gbv+znZ1E1lMQ1Vd0OyGqiVQVCdsMQqnhBAjAIf83giTgH32nVb1pCQppybM00z3dLzFqJF/JriNfdxFRvkKPQ3Vkn6RWiGUCmtxAlVLoKgu2GIUJgJTgDzgv2j9Ef5mz0lVR0oqcGfCmGb6q1cM9YJ8bWqvWRqMBqGAy0jFD8oFa24iFSdQVCdsMQoPSyn/CvzVtEMI8SSagVDkUxKBOxMRZyM4k3gG6sHBHjc4k3iZIILsMj+r8tdKrqLcUG4iRU3AFqPwHoUNwLsW9tV6ihO4M2ESuks+cJrecT7c9XcGNEkLa9LYZcUkdqevEMxjCCp+UCrMO5spN5GiumPVKAghHgYGAU2EELMNh+qhuZIUJcQUPziTeAa/7DQ63vIBYOjjL9q/OjklDvemrtRP+wbCvykcUFarBJuxJjeh3ESKmkBRK4V44ASQAZw07E8BJttzUtUJcwmLojDFD6gH7s7uBLQPqji5ivxWmTrKGJQaY9WxSitV1DSsGgUp5WHgsBBiqZQyowLnVK0wGoSi4gkmqes6LfyIaL+fML8wpgyqILkKEy51lUxFOaGqjhU1FVtiCk2EEDOA9oCraaeUso3dZlXNKK5y2Sh1vdUjCrDeVtMeJM2aRNqVDNybuhY/WGER89iBJW0ihaImYItRWAxMBz4BHgGeQ8UUANsql40G4WpvD856XWJKryl2SzsFCgjZJR1JJu6nmwDUG9DXfves4RhdRip2oKjJ2GIU3KWUPwkhPpFSngfeE0LstPfEqgO2pKGaeigPeH4ic3JWEkaYXQ1C0spVJC+Yp8UPXOqSdkXz/Pn/fiD13/7UbvetSSihOkVtxhajkCk0jYvzQoiXgKtAQ/tOq/pQVBqqsWXmmWYpRO4t2DTHHiSvW0dGfBauDeuCfyfc/bG9o5oCsCxfrVYHitqCLUbhDcADeA2YAdwD/N6ek6oOFOU6MpeuaHdfP+ZcWAmUbyzBJFtBSpyWXQSaQfDKpvkzLeC5YrqpKQpgbHGpVgWK2kqxRkFK+Wv+jynAWAAhRIA9J1XVObnzKtuWngEsu47MO6QZVwlldh0Z4gXJy65pRqBeunbM9R5cG7pQr723KkYrIeYSFWpVoKitFGkUhBDdgCbALinlTSFEBzS5iweAWmsYTLGEfmOCrLqOjB3S5mzUagHKZZVgbIsJuDZ00VYFqubAZorqbaAkKhS1HQdrB4QQHwJLgTHARiHEu2g9FY4CtT4d1VoswRRHMBFxNoLIG+W4Sri0C/w7keQ+Xgsim1pkKoNgMyYXkZEegd7KICgUFL1SeAIIkVKmCyG8gWv522cqZmpVk+LSUE3ZRu3u61eg33K5rRKApIRWxC16HzBrkKMALK8EjKiYgUJhnaKMQoaUMh1ASpkohDhd2w0C2JaGaso2MhmEcq1LaN6H5F+SAPD/4AOVVZSPNT0iS6hMIoXCOkUZhZZCCJMSqgBaGLaRUj5Z3MWFEIOATwFHYIGUspCuQ34Dn6lo3dyOSimfsX36lYMtaqgbLmwAytEgGCWuAfdu3Wq9QbBmCJQekUJReooyCk+ZbX9ekgsLIRyBfwEDgFjggBBirZQyyjCmNVrDnvuklElCiCpd/1DS3svlEkcwYXAdpR3YhHu3buVz3WqMEqZTKMqfogTxtpTx2t2Bc1LKCwBCiBVocYoow5jngX9JKZPy7xlfxnvaleJcR0bRO1NwucyYUlDjjpOUFEzcik2AiiUs+/Uyv15MpEegt4oNKBTliNXso3KgCXDFsB2bv89IG6CNEGK3EGJfvrupEEKIF4QQkUKIyISEBDtN1zaKch2ZgswXGmsS1eWdgpp8yQ1QsQRjTYGKDSgU5Ys9jYKwsE+abTsBrYF+wGhggRCikG9GSvm1lDJMShnm6+tb7hO1BZPrqDjqtPDjZ6+T5ZaCmrTlEJd+8eHSLz5kXL1d62MJRoOgUkgVivLHFpkLAIQQdaSUmSW4dizQ1LAdgJbWaj5mn5QyG7gohDiDZiQOlOA+dqe4CmYjiRlawLNMq4R8l1HSlkPERXoBGbj7g2vbtrXebaT6ICsU9qVYoyCE6A4sRNM8aiaECAH+KKV8tZhTDwCthRCBaCJ6owDzzKL/oa0QFgshGqC5ky6U7C3YH1sqmAES0hJIyUop+yoh32WUfMMfyKj17iITxjiCMggKhX2wZaUwD3gM7QGOlPKoEKJ/cSdJKXOEEBOBn9BSUhdJKU8KIaYBkVLKtfnHBgohooBc4C0p5a1Svhe7YksaarmsEvJJimtO2pWbtcpdVFzRmSntVMURFAr7YYtRcJBSXtLUs3Vybbm4lHIDsMFs3xTDzxL4c/6r2hJxNoINFzbgl52Gp4tn2VYJ+fUIyVEtgdqVZWRJstqISjtVKOyPLUbhSr4LSebXHrwKnLXvtKoXe3/8D35nkvBOccG9seUqWps5/j1J59y19pm1bJWgUkwVisrHFqPwMpoLqRlwA9icv0+Rj9eFTFxTXGjeqgPt7utXspMNUthAgVhCbVklqBRThaLqYItRyJFSjrL7TKo5Gd5OulR2SUj6dhHJR26AS938PT5k3JK1ZpWgUkwViqqFLUbhQH6q6Ergv1LKFDvPqVoRvnQGdeOyuevvXLIT81cIyUdukHHbGdfgTvohV//aE0tQKaYKRdXCls5r9woheqOllH4ghDgCrJBSrrD77KoAxekdXdkfSV2gafdiJC3M3USXdmn/urTENdCX5t/WrtaZxtaXKsVUoag62FS8JqXcA+wRQkwF5qI136kVRsEWqey7/s78Zcy7RV/IrGMazfto3dLOby2vqVZ5rKmaqjiCQlF1sKV4zQNNyG4U0A5YA/S287yqFLbUKNiEqUsakLRyFcmfriPj9Glc27Yt+7WrIOZ1B0reWqGo+tiyUjgB/ADMklLutPN8qhTFuY4izkaQkpWCp4tn0Rcy64WQtHIVce9rndPcu3WrsfED87oDZQgUiqqPLUahpZQyz+4zqYIU5zracGEDDQBv12JqE0yxhE7DAUhetw6omWqnxtWBanupUFQ/rBoFIcQ/pZR/Af4jhDBXN7Wp81pNoDjXkaeLJ77uNii3Nu8DYc/pmzU15dS4OlBtLxWK6kdRK4WV+f+WqONabSF86Qwa7LqCa6obWFsoGBrk4N9JiyOsq3lxBLU6UChqDlb7KUgp9+f/2E5KucX4Qgs412iK6p9wbPNGEtfuxT/RFffGDS1XMUeGw7rXtViCfyfoNLyAQahJcQTT6gBQqwOFoppjS0zh9xReLfzBwr4aRVHxhB0/RwBwtbcHsycttHwBUxzhsbkkna9bINOoutYkWFMxVasDhaLmUFRMYSRaGmqgEOK/hkOeQPEtyGoA1uIJiRmJpHhn0OuR8VbPTTqSrCmdnt9K2gGtZ1B1zDSyVltgRK0OFIqaQ1Erhf3ALbTCq0ujAAAgAElEQVSOaf8y7E8BDttzUlWVY5s3suPnCJxvZuLZwLpEdtLKVcT9dBMAd//fjEFVDyxbWgmo2gKFonZh1ShIKS8CF9FUUWs9EWcjOPXDMpxvZpJYL4v23e+zOjZ5+QIA/B9uQP1Pq4+ryFI/A2UIFIraRVHuo+1Syt8JIZIAY0qqQOuPU8bGAdWLvT/+hyZx2dz1r0P3Pz1nfZUwaxJpp6/g7ptJ/bG/r+BZlh7Vz0ChUEDR7iNTy80GFTGRqo7XhUwAhj7+IsFtBlkdl/zzDgDqPf54gbqEqorJZaRaXSoUCijafWSqYm4KXJNSZgkh+gDBwHdAcgXMr9I5tnkjp3ZvwzUxh7v+zgQ/ZN0gEBkOGXdwb3oP9d/+tOImWQrMjYFyEykUCrAtJfV/QDchxL3AEmA9sAyoXmk0peTU7m1cvXCGBI90clsWsWiKDCdp7jukJXjh3taGCudKxihbrYyBQqEwYbV4zUCelDIbeBKYK6V8FajRPgbzwrVUL9jY8wa9HnnK+knHvyf5khsA9Ub/0d5TLBdMtQXKICgUChO2GIUcIcTTwFhgXf6+ErYZq16YCtfc3M8QG3UCgDC/MKvBZR3Xe6qFppEpqKxQKBTm2GIUfo8WdJ4lpbwghAgEltt3WpVP49Ze3Ik/CsDtlnUqeTbli6kWQQWVFQqFOba04zwhhHgNaCWEaAuck1LOsP/UKpfk+EhuxpygTgs/fvbaTxiW222aRO6Iu0ZGfBau/hU8UQtYk6MwoVpgKhQKa9jSee1+4FvgKlqNgr8QYqyUcre9J1eZpN46BsBWjygABrccXGhMgWY5TV1xbehSqTIWljKKLKFkKRQKhTVsyT6aAwyWUkYBCCHaoRmJYjrVV3/u+jtztlkqU3pNsRhP0JvlPNyA+v6XNDXUSognVOf00uzsbGJjY8nIyKjsqSgUNQJXV1cCAgJwdi5d6NcWo+BiMggAUspTQgiXUt2tGlJkgDklTqtcrn8M/PvondUqmuqcXhobG4unpyctWrRACFHZ01EoqjVSSm7dukVsbCyBgYGluoYtRuGQEOIrtNUBwBhqsCCeKR01LTuNtOw0wHJ/ZiLD4dY57efH5lZa9XJ1l6fIyMhQBkGhKCeEEPj4+JCQkFDqa9hiFF4CXgPeRosp7AA+K/Udqzi7t58AnEl1uo27s7vFWALwW78En1aVahDeWX0cqN6ZRMogKBTlR1n/noo0CkKITsC9wGop5awy3amakJh+i5R6KTQS9fF19y3kOiqQbZTshmuLyks3MmUY/WNYp2rlMlIoFFUXq3UKQoh30CQuxgA/CyGqj+RnKTm58ypu1+LxuvErxKdaHGNqqQlUerYRoFJLywEPD48C24sXL2bixInlcu2pU6fyySefALBv3z569OhBaGgo7dq1Y+rUqQBs27aNPXv2lPjaR44cYcOGDVaPHz58mD/+sWpX13/44Ye0atWKoKAgfvrpJ4tjpJS8++67tGnThnbt2jFv3jxA+9zuueceQkNDCQ0NZdq0afo5c+bMoUOHDnTs2JHRo0friQyjRo0iOjra/m+sGlPUSmEMECylvCuE8AU2AItKcnEhxCDgU8ARWCClnGll3HAgAugmpYwsyT3Kk7P7b5CbdRq4hW+bdoV6LyetXEXagQO4d+tG8wduaTurePWyouowfvx4Vq1aRUhICLm5uZw5cwbQHm4eHh707t3b5mvl5ORw5MgRIiMjGTzYsovzH//4B++9916JrunkZItHuXyIiopixYoVnDx5kmvXrvHQQw9x9uxZHB0dC4xbvHgxV65c4fTp0zg4OBAfH68fu//++1m3bl2B8VevXmXevHlERUXh5ubGiBEjWLFiBRMmTODll19m1qxZ/Pvf/66Q91gdKeo3IFNKeRdASpkghLCl+llHCOGI1rFtABALHBBCrDVmMuWP80SLWfxaopnbiVynLNK9HBj5fmH7ZUpBrffYY5D2TUVPTceUgmreEKe688EPJ4m6Vr7iu+0b1+P9xzuU+vwffviB6dOnk5WVhY+PD0uXLsXPz4+pU6dy+fJlLly4wOXLl3n99dd57bXXAJgxYwZLliyhadOm+Pr60rVrVwDi4+Np1KgRAI6OjrRv356YmBjmz5+Po6Mj3333HZ999hm3b9+2es9r164RExNDgwYN2LVrF+np6ezatYu//e1vjBw5Up93SkoKx44dIyQkBID9+/fz+uuvk56ejpubG+Hh4QQFBbF48WLWr19PRkYGd+/e5ZdffuHjjz9m1apVZGZmMmzYMD744AMAhg4dypUrV8jIyGDSpEm88MILpf5cAdasWcOoUaOoU6cOgYGBtGrViv3799OrV8GEiS+//JJly5bh4KA9gho2bFjstXNyckhPT8fZ2Zm0tDQaN24MaEZkwoQJFW4AqxNFfSotDb2ZBXCvsVezlPLJYq7dHa36+QKAEGIF8AQQZTbu/4BZwJslmXh5Yy6CZ46+SmjqSv20byDuuFaXUMEYg8umFFRF2UhPTyc0NFTfTkxMZMiQIQD06dOHffv2IYRgwYIFzJo1i3/+858AnD59mq1bt5KSkkJQUBAvv/wyx44dY8WKFRw+fJicnBy6dOmiG4U33niDoKAg+vXrx6BBgxg/fjwtWrTgpZdewsPDgzff1P4EkpKSrN7z4MGD7Nq1Czc3NxYvXkxkZCSff/55ofcUGRlJx44d9e22bduyY8cOnJyc2Lx5M++88w7/+c9/ANi7dy/Hjh3D29ubTZs2ER0dzf79+5FSMmTIEHbs2EHfvn1ZtGgR3t7epKen061bN5566il8fHwK3PeNN95g69atheYzatQoJk+eXGDf1atX6dmzp74dEBDA1auFK/HPnz/PypUrWb16Nb6+vsybN4/WrVvrcw8JCaFx48Z88skndOjQgSZNmvDmm2/SrFkz3NzcGDhwIAMHDgTAwcGBVq1acfToUf3/RVGQooyCuSRo4d+8omkCXDFsxwI9jAOEEJ2BplLKdUIIq0ZBCPEC8AJAs2b28Z+f3X+DnMxjOGTEY673Z6xcrucXBzTWDEIl1CXU5OByWb7RlwU3NzeOHDmib5setqDVUYwcOZLr16+TlZVVIPf70UcfpU6dOtSpU4eGDRty48YNdu7cybBhw3B3dwfQjQvAlClTGDNmDJs2bWLZsmUsX76cbdu2FZpPUfccMmQIbm5uxb6n69ev4+v7m4T7nTt3GD9+PNHR0QghyM7O1o8NGDAAb2+t+n3Tpk1s2rSJzp07A5Camkp0dDR9+/Zl3rx5rF69GoArV64QHR1dyCjMmTOn2LmZkFIW2mcpcyYzMxNXV1ciIyP573//y+9//3t27txJly5duHTpEh4eHmzYsIGhQ4cSHR1NUlISa9as4eLFi3h5efH000/z3Xff8eyzzwLaSuPatWvKKFihqCY7W8p4bUt5UfpvQb47ag4wobgLSSm/Br4GCAsLK/ybVE5IcQooLICnVy6H3ab+6/+o0BRUcx0jpVtUsbz66qv8+c9/ZsiQIWzbtk0PDgPUqfPb74mjoyM5OTlA0SmB9957Ly+//DLPP/88vr6+3Lp1q0T3rFu3rk3zdnNzK1Al/ve//53+/fuzevVqYmJi6Nevn8VrSin529/+xosvvljgetu2bWPz5s3s3bsXd3d3+vXrZ7EKvSQrhYCAAK5c+e17Y2xsrO7mMR/31FPad9Rhw4bx3HPa31+9er+5TgcPHswrr7zCzZs32bp1K4GBgbpRfPLJJ9mzZ49uFDIyMmwyrLWVEsUJSkgsWtc2EwHANcO2J9AR2CaEiAF6AmuFEJUmn5Gdm02cd0bBvgmR4RB3HHe/XOo/2KXCaxJMsQMTSreoYrlz5w5Nmmif9zffFB9H6tu3L6tXryY9PZ2UlBR++OEH/dj69ev1b8fR0dE4Ojri5eWFp6cnKSkpJb6n+XlG2rVrx7lz5yxec/HixVav+fDDD7No0SJSU7Xsu6tXrxIfH8+dO3eoX78+7u7unD59mn379lk8f86cORw5cqTQy9wggLbqWbFiBZmZmVy8eJHo6Gi6d+9eaNzQoUP55ZdfANi+fTtt2rQBIC4uTv889+/fT15eHj4+PjRr1ox9+/aRlpaGlJItW7bQrl07/Xpnz56lQ4fKWZVWB+wZaTkAtM6X2r4KjAKeMR2UUt7B0P9ZCLENeLMys48APF08f6tNiAyHda9Dhg+43lOh7iLzYHJ1rFauCUydOpWnn36aJk2a0LNnTy5evFjk+C5dujBy5EhCQ0Np3rw5999/v37s22+/5Y033sDd3R0nJyeWLl2Ko6Mjjz/+OMOHD2fNmjV89tlnNt+zf//+zJw5k9DQ0EKB5rZt23Lnzh1SUlLw9PTk7bffZvz48cyePZsHHnjA6vwHDhzIqVOn9GCvh4cH3333HYMGDWL+/PkEBwcTFBRUIBZQWjp06MCIESNo3749Tk5O/Otf/9IzjwYPHsyCBQto3LgxkydPZsyYMcyZMwcPDw8WLFgAwPfff8+XX36Jk5MTbm5urFixAiEEPXr0YPjw4XTp0gUnJyc6d+6sB8Vv3LiBm5ubHvBXFEZY8utZHChEHSllZokuLsRgYC5aSuoiKeUMIcQ0IFJKudZs7DZsMAphYWHS5O8tL07uvMq2pWdIS/+OdK8kpnyq+U0Jf5SkLYeIi/TS0lC/XVKu9y2KkV/t1Q1CddMzKgmnTp0q8C1OUX7MmTMHT0/PKl+rUJHMmTOHevXq8Yc//KGyp2JXLP1dCSEOSimL9cTYIp3dHVgI3AM0E0KEAH/Mb8tZJFLKDWj1DcZ9U6yM7Vfc9eyFqdNajmthH2nyDX8go0KL1Kq7npGiavDyyy8TERFR2dOoUnh5eTF27NjKnkaVxpaYwjzgMeAWgJTyKFonthqFc0A2iQ75RTGR4RD+qJZ2ChXeYlN1RlOUB66uruoBaMZzzz2n6hOKwZZPx0FKecksoyLXTvOpNJLifsU/0ZU6/k6w7nWSzrmTfMOfjFuyUrqpqQwjhUJRGdhiFK7ku5BkfpXyq8BZ+06r4nFIiQGgr08a5EFyaicybt/GtUPbCnMd1dRKZYVCUX2wxSi8jOZCagbcADbn76tx3PV3JrhpFklHgkk7faXCg8tGg6BcRwqFojIo1ihIKePR0klrLAnpCeTKXMjJ0rONgEpRQFXppwqFojIpNtAshPi3EOJr81dFTK6iSEzXqkq9c3NJvqRVOvp/8EGFBpcVlYejo6MuvxwaGkpMTAyRkZG6wJ0t3L59my+++ELfjomJwc3Njc6dO9OuXTu6d+9eoBBt7dq1zJxpUTRY59q1awwfrtXGGGWyw8PD9bm6uLjQqVMnQkNDLRaIlZZnn32W//3vf8WOu3v3Lv369SMvL6/c7l3ebNiwgaCgIFq1asXHH39scUxMTAy/+93v6Ny5MyEhIWzcuFE/Nn36dFq1akXbtm3ZvHkzoCm8Gn9nPD09dQ2q119/nR07dtj/jdkLKWWRL2Ck4TUercfCZ8WdZ69X165dZXmy6swq+c5b8+Wscc/JFS8OljEPhcqYZ8eW6z0ssXTfJTli/p4Cr47vb5Qj5u+x+72rElFRUZU9BVm3bl2bx2ZnZ1vcf/HiRdmhQwer2+fPn5chISFy0aJFpZpjeHi4/NOf/lRof/PmzWVCQkKprlkUY8aMkatXry523Ny5c+Xnn39u83Xz8vJkbm5uWaZWIrKysmRgYKCMiYmRGRkZsmPHjvLMmTOFxj333HPy66+/llJKefToUXnvvffqP3fu3FlmZmbKc+fOyVatWhWaf3Z2tvT19ZVXrlyRUkp57tw5OWjQIDu/s6Kx9HeFVh9W7DO22JWClHKl4fUN8CTQ3n5mqmLZcEH79uXs6ExOai5pVwrXKtgDc/kKUBIW/DhZSwUuz9ePpfv2vG3bNh7Ldx9OnTqVF154gYEDBzJu3DhOnjxJ9+7dCQ0NJTg4mOjoaCZPnsz58+cJDQ3lrbfeKnS9li1bMnv2bL1BjLGRz/nz5+nZsyfdunVjypQpetOfmJgYOnbsSFZWFlOmTGHlypWEhoaycuVKq/O+efMmQ4YMITg4mN69e3PixAkA3nvvPebOnauPa9u2LbGxsYC28ggODiYkJETXFQLYunUrvXv3pmXLlroQnjlLly7liSeeACA5OZkHHniALl26EBwcrPc5OHfuHB07duSll16iS5cuXL9+nR9//JFevXrpFeB3794F4P3336dbt276eGljca019u3bR7t27WjevDl16tRhxIgRrFmzptA4IQTJydrf4507d3QNpjVr1jB69GhcXFy49957adasGQcPHixw7qZNm2jXrh0BAQGApm91/fr1MvVJrkxKk7AbCDQv74lUFg1iWtM4uTXIg+SkagXb9o4lqOK0qoVROjswMNDiA9AoWf3qq68yadIkxowZQ1ZWFrm5ucycOZMTJ07oaqsxMTGFrtGlSxdO53ftMzJp0iQmTZrE6NGjmT9/fqHjLi4uTJs2zapMtpG///3v9OjRg7Vr17Jp0yYmTJhAUQoAR48e5aOPPmLPnj14e3uTmJioH4uPj2f37t0cP36cESNGMGzYsALnZmRkEBsbqz8M3dzcWLNmDZ6ensTHx3PffffphjUqKorw8HDmz59PfHw8M2fOZMuWLbi7uzNjxgw+/fRT3nnnHSZNmsQHH3yAlJJnnnmGjRs38sgjjxS475IlS5g9e3ah9xIUFFTIYF69epWmTX+TYAsICODo0aOFzp02bRoDBw5kzpw5pKWlsWXLFv18o3igSd67W7du+r4VK1YwevToAtfr3Lkze/bs0Q1mdcKWiuYkflM3dQASgfJzXlYyPldaAODmoPVScG/b1O6xBFWcZoVHivax2wtz6WxLGCWre/XqxYwZM4iNjeXJJ5/Utf2Lw9q33r179+r++2eeeUbvq1Aadu3axfr16wFNx2jChAn6t3BL/PLLL4wcOVKXzjb9C5oQnRCC4OBgi30O4uPjC4yXUvLXv/6VXbt24eDgwJUrV7h58yagfXs2PUj37NlDVFSU3mkuKyuLPn36ALBlyxY+/vhjMjIyuHnzJl27di1kFMaNG8e4ceNs+jwsfeaWVGyXLl3KCy+8wKRJk9i1axdjx47l+PHjxZ6fkZHB+vXrCxkpkzx3daRIoyC0dx+CJmgHkCfLup6rgqT4xOF1KZmsbAfwtm+lmnGVoIrTqg9GeelnnnmGHj16sH79eh5++GEWLFhAy5Yti73G4cOH7a7zZP7nadp2cnIqEAw2yV5LKa1KfRulwS392ZvLcy9ZsoQ7d+5w6NAhnJycCAgI0I+by3MPGjSIb7/9tsD10tLSmDhxIocOHaJJkya89957FuW5S7JSsFWee+HChXpviz59+pCcnExSUlKx569fv54ePXrQoEGDAterzvLcRcYU8g3Aaillbv6rRhmEkzuv4nlLMwI5aVqRtj1dR8auaWqVUH25cOECLVu25LXXXmPIkCEcO3asSBlr0NxJb775Jq++WlgyrGfPnnoXtBUrVlg8v7jrm+jbty9Lly4FYPPmzQQEBFC3bl1atGih+8L379+vP+geeughVqxYobuNjO6j4vD19SUjI4OsrCxA88U3bNgQJycnfv75Z4urC4DevXuzfft2Lly4AGgZTNHR0aSnp+Pg4ECDBg1ISUnRPxNzxo0bZ1Ge21KspWfPnkRFRXHp0iUyMzNZtWpVgcZHJpo1a6a7jE6ePEleXh7e3t4MGTKE5cuXk5WVxfnz57l06VKB5jzLly8v5DoCTZ7b2PmuOmGL9tF+IUQXu8+kEti9XQvC3WoaA4BDHQe7uY6MBqEmdk2rTaxcuZKOHTsSGhrK6dOnGTduHD4+Ptx333107NhRDzSfP39eT0kdMWIEr776aoFArom5c+cye/ZsunfvzvXr17nnnnsKjenfv7+eBllUoHnatGns2bOH4OBgpkyZQnh4OABPP/00N27coHPnzixcuFBf2QQHB/P222/Tt29fq0HyonjwwQfZs2cPAGPHjmXPnj2EhYURERFh1a3m5+fHwoULGTlyJCEhIfTu3ZuzZ8/i4+PD+PHj6dixI8OGDaNHjx4Wzy8Jzs7OzJs3jwEDBtC+fXueffZZgoKCAHj33Xf1NN85c+bwxRdfEBISwrPPPqv3nAgJCWHo0KG0a9eOwYMH88UXX+i9olNTU9m6dStDhw4tcM/MzExiYmL07nXVDavS2UIIJylljhDiONAOOA/cReuoJqWUlWIoylM6e+a7y0jJTqFVyE0S1+6lQXYm4//7c7lc25yRX+3l14uJyiCYoaSzNbeJm5sbQghWrFjB8uXLLWbIVEUOHDjAF198oRsfBURERBAVFcX7+S18KwN7SWfvB7oAQ4sYU+3xdPbEZc9+AJplpdn1XiqOoLDEwYMHmThxIlJKvLy8WLRoUWVPyWa6detGnz59yMvL079B13aklLzxxhuVPY1SU5RREABSyvMVNJdKI+fWLbxT0wltVX6/1JZ6KyuRO4Ul7r//fotpktWFmt6wpqSMGFG9lRCKMgq+Qog/WzsopSwc/q+u5Gbh4JxH/dDye2ibq53W+sI0hUJRLSjKKDgCHuSvGGoapsyjVKdd3HRw0JpFl3MPZiVup1AoqhtFGYXrUsppFTaTCsbUgtMpWctAapaTBWGFM0NKg7EWQaFQKKoTxcYUajIpPnHcc/M2rum55RpPUBXLCoWiulLUk/DBCptFJeNQx6Fc4gnLfr3MyK/2EnU9WWUaVSNM0tkhISF06dJFz7u3RkxMDMuWLdO3jeJ25ixatIhOnToRHBxMx44d9VTTxYsXl0oG4X//+x9RUVH69oQJE/j+++9LfJ2imDp1Kp988ol+/cDAQEJDQ+nSpQt79+4FoF+/fkVqKpU3VV2OOjExkQEDBtC6dWsGDBhAUlKSxXFvv/02HTp0oF27drz22mtIKUlJSSkgw92gQQNef/11AGbPnk379u0JDg7mwQcf5NKlSwAkJCQwaNAgu7wXq0ZBSml7aaMCUJ3Tqism7aOjR4/y4Ycf8re//a3I8eZGwRqxsbHMmDGDXbt2cezYMfbt20dwcDBQOqOQk5NTyChUBB9//DFHjhxh5syZvPjiixV6b9AeuPv27aNv3742n5OTk2PHGRVm5syZPPjgg0RHR/Pggw9a7JWxZ88edu/ezbFjxzhx4gQHDhxg+/bteHp6FqjMbt68OU8++SSgCetFRkZy7Ngxhg8fzttvvw1o1eSNGjVi9+7d5f5eSqOSqsjHWtqpCi6Xjo/2f8TpxMIqomWhrXdb/tr9rzaPT05Opn79+oCWb/7222/z448/IoTgvffeY+TIkUyePJlTp04RGhrK+PHjqV+/PteuXWPQoEGcP3+eYcOGMWvWLOLj4/H09NSlsD08PPDw8OD7778nMjKSMWPG4Obmxt69e/n444/54YcfSE9Pp3fv3nz11VcIIejXrx+9e/dm9+7dDBw4kLVr17J9+3amT59uVQbC2rxTU1N54oknSEpKIjs7m+nTp+sqnjNmzGDJkiU0bdoUX1/fAlIOJvr27cu5c+f07YiICF555RVu377NwoULuf/++4mJiWHs2LG6CN/nn39O7969uX79OiNHjiQ5OZmcnBy+/PJL7r//fjZt2sT7779PZmYm9957L+Hh4frnZeL7778v8K142rRpxX5WQ4YMYdy4cbz00ktcvnwZ0CrH77vvPvbv38/rr79Oeno6bm5uhIeH61XOpWXNmjW6dtL48ePp168fH330UYExQghdFkRKSXZ2Nn5+fgXGREdHEx8fz/333w9olewmevbsyXfffadvDx06lKVLl3LfffeVae7m1FqjkJCeQFbiCdIcXXDPuQu4lPgaKu20ZmCSzs7IyOD69ev88ssvAPz3v//VVxA3b96kW7du9O3bl5kzZ/LJJ5/o/QIWL17MkSNHOHz4MHXq1CEoKIhXX32VkJAQ/Pz8CAwM5MEHH+TJJ5/k8ccfZ/jw4Xz++ed88sknhIVpBaYTJ05kypQpgCYXsW7dOh5//HFA6+q2fft2QHtoPPbYY3pHNktYm7evry+rV6+mXr163Lx5k549ezJkyBAOHTrEihUrOHz4MDk5OXTp0sWiUfjhhx/o1KmTvp2Tk8P+/fvZsGEDH3zwAZs3b6Zhw4b8/PPPuLq6Eh0dzejRo4mMjGTZsmU8/PDDvPvuu+Tm5pKWlsbNmzeZPn06mzdvpm7dunz00UfMnj1b/xxM7N69u8D7tfWzeuaZZ3jjjTfo06cPly9f5uGHH+bUqVO0bduWHTt24OTkxObNm3nnnXcKGdiUlBT9wWzOsmXLaN++YEuZGzdu0KhRIwAaNWpEfHx8ofN69epF//79adSoEVJKJk6cWKjqePny5YwcOdKiSOHChQsLKMaGhYXx3nvvWZxjWai1RiEx/RYud7Vv+c3S70An26R4zVErg/KjJN/oyxOjdPbevXsZN24cJ06cYNeuXYwePRpHR0f8/Pz43e9+x4EDB6hXr3D86cEHH9Q1i9q3b8+lS5do2rQpGzdu5MCBA2zZsoU33niDgwcPMnXq1ELnb926lVmzZpGWlkZiYiIdOnTQH3QjR44s0fuxNu9HHnmEd955hx07duDg4MDVq1e5ceMGO3fuZNiwYbi7uwMUEox76623mD59Or6+vixcuFDfb3JxdO3aVe8fkZ2dzcSJEzly5AiOjo6cPXsW0Cqff//735Odnc3QoUMJDQ1l+/btREVF6d90s7Ky6NWr8N/S9evX8fX1LfFntXnz5gKutuTkZFJSUrhz5w7jx48nOjoaIQTZ2dmF7mly6ZQn586d49SpU3pzowEDBrBjx44CbrEVK1YUUo8F+O6774iMjNQNHthPnrvWGgUAlzwH6qem0zJPljgdVaWd1kx69erFzZs3SUhIKFHXL6PMtH2a0+cAACAASURBVKOjo+7TFkLQvXt3unfvzoABA3juuecKGYWMjAxeeeUVIiMjadq0KVOnTi0gGW2UnbYFa/NeunQpCQkJHDx4EGdnZ1q0aKHfx5p8NmgxBUsrE9N7Nr7fOXPm4Ofnx9GjR8nLy8PV1RXQXE87duxg/fr1jB07lrfeeov69eszYMAAli9fXuT7MUp0l+SzysvLY+/evYUkrF999VX69+/P6tWriYmJKdBEx0RJVwp+fn5cv36dRo0acf36dRo2bFjovNWrV9OzZ0/dPfbII48UiJUcPXqUnJycQqu0zZs3M2PGDLZv317g98xe8ty1WqzEIVfTl6/X3qOYkRqm7KKRX+1VEtg1lNOnT5Obm4uPjw99+/Zl5cqV5ObmkpCQwI4dO+jevbvNMtbXrl3j0KFD+rYpiAgFpbBND7UGDRqQmppaZDaRLfe2Nm+TtLWzszNbt27VM1n69u3L6tWrSU9PJyUlhR9++KHY92aNO3fu0KhRIxwcHPj222/JzdUk6S9dukTDhg15/vnn+cMf/sChQ4fo2bMnu3fv1uMUaWlp+srCSLt27fQxJfmsBg4cWKBTnemb/507d2jSRPu7NamhmmMe/DW+zA0CaKurb775BoBvvvnGYse1Zs2asX37dnJycsjOzmb79u0F3EeWZLgPHz7Miy++yNq1awsZGnvJc9fqlQJgk7yFKaD860UtIatHoDc9Ar15IrSJSjutARjbcUop+eabb3B0dGTYsGHs3buXkJAQhBDMmjULf39/fHx8cHJyIiQkhAkTJuiBaXOys7N58803uXbtGq6urvj6+urtNidMmMBLL72kB5qff/55OnXqRIsWLQq0ejRn1KhRPP/888ybN09/IL744ot6CmPTpk3Zs2ePxXmPGTOGxx9/nLCwMEJDQ2nbti2A3ic5NDSU5s2bW/2GbAuvvPIKTz31FBEREfTv31//5r5t2zY+/vhjnJ2d8fDwYMmSJfj6+rJ48WJGjx5NZqbWCnf69Om0adOmwDUfffRRvvrqK/74xz/i5eVl82c1b948/vSnPxEcHExOTg59+/Zl/vz5vP3224wfP57Zs2fzwAMPlPq9Gpk8eTIjRoxg4cKFNGvWjIiICAAiIyOZP38+CxYsYPjw4fzyyy906tQJIQSDBg3S3V4Aq1at0qW8Tbz11lukpqby9NNPA5phWbt2LaC50R599NFymb8Rq9LZVZXyks6e+e4yXM//RP2My4x/b1yR7iNT7YEpkKwMQfmhpLMVttCnTx/WrVuHl5dXZU+lytC3b1/WrFlj8UuJvaSzawcOTkUaBGPsQAWUFYrK4Z///CeXL19WRiGfhIQE/vznP1tdpZYFu8YUhBCDhBBnhBDnhBCTLRz/sxAiSghxTAixRQjR3J7zKSmqfaZCUTXo0aOHXvin0IrXzDu+lRd2MwpCCEfgX8AjQHtgtBDCPEJzGAiTUgYD3wOz7DUfIxFnI8hKPEGuvGV1jGqfqVAoaiP2XCl0B85JKS9IKbOAFUCBkLyUcquU0tTubB8QYMf56Gy4sOG3GgUr3dZMlcrKICgUitqEPWMKTYArhu1YoKhO3H8AfrR0QAjxAvACaNH38sARcBHetHTKKrDflGmkRO0UCkVtxJ4rBUvVMBZTnYQQzwJhwMeWjkspv5ZShkkpw4yVjaWl6R5PHDJvISXg6V/gmBK1UygUtRl7GoVYoKlhOwAoVJMthHgIeBcYIqXMtON8dDwvpQLgl5xDvcce0/ebMo1M0hVqlVA7MBdgA5g/fz5LliwBtIK20NBQOnfuzMGDB/niiy8KjD158iQPPPAAbdq0oXXr1vzf//2fXlWcmZnJQw89RGhoKCtXrmTnzp106NCB0NBQ0tPTC1wnPT2d3/3ud3rBV1Vk48aNBAUF0apVK4tKoACXL1+mf//+dO7cmeDgYD33/ueff6Zr16506tSJrl276hpTAIMGDSIkJIQOHTrw0ksv6Z/Bm2++WWCcogKQUtrlheaaugAEoqnNHQU6mI3pDJwHWtt63a5du8qycPTnH+UnIx6Vc0aOlTEPhRY4NmL+Htn8r+vk0n2XynQPhe1ERUVV9hRk3bp1izz+4YcfyilTpkgppbx48aLs0KGDfiwtLU22bNlS/vTTT1JKKe/evSsHDRokP//8cymllHv37pV9+/bVx7/44oty0aJFFu/z+eefy7lz59o877y8PJmbm2vz+LKSk5MjW7ZsKc+fPy8zMzNlcHCwPHnyZKFxzz//vPziiy+klFKePHlSNm/eXEop5aFDh+TVq1ellFIeP35cNm7cWD/nzp07UkrtPT355JNy+fLlUkopY2Ji5IABA+z5tmoklv6ugEhpwzPWbjEFKWWOEGIi8BOaC3+RlPKkEGJa/uTWormLPICIfO2Vy1LKIVYvWg6c2r0NABfHJlA3rtBxFUeoPOL+8Q8yT5WvdHaddm3xf+edEp83depUPDw8aN++PXPnzsXR0ZEdO3bg5+fH+fPnCQ0NZcCAAfx/e2ceVdWR9e1nAyqgtiEa0+QjiooTqOCsbZzaBKeIQ9IamkT5jCbSDokau82KJrG136TjGIKJr1OMxlcxJg7r/TQaEOPQqGhAglMwSju24gRiQATq++NcjgwXuSrzrWetu9Y959ap2nUvnH1qV9Vvt2jRgm7duuHv7w+Aq6srYWFh9OrViz/96U+8+uqrJCcn4+fnR0hICBs2bGDHjh1ERESwdu3afG2uXbvWzNNQlMx1UlIS/fv3p3fv3kRHR7N582ZOnTplVX66KInpR+XQoUN4eXnRuHFjwNhdvWXLlkKyDyJCamoqYEhKPPPMM4CRGyAXHx8fMjIyuHv3LjVq1DBFBrOyssjMzDTtbNiwIdevX+c///kPv/99/lCvpnQo1X0KSqltSqlmSqkmSql/WM69b3EIKKWeV0o9rZTys7xK1SHkklOjLjWcPAvNJ2g0BRkwYADjxo1j8uTJREVF8fHHH9OkSRPi4uKYO3cux44dKyRg1qRJE9LS0nB2dmb58uV0796duLg43nzzTQICApg7d24hh5CZmcmZM2fw9PQEwNnZmU2bNvHTTz8RFRXF1KlTzZDUqVOnGDlyJLGxsdSsWdOUn/7pp5/o0KEDCxYsAAyJ6ZiYGBISEkhPTzelvvOydu3afFm/cl/WBPAuXrzIs8/ejwh7eHhw8eLFQuU+/PBDvv76azw8PBgwYACfffZZoTLffvstbdu2zSfw1rdvX+rXr0/t2rXztd+uXbtSSSajsY7e0WxBq56WP4/yRF/eKKWKfPp+mKfya9eu5dutq5SyKnMNxtNzly5dADhw4ECR8tMPkpjOJSgoiKCgIJv7aksf161bR3BwMFOnTiU6OprXXnuNhIQEHByMZ9Bjx47xt7/9jZ07d+a7bseOHWRkZBAUFMSuXbt44YUXgNKTiNZYRzsFC7n7EvSKI83D4OPjUyh38JkzZ6hVqxa1a9e2uZ688tDwYJnrvPLQSimr8tPFSUznbWfu3MKL/ry8vAopkHp4eHD+/P1V5hcuXDBDQ3lZsWIF33//PWBIkWdkZHDt2jXq16/PhQsXGDp0KKtXr6ZJkyaFrnV2diYgIIAtW7aYTqG0JKI11rFr6eyC6PkETXEUlK4OCgpi3759REREAMYKokmTJpm5dG3Fzc2N7Oxs88ZdlMx1QYqSn7ZVYjooKMiqPLS18h07diQxMZGzZ8+SmZnJ+vXrCyXkAWMvUWRkJGAIs2VkZPDUU09x69YtBg4cyEcffZQvhWRaWhqXL18GjDmFbdu2mQquUHoS0Rrr2J1TuJJ8HcdsF5zvVi51WE3p8dtvv+Hh4WG+cmPy1qhbty7dunWjVatWTJs2DRcXF7Zs2cKcOXNo3rw5rVu3pmPHjkyYMOGh7fD392ffvn2AcbM+fPgwHTp0YO3atfluknnJKz/dpk0bunTpwsmTJ/NJTA8ZMuSBEtO24uTkRFhYGH379qVly5YMHz4cHx8fAN5//31T0nn+/PksW7YMX19fAgMDWbVqFSJCWFgYp0+fZvbs2ebcxdWrV7lz5w4BAQG0adMGX19f6tevz7hx4wBDfvz06dNm2lJN6WN30tlzR43GMas6bS5l0X6cP24jhgOGPDaglVDLGC2dfZ/Y2FgWLFhgNR2jvZI72T579uzyNqVS8TjS2XY3UgBwyE6nqdMR0yFoNBWBtm3b0rt37wq9ea2sycrKYurUqeVthl2hJ5o1mgrE6NGjy9uECkVuxjFN2WFXI4X4iO9xyLia71xu3uXjl1PLySqNRqOpONiVU8i3m9mCFsDTaDSa+9hd+CjHuT41MBK86VSbGo1Gkx+7GinkJTM7R6fa1Gg0mgLYrVO4l50D6MxqGnB0dMTPz49WrVoxaNAgbt269ch19erVi8dZMl0cVV1eu6AWk4ODA3FxcfmuDQgIyLeZTctrlyx26BRywLI3Q+9g1oAhMREXF0dCQgJPPvkkixcvLm+TimTlypUMGzYMR0dHm8orpcjJySllq+6TnZ3N+PHj2b59O8ePH2fdunUcP368ULk5c+YwfPhwYmNjWb9+PX/5y1+A/Dus16xZg6enJ35+fuZ13333XaH8FxMnTizS+WgeHruaU0j+LZlsi0NIcXiimNKasmbvhl+4dj6tROus92wtug9vZnP5rl27Eh8fbx7PnTuXDRs2cPfuXYYOHcqsWbNISkqiX79+dO7cmdjYWJo1a8bq1atxdXXNV1dISAgxMTGkp6fz8ssvM2vWLABiYmJ46623uHPnDjVq1CAyMhJXV1emT5/O7t27uXv3LuPHj+fNN98sZF9Vl9fOy7p16wgMDDSP09LSWLBgAUuXLmX48Pt7jLS8dsliVyOF27fSqZ7tQjVx4JZj3fI2R1PByM7OJjIy0tTz2blzJ4mJiRw6dIi4uDiOHDliit+dOnWKN954g/j4eH73u98VysYG8I9//IPDhw8THx/Pjz/+SHx8PJmZmYwYMYJPP/2Uo0ePEhERgYuLCytWrKBOnTrExMQQExPDsmXLOHv2bL767E1eOzw8PJ9TmDlzJlOnTi3kfEHLa5ckdjVScMpwBsDzdix3ytkWTWEe5om+JElPT8fPz4+kpCTat29vqnPu3LmTnTt3mslh0tLSSExMpEGDBjz77LOmqNurr75KaGgo77zzTr56N2zYwNKlS8nKyuLy5cscP34cEcHd3d3UIspNLrNz507i4+NNIbqUlBQSExNp1KiRWZ89yWsfPHgQV1dXc+4gLi6O06dPs3DhQpKSkgrVp+W1Sw67cgqO2QqH7HSe/vUwZ55qWt7maCoIuXMKKSkpvPjiiyxevJhJkyahlOLdd98tFMZJSkoqdKMreHz27FnmzZtHTEwMbm5uBAcHk5GRUWT+BaUUn332GX379n2gnfYgrw2wfv36fKOE6Ohojhw5gqenJ1lZWVy9epVevXqxe/dusy9aXrtksKvwkUN2Dg5K4VDXia31Wpe3OZoKRp06dQgNDWXevHncu3ePvn37snLlStLSjHmOixcvcvWqsSP+3LlzREcbIorr1q3jueeey1dXamoqNWvWpE6dOly5coXt27cD0KJFCy5dukRMTAwAt2/fJisri759+/LFF19w7949wJCLvnMn/3jWHuS1AXJycvjmm2945ZVXzPIhISFcunSJpKQk9u3bR7NmzUyHkPt9aXntksGuRgoAOSJkPl+b7ald+C+9P0FTgLZt2+Lr68v69et57bXXOHHihBlqqVWrFl9//TWOjo60bNmSr776ijfffJOmTZsSEhKSrx5fX1/atm2Lj48PjRs3NkM31atXJzw8nIkTJ5Keno6LiwsRERGMGTOGpKQk2rVrh1KKp556is2bNxeyL1de+/nnnycoKIhBgwbRoUMH/Pz8bJLXvnv3LmCs/mnWrJkpr+3p6Vni8trZ2dmMHj06n7x2hw4dCAgIYP78+YwdO5aFCxciIqa8NsCePXvw8PAwJ6uLQ8trlyx2JZ29KHAUKMULbc7w97pz9S7mCkBllM5OSkrixRdfJCEhoczb1vLahdHy2oXR0tm2YvF/+116l68dGs0jouW1C6PltUsWuwsfgRDpOqC8jdBUYjw9PctllJCLltfOj5bXLlnsa6Sg0Wg0mgdil07h4Nkb5W2CRqPRVEjsxikc23uRHMf765i1MqpGo9EUxm6cwi+HjJ2ejtm3tRCeRqPRFIHdOAUAh+x0nLJTytsMTQUjVzrb19eXdu3a8a9//euB5ZOSkkxROoBVq1YxYcIEq2U9PT1p3bo1bdq0oWfPnkVuMCt4zbVr1x6uEyVAUe0qpfjjH/9oCthVRI4cOULr1q3x8vIyd6MXJCUlhUGDBuHr64uPjw9ffvml+dm5c+fw9/enZcuWeHt7m1IakZGRtGvXDj8/P5577jlzA2BYWFi+66sSduUUNBpr5MpcHD16lI8++oh33333geULOoXiiIqKIj4+nl69ejFnzpzHNbfM2bZtG76+vqZOky2U9ZLZkJAQli5dSmJiIomJiaaERl4WL16Mt7c3R48eZffu3UydOpXMzEwARo4cybRp0zhx4gSHDh0y5TZCQkJYu3YtcXFx/PnPfzZ/v9GjRxMaGlp2HSxD7HBJqqaiErVqKVf/faZE66zfsDG9g9+wuXxqaipubm6A8YT817/+le3btyMizJgxgxEjRjB9+nROnDiBn58fo0aNws3NjUuXLtGvXz9+/fVXhg4dyieffFKo7q5du+a7kXz99deEhoaSmZlJ586d+fzzzwvlSSiqTFGy3NOnT2fr1q04OTnh7+/PvHnzSE5OZty4cZw7dw6ARYsW0a1bN65fv05gYCDJycl06tTJ6tM1GNpHb7xx/zscMmQI58+fJyMjg7feesv8rFatWkyZMoUdO3Ywf/58XFxcmDJlCmlpadSrV49Vq1bh7u7OsmXLWLp0KZmZmXh5ebFmzRqryqe2cvnyZVJTU82d5yNHjmTz5s30798/XzkR4fbt2yilSEtL48knn8TJyYnjx4+TlZVlCiHmzddQlMS3q6srnp6eHDp0iE6dOj2y7RUR+xkp3P4P5u41jSYPuSqpLVq0YMyYMcycORMwErrkjiAiIiKYNm0aly9f5uOPP6Z79+7ExcUxefJkwFDxDA8P5+effyY8PDyfKFwu33//PUOGDAGMHafh4eHs37+fuLg4HB0dWbt2bb7yDypjTZb7xo0bbNq0iWPHjhEfH8+MGTMAeOutt5g8eTIxMTF8++23jBkzBoBZs2bx3HPPERsbS0BAgOk0CrJ//37at29vHq9cuZIjR45w+PBhQkNDuX79OgB37tyhVatWHDx4kM6dOzNx4kQ2btzIkSNHGD16NO+99x4Aw4YNIyYmhqNHj9KyZUtWrFhRqM2oqCirct1/+MMfCpW9ePEiHh4e5nFRct0TJkzgxIkTPPPMM7Ru3ZpPP/0UBwcHfvnlF5544gmGDRtG27ZtmTZtmjnSWb58OQMGDMDDw4M1a9Ywffp0s74OHTqwd+9eq99ZZcZuRgpZVy7joCAH0SuPKigP80RfkuSGj8BQ4xw5ciQJCQns27ePwMBAHB0defrpp+nZsycxMTFWwyh9+vShTp06AHh7e/Pvf//bzCvQu3dvrly5Qv369c3wQ2RkJEeOHDH1htLT082QRS4PKmNNltvb2xtnZ2fGjBnDwIEDefHFFwGIiIjIl/0sNTWV27dvs2fPHr777jsABg4caI6QCnLjxg1q165tHoeGhrJp0yYAzp8/T2JiInXr1sXR0ZGXXnoJMPI5JCQkmE/f2dnZuLu7A5CQkMCMGTO4desWaWlpVpVhe/fuXSgNZ1HYKte9Y8cO/Pz82LVrF7/++isvvPAC3bt3Jysri7179xIbG0uDBg0YMWIEq1at4vXXX2fhwoVs27aNzp07M3fuXKZMmcLy5csBQ6775MmTNtlYmShVpyAi/YBPAUdguVLq4wKf1wBWA+2B68AIpVRSadiS9Zvh+VNdqzFerzzSFEHXrl25du0aycnJRYZTrFGjRg3zvaOjI1lZWeZxVFQUNWvWJDg4mPfff58FCxaglGLUqFF89NFHRdZZVJmiZLmdnJw4dOgQkZGRrF+/nrCwMHbt2kVOTg7R0dFWpaVtybLm5ORETk4ODg4O7N69m4iICKKjo3F1daVXr16m2qqzs7MZ/lJK4ePjYyrJ5iU4OJjNmzfj6+vLqlWr8qmd5v3OckdheXF1dS20EMDDw4MLFy6Yx0XJdX/55ZdMnz4dEcHLy4tGjRpx8uRJPDw8aNu2rSnAN2TIEA4cOEBAQABHjx6lc+fOAIwYMYJ+/fqZ9VVVue5SCx+JiCOwGOgPeAOBIuJdoNjrwE2llBewEPhnadmTlpXEPW5wq5bdDI40j8DJkyfJzs6mbt269OjRg/DwcLKzs0lOTmbPnj106tSJ2rVrc/v27Yeq18XFhUWLFrF69Wpu3LhBnz592LhxoynFfePGjUIrk4oqU5Qsd1paGikpKQwYMIBFixaZT9r+/v6EhYWZ9eae79GjhxmO2r59Ozdv3rRqe/PmzTlzxpjrSUlJwc3NDVdXV06ePMmBAweKvCY5Odl0Cvfu3ePYsWOAIRfu7u7OvXv3CoXMcskdKRR8WVsZ5u7uTu3atTlw4ABKKVavXs3gwYMLlcsr133lyhVOnTpF48aN6dixIzdv3iQ5ORmAXbt24e3tjZubGykpKfzyyy8A/PDDD/lE5qqqXHdp3iE7AaeVUmcARGQ9MBjIm8V7MPCh5f1GIExERJWCdOsdZcQYb3jWKKakxt7InVMA4wn3q6++wtHRkaFDhxIdHY2vry8iwieffMLvf/976tati5OTE76+vgQHBxcZdimIu7s7gYGBLF68mJkzZzJnzhz8/f3JycmhWrVqLF68mIYNG5rlvb29rZbp0qWLVVnu27dvM3jwYDOZz8KFCwEj3DN+/HjatGlDVlYWPXr0YMmSJXzwwQcEBgbSrl07evbsSYMG1kfQAwcOZPfu3Xh5edGvXz+WLFlCmzZtaN68uZndrSDVq1dn48aNTJo0iZSUFLKysnj77bfx8fFh9uzZdO7cmYYNG9K6deuHdrDW+OKLLwgODiY9PZ3+/fubk8xLliwBYNy4ccycOZPg4GBat26NUop//vOf1KtXD4B58+bRp08flFK0b9+esWPH4uTkxLJly3jppZdwcHDAzc2NlStXmm3u37+fDz744LFtr2iUmnS2iLwM9FNKjbEcvwZ0VkpNyFMmwVLmguX4V0uZawXqegN4A6BBgwbtbVnrXZD5b0/lbnYGTSf24k/NtIBWRaEySmfbG5cvX2bkyJH88MMP5W1KhaGiS5g/jnR2aY4UrAUrC3ogW8qglFoKLAUjn8KjGDN10fxHuUyjsXvc3d0ZO3YsqampD7VXoSpz7dq1Kpu/oTSdwgXg2TzHHkDBzNq5ZS6IiBNQB9BqdRpNBWP48OHlbUKFIndVVVWkNPcpxABNRaSRiFQHXgG2FiizFRhlef8ysKs05hM0FRv9k2s0Jcfj/j+VmlNQSmUBE4AdwAlgg1LqmIj8XURyM3mvAOqKyGlgCjDdem2aqoqzszPXr1/XjkGjKQGUUly/fh1nZ+dHrsOucjRrKh737t3jwoUL5lp3jUbzeDg7O+Ph4UG1atXyna8IE80aTbFUq1aNRo0albcZGo3Ggv1oH2k0Go2mWLRT0Gg0Go2JdgoajUajMal0E80ikgw8/JZmg3pA2ae0Kl90n+0D3Wf74HH63FAp9VRxhSqdU3gcROSwLbPvVQndZ/tA99k+KIs+6/CRRqPRaEy0U9BoNBqNib05haXlbUA5oPtsH+g+2wel3me7mlPQaDQazYOxt5GCRqPRaB6AdgoajUajMamSTkFE+onIKRE5LSKFlFdFpIaIhFs+PyginmVvZcliQ5+niMhxEYkXkUgRaWitnspEcX3OU+5lEVEiUumXL9rSZxEZbvmtj4nI/5S1jSWNDX/bDUQkSkRiLX/fA8rDzpJCRFaKyFVLZkprn4uIhFq+j3gRaVeiBiilqtQLcAR+BRoD1YGjgHeBMn8BlljevwKEl7fdZdDn3oCr5X2IPfTZUq42sAc4AHQob7vL4HduCsQCbpbj+uVtdxn0eSkQYnnvDSSVt92P2eceQDsgoYjPBwDbMTJXdgEOlmT7VXGk0Ak4rZQ6o5TKBNYDgwuUGQx8ZXm/EegjItZSg1YWiu2zUipKKfWb5fAARia8yowtvzPAbOAToCpoc9vS57HAYqXUTQCl1NUytrGksaXPCsjNE1qHwhkeKxVKqT08OAPlYGC1MjgAPCEi7iXVflV0Cv8HOJ/n+ILlnNUyykgGlALULRPrSgdb+pyX1zGeNCozxfZZRNoCzyql/rcsDStFbPmdmwHNRGS/iBwQkX5lZl3pYEufPwReFZELwDZgYtmYVm487P/7Q1EV8ylYe+IvuO7WljKVCZv7IyKvAh2AnqVqUenzwD6LiAOwEAguK4PKAFt+ZyeMEFIvjNHgXhFppZS6Vcq2lRa29DkQWKWUmi8iXYE1lj7nlL555UKp3r+q4kjhAvBsnmMPCg8nzTIi4oQx5HzQcK2iY0ufEZHngfeAAKXU3TKyrbQors+1gVbAbhFJwoi9bq3kk822/m1vUUrdU0qdBU5hOInKii19fh3YAKCUigacMYTjqio2/b8/KlXRKcQATUWkkYhUx5hI3lqgzFZglOX9y8AuZZnBqaQU22dLKOW/MRxCZY8zQzF9VkqlKKXqKaU8lVKeGPMoAUqpypzL1Za/7c0YiwoQkXoY4aQzZWplyWJLn88BfQBEpCWGU0guUyvLlq3ASMsqpC5AilLqcklVXuXCR0qpLBGZAOzAWLmwUil1TET+DhxWSm0FVmAMMU9jjBBeKT+LHx8b+zwXqAV8Y5lTP6eUCig3ox8TNXeDZQAABD1JREFUG/tcpbCxzzsAfxE5DmQD05RS18vP6sfDxj5PBZaJyGSMMEpwZX7IE5F1GOG/epZ5kg+AagBKqSUY8yYDgNPAb8D/LdH2K/F3p9FoNJoSpiqGjzQajUbziGinoNFoNBoT7RQ0Go1GY6Kdgkaj0WhMtFPQaDQajYl2CpoKh4hki0hcnpfnA8p6FqUm+ZBt7rYocR61SEQ0f4Q6xonISMv7YBF5Js9ny0XEu4TtjBERPxuueVtEXB+3bY19oJ2CpiKSrpTyy/NKKqN2g5RSvhhiiXMf9mKl1BKl1GrLYTDwTJ7PxiiljpeIlfft/Bzb7Hwb0E5BYxPaKWgqBZYRwV4R+cny+oOVMj4icsgyuogXkaaW86/mOf/fIuJYTHN7AC/LtX0sOv0/W3Tua1jOfyz381PMs5z7UETeEZGXMfSl1lradLE84XcQkRAR+SSPzcEi8tkj2hlNHiE0EflCRA6LkUdhluXcJAznFCUiUZZz/iISbfkevxGRWsW0o7EjtFPQVERc8oSONlnOXQVeUEq1A0YAoVauGwd8qpTyw7gpX7DIHowAulnOZwNBxbQ/CPhZRJyBVcAIpVRrDAWAEBF5EhgK+Cil2gBz8l6slNoIHMZ4ovdTSqXn+XgjMCzP8Qgg/BHt7Icha5HLe0qpDkAboKeItFFKhWLo4vRWSvW2SF/MAJ63fJeHgSnFtKOxI6qczIWmSpBuuTHmpRoQZomhZ2No+hQkGnhPRDyA75RSiSLSB2gPxFjkPVwwHIw11opIOpCEIb/cHDirlPrF8vlXwHggDCM/w3IR+X+AzdLcSqlkETlj0axJtLSx31Lvw9hZE0P2IW/WreEi8gbG/7U7RsKZ+ALXdrGc329ppzrG96bRANopaCoPk4ErgC/GCLdQ0hyl1P+IyEFgILBDRMZgyAx/pZR614Y2gvIK5omI1RwbFj2eThgibK8AE4A/PkRfwoHhwElgk1JKiXGHttlOjAxkHwOLgWEi0gh4B+iolLopIqswhOEKIsAPSqnAh7BXY0fo8JGmslAHuGzRyH8N4yk5HyLSGDhjCZlsxQijRAIvi0h9S5knxfb81CcBTxHxshy/BvxoicHXUUptw5jEtbYC6DaGfLc1vgOGYOQBCLeceyg7lVL3MMJAXSyhp98Bd4AUEXka6F+ELQeAbrl9EhFXEbE26tLYKdopaCoLnwOjROQARujojpUyI4AEEYkDWmCkLDyOcfPcKSLxwA8YoZViUUplYChQfiMiPwM5wBKMG+z/Wur7EWMUU5BVwJLcieYC9d4EjgMNlVKHLOce2k7LXMV84B2l1FGM3MzHgJUYIalclgLbRSRKKZWMsTJqnaWdAxjflUYDaJVUjUaj0eRBjxQ0Go1GY6Kdgkaj0WhMtFPQaDQajYl2ChqNRqMx0U5Bo9FoNCbaKWg0Go3GRDsFjUaj0Zj8f9ItjGswC+vgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "multiple_metric_auc_score(prediction_total, test_data_total, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
